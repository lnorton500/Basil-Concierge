[
  {
    "_name": "Janson",
    "event":
    [
      {
        "_id": "9025",
        "start": "09:30",
        "duration": "00:25",
        "room": "Janson",
        "slug": "keynotes_welcome",
        "title": "Welcome to FOSDEM 2020",
        "subtitle": [],
        "track": "Keynotes",
        "type": "keynote",
        "language": [],
        "abstract": "<p>FOSDEM welcome and opening talk.<\/p>",
        "description": "<p>Welcome to FOSDEM 2020!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6",
            "value": "FOSDEM Staff"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9025.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9249",
        "start": "11:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "libreoffice_turns_ten",
        "title": "LibreOffice turns ten and what's next",
        "subtitle": "Lots to learn, and get excited about",
        "track": "History",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>From ten years of LibreOffice, how can you apply what we\nlearned to your project ? What is going on in LibreOffice today, and\nwhere is it going ? and How can you re-use or contribute to the story.<\/p>",
        "description": "<p>Come hear about the story of LibreOffice, the reasons we\nstarted - and some of the highlights: successes, failures and other\nlessons learned from our first ten years. Hear how our initial\ndecisions and vision of open-ness and vendor neutrality panned\nout. See what has been learned about building an effective commercial\necosystem, with certification.<\/p>\n\n<pre><code>Hear about the trajectory of technical updates and how we\n<\/code><\/pre>\n\n<p>re-juvenated an open-source code-base through massive re-factoring, as\nwell as re-targetting for web and mobile.<\/p>\n\n<pre><code>Catch up with the latest in Online innovation, optimization\n<\/code><\/pre>\n\n<p>and scalability work as well as our growing integration with lots of\nother Open Source projects.<\/p>\n\n<pre><code>Finally catch up with the latest and greatest feature/function\n<\/code><\/pre>\n\n<p>improvements as we move towards LibreOffice 7, and find out how you\ncan best get involved with the next decade of the LibreOffice story.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "425",
            "value": "Michael Meeks"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9249.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9045",
        "start": "12:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "automation",
        "title": "Over Twenty Years Of Automation",
        "subtitle": [],
        "track": "History",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Over the past twenty years, the automation landscape has changed dramatically.\nAs our hunger for complex technical infrastructure increased, and our inability to keep up with these demands faltered, we've outsourced a lot of the work to third-parties and cloud providers.\nWe'll step backwards and show where we came from, and where we're going.\nIf we don't understand this future, and step up to the challenge, then we eventually won't control our own computers anymore.\nWe'll discuss this timeline from a tools perspective and showcase many live demos of the past, present, and what will be possible in the future.\nThis presentation will contain many demos and interactive examples. I will showcase some modern ideas I have with my Free Software project called mgmtconfig.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2026",
            "value": "James Shubin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9045.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9314",
        "start": "13:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "blender",
        "title": "Blender, Coming of Age",
        "subtitle": "18 years of Blender open source projects",
        "track": "History",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>The presentation is going to be audiovisual and entertaining; based on a number of short videos I want to tell the story of Blender. Starting in late 90s, how Blender became open source, going over the big milestones for Blender, end ending with the fast growth of our project and the interest of the film and game industry. Blender now is a more mature project now, which involves a different dynamics than it used to be. How are we going to tackle the challenges of the industry, while not losing the community that brought us this far?<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6621",
            "value": "Ton Roosendaal"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9314.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9066",
        "start": "15:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "generation_gaps",
        "title": "Generation gaps",
        "subtitle": [],
        "track": "History",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>For as long as computers have been around, roughly every 10-15 years, the whole industry underwent a reset and reinvented itself anew… until the early 1990s, when somehow, the industry skipped a generation. Instead, it looked backwards, and adopted an older model of computing. The cost has been very high and is holding back the development of the entire field.<\/p>",
        "description": "<p>This talk looks at how we turned to the past instead of the future, what we missed out on as a result, and how to move forward. It follows on from the above proposal, but takes a different tack and should stand alone. It looks at where personal computers might have – but didn’t – go in the 1980s and 1990s. At a sampling of advanced OS technologies that never caught on – Plan 9, Inferno, Taos, Oberon – and the cool stuff we lost out on as a result.<\/p>\n\n<p>It will end with trying to identify the next such generation gap, and why we should consider starting afresh rather than adapting current tech for the next gen.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4843",
            "value": "Liam Proven"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9066.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9008",
        "start": "16:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "http3",
        "title": "HTTP/3 for everyone",
        "subtitle": "The next generation HTTP is coming",
        "track": "Internet",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>HTTP/3 is designed to improve in areas where HTTP/2 still has some shortcomings, primarily by changing the transport layer. HTTP/3 is the first major protocol to step away from TCP and instead it uses QUIC.<\/p>",
        "description": "<p>HTTP/3 is the designated name for the coming next version of the protocol that is currently under development within the QUIC working group in the IETF.<\/p>\n\n<p>HTTP/3 is designed to improve in areas where HTTP/2 still has some shortcomings, primarily by changing the transport layer. HTTP/3 is the first major protocol to step away from TCP and instead it uses QUIC.<\/p>\n\n<p>Daniel Stenberg does a presentation about HTTP/3 and QUIC. Why the new protocols are deemed necessary, how they work, how they change how things are sent over the network and what some of the coming deployment challenges will be.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "362",
            "value": "Daniel Stenberg"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9008.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9189",
        "start": "17:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "tor",
        "title": "State of the Onion",
        "subtitle": "The Road to Mainstream Adoption and Improved Censorship Circumvention",
        "track": "Internet",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>The Tor Project is building usable free software to fight surveillance and censorship across the globe. In this talk we'll give an update on what we got up to during 2019, what happened in the wider Tor ecosystem, and what lies ahead of us.<\/p>",
        "description": "<p>During the past year the Tor Project has been working hard on improving the software, building and training communities around the world as well as creating an anti-censorship team and roadmap that can push forward technologies to circumvent censorship.<\/p>\n\n<p>This talk will cover major milestones we achieved and will give an outline about what is lying ahead. In particular, we'll talk about our work to scale the network so it can cope with increased demand as we move forward with our plans for mainstream adoption of Tor Browser and the Tor network.<\/p>\n\n<p>We will also share updates about our anti-censorship efforts, a year on from the formation of a dedicated Anti-Censorship team, and their work on next generation pluggable transports. Moreover, we'll explain our defense against website traffic fingerprinting attacks and plans for improving onion services and making them more usable (DDoS resistance, better user interfaces for authentication and dealing with errors).<\/p>\n\n<p>Finally, we'll shed some light onefforts to get Tor support directly embedded into other browsers, like Firefox and Brave, and educating users both by reorganizing the content on our website, creating dedicated community and developer portals and extensive trainings throughout the world.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6431",
            "value": "Pili"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9189.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9171",
        "start": "18:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "scion",
        "title": "SCION",
        "subtitle": "Future internet that you can use today",
        "track": "Internet",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Do you know where your internet traffic flows? Does it go through China even if you don't want it to? SCION is a new internet architecture aimed at solving this problem. We will show how you can easily join the already existing worldwide network.<\/p>",
        "description": "<p>The current Internet was not designed with control and security considerations in mind: incidents such as the hijacking of all traffic for YouTube by a Pakistani ISP in February 2008, the Cloudflare DNS service hijacked by AnchNet in May 2018, or a large chunk of European mobile traffic being rerouted through China in June 2019 show that we cannot quite trust the current Internet. SCION is a proposed future Internet architecture aiming to offer high availability and security, even in the presence of actively malicious network operators and devices.<\/p>\n\n<p>Designing a new Internet from scratch gives us the opportunity to make it work a lot better: we are aiming to notably improve security, availability, and performance. At the same time, just replacing the Internet would not be feasible, and thus we also emphasise practical concerns, such as incremental deployment and backwards compatibility. Thanks to that, SCION is currently the only clean-slate Internet architecture with a world-wide research network and production deployments in several large institutions in Switzerland; and you can start using it today.<\/p>\n\n<p>In the first part of this talk, we will drive you through the current state of SCION design and implementation, showing how it provides its important features:<\/p>\n\n<ul>\n<li>path awareness and path control by end hosts<\/li>\n<li>geofencing and isolation from untrusted actors<\/li>\n<li>scalability<\/li>\n<li>backward compatibility with existing infrastructure and protocols<\/li>\n<li>increased performance by active usage of multiple links<\/li>\n<li>fast rerouting in case of outages in any segment of the network<\/li>\n<\/ul>\n\n\n<p>The world-wide test deployment, SCIONLab, consists of around 50 different points-of-presence around the globe, many of them connected via direct, BGP-free, links. Having many independent organizations belonging to a continually evolving network introduces some non-trivial challenges of managing what you don’t own, which we will also talk about.<\/p>\n\n<p>We will show a live demo presenting how easy it is today for the end user to join the network and start using the available services. We will also present how taking down a part of the network can look from the user perspective and how SCION prevents a scenario of China or Pakistan hijacking traffic.<\/p>\n\n<p>To close the talk, we will very briefly present the future plans and the direction in which we want the project to evolve.<\/p>",
        "persons":
        [
          {
            "_id": "6396",
            "value": "Mateusz Kowalski"
          },
          {
            "_id": "7425",
            "value": "Kamila Součková"
          }
        ],
        "links":
        [
          {
            "_href": "https://www.scion-architecture.net",
            "value": "SCION Internet Architecture"
          },
          {
            "_href": "https://www.scionlab.org",
            "value": "SCIONLab global research network"
          },
          {
            "_href": "https://github.com/scionproto/scion",
            "value": "SCION implementation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9171.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.1.105 (La Fontaine)",
    "event":
    [
      {
        "_id": "9265",
        "start": "11:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "selfish_contributor",
        "title": "The Selfish Contributor Explained",
        "subtitle": [],
        "track": "Community and Ethics",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>It has become very popular in the last several years to think of free and open source as a community forward activity, indeed the modern approach is to try and form a community or foundation first and do code second.  There is also much talk about maintainer burn out and community exploitation.  However, the same people who talk about this still paraphrase the most famous quote from the Cathedral and the Bazaar \"Scratching your own itch\".  They forget this is your own itch not everyone else's because Open Source begins as a selfish activity.  The fact that communities do form around a load of selfish competing individuals is actually a testament to the unacknowledged power of open source to co-opt the selfish instinct and make it synergistic to some communal good.<\/p>\n\n<p>This talk will explore the selfish origins of free and open source and dissect the co-option power it has to form broad and deep communities from what are apparently simple transactional engagements.  We'll also explain how some of the more recent community failures have been engendered by the concentration on long term community to the detriment of enabling purely transactional mechanics by which initially selfish contributors come to the project.<\/p>",
        "description": "<p>The origins of selfish contributions, while called out in the founding canons of the open source and free software movements, were initially not very well recognized until the first open source projects (and here the author will use the example he's familiar with: the Linux Kernel) tried to engage successfully with companies trying to utilize the projects for their own ends.  We became adept at explaining why forking is bad and how your cost structure will rise exponentially if you do it and how the cheapest method of achieving your business goals is in fact to work with the existing community on whatever feature the company was trying to add as part of its business plan.  In fact, those of use who did company engagement because transactional sales people offering a corporation the achievements of business goals in exchange for some unexpected community engagement.<\/p>\n\n<p>Nowadays, all companies have drunk the open source coolaid and all pledge their loyalty to further the interests of the community and this previous learning is all but forgotten in the third and fourth waves of open source.  However, at their hearts, corporations are still the same business goal focussed transactional entities we had to deal with in the early days of open source and an understanding of how to co-opt their transactional nature would go a long way to assisting new open source developers in their quest to form communities.<\/p>\n\n<p>This talk will begin with some history of the Linux kernel's corporate engagement, explore and explain some of the processes within open source development that lead to the conversion of transactionalism into long term community synergy (the truly astounding ability of open source to co-opt selfishness) and then give a few examples of how serving the community rather than enabling transactionalism can give rise to burn out and apparent exploitation.  In conclusion we'll give some simple rules to enable this co-opting and suggest how some of the competing interests of the ethical source and social justice movements might likewise be co-opted.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3124",
            "value": "James Bottomley"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9265.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9271",
        "start": "12:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "iot_ethics",
        "title": "The Ethics Behind Your IoT",
        "subtitle": [],
        "track": "Community and Ethics",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Internet of Things (IoT) devices are part of the future we were promised. Armed with our mobile devices, we can control everything from our cars to our toasters to the doors of our homes. Along with convenience, IoT devices bring us ethical quandaries, as designers and users. We need to consider the ethical implicates of the technologies we are building and ask ourselves not just about the ways they are being used, for both good and evil, but the potential use cases we might encounter in the future.<\/p>",
        "description": "<p>IoT devices are becoming increasingly prevalent in our lives -- even my water filter is wifi enabled. In this session, we'll be looking at two case studies of how one might interact with IoT devices, and then consider the ethical implications of these devices, focused on the social impacts they can have on an individual or a society. While we will focus on smart doorbells and smart locks and situations in which installing these could significantly impact quality of life, we will touch on other common IoT devices.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4180",
            "value": "Molly de Blanc"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9271.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9163",
        "start": "13:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "ethical_ai",
        "title": "Freedom and AI: Can Free Software include ethical AI systems?",
        "subtitle": "Exploring the intersection of Free software and AI",
        "track": "Community and Ethics",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Despite the number of working groups, advisory committees, and coordination roundtables, there is little progress towards creating more ethical and safe AI systems. AI systems are deployed in increasingly fragile contexts. From law enforcement to humanitarian aid, several organizations use AI powered systems to make or inform critical decisions with increasingly outsized side effects.<\/p>\n\n<p>What is a rights-based approach for designing minimally safe and transparent guidelines for AI systems? In this talk, we explore what a Free AI system might look like. Then, taking research and guidelines from organizations such as Google and the UN Office for the Coordination of Humanitarian Affairs, we propose practical policies and tools to ensure those building an AI system respect user freedom. Lastly, we propose the outlines of a new kind of framework where all derivative works also respect those freedoms.<\/p>",
        "description": "<p>Rights based approaches are commonly used within humanitarian contexts to approach problems that the sector faces. In this talk, we use the same approach to solving the issue of “unethical” AI systems. We do so by first defining a set of rights that we feel must be respected, proposing a number of methods that we feel helps ensure a system respects those rights, and lastly propose an organizational and regulatory framework that we feel could help encourage and enforce those methods be used by developers of AI systems.<\/p>",
        "persons":
        [
          {
            "_id": "3816",
            "value": "Justin W. Flory"
          },
          {
            "_id": "6380",
            "value": "Michael Nolan"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9163.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9599",
        "start": "14:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "riek_kubernetes",
        "title": "How Containers and Kubernetes re-defined the GNU/Linux Operating System",
        "subtitle": "A Greybeard's Worst Nightmare",
        "track": "Containers and Security",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Free Software (as in Freedom) had won. The vertically integrated Cloud now is the predominant operational paradigm and is threatening to undermine software freedom. To many all seems lost, but the world keeps changing and decentralized compute is making a comeback. Containers and Kubernetes are already having a deep impact on the Linux operating system (OS) that goes well beyond DevOps and cloud-native applications. The concepts of application-centric packaging, process isolation through Linux containers, and immutable infrastructure are shaking up the core traditions of today's GNU/Linux operating systems. These concepts are also challenging the assumptions and approaches derived from the past 40+ years of work that originated with UNIX. The Linux distribution as we know it is coming to an end, and is being replaced by a new concept of containerized, multi-instance, multi-user applications, which can be deployed in scale-out environments as well as for widely distributed compute scenarios. In this session, we'll assess this new OS environment in the times of '5G' de-centralized cloud and take a deep look at the consequences this new OS model has for both developers and admins.<\/p>",
        "description": "<p>This talk will draw on the history of compute in general and Free and Open Source in specific to explain an evolution of paradigms from the GNU/Linux Distribution to modern Free Software application plattforms build on Kubernetes and how they can shape the future of compute in the face of major technological changes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6840",
            "value": "Daniel Riek"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=JEVZKmPG-5s",
            "value": "Recording of a previous iteration of the talk."
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9599.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9116",
        "start": "15:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "kubernetes",
        "title": "Fixing the Kubernetes clusterfuck",
        "subtitle": "Understanding security from the kernel up",
        "track": "Containers and Security",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Kubernetes is complex, and extremely vulnerable. In 2019 we explored the complexity of the Kubernetes codebase, and the antipatterns therein. This year we want to look at understanding how we observe our cluster at runtime. Let's live code some C and C++ and explore the libraries that bring Wireshark, Falco, and Sysdig to life. We concretely demonstrate how we are able to audit a Kubernetes system, by taking advantage of auditing the kernel's syscall information while enriching this data with meta information from Kubernetes.<\/p>",
        "description": "<p>We start off by presenting the problem of Kubernetes security at runtime. We discuss concerns with namespace and privilege escalation in a Kubernetes environment. We discover how auditing the kernel gives us visibility into both the container layer, as well as the underlying system layer.<\/p>\n\n<p>We look at building an eBPF probe, or kernel module to begin auditing syscall metrics. We discover how we are able to pull those out of the kernel into userspace, and start exploring powerful patterns for using these metrics to secure a Kubernetes cluster.<\/p>\n\n<p>The audience walks away understanding how the kernel treats containers, and how we are able to easily make sense of them. The audience also walks away equipped with an OSS toolkit for understanding, observing, and securing a Kubernetes environment.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6137",
            "value": "Kris Nova"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9116.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9564",
        "start": "16:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "kernel_address_space_isolation",
        "title": "Address Space Isolation in the Linux Kernel",
        "subtitle": [],
        "track": "Containers and Security",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Security is a big problem especially in the cloud of container workloads. This presentation investigates improving security in the Linux kernel itself. The first target is securing sensitive application data, for instance, private keys.<\/p>",
        "description": "<p>Address space isolation has been used to protect the kernel and userspace programs from each other since the invention of the virtual memory.<\/p>\n\n<p>Assuming that kernel bugs and therefore exploits are inevitable it might be worth isolating parts of the kernel to minimize damage that these exploits can cause. Moreover, restricted mappings in the kernel mode may improve mitigation of hardware speculation vulnerabilities.<\/p>\n\n<p>There are several ongoing efforts to use restricted address spaces in Linux kernel for various use cases:\n* speculation vulnerabilities mitigation in KVM\n* support for memory areas visible only in a single owning context\n* hardening of the Linux containers<\/p>\n\n<p>We are going to present the approach for the implementation of restricted mappings in the Linux kernel and how this implementation would be used with various use-cases.<\/p>\n\n<p>We are also going to take a closer look at possibility to assign an address space to the Linux namespaces, so that tasks running in namespace A have different view of kernel memory mappings than the tasks running in namespace B. For instance, by keeping all the objects in a network namespace private, we can achieve levels of isolation equivalent to running a separated network stack.<\/p>",
        "persons":
        [
          {
            "_id": "3124",
            "value": "James Bottomley"
          },
          {
            "_id": "4942",
            "value": "Mike Rapoport"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9564.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9326",
        "start": "17:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "guix",
        "title": "Guix: Unifying provisioning, deployment, and package management in the age of containers",
        "subtitle": [],
        "track": "Containers and Security",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>This talk will reflect on what GNU Guix has to offer to users and how it compares to other approaches—from CONDA and pip to Flatpak and Docker.  Guix is not only a transactional package manager and declarative GNU/Linux distribution: it’s also an environment manager, a container provisioning tool, and more.  We will describe these tools and our journey to 1.0, emphasizing key properties that set Guix apart:\nreproducibility, transparency, and hackability.<\/p>",
        "description": "<p>When it comes to software deployment, we are getting used to a new distribution of roles among many actors: traditional distros take care\nof core software pieces, “application bundles” à la Docker/Flatpak provide complex applications, Cabal, Gem, npm, pip, and friends take care of language-specific software, and Puppet/Ansible orchestrate the whole thing.  Each of these tools has its justification, but the end result is a maze that’s hard to deal with.<\/p>\n\n<p>In this talk I will present GNU Guix, a software deployment toolbox and its associated distro that feature transactional upgrades and rollbacks, declarative OS deployment inspired by Nix, and reproducible builds.  I will show how Guix approaches a variety of use cases: “package management” à la apt-get, environment management à la VirtualEnv, Ansible-style declarative OS deployment, and container provisioning à la Docker.<\/p>\n\n<p>Guix emphasizes programmability and one of its salient features is that it provides a unified Scheme programming environment to deal with with all the aspects of configuration, deployment, and system management—including service management by PID 1.  I will illustrate how\nthis works out on standalone Guix systems, and show the benefits of the approach by discussing applications that take advantage of Guix as a library to support reproducible software deployment.<\/p>\n\n<p>Last, I will reflect on the road that led to Guix 1.0 six months ago and present some of the challenges ahead.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2003",
            "value": "Ludovic Courtès"
          }
        },
        "links":
        [
          {
            "_href": "https://guix.gnu.org",
            "value": "GNU Guix"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9326.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.2215 (Ferrer)",
    "event":
    [
      {
        "_id": "9080",
        "start": "12:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "free_software_hackers_needed",
        "title": "Civil society needs Free Software hackers",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>More and more traditionally processes in our society now incorporate, and are influenced by software.<\/p>",
        "description": "<p>Processes that decide for example: Who will be able to go to which university? Who will be invited for a job interview? How long does someone have to go to jail?<\/p>\n\n<p>Therefore many organisation which work for people's rights are now confronted with the problems proprietary software creates for society.  The pupils associations, the unions, human right organisations, or environmental organisations -- all of them need to understand how software works to do their work in our society.<\/p>\n\n<p>To continue to fulfil their role, civil society needs to understand how processes are implemented in software, they need to be able to challenge the assumptions, the values, and the way programmers designed them, and have a better understanding how you could change them.<\/p>\n\n<p>In short: in a world in which more and more of our live is controlled by software, civil society organisations need us as Free Software hackers to support them doing their job.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "421",
            "value": "Matthias Kirschner"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9080.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9953",
        "start": "12:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "openolitor_community_supported_agriculture",
        "title": "A tool for Community Supported Agriculture (CSA) management, OpenOlitor",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>OpenOlitor is a SaaS open-source tool facilitating the organization and management of CSAs (Community Supported Agriculture) communities. This\ntool covers a large spectrum of functionalities needed for CSAs such as member management, emailing, invoicing, share planning and delivery, absence\nscheduling, etc. This software is organized and monitored by an international community that promotes the tool, helps operate it and support the\ninterested communities. In order to promote the sustainability of the tool and this international community an organization based on CSS\n(Community Supported Software) has been proposed.<\/p>",
        "description": "<h1>1 - Introduction<\/h1>\n\n<p>The Community Supported Agriculture movement has grown considerably the last few years proposing a new model of food production and distribution. CSA initiatives connect producers and consumers directly. The consumer receives a basket of locally produced, fresh products on a subscription basis. Risk is shared among all participants of the community, independently of being a consumer or producer. The growing popularity of the CSA model has lead to larger sized communities. Consequently, the management effort for this organizations is becoming unaffordable on a volunteer basis.\nIn such conditions a software helping with the redundant tasks, and connecting all participants of these communities, can be particularly supportive.\nThe main motivations for the creation of OpenOlitor (OO) are to attend to the growing popularity of the CSA model with the aim of keeping the model\neconomically viable and sustainable by reducing management task time investment through building software which facilitates easy organization.<\/p>\n\n<h1>2 - OpenOlitor<\/h1>\n\n<p>OpenOlitor is a web-based, open source tool facilitating the organization and management of CSAs (Community Supported Agriculture)\ncommunities. This tool is composed of two different access points:<\/p>\n\n<ul>\n<li>The participant console: any member holding one or more subscriptions, has an access to this console. This displays basic information about next subscription, products that will be delivered, absences, etc.<\/li>\n<li>The admin console: only defined administrators can access this console. All the community management tools are available from this portal. Please, refer to the next subsection for a detailed list of functionalities.<\/li>\n<\/ul>\n\n\n<h2>2.1 - Functionalities  OpenOlitor (OO) covers the main functionalities CSAs need:<\/h2>\n\n<ul>\n<li>Members and people management: OO allows the management of all the current members, historical members or interested individuals. A member can be composed of multiple people. Basic information is required for every member, such us contact information, details of payment, etc.<\/li>\n<li>Subscription types: A member receives one or several baskets (also called shares) of products periodically. Different types of baskets are allowed. Types are defined by the community and may include delivery type, pickup or frequency, for example;<\/li>\n<li>Subscription management: A member can be subscribed to one or several subscriptions;<\/li>\n<li>Delivery management: Deliveries are prepared by the administrators. As a result shares will be created where subscriptions, delivery types, prices are calculated automatically;<\/li>\n<li>Billing: Automatic invoices are created for every member;<\/li>\n<li>Participatory task management: Some CSAs require a certain community work hours in order to be part of the community. OO can track this information and publish available tasks to the members;<\/li>\n<li>Absence management: Members can feed the system their pickup absences that would be taken into account automatically;<\/li>\n<li>Product/producer management: A CSA can have one or multiple producers and each producer can have one or more products. This information can be used for billing purposes or basket shaping purposes;<\/li>\n<li>Emailing: an integrated emailing functionality is provided for some of the modules already explained. This allows administrators to easily mail information to the participants, such as invoices, general announcements, etc.<\/li>\n<li>Payment management: SEPA and ESR payment work-flows are integrated;<\/li>\n<\/ul>\n\n\n<h2>2.2 - Basic architecture<\/h2>\n\n<p>The OO platform is divided in back-end and front-end:<\/p>\n\n<ul>\n<li>Front-end: The front-end is a Web-Application (AngularJS) accessible from any browser. A front-end application is dedicated to every CSA. The code is accessible publicly in Github:<\/li>\n<li>Administration portal (https://github.com/OpenOlitor/openolitor-client-admin)<\/li>\n<li><p>Members portal (https://github.com/OpenOlitor/openolitor-client-kundenportal)<\/p><\/li>\n<li><p>Back-end: Programmed in Scala using the Akka library for concurrency and distributed systems. A single server can be shared among multiple initiatives. The code is published on Github. Even if the server can be shared among multiple organizations, a MariaDB database is created per initiative. This model guaranties data ownership and privacy. The code is accessible publicly in Github: https://github.com/OpenOlitor/openolitor-server<\/p><\/li>\n<\/ul>\n\n\n<h1>3 - Current numbers<\/h1>\n\n<p>Currently, seven CSAs are using OpenOlitor to support their organizations in a production environment. Three more CSAs are in the process of transitioning to this digital tool. A few numbers extracted from the last two years and a half to put into perspective the work volume facilitated by OO:<\/p>\n\n<ul>\n<li>+/- 100'000 baskets already delivered<\/li>\n<li>+/- 3'000 managed deliveries, average 33 baskets per delivery<\/li>\n<li>+/- 3'400 subscriptions<\/li>\n<li>+/- 2'100 subscribers<\/li>\n<\/ul>\n\n\n<h1>4 - Hosting and Operations<\/h1>\n\n<p>As shown by the architecture, the database and the front-end are CSA specific but the server can be used by multiple organizations. We promote the idea of hosting communities where a group of CSAs share the costs for the hosting and the effort for the operational work. This model is currently in use for all CSAs using the software.<\/p>\n\n<h1>5 - Sustainability model<\/h1>\n\n<p>As a financial model we promote the idea of Community Supported Software (CSS). This model is directly inspired by the CSA model where all participants share the risk and responsibility of the food production. Transferring this idea to software, an organization working with OO is invited to participate on the maintenance, operation, support and further development of the software. A fixed financial contribution is defined per basket delivered. All contributions are  shared with all projects using the tool. Using this model, the effort and risk is equally shared, independently of the size of the CSA.<\/p>\n\n<h1>6 - Legal organizations supporting OO<\/h1>\n\n<p>This software is organized and monitored by an international community that promotes this tool:<\/p>\n\n<p>OpenOlitor International: Non legally formed organization composed by around 10 members from different European countries. This organization is in charge of the vision and principles of all interactions with the software. This group meets periodically to decide OO main features and how to evolve the platform. Everyone interested in OO is invited to join;\nOpenOlitor association: non-profit organization based in Switzerland. Legal body managing the founds received by initiatives and public sources;\nOpenOlitor operations association: Organization in charge for the operation and support of the Swiss based CSAs;\nSunu: a German based organization that promotes digitalization for CSAs. They are promoting the ue of OO as well as the operational and support for German CSAs.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6614",
            "value": "Mikel Cordovilla"
          }
        },
        "links":
        [
          {
            "_href": "https://openolitor.org",
            "value": "official website"
          },
          {
            "_href": "http://sunu.eu",
            "value": "German association promoting the software"
          },
          {
            "_href": "https://github.com/OpenOlitor",
            "value": "main github repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9953.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10116",
        "start": "12:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "open_food_facts",
        "title": "What's in my food ? Open Food Facts, the Wikipedia of Food",
        "subtitle": "Mixing mobile crowdsourcing, ai, opensource and opendata to improve food transparency",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Open Food Facts is a collaborative and crowdsourced database of food products from the whole planet, licensed under the Open Database License (ODBL). It was launched in 2012, and today it is powered by 27000 contributors who have collected data and images for over 1 million products in 178 countries (and growing strong…)\nThis is the opportunity to learn more about Open Food Facts, and the latest developments of the project.<\/p>",
        "description": "<p>Scan a product using your phone, take a picture, and you're already part of the Open Food Facts revolution !<\/p>\n\n<p>In this talk we'll show how Open Food Facts leverages open source technologies such as Perl, Python, TensorFlow, MongoDB, Java, Swift, React and Flutter as well as the great power of communities to open data of public interest for health &amp; science, as well as unforeseen applications in your daily life.<\/p>\n\n<p>We will also introduce you to Open Beauty Facts, for freeing your cosmetic cupboard: shampoos, toothpastes, lipsticks, etc.<\/p>\n\n<p>How does it work?\nUsing our Android or iPhone app, you can easily scan the barcode of products from your home or local store.\nYou can either check them out (thanks to the decoding and comparison tools) or contribute pictures of their labels, assisted by our label-reading AI.\nThe same can also be done from the website, where additional tools are available to fill in the product details from the labels, navigate or vizualise the database based in various ways, or access the APIs and raw data to make your own tools and analysis.<\/p>\n\n<p>Open Food Facts is developed and managed by a community of open source, open data and food enthusiasts and is organised as a non-profit association. All its creations are open:\n- the collected data is published as Open Data,\n- the software running the server(s) is open source and reusable (it was also used to create the Open Beauty Facts database),\n- the mobile applications are open source as well.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6332",
            "value": "Pierre Slamich"
          }
        },
        "links":
        [
          {
            "_href": "https://world.openfoodfacts.org/discover",
            "value": "Discover Open Food Facts"
          },
          {
            "_href": "https://world.openfoodfacts.org/contribute",
            "value": "How to contribute"
          },
          {
            "_href": "http://world.openfoodfacts.org/development",
            "value": "Development"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10116.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9790",
        "start": "13:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "web3",
        "title": "Web3 - the Internet of Freedom, Value, and Trust",
        "subtitle": "On exiting the system and reclaiming control of our digital and physical lives",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>For as long as human society has existed, humans have been unable to trust each other. For millennia, we relied on middlemen to establish business or legal relationships. With the advent of Web2.0, we also relayed the establishment of personal connections, and the system has turned against us. The middlemen abuse our needs and their power and we find ourselves chained to convenience at the expense of our own thoughts, our own privacy. Web3 is a radical new frontier ready to turn the status quo on its head, and these are the technologies we're using to make it happen.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6942",
            "value": "Bruno Škvorc"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9790.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9792",
        "start": "13:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "next_web_browser",
        "title": "Next, the programmable web browser",
        "subtitle": "How the architectural choices and the Lisp language make for an infinitely extensible web browser",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>While actual browsers expose their internals through an API and limit access to the host system, Next doesn't, allowing for infinite extensibility and inviting the users to program their web browser. On top of that, it doesn't tie itself to a particular platform (we currently provide bindings to WebKit and WebEngine) and allows for live code reloads, thanks to the Common Lisp language, about which we'll share our experience too.<\/p>",
        "description": "<p>Next is a keyboard-oriented, extensible web browser designed for power users. While most (all?) current browsers expose their internals through an API, Next exposes its entire code to the user. Modern browsers limit access to the host system, and Next doesn't, allowing for a broad range of new features. Similar projects have failed due to being tied to a particular platform (Vimperator, Conkeror…), but Next's choice is to have its core written as an independent library, and to provide bindings to web engines (currently WebKit and WebEngine are supported). Next's magic touch is its live coding capability: we can develop a command from a REPL, compile the function and try the changes immediately, without restarting anything. Or just edit our init file and reload it into the current session. This flexbility comes for free thanks to the Common Lisp language, the experience with which we'd like to share too.<\/p>\n\n<p>Next is usable as of today. It features ad-blocking (only basic for now, contributions are welcome), multi-selection, bookmarks, session persistence, Emacs and Vim-like shortcuts, history seen as a tree, fuzzy completion everywhere, basic git-forking and file management interfaces…<\/p>\n\n<p>We are entering a new phase of development, with hopefully announcements that we can make public at the time of the conference :)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6940",
            "value": "Atlas Engineer"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/atlas-engineer/next",
            "value": "GitHub"
          },
          {
            "_href": "https://next.atlas.engineer/articles",
            "value": "Next releases"
          },
          {
            "_href": "https://ambrevar.xyz/",
            "value": "Pierre's website (Lisp, Guix, Emacs)"
          },
          {
            "_href": "https://lisp-journey.gitlab.io/",
            "value": "Vincent's blog (Common Lisp)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9792.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10029",
        "start": "13:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "weblate",
        "title": "Weblate: open-source continuous localization platform",
        "subtitle": "How to bring your project closer to its users with localization platform that doesn’t bother anyone with manual work.",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>You will learn how to localize your project easily with little effort, open-source way. No repetitive work, no manual work with translation files anymore. Weblate is unique for its tight integration to VCS. Set it up once and start engaging the community of translators. More languages translated means more happy users of your software. Be like openSUSE, Fedora, and many more, and speak your users' language now thanks to Weblate!<\/p>",
        "description": "<p>I will show you the main perks of Weblate and the setup of the project. If you have a project with open repo and you want to start translating it, take your git:// link, and we will set it up right on the spot. FOSDEM is a great time and place to found your translating community.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7059",
            "value": "Václav Zbránek"
          }
        },
        "links":
        [
          {
            "_href": "https://weblate.org",
            "value": "Weblate project site"
          },
          {
            "_href": "https://github.com/WeblateOrg/",
            "value": "Weblate code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10029.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9980",
        "start": "14:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "kapow_web_framework",
        "title": "Kapow! A Web Framework for the Shell",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>This talk is about \"Kapow!\" an open source webframework for the shell developed by BBVA Innovation Labs. We will talk about the current development of the project including an overview of Kapow!'s technology stack and the recent release of the first stable version.<\/p>",
        "description": "<p>The motivation behind the project was to create an adapter between the shell and the web. Allowing users to expose command line programs as HTTP services with a high degree of freedom and flexibility, not imposing any predefined behavior.\nThe project is based on an open specification.<\/p>\n\n<p>Kapow! supports an increasing list of HTTP features; including forms, websockets and streaming. The architecture is based on exposing a private REST API through which the shell can interact with the incoming user HTTP requests.<\/p>\n\n<p>Leveraging this architecture an ecosystem of specialized tools is planned, to help with common high level tasks in Kapow! services.\nFor example:\n- Shell commands that can interact with incoming web browser requests and render specialized web pages.\n- Automatic mapping of shell command parameters to REST API through bash completion scripts.<\/p>\n\n<p>Roberto will do some demos about creating Kapow! services from scratch (expose nmap as a service, tcpdump, pandoc and ffmpeg).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6439",
            "value": "Roberto Abdelkader Martínez Pérez"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/BBVA/kapow",
            "value": "Repository"
          },
          {
            "_href": "https://kapow.readthedocs.io/en/latest/",
            "value": "Documentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9980.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9973",
        "start": "14:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "yjs_shared_editing",
        "title": "Yjs: A CRDT framework for shared editing",
        "subtitle": "Enable shared editing in every application",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Shared editing is the ability to collaboratively edit the same text in real-time. The market for shared editing solutions is fragmented. Once you choose a solution you will be locked into using a specific editor and a specific backend. Yjs is a data synchronization framework that aims to enable shared editing in all open-source editors using any networking stack.<\/p>",
        "description": "<p>Yjs is a data synchronization framework that is specifically designed for creating shared editing applications like Google Docs. The number of editors, that Yjs supports, is steadily growing. At this time we implemented shared-editing support for six of the most prominent open-source rich-text editors - including <a href=\"https://quilljs.com/\">Quill<\/a>, <a href=\"http://prosemirror.net/\">ProseMirror<\/a>, and <a href=\"https://codemirror.net/\">CodeMirror<\/a>. We are currently working on integrating Yjs in Gutenberg, the new WordPress editor.<\/p>\n\n<p>Since Yjs is network agnostic and does not require a central authority to resolve sync conflicts, it is possible to use any networking stack to share document updates of the collaborative document. We created an ecosystem of modules that handle data synchronization over, for example, WebRTC, <a href=\"https://www.datprotocol.com/\">Dat Protocol<\/a>, <a href=\"https://ipfs.io/\">IPFS<\/a>, and traditional client-server connections via WebSockets.<\/p>\n\n<p>In this lightning talk, we want to show the huge potential of Yjs that hopefully will make it the go-to solution for creating shared editing applications on the web.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2971",
            "value": "Kevin Jahns"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/yjs/yjs",
            "value": "Yjs"
          },
          {
            "_href": "https://yjs.dev/",
            "value": "Yjs Demos"
          },
          {
            "_href": "https://publishpress.com/blog/yjs/",
            "value": "Yjs in Gutenberg"
          },
          {
            "_href": "https://tag1consulting.com/blog/deep-dive-real-time-collaborative-editing-solutions-tagteamtalk-001-0",
            "value": "Webinar: A Deep Dive Into Real Time Collaborative Editing Solutions"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9973.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9988",
        "start": "14:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "cryptpad_collaboration",
        "title": "Encrypt your collaboration with CryptPad",
        "subtitle": "Real demo !",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>We'll show a real demonstration of how you can encrypt your data and collaborate with others in real-time using the CryptPad Open Source project.\nThis demonstration will include real-time Wysiwyg, Text, Kanban, Spreadsheet, File storage and Teams features allowing to share your documents securely with your friends and co-workers.<\/p>",
        "description": "<p>The Internet business model is about \"surveillance capitalism\" and every day our data is being used to target us with more and more invading advertisements, and every day data is being leaked by Internet business and cloud providers.<\/p>\n\n<p>CryptPad is using end-to-end encryption to protect your data, while including innovative algorithms to allow collaboration between users. With CryptPad, the cloud hoster cannot read your data and if data leaks, hackers only get encrypted data which they cannot read without the keys.<\/p>\n\n<p>Start ditching proprietary privacy invading cloud services for an free software privacy protecting alternative.<\/p>\n\n<p>Come join the 20000 weekly users of the cryptpad.fr main instance and the 300 other instances available, including the German Pirate Party and C3 Wien instances.<\/p>\n\n<p>Come join us restoring our privacy.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2113",
            "value": "Ludovic Dubost"
          }
        },
        "links":
        [
          {
            "_href": "https://cryptpad.fr",
            "value": "CryptPad Main Instance"
          },
          {
            "_href": "https://github.com/xwiki-labs/cryptpad",
            "value": "CryptPad GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9988.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9823",
        "start": "15:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "protect_data_objects",
        "title": "Protect your data objects, not your network connections",
        "subtitle": "Good news for a paradigm shift",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Agenda<\/p>\n\n<p>1) Current situation: complicated &amp; incomplete threat models\n2) Concepts worth looking into\n3) data sovereignty\n4) named data networks\n5) zero trust\n6) Our hands-on experience with the above<\/p>",
        "description": "<p>The current state of play to protect data is a tedious task that involves many stakeholders and blocks resources.\nThe shift from on-premise to private/public cloud systems requires a careful inspection of an assumed threat model.\nThe application of a zero-trust model is one radical shift to authenticate and authorize at any given point in your\nIT landscape, but most importantly it breaks with the assumption that we can design systems that are \"safe and secure\".\nThe talk will highlight the above mentioned concepts and will give a brief outline of a new approach called Named Data\nNetwork (NDN) and how this could improve the situation in terms of data sovereignty.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5493",
            "value": "Stephan Schwichtenberg"
          }
        },
        "links":
        [
          {
            "_href": "https://named-data.net/",
            "value": "Named Data Networking"
          },
          {
            "_href": "https://en.wikipedia.org/wiki/Named_data_networking",
            "value": "Wikipedia"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9823.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9229",
        "start": "15:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "sandboxfs_bazel_speedup",
        "title": "Optimizing sandbox creation with a FUSE file system",
        "subtitle": "Using sandboxfs to speed up Bazel builds",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The Bazel build system sandboxes each action (e.g. each compiler invocation) to ensure the action only has access to declared inputs and that the action only generates the promised outputs. This ensures that the execution of each build tool is deterministic and not subject to system-wide state. Unfortunately, creating these sandboxes is costly, and every millisecond added to the runtime of each action has a large impact on total build time. Just consider that Bazel focuses on large-ish builds with thousands of actions in them: each little inefficiency quickly multiplies and can result in significant slowdowns, and developers always want faster build times. In this talk, I'll explain how Bazel implements sandboxing and I will cover a FUSE file system I've been developing, sandboxfs, to optimize this process. I'll go into the details of the file system, explain how it started as a Go project and was then rewritten in Rust, and then show some performance metrics.<\/p>",
        "description": "<p>Possible outline:<\/p>\n\n<ul>\n<li>Brief introduction to Bazel: what are actions.<\/li>\n<li>Why is sandboxing of actions important and what it intends to achieve.<\/li>\n<li>How does sandboxing work in the default case and what problems it carries performance- and correctness-wise.<\/li>\n<li>The solution: how we can use FUSE to eliminate the major source of slowdowns.<\/li>\n<li>Brief explanation of what sandboxfs is and how Bazel takes advantage of it.<\/li>\n<li>Delve a little bit into why the project started in Go and was then rewritten in Rust.<\/li>\n<li>Present performance metrics.<\/li>\n<li>Ideas for other possible uses for sandboxfs (NixOS and reproducible package builds).<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6568",
            "value": "Julio Merino"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/bazelbuild/sandboxfs/",
            "value": "Project homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9229.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9316",
        "start": "15:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "bloom_filters",
        "title": "Indexing Encrypted Data Using Bloom Filters",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Bloom filters are a probabilistic data structure that tell us where things are not.  They also utilize one way hash functions to build a probabilistic representation of an object.  This talk will address how this structure can be used to provide an index into encrypted data that can be made publicly available with minimal risk.<\/p>",
        "description": "<p>Talk will cover how bloom filters are constructed, the Flat Bloofi indexing implementation and how to take the properties to be indexed and create Bloom filters, and then how to associate the bloom filter with the encrypted object in the index.<\/p>\n\n<p>The result is an extremely fast index that can retrieve data items containing partial keys.<\/p>\n\n<p>After this talk participants will be able to provide search capabilities across a collection of encrypted objects.<\/p>\n\n<p>Code examples will be provided.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3098",
            "value": "Claude Warren"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/Claudenw/MultidimentionalBloom",
            "value": "Multidimensional Bloom FIlter Src"
          },
          {
            "_href": "https://github.com/Claudenw/BloomEncryptedIndex",
            "value": "Bloom Filter Encryption"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9316.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9294",
        "start": "16:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "verifpal",
        "title": "Verifpal",
        "subtitle": "Cryptographic Protocol Analysis for Students and Engineers",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Verifpal is new software for verifying the security of cryptographic protocols. Building upon contemporary research in symbolic formal verification, Verifpal’s main aim is to appeal more to real-world practitioners, students and engineers without sacrificing comprehensive formal verification features. Verifpal represents a serious attempt at making the formal analysis of advanced cryptographic systems such as Signal and TLS 1.3 easier to achieve.<\/p>",
        "description": "<p>Contemporary research in symbolic formal verification has led to confirming security guarantees (as well as finding attacks) in secure channel protocols such as TLS and Signal. However, formal verification in general has not managed to significantly exit the academic bubble. Verifpal is new software for verifying the security of cryptographic protocols that aims is to work better for real-world practitioners, students and engineers without sacrificing comprehensive formal verification features.<\/p>\n\n<p>In order to achieve this, Verifpal introduces a new, intuitive language for modeling protocols that is easier to write and understand than the languages employed by existing tools. Its formal verification paradigm is also designed explicitly to provide protocol modeling that avoids user error. By modeling principals explicitly and with discrete states, Verifpal models are able to be written in a way that reflects how protocols are described in the real world. At the same time, Verifpal is able to model protocols under an active attacker with unbounded sessions and fresh values, and supports queries for advanced security properties such as forward secrecy or key compromise impersonation.<\/p>\n\n<p>Verifpal has already been used to verify security properties for Signal, Scuttlebutt, TLS 1.3 and other protocols. It is a community-focused project, and available under a GPLv3 license.<\/p>\n\n<p>An Intuitive Protocol Modeling Language:\nThe Verifpal language is meant to illustrate protocols close to how one may describe them in an informal conversation, while still being precise and expressive enough for formal modeling. Verifpal reasons about the protocol model with explicit principals: Alice and Bob exist and have independent states.<\/p>\n\n<p>Modeling that Avoids User Error:\nVerifpal does not allow users to define their own cryptographic primitives. Instead, it comes with built-in cryptographic functions — this is meant to remove the potential for users to define fundamental cryptographic operations incorrectly.<\/p>\n\n<p>Easy to Understand Analysis Output:\nWhen a contradiction is found for a query, the result is related in a readable format that ties the attack to a real-world scenario. This is done by using terminology to indicate how the attack could have been possible, such as through a man-in-the-middle on ephemeral keys.<\/p>\n\n<p>Friendly and Integrated Software:\nVerifpal comes with a Visual Studio Code extension that offers syntax highlighting and, soon, live query verification within Visual Studio Code, allowing developers to obtain insights on their model as they are writing it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6607",
            "value": "Nadim Kobeissi"
          }
        },
        "links":
        [
          {
            "_href": "https://verifpal.com",
            "value": "Verifpal Website"
          },
          {
            "_href": "https://verifpal.com/res/pdf/manual.pdf",
            "value": "Verifpal User Manual"
          },
          {
            "_href": "https://verifpal.com/paper",
            "value": "Verifpal Paper"
          },
          {
            "_href": "https://verifpal.com/source",
            "value": "Verifpal Source Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9294.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9015",
        "start": "16:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "mandos_disk_encryption",
        "title": "Mandos",
        "subtitle": "Disk encryption without passwords",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Disk encryption is essential for physical computer security, but seldom used due to the trouble of remembering and typing a password at every restart. We describe Mandos, a program which solves this problem, its security model, and the underlying concepts of its design, as well as its evolution over the 10 years since its initial release.<\/p>",
        "description": "<p>Any security system must have a clear view of its intended threat model – i.e. what threats it is actually intended to protect against; the specific choices and tradeoffs made for Mandos will be explained. Another danger of security system design is the risk of its non-use; i.e. that the system will not be used for some real or perceived drawbacks, such as complexity. The deliberate design choices of Mandos, involving low-interaction, “invisible” and automatic features, will be covered.  Special emphasis will be made on the many necessary changes made since the last FOSDEM talk in 2015.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2811",
            "value": "Teddy Hogeborn"
          }
        },
        "links":
        [
          {
            "_href": "https://www.recompile.se/mandos",
            "value": "Mandos Home Page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9015.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9604",
        "start": "16:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "redwax_trust_only_yourself",
        "title": "RedWax - trust only yourself",
        "subtitle": "Easy Industry best practice authentication and security - federated or just for you.",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>In this talk we will show you, practical, hands on, how you can secure your application, a small user community or environment using industry best of breed security, fully self-supporting and  <em>without<\/em> having to rely on a central certificate authority, big-tech or other central powerhouses. As devolved &amp; federated, or as central as you want - you set the rules. Working for you, with your standard-issue iPhone, your router or your laptop out of the box.<\/p>\n\n<p>Project redwax produces industry best practice crypto in a small package. Available today. If you know how to install the apache webserver - you are almost there.<\/p>\n\n<p>Project Redwax lets you download,a set of easy to deploy simple tools that capture and hard code a lot of industry best practice and specialist PKI knowledge. So that they can be put into the hands of a much wider community than currently served by a few specialist industries. It provides a non centralised, interoperable, open standard, open source, fully federated trust network where participants are not required to ask permission and can be self sufficient.<\/p>\n\n<p>This presentation presents what is available <em>today<\/em> and our plans on how to take this further, to engage with the wider open source community that together we can support individuals, organisations and (small) companies to get best of breed, distributed, peer to peer, security, confidentiality and privacy without having to rely on central infrastructures.<\/p>",
        "description": "<p>Wouldn’t it be nice to be able to trust your own environment without having to trust a corporation or government? Wouldn’t it be nice to take the sting out of certificate management?<\/p>\n\n<p>With some hands on examples we introduce the audience to the advantages of running your own certificate authority for security IOT in and around your home and establishing a trusted channel for exchanging information with your friends.<\/p>\n\n<p>This project (and code) helps you to decentralize trust management so that the values security, confidentiality and privacy can be upheld in public infrastructure and private interactions. We strengthen the existing technologies and infrastructure by providing a modular, very simple and foremost practical set of tools to manage public key based trust infrastructures as currently used.<\/p>\n\n<p>Project Redwax lets you download, a set of easy to deploy simple tools that capture and hard code a lot of industry best practice and specialist PKI knowledge. So that they can be put into the hands of a much wider community than currently served by a few specialist industries. It provides a non centralised, interoperable, open standard, open source, fully federated trust network where participants are not required to ask permission and can be self sufficient.<\/p>\n\n<p>With support from NLNET project Redwax has made the code available under the Apache license from a infrastructure that is firmly rooted in Europe. And the good news - it is simple - if you know how to install the Apache Webserver - you are almost there. We are working with the unix/linux community to get the code in standard distro’s and cloud init scripts so that these capabilities are made available to wider community of application developers.<\/p>\n\n<p>This presentation presents what is available <em>today<\/em> and our plans on how to take this further, to engage with the wider open source community that together we can support individuals, organisations and (small) companies to get best of breed, distributed, peer to peer, security, confidentiality and privacy without having to rely on central infrastructures, rare knowledge or big interests.<\/p>\n\n<p>Speaker:        Dirk-Willem van Gulik (Dirkx@apache.org)\nTalk:           50 minutes.\nTravel support:     not needed\nLanguage:               English<\/p>\n\n<p>BIO\nDirk-Willem van Gulik?<\/p>\n\n<p>During the startup-years - Dirk-Willem van Gulik helped shape the world-wide-web. He was one of the founders, and the first president, of the Apache Software Foundation; and worked on standards such as HTTP at the Internet Engineering Taskforce. He has worked for the Joint Research Centre of the European Commission, the United Nations, telecommunications firms, the BBC, several satellite&amp;space agencies and founded several startups. He participated in different international standards bodies, such as the IETF and W3C on metadata, GIS, PKI, Security, Architecture and Internet standards. Dirk build the initial engineering team at Covalent - the first open source company; and was one of the Founders of Asemantics, a leader in Enterprise Information Integration; which helped make the Semantic Web a reality. He then initiated Joost.com, a peer to peer based video and build and lead the team that created the worlds first instant play P2P viewer and a back office system with user profile driven advert targeting and payment settlements. He was the Chief Technical Architect at the BBC where has helped shape the audience facing delivery platform Forge in the time for the Olympics and where he made information security and compliance a core enabler for business processes. He currently works on several medical and privacy intensive security projects with a heavy emphasis on Architecture and Governance. When not at work, he loves to sail, hang out at the makerspaceleiden.nl or play with his lego.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6843",
            "value": "Dirk-Willem van Gulik"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9604.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9146",
        "start": "17:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "kde_itinerary",
        "title": "KDE Itinerary",
        "subtitle": "A privacy by design travel assistant",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Getting your itinerary presented in a unified, well structured and always up to date fashion rather than as advertisement overloaded HTML emails or via countless vendor apps has become a standard feature of digital assistants such as the Google platform. While very useful and convenient, it comes at a heavy privacy cost. Besides sensitive information such as passport or credit card numbers, the correlation of travel data from a large pool of users exposes a lot about people's work, interests and relationships. Just not using such services is one way to escape this, or we build a privacy-respecting alternative ourselves!<\/p>",
        "description": "<p>Standing on the shoulders of KDE, Wikidata, Navitia, OpenStreetMap and a few other FOSS communities we have been exploring what it would take to to build a free and privacy-respecting travel assistant during the past two years, resulting in a number of building blocks and the \"KDE Itinerary\" application. In this talk we will look at what has been built, and how, and what can be done with this now. In particular we will review the different types of data digital travel assistants rely on, where we can get those from, and at what impact for your privacy.<\/p>\n\n<p>The most obvious data source are your personal booking information. Extracting data from reservation documents is possible from a number of different input formats, such as emails, PDF files or Apple Wallet passes, considering structured annotations and barcodes, but also by using vendor-specific extractors for unstructured data. All of this is done locally on your own devices, without any online access.<\/p>\n\n<p>Reservation data is then augmented from open data sources such as Wikidata and OpenStreetMap to fill in often missing but crucial information such as timezones or geo coordinates of departure and arrival locations. And finally we need realtime traffic data as well, such as provided by Navitia as Open Data for ground-based transport.<\/p>\n\n<p>We will of course also look at how features based on that data can be integrated into applications. While there is the KDE Itinerary mobile application presenting these information in a timeline view with access to the corresponding boarding passes or ticket tokens, the underlying building blocks are explicitly meant to be reusable for wider integration. This might be of particular interest for people working on e.g. email application or digital assistants.<\/p>\n\n<p>Should the author fail to show up to this presentation it might be that last year's fixes for the barcode scanners at the Brussels airport station didn't work after all ;-)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6017",
            "value": "Volker Krause"
          }
        },
        "links":
        [
          {
            "_href": "https://phabricator.kde.org/project/profile/280/",
            "value": "KDE Itinerary project overview"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9146.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10005",
        "start": "17:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "gate_portable_execution_state",
        "title": "Gate project",
        "subtitle": "Portable execution state",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>This presentation is an introduction of an open source project I have been working on for five years: https://github.com/tsavola/gate.<\/p>\n\n<p>Building on WebAssembly, Gate makes it possible to snapshot running programs and resume them in diverse environments: unlike with other snapshot-and-restore solutions, the snapshots are portable across CPU architectures and operating systems.  Part of the solution is appropriate resource abstraction.  The presentation hopefully includes a quick demonstration of migration of a live program between x86-64 and ARM64 machines.<\/p>",
        "description": "<p>A subproject of Gate is a specialized WebAssembly compiler implemented in Go: https://github.com/tsavola/wag<\/p>\n\n<p>Gate is at the stage where a proof-of-concept has been implemented; it works.  Its future would greatly benefit from wider community engagement, so I wish to present the project and its ideas to a technical user and developer audience.<\/p>\n\n<ul>\n<li>Blog article: https://savo.la/introduction-to-gate.html<\/li>\n<li>Server running Gate: https://www.gate.computer<\/li>\n<li>Port of DOOM for Gate: https://github.com/tsavola/DOOM/tree/gate<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6815",
            "value": "Timo Savola"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10005.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9907",
        "start": "17:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "innersource_skills",
        "title": "The pool next to the ocean: How to bring OpenSource skills to more people",
        "subtitle": "InnerSource as a way to teach open collaboration skills and facilitate the opensourcing process for enterprises",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The pool next to the ocean: How to bring OpenSource skills to more people<\/p>\n\n<p>OpenSource powers the world and is everywhere with more and more enterprises and large companies understanding the value of it and the need to be able to be a good OpenSource citizen.\nHowever, not everyone in those enterprises has the skills to participate in OpenSource communities, feels ready to contribute something or to create and run a vibrant OpenSource community. I observed that there are two distinct groups of people - one with OSS background, ability and willingness to operate in that domain and those that will likely only use OSS without any likeliness to contribute or participate.\nLet's change that and build a bridge between those two groups while generating value for the enterprise making it more likely to receive support for this activity.\nInnerSource, the application of OpenSource principles and practices within the enterprise, can be this bridge.\nYou'll learn about creating opportunities for people who haven't been exposed to OpenSource collaboration to learn about the OpenSource ways of collaboration in a safe environment within their organization by creating shared projects internally that follow OpenSource practices and principles.\nYou'll also learn about how organizations can profit from cross-team/silo collaboration and knowledge exchange. Also, the acquisition of very valuable skills by their employees that can facilitate the successful transition of those internal projects into OpenSource and creation of vibrant communities around them.\nThis approach is successfully used by many enterprises, and I'm part of a community who has built and is building OpenSource-d training material for this.\nAttend this talk if you want to learn about how to deal with silo issues within your company, how to facilitate your companies way to transition projects to OpenSource or how to build up skills to successfully interact with OpenSource projects. Also attend if you want to hear a bit about freely available training material explaining InnerSource  concepts for people who haven't been involved in it yet.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6987",
            "value": "Johannes Tigges"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9907.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9219",
        "start": "18:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "reuse_code_licensing",
        "title": "Go REUSE to license your code",
        "subtitle": "Free Software licensing made simple for everyone",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Why is it so hard to detect the licensing and copyright information of source code? Because it is a tedious and often confusing task for developers to provide this information. The REUSE project changes that! With three simple steps, it makes adding and reading licensing and copyright information easy for both humans and machines. In this presentation, Max Mehl will guide through the REUSE principles and presents how to make clear licensing simple.<\/p>",
        "description": "<p>If you want to grant users the freedom to use, study, share, and improve your software, you have to grant those freedoms in the license of the software. To encourage people to develop Free Software, we help developers to understand and apply Free Software licensing. REUSE, started in 2017, contributes to this goal. Any project following the initiative's recommendations makes copyright and licensing information readable to both: humans and machines. This way, we want to ensure that individuals, organisations and companies who are re-using code are aware of the license terms chosen by the original author.<\/p>\n\n<p>REUSE does not reinvent the wheel. On the opposite, it integrates nicely into development processes and other best practices for Free Software licensing. Additionally, there are tools and documentation to help you get started. We will have a closer look at these during this talk.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3794",
            "value": "Max Mehl"
          }
        },
        "links":
        [
          {
            "_href": "https://reuse.software",
            "value": "REUSE website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9219.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9145",
        "start": "18:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "concept_programming",
        "title": "Concept Programming, from ideas to code",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Programming is the art of turning ideas into code.\nIdeas and code do not live in the same space. Any translation is lossy.\nConcept programming is a cross-language approach that focuses on this translation process, and helps identify often overlooked classes of issues.<\/p>",
        "description": "<p>Programming is the art of turning ideas into code.\nIdeas and code do not live in the same space. Consequently, any translation is lossy. But this loss is not immediately visible. For example, how does your programming language coerce you into coding a concept as simple as \"maximum\" or list in a way that is generally full of warts?\nConcept programming is a cross-language approach that focuses on this translation process, and helps identify often overlooked classes of issues. It separates the \"concept space\" and the \"code space\", and focuses on how the mechanics in one space translate (or not) into the other.<\/p>\n\n<p>It introduces a few core ideas:\n- Syntactic noise is the difference in look between code and concept. For example, in Lisp, you write (+ 1 2)\n- Semantic noise is the difference in behavior between code and concept. For example, in C, text is null-terminated.\n- Bandwidth is the amount of the concept space covered by the code. For example, the \"+\" operator has higher bandwidth in C++ than in C\n- Signal/noise ratio is the amount of code that does not carry any useful concept. For example, curly braces and semi-colons in C.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5672",
            "value": "Christophe de Dinechin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9145.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10044",
        "start": "18:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "deskconnd_crossplatform_ipc",
        "title": "DeskConnD: Secure, cross-platform IPC on the network",
        "subtitle": "Zeroconf + WAMP = Cross platform IPC",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>DeskConnD is a cross-platform, python based daemon that uses Crossbar and WAMP to enable end-to-end encrypted IPC over the network.<\/p>",
        "description": "<p>In this talk Omer Akram will talk about his new project that he has been working on for the past year to mainly make it easy for developers to add functionalities to their apps that were previously cumbersome to implement, having no platform-specific dependencies enables this project to be cross-platform.<\/p>\n\n<p>Combining proven technologies like WebSocket/WAMP and ZeroConf, DeskConnD allows different components of a distributed app on the local network to securely communicate and do messaging based on the RPCs and PubSub paradigms.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6565",
            "value": "Omer Akram"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/deskconn/",
            "value": "https://github.com/deskconn/"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10044.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.1301 (Cornil)",
    "event":
    [
      {
        "_id": "10767",
        "start": "10:30",
        "duration": "00:30",
        "room": "H.1301 (Cornil)",
        "slug": "getting_started_with_quantum_software_development",
        "title": "Getting started with quantum software development",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5592",
            "value": "Tomas Babej"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10767.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10768",
        "start": "11:05",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_machine_learning_with_pennylane",
        "title": "Quantum machine learning with PennyLane",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6225",
            "value": "Joshua Izaac"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10768.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10769",
        "start": "11:50",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_computing_hardware_and_control_systems",
        "title": "Quantum computing hardware and control systems",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6206",
            "value": "Felix Tripier"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10769.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10770",
        "start": "12:35",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "the_role_of_open_source_in_building_quantum_computing_ecosystemfrom_scratch",
        "title": "The role of open source in building quantum computing ecosystem from scratch",
        "subtitle": "Context of a developing country",
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7415",
            "value": "Hakob  Avetisyan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10770.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10771",
        "start": "13:20",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_advantage_and_quantum_computing_in_the_real_world",
        "title": "Quantum Advantage and Quantum Computing in the Real World",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6240",
            "value": "Mark Mattingley-Scott"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10771.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10772",
        "start": "14:05",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_circuit_optimisation_verification_and_simulation_with_pyzx",
        "title": "Quantum circuit optimisation, verification, and simulation with PyZX",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6200",
            "value": "John van de Wetering"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10772.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10773",
        "start": "14:50",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "simulaqron_a_simulator_for_developing_quantum_internet_software",
        "title": "SimulaQron - a simulator for developing quantum internet software",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7416",
            "value": "Axel Dahlberg"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10773.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10774",
        "start": "15:35",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "tools_for_quantum_machine_learning",
        "title": "Tools for Quantum Machine Learning",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7417",
            "value": "Jack Hidary"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10774.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10775",
        "start": "16:20",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "computing_with_the_tensornetwork_library",
        "title": "Computing with the TensorNetwork Library",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7418",
            "value": "Stefan Leichenauer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10775.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10776",
        "start": "17:05",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_classifiers_robust_data_encodings_and_software_to_implement_them",
        "title": "Quantum classifiers, robust data encodings, and software to implement them",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6246",
            "value": "Ryan LaRose"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10776.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10777",
        "start": "17:50",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_computer_brands_connecting_apples_and_oranges",
        "title": "Quantum computer brands: connecting apples and oranges",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7419",
            "value": "Petar Korponaić"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10777.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10778",
        "start": "18:30",
        "duration": "00:30",
        "room": "H.1301 (Cornil)",
        "slug": "quantum_open_source_foundation",
        "title": "Quantum Open Source Foundation",
        "subtitle": [],
        "track": "Quantum Computing",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6291",
            "value": "Mark Fingerhuth"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10778.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.1302 (Depage)",
    "event":
    [
      {
        "_id": "10717",
        "start": "10:30",
        "duration": "00:45",
        "room": "H.1302 (Depage)",
        "slug": "state_openjdk",
        "title": "State of OpenJDK",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A review of the past year in the life of the OpenJDK Community, and a look at what's ahead.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "218",
            "value": "Mark Reinhold"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10717.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10718",
        "start": "11:20",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "loom",
        "title": "Project Loom: Advanced concurrency for fun and profit",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Project Loom, an OpenJDK project, is \"intended to explore, incubate and deliver Java VM features and APIs built on top of them for the purpose of supporting easy-to-use, high-throughput lightweight concurrency and new programming models on the Java platform.\"  These feature include Lightweight Threads, delimited continuations, and tail-call elimination.<\/p>\n\n<p>The speaker, a Project Loom team member, will describe the project in depth, in particular the gnarly details of how coroutine and continuation scheduling mechanism works, and a new feature, Scoped Locals.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "719",
            "value": "Andrew Haley"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10718.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10720",
        "start": "11:50",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "tornadovm",
        "title": "TornadoVM: A Virtual Machine for Exploiting ​High-Performance Heterogeneous ​Execution of Java Programs​",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The proliferation of heterogeneous hardware in recent years has driven us to consider that every system we program, most likely includes a mix of computing elements; each of which with different hardware characteristics enabling programmers to improve performance while reducing energy consumption. These new heterogeneous devices include multi-core CPUs, GPUs and FPGAs. This trend has been accompanied by changes in software development norms that do not necessarily favor programmers. A prime example is the two most popular heterogeneous programming languages, CUDA and OpenCL, which expose several low-level features to the API making them difficult to use by non-expert users.<\/p>\n\n<p>Instead of using low-level programming languages, developers in industry and academia tend to use higher-level, object-oriented programming languages, typically executed on managed runtime environments, such as Java, R, and Javascript. Although many programmers might expect that such programming languages would have already been adapted for transparent execution on heterogeneous hardware, the reality is that their support is either very limited or absent.<\/p>\n\n<p>In this talk, we present TornadoVM (https://github.com/beehive-lab/TornadoVM), a heterogeneous programming framework for Java programs. TornadoVM co-exists with standard JVMs (e.g., OpenJDK) that implement the JVMCI. TornadoVM consists of three components: 1) a simple API for composing pipelines of existing Java methods, 2) an optimizing JIT compiler that extends the Graal compiler with hardware-aware optimizations that generate OpenCL C code, and 3) a runtime system that executes TornadoVM specific bytecodes, performs memory management, and schedules the code for execution on GPUs, multicore CPUs, and FPGAs. Essentially, TornadoVM is a “VM-in-a-VM” that can adapt execution completely dynamically and transparently to the user, always finding the highest-performing combination of hardware accelerators through dynamic reconfiguration.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7005",
            "value": "Thanos Stratikopoulos"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10720.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10721",
        "start": "12:20",
        "duration": "00:40",
        "room": "H.1302 (Depage)",
        "slug": "bytebuffers",
        "title": "ByteBuffers are dead, long live ByteBuffers!",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Abstract: Direct buffers are, to date, the only way to access foreign,\noff-heap memory. Despite their success, direct buffers suffer from some\nlimitations --- stateful-ness, lack of addressing space,\nnon-deterministic deallocation to name a few --- which makes them a\nless-than-ideal choice under certain workloads. In this talk we paint\nthe path to the future: a safe, supported and efficient foreign memory\naccess API for Java. By providing a more targeted solution to the\nproblem of accessing foreign memory, not only developers will be freed\nby the above limitations - but they will also enjoy improved\nperformances, as the new API is designed from the ground-up with JIT\noptimizations in mind - and all without sacrificing memory access safety.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7374",
            "value": "Maurizio Cimadamore"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10721.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10722",
        "start": "13:05",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "jakartaee",
        "title": "Free at Last! The Tale of Jakarta EE",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In September 2017 Oracle announced that it would be migrating governance of the Java EE platform to the Eclipse Foundation, the home of MicroProfile. Two years later Jakarta EE 8 shipped, signaling the successful completion of that move. As a result, Free Java has a new home for a significant piece of the Java ecosystem. A home which is purely open source, vendor neutral, and community led.<\/p>\n\n<p>This talk will be about how the long and painful journey from Java EE to Jakarta EE unfolded. But more importantly it will focus on how the new Jakarta EE community works, and how there is a new, open, specification process for Java APIs (other than SE) that is available for the community. We are looking forward to welcoming many of those interested in Free Java to participate in driving new innovation in Java APIs for cloud and other exciting use cases.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4193",
            "value": "Mike Milinkovich"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10722.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10723",
        "start": "13:35",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "shenandoah",
        "title": "Shenandoah 2.0",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Shenandoah GC landed in JDK12 about a year ago, giving OpenJDK\nanother low-pause garbage collector. It has undergone substantial\nchanges since then. Specifically we have a new barrier scheme, and have\neliminated the extra forwarding pointer word per object, thus\nsubstantially reducing memory footprint. After giving a general\nintroduction to OpenJDK GC landscape and Shenandoah GC, this talk\nfocuses on those recent changes in Shenandoah and what's in it for you.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "740",
            "value": "Roman Kennke"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10723.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10724",
        "start": "14:05",
        "duration": "00:40",
        "room": "H.1302 (Depage)",
        "slug": "imc",
        "title": "JMC & JFR - 2020 Vision",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>JDK Flight Recorder provides production time profiling and diagnostics\nvia a compact events-based infrastructure inside the Hotspot JVM\nitself. JDK Mission Control is a stand-alone application that provides\nreal-time monitoring information for Hotspot JVMs, as well as tools to\nread, automatically analyze and visualize flight recording data\nproduced by JDK Flight Recorder.<\/p>\n\n<p>When this talk is presented, JMC 7.1.0 has (hopefully) been out for a\nlittle while. This presentation talks about what is new and the\nroadmap for the upcoming JMC 8. We will also discuss recent changes in\nthe project, such as the move to Skara. Towards the end we will demo\nhow JDK Flight Recorder and JMC core libraries can be used to diagnose\napplications deployed in container orchestration platforms.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7377",
            "value": "Jie Kang"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10724.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10725",
        "start": "14:50",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "hacking_graalvm",
        "title": "Hacking on GraalVM: A (very) Rough Guide",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The GraalVM project provides, among other options, a means to deliver\nJava programs as compact, self-contained, fast-startup native images.\nGraalVM has been moving from research to development for quite a few\nyears now. However, it is only just beginning to be properly integrated\nwith the latest OpenJDK releases and there is still much to be done to\nget it fully productized and to improve usability and performance.<\/p>\n\n<p>This talk will recount our joint experiences of trying to add new and/or\nimproved capabilities to the the GraalVM code base. Our story will\nstumble gracelessly from one pitfall to the next cock-up in the hope\nthat by exposing and explaining our own history of lamentable error and\noccasional failure you will be able to avoid being doomed to repeat it.<\/p>\n\n<p>We will provide a guide to getting started and building GraalVM, an\noverview of the how the compiler, native image generator and other\nelements of the GraalVM toolkit operate plus a map of what code sits\nwhere in the source tree and how it fits together and offer tips for\ndebugging the Graal compiler and native image generator -- all the tasks\nyou will need to perform in order to attain a vantage point from which\nto change or add to the current functionality.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "742",
            "value": "Andrew Dinn"
          },
          {
            "_id": "7378",
            "value": "Josh Matsuoka"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10725.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10726",
        "start": "15:20",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "reducing_gc_times",
        "title": "Reducing OpenJDK Java Garbage Collection times with stack allocation",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we'll explore ways that the JVM can reduce the object allocation rate of Java programs automatically by performing stack allocation of objects that are known to be local to a method, or in compiler terms non-escaping. The discussion is focused on employing the escape analysis optimization in the OpenJDK Hotspot C2 compiler to determine which Java objects can be stack allocated, and how this optimization can reduce pressure on the Java JVM garbage collectors.<\/p>\n\n<p>We'll show some results on how various real world applications can benefit from such optimizations and describe the methodology of how we prototyped this in OpenJDK. Our work is only in prototype state at this moment and we are looking for more data to understand how broadly applicable this optimizations is. This work wouldn't be possible without free open source access to Java.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7375",
            "value": "Nikola Grcevski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10726.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10727",
        "start": "15:50",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "g1",
        "title": "G1: To infinity and beyond",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Abstract: G1 has been around for quite some time now and since JDK 9 it\nis the default garbage collector in OpenJDK. The community working on G1\nis quite big and the contributions over the last few years have made a\nsignificant impact on the overall performance. This talk will focus on\nsome of these features and how they have improved G1 in various ways. We\nwill also take a brief look at what features we have lined up for the\nfuture.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7376",
            "value": "Stefan Johansson"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10727.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10728",
        "start": "16:20",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "jit2020",
        "title": "Just-in-time compiling Java in 2020",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Client compiler, server compiler, JVMCI, Graal ... What are we using today and how do they work together?\nIn this talk I'll give and overview of the Just-in-time compilers included in OpenJDK and explain how to play with them.\nI'll also address Just-in-time compiler threads and resource related issues.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7380",
            "value": "Martin Doerr"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10728.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10729",
        "start": "16:50",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "npes",
        "title": "Helpful NullPointerExceptions - The little thing that became a JEP",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>One of the most prevalent - if not the most prevalent - exception type in Java is the NullPointerException. While Java set out to overcome the possibilities\nto do the mistakes one can do when programming in languages like C/C++ by not exposing pointers in the Java language, the misleading term 'pointer' sneaked\ninto this exception. To this day, NullPointerExceptions thrown by the runtime system didn't contain messages. All you had was a callstack and a line number.\nBut in typical expressions and statements there are several dereferences where an NPE can occur in one line.<\/p>\n\n<p>We - some engineers in the SAP team - thought this could be helped by a little enhancement. The new NPE message gives precise information about the location\nand tries to explain what was going on when a null reference was encountered. However, due to its prominent nature, it eventually became a JEP.<\/p>\n\n<p>In my talk I'll demonstrate the improvements that come with this enhancement. I will lift the hood a little and provide a glance at its implementation details.\nAnd finally I'll say some words about the current status and share some ideas for further improvements in the area of exception messages.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7379",
            "value": "Christoph Langer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10729.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10730",
        "start": "17:20",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "metaspace",
        "title": "Taming Metaspace: a look at the machinery, and a proposal for a better one",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>When examining memory footprint of a JVM process, the delta between Java\nheap usage and actual working set size can be surprisingly large. The JVM\nuses off-heap memory for a lot of things: thread stacks, compiler arenas,\ncode heap, byte buffers, GC control... however, one of the largest\nconsumers of off-heap memory can be class metadata. Class metadata are\nstored in Metaspace, which includes the Compressed Class Space.<\/p>\n\n<p>The talk will explore what Metaspace actually is and what is stored there;\ndescribe the architecture of the Metaspace allocator and the Compressed\nClass Space; how it interacts with the GC; how it is sized. We will\nhighlight waste areas and demonstrate how to use jcmd to examine Metaspace\ninternals.<\/p>\n\n<p>The current implementation of the Metaspace allocator suffers from a number\nof shortcomings. They can manifest in excessive waste and a certain\n\"clinginess\" - an unwillingness to let go of unused memory.<\/p>\n\n<p>At SAP, we developed an improved version which is more frugal with memory\nand provides a much improved elasticity. So the second part of this talk\nwill concentrate on our new implementation. We will highlight the\ndifferences to the old architecture, demonstrate advantages and examine how\nit works.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7381",
            "value": "Thomas Stüfe"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10730.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10731",
        "start": "17:50",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "secure_jvm",
        "title": "The OpenJDK JVM : Securing a moving target or What could possibly go wrong?",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The OpenJDK Java Virtual Machine presents some interesting challenges\nwhen it comes to guarding against potential vulnerabilities. This talk\nwill explain how dynamic class-loading, JIT compilation, speculative\ncompilation and other aspects of the JVM's operation present a moving\nattack surface that presents some very different challenges to those\nfound in other programs or runtimes.<\/p>\n\n<p>This talk won't say anything about specific vulnerabilities but it will\nidentify a few areas of the OpenJDK JVM where some of these unique types\nof vulnerability have been identified and resolved. It may teach you\nsome things you didn't know about the complexity of the JVM and\nhopefully reassure you that the OpenJDK devs are very aware of what\ncould possibly go wrong. Whether we have got it all right is left as a\nfollow-up exercise for attendees.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "742",
            "value": "Andrew Dinn"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10731.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10719",
        "start": "18:20",
        "duration": "00:40",
        "room": "H.1302 (Depage)",
        "slug": "ruby",
        "title": "JRuby Startup and AOT",
        "subtitle": [],
        "track": "Free Java",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Rubyists work from a command line, which makes JRuby startup time a critical concern. Traditionally, the JVM has not been optimized for startup, but that's changing. This talk will explore all available options for making a heavy runtime like JRuby start up quickly, from using class data caching services like Hotspot's CDS and OpenJ9's Quickstart to ahead-of-time compilation of JRuby using GraalVM's Native Image. We'll compare approaches and trade-offs.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "743",
            "value": "Charles Nutter"
          },
          {
            "_id": "4501",
            "value": "Thomas Enebo"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10719.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.1308 (Rolin)",
    "event":
    [
      {
        "_id": "9957",
        "start": "10:30",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "fundamental_technologies_we_need_to_work_on_for_cloud_native_networking",
        "title": "Fundamental Technologies We Need to Work on for Cloud-Native Networking",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Many people and companies are betting that cloud-native networking\nwill be the preferred way of implementing network functions in an easy\nand scalable way. It is based around the tenants of modularity, high\navailability, scalability, low-overhead networking, and ease of\ndeployment. And a number of companies such as Google has shown that it\nis really possible to achieve these properties with it. But the\narchitectural basis of cloud-native is quite different from the ones\nof virtualization-based NFV, but nevertheless, in many cases we\ncontinue to use the software packages that were designed for that\ndrastically different architecture. The question is, how well does\nthe current set of open source projects used in NFV work in a\ncloud-native environment and what needs to change in them in order to\nrealize the cloud-native vision?<\/p>\n\n<p>In this presentation, I will define what I mean with cloud-native\nnetworking and from that derive the system requirements needed to realize\nthat vision. Based on these requirements, we can deduce a number of\nbasic architectural properties, features and services that are needed\nin the system to be able to satisfy these requirements. Then I will go\nthrough the most popular open source projects such as Linux, DPDK and\nOVS and see how they satisfy these architectural properties and\nfeatures. The main contribution of this presentation will be to show\nwhat we need to work on within these SW packages in order to realize\ncloud-native networking. Or maybe we need completely new SW projects\nto be able to achieve this.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4937",
            "value": "Magnus Karlsson"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9957.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9388",
        "start": "11:10",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "real_time_network_topology_and_protocols_analyzer",
        "title": "Skydive",
        "subtitle": "A real time network topology and protocols analyzer",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Skydive is an open source real-time network topology and protocols analyzer providing a comprehensive way of understanding what is happening in your network infrastructure.<\/p>",
        "description": "<p>Skydive is a toolbox to monitor, visualize and troubleshoot an infrastructure.<\/p>\n\n<p>It first collects all the information about the physical and logical infrastructure : network interfaces, Linux and Openvswitch bridges, network namespaces, Docker/runc containers, Kubernetes objects, virtual machines and more. All these objects are stored into a graph to allow the operator to visualize and query the whole topology. On top of this, Skydive is able to inject, capture and analyze traffic at any point of this infrastructure - using various technics such as AFpacket, eBPF, DPDK or SFlow samples. This make possible use cases like :<\/p>\n\n<pre><code>• troobleshoot dropped packets\n\n• get metrics and bandwidth about some specific traffic\n\n• trigger alert on some abnormal traffic detection\n\n• get latency on the whole path of a flow\n\n• and a lot more...\n<\/code><\/pre>\n\n<p>Skydive is agnostic to any SDN, container orchestration engine or virtualization platform. That being said, Skydive has plugins for specific technologies such as Kubernetes/Istio, OpenStack, Openvswitch, Network Service Mesh, OpenContrail, VPP and more.<\/p>\n\n<p>This presentation will present the architecture of Skydive and demonstrate some use cases through a demo.<\/p>",
        "persons":
        [
          {
            "_id": "476",
            "value": "Sylvain Baubeau"
          },
          {
            "_id": "7383",
            "value": "Sylvain Afchain"
          }
        ],
        "links":
        [
          {
            "_href": "https://skydive.network",
            "value": "Project website"
          },
          {
            "_href": "https://github.com/skydive-project/skydive",
            "value": "Project source code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9388.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10014",
        "start": "11:30",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "do_you_really_see_whats_happening_on_your_nfv_infra",
        "title": "Do you really see what’s happening on your NFV infrastructure?",
        "subtitle": "(and what can you do about it?)",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As CoSP’s accelerate their adoption of SDN and NFV technologies, the increased need for metrics, performance measurement and benchmarking becomes a focus, to ensure the continued delivery of “best in class” services. As NFV environments have grown in size and complexity, the tools required to gain this greater visibility into the NFVi need to continue to evolve to meet the requirements for manageability, serviceability and resiliency.<\/p>\n\n<p>Using Collectd as a metrics collection tool, OPNFV Barometer monitors the performance of the NFVi resources and has the capability to expose these insights via open industry standard interfaces to analytics or MANO components for potential enforcement or corrective actions.  Barometer works with related open source technologies and communities (collectd, DPDK, OpenStack, Prometheus, SAF, etc.) to provide numerous metrics and events that address various different use cases such as service healing, power optimization and ensuring application QoS.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "5016",
            "value": "Emma Foley"
          },
          {
            "_id": "7040",
            "value": "Krzysztof Kepka"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10014.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10119",
        "start": "12:10",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "endless_network_programming",
        "title": "Endless Network Programming − An Update from eBPF Land",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Linux kernel networking capabilities have been undergoing major changes over the last years. At the heart of the performance gain, eBPF (extended Berkeley Packet Filter) and XDP (eXpress Data Path) have brought new possibilities in terms of tracing and network packet processing. eBPF is a trendy topic in the Linux world, and today it needs little introduction among the SDN and NFV community. But the technology is still under heavy development, bringing new features, more flexibility, and better performance to the users. This presentation is an update on the latest evolutions in the eBPF world!<\/p>\n\n<p>Many of those changes occur directly inside the eBPF subsystem architecture. New program types are being added. Early constraints such as the maximal number of instructions for programs, or the unavailability of loops, are changing. The internals are improved with support for debug information (BTF) or 32-bit instructions. And many new mechanisms are implemented, such as global data support, the “BPF trampoline”, batched map operations (in progress), XDP program chaining (in progress). Let's review all the latest trends in eBPF kernel development!<\/p>\n\n<p>But beyond kernel code, eBPF has grown as a full ecosystem, with a variety of tools used to work with it, or to build upon it. Bpftool, a reference utility to manage eBPF programs, keeps evolving. The networking projects using eBPF keep growing in number (e.g. Katran, Suricata, Sysdig, Hubble, Libkefir) or in features (e.g. Cilium). Let's review (briefly) some of those projects that assert eBPF as one of the essential fast dataplane solutions in the Linux world.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4933",
            "value": "Quentin Monnet"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10119.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10134",
        "start": "12:30",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "replacing_iptables_with_ebpf",
        "title": "Replacing iptables with eBPF in Kubernetes with Cilium",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Michal Rostecki is a Software Engineer working at SUSE. He's working on Cilium, both upstream and on integrating it with openSUSE Kubic Project and SUSE CaaS Platform.<\/p>\n\n<p>Swaminathan Vasudevan is a Software Engineer working at SUSE. Worked on Neutron Networking Upstream and currently migrating to Cilium and openSUSE Kubic Project and SUSE CaaS Platform.<\/p>",
        "description": "<p>Cilium is an open source project which provides networking, security and load balancing for application services that are deployed using Linux container technologies by using the native eBPF technology in the Linux kernel.\nIn this presentation we would talk about:\n- The evolution of the BPF filters and will explain the advantages of eBPF Filters and its use cases today in Linux especially on how Cilium networking utilizes the eBPF Filters to secure the Kubernetes workload with increased performance when compared to legacy iptables.\n- How Cilium uses SOCKMAP for layer 7 policy enforcement\n- How Cilium integrates with Istio and handles L7 Network Policies with Envoy Proxies.\n- The new features since the last release such as running Kubernetes cluster without kube-proxy, providing clusterwide NetworkPolicies, providing fully distributed networking and security observability platform for cloud native workloads etc.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4449",
            "value": "Michal Rostecki"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10134.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10114",
        "start": "12:50",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "analyzing_dpdk_applications_with_ebpf",
        "title": "Analyzing DPDK applications with eBPF",
        "subtitle": "Sharpening the toolset",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>One of the challenges of doing software network applications is observing the inputs, outputs, and what the application is doing with them. Linux provides a rich tool set with eBPF but integrating this into a DPDK application is challenging. The DPDK libraries for capturing is incomplete which leads to lots of time debugging the tools. This talk addresses these issues, recommends solutions and proposes enhancements to make developers live easier.<\/p>",
        "description": "<p>The DPDK provides a limited form of packet capture, but it only works on a single interface with no filtering and inaccurate timestamps.\nI go over  what packet capture does now, how it can be improved, and how it can be integrated with other tracing.<\/p>\n\n<p>This talk is an extension of the talk  (based on community feedback) given in 2019 at the DPDK userspace summit.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2453",
            "value": "Stephen Hemminger"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10114.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10091",
        "start": "13:10",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "xdp_and_page_pool_api",
        "title": "XDP and page_pool API",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>XDP support is an increasing trend on the network devices. XDP main goal is\nprocessing packets at the lowest point in the software stack avoiding\noverheads. Memory recycling of received buffers achieved through\nthe in kernel page<em>pool API plays a fundamental role in the increased performance.\nAdding XDP support on a driver can be non-trivial. In this talk we'll demonstrate\nhow porting a standard ethernet driver (mvneta/netsec) to XDP and the page<\/em>pool API can\nboost performance.\nPart of the page_pool evolution involves adding the recycling support\nin the kernel's SKB stack and leverage the increased performance\nattributes of the API.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7082",
            "value": "Ilias Apalodimas"
          },
          {
            "_id": "7382",
            "value": "Lorenzo Bianconi"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10091.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10662",
        "start": "13:30",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "weave_net_an_open_source_container_network",
        "title": "Weave Net, an Open Source Container Network",
        "subtitle": "Five years with no central point of control",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A tour of the internals of Weave Net, one of the most popular container networks:\ndesign challenges and lessons learned from five years in the wild. Including\nKubernetes integration and how CNI was born.<\/p>\n\n<p>Weave Net is written in Go, using many Linux kernel features such as veths, bridges and iptables.\nAimed at developers rather than network engineers, Weave Net tries to be self-configuring and\nfind the best available transport between nodes. The control plane operates via gossip,\nwith no central point of control.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4278",
            "value": "Bryan Boreham"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10662.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9704",
        "start": "14:10",
        "duration": "00:50",
        "room": "H.1308 (Rolin)",
        "slug": "rethinking_kubernetes_networking_with_srv6",
        "title": "Rethinking kubernetes networking with SRv6 and Contiv-VPP",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kubernetes (k8s) is currently the de-facto standard for containers orchestration. However, K8s does not provide any solution for handling containers networking. Instead, it offloads the networking to third-party certified plugins called CNI plugins. Contiv-VPP is a k8s CNI plugin that offers fast I/O by leveraging the carrier-grade capabilities of VPP and DPDK in the dataplane.<\/p>\n\n<p>The adoption of containers and microservices calls for IPv6 to provide addressing and reachability for such massive number of endpoints. SRv6 leverages the IPv6 dataplane to provide overlay networking, traffic engineering, load balancing, network policy and service chaining.<\/p>\n\n<p>In this talk, we present an SRv6-based solution for k8s networking. We will show how SRv6 is used for pod-to-pod communication, k8s services and service function chaining (SFC), and how SRv6 solves several k8s networking challenges. We will also show the integration of our solution in Contiv-VPP. This solution is the result of combined effort between Bell Canada, Cisco and Pantheon.tech.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "5984",
            "value": "Ahmed Abdelsalam"
          },
          {
            "_id": "7052",
            "value": "Miroslaw Walukiewicz"
          },
          {
            "_id": "7408",
            "value": "Filip Gschwandtner"
          },
          {
            "_id": "7409",
            "value": "Daniel Bernier"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9704.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9795",
        "start": "15:00",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "akraino_edge_kni_blueprint",
        "title": "Akraino Edge KNI blueprint",
        "subtitle": "A Kubernetes Native Infrastructure approach to the Edge",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Blueprints in the Kubernetes-Native Infrastructure Blueprint Family leverage the best-practices and tools from the Kubernetes community to declaratively manage edge computing stacks at scale and with a consistent, uniform user experience from the infrastructure up to the services and from developer environments to production environments on bare metal or on public cloud.<\/p>\n\n<p>All blueprints in this family share the following characteristics:<\/p>\n\n<ul>\n<li>K8s Machine API: declarative API to manage a configure the infrastructure of a cluster.<\/li>\n<li>Operator Framework: automated and secure lifecycle of applications running on the edge stack.<\/li>\n<li>Kubernetes-native workloads: allowing the mix of CNFs and VM-based workloads via Kubevirt.<\/li>\n<\/ul>\n\n\n<p>Come and see the leading edge!<\/p>",
        "description": "<p>Launched in 2018, Akraino Edge Stack aims to create an open source software stack that supports high-availability cloud services optimized for edge computing systems and applications.<\/p>\n\n<p>As part of the Akraino project, Kubernetes-Native-Infrastructure blueprint family represents the reference edge stack managed as a declarative platform, where controllers monitor a system for deviations between the user-declared target state and reality and take corrective\nactions to reconcile reality with the declared target state.<\/p>\n\n<p>KNI blueprints cover up two different use cases:<\/p>\n\n<ul>\n<li><p>Provider Access Edge: as part of the network transformation, telco operators are moving to run its radio access network in a cloud-native manner. Technologies like vRAN will be only possible with a declarative approach, and leveraging open networking best practices.<\/p><\/li>\n<li><p>Industrial Edge: workloads such IoT, AI/ML, AR/VR, and ultra-low latency control will be run in the edge. These workloads will require specific hardware such GPUs and FPGAs. KNI can show how this needs can be a reality today.<\/p><\/li>\n<\/ul>\n\n\n<p>With Kubernetes Native Infrastructure learn about the k8s way of managing infrastructure. By defining a declarative state, the edge administrator will be able to manage thousands of sites by following an innovative GitOps approach.<\/p>\n\n<p>If you are interested in these exciting topics, don't miss the talk!<\/p>",
        "persons":
        [
          {
            "_id": "5262",
            "value": "Yolanda Robla Mota"
          },
          {
            "_id": "5936",
            "value": "Ricardo Noriega"
          }
        ],
        "links":
        [
          {
            "_href": "https://oglok.github.io/2019-09-26-Akraino-Edge-KNI/",
            "value": "Blogpost about Akraino KNI"
          },
          {
            "_href": "https://www.lfedge.org/projects/akraino/release-1/kubernetes-native-infrastructure-provider-access-edge/",
            "value": "Akraino Wiki for KNI PAE"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9795.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9500",
        "start": "15:40",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "fast_quic_sockets_for_cloud_networking",
        "title": "Fast QUIC sockets for cloud networking",
        "subtitle": "Using vector packet processing for QUIC acceleration and offload",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>QUIC was introduced by Google to move the transport protocol implementation out of the kernel, and is now being standardized in the IETF. It provides both encryption and multiplexing, and will be the default transport for HTTP/3. In this talk we'll present the work we've done investigating whether QUIC would benefit from vectorized packet processing, the impact it has on performance and how it can be consumed by external applications.<\/p>\n\n<p>VPP (vector packet processing) is a fast network data plane, part of the Linux Foundation FD.io project providing fast network functions on top of DPDK. It provides an optimized support of TCP &amp; UDP allowing significant performance improvements. In this presentation, we'll discuss:<\/p>\n\n<ul>\n<li>How we took advantage of the open source protocol implementation quicly and vpp's hoststack, to implement fast QUIC sockets.<\/li>\n<li>How this can be consumed by external applications and to what ends.<\/li>\n<li>What this enables regarding hardware and software offloads.<\/li>\n<\/ul>",
        "description": [],
        "persons":
        [
          {
            "_id": "6508",
            "value": "Nathan Skrzypczak"
          },
          {
            "_id": "6509",
            "value": "Aloys Augustin"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9500.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9813",
        "start": "16:20",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "mixing_kool_aids",
        "title": "Mixing kool-aids! Accelerate the internet with AF_XDP & DPDK",
        "subtitle": [],
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>\"With its recent advancements, AF<em>XDP is gaining popularity in the high performance packet processing space. As a result, existing frameworks for packet processing, such as DPDK, are integrating AF<\/em>XDP support to provide more options for moving packets to user space applications. The challenge with such integration is that both AF_XDP and frameworks like DPDK have their own assumptions and constraints about such things as, for example, how to align or manage packet buffers, making the integration less straight forward than it might appear at first glance.<\/p>\n\n<p>This talk takes a look at the usability of AF<em>XDP pre-kernel v5.4, before diving into the recent challenges we encountered when integrating DPDK and AF<\/em>XDP, and how we made changes (on both sides) to allow the two to work together in a much more seamless manner.\"<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "5135",
            "value": "Ciara Loftus"
          },
          {
            "_id": "6005",
            "value": "Kevin Laatz"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9813.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9269",
        "start": "16:40",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "dial_your_networking_code_up_to_11",
        "title": "Dial your Networking Code up to 11",
        "subtitle": "Vectorizing your network app to break the performance barrier",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Modern CPUs provide a wide variety of Single-instruction-multiple-data (SIMD) instructions, or vector instuctions, for operating on larger blocks of data than with regular instructions. Though thought of by many programmers primarily as instructions for doing calculations in parallel on arrays of data, these vector instructions can actually be used in other ways to accelerate packet processing applications. This talk goes through a number of examples in open-source projects, such as DPDK and OVS, where vector instructions have been used to boost performance significantly, and explains the general techniques used that can be applied to other applications.<\/p>",
        "description": "<p>The talk focuses on the work done on DPDK and OVS to leverage the SSE and AVX instruction sets for packet acceleration. It shows how the different tasks to be performed in those applications can be mapped to SIMD instructions, and presents general guidelines on how to think about packet processing work from a vectorization viewpoint. It also discusses some considerations in application design so as to allow the app to run with best performance on a variety of platforms, each of which may have different instruction sets available.<\/p>",
        "persons":
        [
          {
            "_id": "6263",
            "value": "Bruce Richardson"
          },
          {
            "_id": "6588",
            "value": "Harry van Haaren"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9269.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9502",
        "start": "17:20",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "userspace_networking_how_to_have_your_cake_and_eat_it_too_thanks_to_rdma",
        "title": "Userspace networking: beyond the kernel bypass with RDMA!",
        "subtitle": "Using the RDMA infrastructure for performance while retaining kernel integration",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While userspace networking has demonstrated great performance benefits, it does come with greater complexity than kernel networking.<\/p>\n\n<p>In parallel, Remote Direct Memory Access (RDMA) was developed as an efficient way to move data in HPC and storage clusters with great success.<\/p>\n\n<p>Key properties of this technology are also highly desirable for userspace networking: native integration with the operating system (OS), OS bypass and a very efficient software interface.\nRDMA-capable network adapters are now enabling standard Ethernet networking functions through the RDMA interface, allowing userspace networking software such as <a href=\"https://fd.io\">VPP<\/a> to achieve extreme performance while integrating transparently with the OS.<\/p>\n\n<p>We'll present:<\/p>\n\n<ul>\n<li>the RDMA Ethernet concepts, architecture and interfaces<\/li>\n<li>how VPP leverages it<\/li>\n<li>the problems solved by this architecture and the usecase it enables<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6539",
            "value": "Benoît Ganne"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9502.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9734",
        "start": "17:40",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "vita_high_speed_traffic_encryption_on_x86_64",
        "title": "Vita: high-speed traffic encryption on x86_64 with Snabb",
        "subtitle": "Coming to your cloud with XDP, AVF, and Kubernetes integration",
        "track": "Software Defined Networking",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Vita is a high-performance IPsec VPN gateway designed with medium and large network operators in mind. It is written in a high-level language (Lua) using the Snabb networking toolkit and achieves high performance via networking in userspace, i.e. bypassing the kernel network stack.<\/p>\n\n<p>This talk will discuss Vita and how it was developed using Snabb. Topics include: fast software networking using a dynamic, high-level language; cryptographic ciphers implemented in software software accelerated by x86 extensions; modern cryptography; limiting complexity; multi-core scaling; YANG enabled control planes; minimalist NIC drivers.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6923",
            "value": "Max Rottenkolber"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/inters/vita/#-",
            "value": "Vita project page"
          },
          {
            "_href": "https://blog.ipspace.net/2019/02/high-speed-ipsec-on-snabb-switch-on.html",
            "value": "High-Speed IPsec with Snabb on Software Gone Wild"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9734.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.1309 (Van Rijn)",
    "event":
    [
      {
        "_id": "10654",
        "start": "10:30",
        "duration": "00:05",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_opening",
        "title": "DNS Devroom Opening",
        "subtitle": [],
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the DNS DevRoom<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "1325",
            "value": "Shane Kerr"
          },
          {
            "_id": "3076",
            "value": "Pieter Lexis"
          },
          {
            "_id": "3270",
            "value": "Peter van Dijk"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10654.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10207",
        "start": "10:35",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_openstack",
        "title": "DNS Management in OpenStack",
        "subtitle": "What is the OpenStack DNS API?",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>All major clouds have integrated DNS management these days, and OpenStack is one of them. We will run through the OpenStack DNS (Designate) project - how it works, why we laid it out the way we did, how you can use it, and how other OpenStack components can leverage it.<\/p>",
        "description": "<p>We will run through the general architecture of the project, and show how we can remain a simple control layer over multiple DNS servers and service providers.<\/p>\n\n<p>We will show how you can run Designate stand alone, as a multi tenant API for managing DNS inside your company, and how you can use the ability to have multiple pools of servers available for multiple purposes.<\/p>\n\n<p>Finally we will show the myriad of both OpenStack and other Open Source software integrations for DNS management, and DNS-01 ACME validation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2777",
            "value": "Graham Hayes"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.openstack.org/designate/latest/",
            "value": "Project Docs"
          },
          {
            "_href": "https://docs.openstack.org/api-ref/dns/",
            "value": "OpenStack DNS API"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10207.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10508",
        "start": "11:10",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_hashdns",
        "title": "HashDNS and FQDNDHCP",
        "subtitle": "IPv6 DNS configuration made easy",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Would you like a DNS server for IPv6 where adding a new node is as simple as typing in its name?\nIf the answer is yes, try HashDNS.<\/p>",
        "description": "<p>IPv6 autoconfiguration methods can give addresses to interfaces but do not provide any means of configuring the DNS. So autoconfiguration is suitable for clients. If a host has to act as a server, it must have a fully qualified domain name and the DNS service has to map its name to its IP address.<\/p>\n\n<p>In the Internet of Thread scenario, the number of network nodes can be orders of magnitude higher than before, as each process or thread can be a node. This idea of hash based IPv6 addresses is a viable solution to the problem to manage the DNS resolution in IoTh environments.<\/p>\n\n<p>The host part of an IPv6 address can be computed as the result of a hash function computer on the fully qualified domain name.<\/p>\n\n<p>In this way it is possible to write a DNS server able to resolve the addresses of any hostname in a sub-domain provided the network prefix of that sub-domain.<\/p>\n\n<p>The installation of a new node of the network (computer, namespace, IoTh process) is as simple as providing it with its IPv6 address (the one obtained by concatenating the network prefix and the host address computed by the hash function).<\/p>\n\n<p>There is no need to change the configuration of the DNS.<\/p>\n\n<p>Actually the installation of a new node (or its renaming) is even simpler than that. The host can use a DHCP service designed to get the right address from the DNS server given its fully qualified domain name.<\/p>\n\n<p>So a system administrator has nothing to do more than assigning the new node its name. (They have just to baptize the new node)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2639",
            "value": "Renzo Davoli"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/rd235/vde_dnsutils",
            "value": "dnsultils project"
          },
          {
            "_href": "http://wiki.virtualsquare.org/",
            "value": "virtualsquare"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10508.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10347",
        "start": "11:45",
        "duration": "00:20",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_djbdnscurve",
        "title": "State of djbdnscurve6",
        "subtitle": "IPv6 LLU address support",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The fehQlibs and djbdnscurve6 provide both a DNS library which support IPv6 LLU addresses. The inclusion and use of IPv6 LLU addresses is discussed. While the typical Unix /etc/resolv.conf is applied system-wide and the Microsoft Window's pendent works interface-dependent, here application specific DNS settings can be used.<\/p>",
        "description": "<p>Overview:\n1. Background and heritage on fehQlibs and djbdnscurve6\n2. Application specific DNS resolver settings\n3. Integration of IPv6 LLU addresses - benefits\n4. Integration of IPv6 LLU addresses - recipe\n5. Outlook and future challenges<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6793",
            "value": "Erwin Hoffmann (feh)"
          }
        },
        "links":
        [
          {
            "_href": "https://www.fehcom.de/ipnet/djbdnscurve6.html",
            "value": "DJBDNSCurve6"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10347.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9451",
        "start": "12:10",
        "duration": "00:20",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_doh_dot_testing",
        "title": "Testing DoH and DoT servers, compliance and performance",
        "subtitle": [],
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Of course, encrypting DNS is necessary for privacy and security, like\nfor every other Internet protocol. That's why DoT and DoH deployment\nis very important, so that users could safely go to a resolver they\ntrust. Now, it is time to assert the technical compliance and\nperformance of these trusted resolvers. We will talk about the things\nthat could and should be tested against DoT and DoH servers and how to\nimplement it. We will then discuss performance measurements, specially\nwith the opportunities brought by parallelism (both in DoT and DoH)\nand the challenges they create for measurements.\nThis talk will be inspired by the development of a tool which is, at\nthis stage, in a very alpha state.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5216",
            "value": "Stéphane Bortzmeyer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9451.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10142",
        "start": "12:35",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_bind9_codequality",
        "title": "Improving BIND 9 Code Quality",
        "subtitle": "Why is concurrent programming so hard?",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>BIND 9 consists of a huge and old codebase. In this talk, I would like you to show all the available tools that we use on regular basis to improve, refactor and make the BIND 9 code safer. I'll show the examples of various Google/LLVM Sanitizers, cppcheck, LLVM scan-build and semantic patching using coccinelle.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2795",
            "value": "Ondřej Surý"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10142.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9328",
        "start": "13:10",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_unwind",
        "title": "unwind(8)",
        "subtitle": "A privilege-separated, validating DNS recursive nameserver for every laptop",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>DNS is easy. You type fosdem.org in your browser's address bar, hit enter and you will be greeted by your favorite open-source event's start page. Actually...<\/p>",
        "description": "<p>We will introduce unwind(8) - an always-running, validating DNS recursive nameserver, answering queries on localhost (127.0.0.1). We will explain its privilege-separated design and show that it is secure to run this daemon by default. We will then show how its novel approach of observing changes in network location and actively probing the quality of the local network improve the user experience in DNS resolution. The focus will be on laptops that move through many networks, some good, some bad, some outright hostile.<\/p>\n\n<p>We will compare unwind(8) to prior solutions and show how its design enables it to run without user intervention.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6635",
            "value": "Florian Obser"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9328.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9415",
        "start": "13:45",
        "duration": "00:15",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_catz",
        "title": "extending catalog zones",
        "subtitle": "auto-maintain DNS servers",
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6710",
            "value": "Leo Vandewoestijne"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9415.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10611",
        "start": "14:05",
        "duration": "00:20",
        "room": "H.1309 (Van Rijn)",
        "slug": "dns_minimizing_any",
        "title": "The Different Ways of Minimizing ANY",
        "subtitle": [],
        "track": "DNS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The DNS Protocol has features that have grown to become liabilities.  The query type \"ANY\" is one.  Earlier this year a published RFC document describes how a DNS server may respond to such queries while reducing the liability.  But the document does not define a definitive means for a server to signal that it is differing from the original protocol.  This presentation measures of the impact of having no definitive means specified and examines the \"fear, uncertainty, and doubt\" of lacking explicit signals.<\/p>",
        "description": "<p>The \"minimal ANY responses\" RFC (Providing Minimal-Sized Responses to DNS Queries That Have QTYPE=ANY, a.k.a. RFC 8482) results in about 1% of the TLD nameservers indicating they are minimizing ANY responses.\n That's (only) about 250 cases.\n What is troubling is that there are about 9 different responses observed to indicate the response is \"minimized\"\n 9 different ways in just 250 samples, \"fuzzing\" the protocol\n The morale of this tale is that \"fuzzying\" the protocol is worrisome.  (Not that minimizing ANY is a bad thing.)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6128",
            "value": "Edward Lewis"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10611.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10552",
        "start": "15:00",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_boomerang_optimisation",
        "title": "Check Yourself Before You Wreck Yourself",
        "subtitle": "Auditing and Improving the Performance of Boomerang",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Boomerang is an open-source Real User Monitoring (RUM) JavaScript library used by thousands of websites to measure their visitor's experiences. The developers behind Boomerang take pride in building a reliable and performant third-party library that everyone can use without being concerned about its measurements affecting their site.  We recently performed and shared an audit of Boomerang's performance, to help communicate its \"cost of doing business\", and in doing so we found several areas of code that we wanted to improve. We'll discuss how we performed the audit, some of the improvements we've made, how we're testing and validating our changes, and the real-time telemetry we capture for our library to ensure we're having as little of an impact as possible on the sites we're included on.<\/p>",
        "description": "<p>Boomerang is an open-source Real User Monitoring (RUM) JavaScript library used by thousands of websites to measure their visitor's experiences.<\/p>\n\n<p>Boomerang runs on billions of page loads a day, either via the open-source library or as part of Akamai's mPulse RUM service.  The developers behind Boomerang take pride in building a reliable and performant third-party library that everyone can use without being concerned about its measurements affecting their site.<\/p>\n\n<p>Recently, we performed and shared an audit of Boomerang's performance, to help communicate the \"cost of doing business\" of including Boomerang on a page while it takes its measurements.  In doing the audit, we found several areas of code that we wanted to improve and have been making continuous improvements ever since.  We've taken ideas and contributions from the OSS community, and have built a Performance Lab that helps \"lock in\" our improvements by continuously measuring the metrics that are important to us.<\/p>\n\n<p>We'll discuss how we performed the audit, some of the improvements we've made, how we're testing and validating our changes, and the real-time telemetry we capture on our library to ensure we're having as little of an impact as possible on the sites we're included on.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7299",
            "value": "Nic Jansma"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/akamai/boomerang",
            "value": "Boomerang on Github"
          },
          {
            "_href": "https://nicj.net/an-audit-of-boomerangs-performance/",
            "value": "Boomerang Performance Audit"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10552.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9742",
        "start": "15:40",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_qoe_research",
        "title": "Metrics and models for Web performance evaluation",
        "subtitle": "or, How to measure SpeedIndex from raw encrypted packets, and why it matters",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The World Wide Web is still among the most prominent Internet applications. While the Web landscape has been in perpetual movement since the very beginning,\nthese last few years have witnessed some noteworthy proposals such as SPDY, HTTP/2 and QUIC, which profoundly reshape the application-layer protocols family.\nTo measure the impact of such changes,  going beyond the classic W3C notion of page load time, a number of Web  performance metrics has been proposed (such as\nSpeedIndex,  Above-The-Fold and variants).  At the same time, there is still a limited amount of understanding on how these metrics correlate with the user\nperception (e.g., such as user ratings, user-perceived page load time, etc.). In this talk, we discuss the state of the art in metrics and models for Web\nperformance evaluation, and their correlation with user experience through several real-world studies. Additional information, software and datasets are\navailable at https://webqoe.telecom-paristech.fr<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6928",
            "value": "Dario Rossi"
          }
        },
        "links":
        [
          {
            "_href": "https://webqoe.telecom-paristech.fr",
            "value": "https://webqoe.telecom-paristech.fr"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9742.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10539",
        "start": "16:20",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_font_loading",
        "title": "Hint, Hint, Font Loading Matters!",
        "subtitle": "Fonts are lovely but can slow down our loads. How can we make them faster?",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We all love fonts. From Google Fonts to Typekit, Hoefler&amp;Co and more, they give character and tone to our websites. The down side of fonts is that they can really slow down our loads. In this talk we'll learn about common pitfalls like critical requests depth and how to use resource hints to play tricks with latency to load web applications faster. We'll walk through a network profile to understand what's going on in the browser and how to make it faster.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7292",
            "value": "Sia Karamalegos"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10539.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9304",
        "start": "17:00",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_http_prioritization",
        "title": "The ultimate guide to HTTP resource prioritization",
        "subtitle": "How to make sure your data arrives at the browser in the optimal order",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Come learn about how browsers try to guess in what order web page resources should be loaded and how servers use that information to often (accidentally) make your web page slower instead.\nWe look at what resource prioritization is, how it's often implemented terribly in modern HTTP/2 stacks and how we're trying to fix it in QUIC and HTTP/3.\nWe use clear visualizations and images to help explain the nuances in this complex topic and also muse a bit on whether prioritization actually has that large an impact on web performance.<\/p>",
        "description": "<p>HTTP/2 started the move from multiple parallel TCP connections to a single underlying pipe. QUIC and HTTP/3 continue that trend.\nWhile this reduces the connection overhead and lets congestion controllers do their work, it also means we no longer send data in a truly parallel fashion.\nAs such, we need to be careful about how exactly we send our resource data, as some files are more important than others to achieve good web performance.<\/p>\n\n<p>To help regulate this, HTTP/2 introduced a complex prioritization mechanism. Browsers use complex heuristics to try and estimate the importance of a resource and, with various success, communicate their preferences to the servers.\nIt has however become clear that this scheme does not work well in practice. Between server implementation bugs, questionable browser choices and bufferbloat in caches and network setups, HTTP/2 prioritization is sometimes more a liability than a useful feature.<\/p>\n\n<p>For this reason, this feature is being completely reworked in HTTP/3 over QUIC. However, there a whole new can of worms is opened.\nOne of QUIC's main features for improving performance over TCP is that it removes \"head of line blocking\": if one resource suffers packet loss, other can still make progress.\nThat is... if there are other resources in progress! What performs well for lossy links turns out to be exactly what to prevent for high speed connections.<\/p>\n\n<p>Along the way, we also discuss existing options for web developers to impact the browser's heuristics and server behaviour (such as resource hints (e.g., preload) and the upcoming priority hints).<\/p>\n\n<p>Finally, we question about how we got in this terrible state of things to begin with: if people made so many mistakes implementing HTTP/2 prioritization, why didn't anyone really notice until 3 years later?\nCould it be its impact on web performance is actually limited? Or have we just not seen its full potential yet?<\/p>\n\n<p>We make this complex topic approachable with plenty of visualizations and animations.\nThe content is mainly based on our own research (and papers) and that of others in the web community, such as Patrick Meenan and Andy Davies.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6615",
            "value": "Robin Marx"
          }
        },
        "links":
        [
          {
            "_href": "https://speeder.edm.uhasselt.be/www18/",
            "value": "HTTP/2 prioritization paper"
          },
          {
            "_href": "https://h3.edm.uhasselt.be/",
            "value": "HTTP/3 prioritization paper"
          },
          {
            "_href": "https://www.slideshare.net/patrickmeenan/http2-in-practice",
            "value": "Patrick Meenan's deep dive"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9304.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10356",
        "start": "17:40",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_chromium_development",
        "title": "Shipping a performance API on Chromium",
        "subtitle": "Experiences from shipping the Element Timing API",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Adding new web performance APIs to the web is a complex process. In this talk, I'll go over the steps we went through to ship the Element Timing API in Chromium, which enables measuring rendering timing of image and text content. You'll learn about the process to ship an API exposing performance information to web developers. There were many steps involved in the process: engaging with developers and other browser vendors, brainstorming, privacy and security reviews, Origin Trials, posting an Intent, and addressing questions and ideas after the API has shipped.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7214",
            "value": "Nicolás Peña Moreno"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10356.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10297",
        "start": "18:20",
        "duration": "00:35",
        "room": "H.1309 (Van Rijn)",
        "slug": "webperf_building_openspeedmonitor",
        "title": "The journey of building OpenSpeedMonitor",
        "subtitle": "Learnings from unexpectedly finding ourselves developing a FLOSS project",
        "track": "Web Performance",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Keeping track caring about web performance is hard with constantly changing standards, improving browsers, frameworks and devices.\nIt gets even harder when you develop a tool meeting these changing requirements.\nEight years ago, as an IT service provider, we were faced with the task of permanently monitoring the performance of one of the largest e-commerce platforms. After the initial use of WebPagetest, we quickly needed to develop our own features.\nWhat started as minor extensions became a separate project over time.\nIn this talk, we would like to take you on the journey we have taken developing OpenSpeedMonitor. You will hear about some unexpected challenges, what we learned the hard way and why we would have failed years ago, if we didn't decide to develop FLOSS.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7168",
            "value": "Stefan Burnicki"
          },
          {
            "_id": "7186",
            "value": "Nils Kuhn"
          }
        ],
        "links":
        [
          {
            "_href": "https://github.com/iteratec/OpenSpeedMonitor",
            "value": "Github Repository of the OpenSpeedMonitor"
          },
          {
            "_href": "https://iteratec.github.io/OpenSpeedMonitor/",
            "value": "Landing page of the OpenSpeedMonitor"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10297.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.2213",
    "event":
    [
      {
        "_id": "9422",
        "start": "10:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "olimex",
        "title": "Designing and Producing Open Source Hardware with FOSS/OSHW tools",
        "subtitle": "We will show you how easy is now to design and setup your own production of Open Source Hardware with only FOSS/OSHW tools",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We have possibility to setup small electronic assembly/production \"factory\" at our house for less than EUR 1000.\nI will try to explain every step from the design to final product:<\/p>",
        "description": "<p>We live in exciting times. It was never so easy to design and produce electronic devices like today.\nThis really unleash people's creativity.\nThe Open Source Hardware movement helps people to study, modify, improve and share designs and knowledge.\nToday we have FOSS CAD tools like KiCad to design our electronic boards.\nThere are multiply choices to manufacture PCBs even in small quantity.\nThere are lot of places to source components at low cost.\nWe have possibility to setup small electronic assembly/production \"factory\" at our house for less than EUR 1000.\nI will try to explain every step from the design to final product:<\/p>\n\n<ol>\n<li>How to design your product with KiCad<\/li>\n<li>How to generate files for production<\/li>\n<li>Where to order your PCBs<\/li>\n<li>Where to source the components for the assembly<\/li>\n<li>How to setup small \"factory\" at home at budget<\/li>\n<li>How to certify your OSHW project at OSHWA.org<\/li>\n<\/ol>\n\n\n<p>and will demonstrate Do-It-Yourself oven, solder paste printer, manual pick and place tools which could be used for production.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1641",
            "value": "Tsvetan Usunov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9422.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9797",
        "start": "10:55",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "librepcb",
        "title": "LibrePCB Status Update",
        "subtitle": "The progress of LibrePCB within the last two years",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An overview about what's new in LibrePCB since the last presentation at FOSDEM 2018, and a short live demonstration to see LibrePCB in action.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5141",
            "value": "Urban Bruhin"
          }
        },
        "links":
        [
          {
            "_href": "https://librepcb.org/",
            "value": "Website"
          },
          {
            "_href": "https://github.com/LibrePCB/LibrePCB",
            "value": "GitHub Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9797.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9894",
        "start": "11:20",
        "duration": "00:30",
        "room": "H.2213",
        "slug": "freecad",
        "title": "Open-source design ecosystems around FreeCAD",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A walk through the different ways in which people from different areas and backgrounds use a same application (FreeCAD), and the impact this has on their workflows, and even on FreeCAD development<\/p>",
        "description": "<p>The FreeCAD project gathers a community of developers and users coming from a very large array of specialties: Makers, mechanical engineers, civil engineers, electronics engineers, architects, opticians, graphic designers, etc. All these people using the same software is a unique opportunity to explore and build cross-discipline workflows, and have people coming from one field learn unusual ways from other fields. This constant interchange of paradigms also influences FreeCAD development itself, and connects it to other fields and applications too, to create larger ecosystems. In this talk, we will show some examples of how this happens in different areas.<\/p>",
        "persons":
        [
          {
            "_id": "2906",
            "value": "Yorik van Havre"
          },
          {
            "_id": "7324",
            "value": "Brad Collette"
          }
        ],
        "links":
        [
          {
            "_href": "http://www.freecadweb.org",
            "value": "The FreeCAD project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9894.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9748",
        "start": "11:55",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "ngspice",
        "title": "ngspice open source circuit simulator",
        "subtitle": "dev update and electrothermal simulation",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An update of the development activities will be presented leading to ngspice-32. Its interface to KiCad has been extended, PSPICE device model compatibility and OpAmp convergence are improved, several bugs have been fixed.<\/p>\n\n<p>The VBIC bipolar model and the VDMOS power MOS model now incorporate the self heating effect.<\/p>\n\n<p>This will lead to the second part of the talk: ngspice may be very well used to simulate thermal device behavior. Heat generation, transport and temperatures are translated into electrical signals. Thus we simulate two circuits: The electrical circuit with its power losses, and the thermal circuit withany resulting device heating, its feedback on the electrical behavior, and the external cooling measures that need to be provided. Some ciruit examples will be given.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6153",
            "value": "Holger Vogt"
          }
        },
        "links":
        [
          {
            "_href": "http://ngspice.sourceforge.net/index.html",
            "value": "ngspice home"
          },
          {
            "_href": "http://ngspice.sourceforge.net/ngspice-electrothermal-tutorial.html",
            "value": "tutorial on electrothermal simulation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9748.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9761",
        "start": "12:20",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "cadquery",
        "title": "Towards CadQuery 2.0",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>CadQuery (CQ) [1] is a Python library for building of parametric 3D models. The overarching\ndesign goal is to be extremely fluent and as close as possible to the design intent. CQ is based on\nthe open source CAD kernel from OpenCascade and therefor offers industry standard B-Rep\nmodeling capabilities and allows exporting to lossless formats such as STEP as well as lossy ones\nsuch as STL. Originally it used Python bindings based on FreeCAD [2] but recently we switched to\nPythonOCC [3] to be more flexible and have full access to the underlying CAD kernel capabilities.\nIn the talk I will summarize the current status of the CQ project, show some interesting\nusage examples and discuss newly implemented features. Furthermore I will elaborate on the future\nplans of the core development team and touch on some of the challenges of maintaining a project\nsuch as CQ. I will also present a fairly new addition to the CQ ecosystem – CQ-editor [3]. It is a\nPython/PyQt5 based lightweight cross-platform GUI editor that allows to quickly develop and\npreview CQ 3D models. It also offers graphical debugging and CQ stack introspection capabilities\nwhich dramatically lowers the entry barrier for trying out and using CQ.<\/p>\n\n<p>References<\/p>\n\n<p>[1] https://github.com/CadQuery/cadquery\n[2] https://www.freecadweb.org\n[3] https://github.com/tpaviot/pythonocc-core\n[4] https://github.com/CadQuery/CQ-editor<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6930",
            "value": "Adam Urbanczyk"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/CadQuery/cadquery",
            "value": "CadQuery repository"
          },
          {
            "_href": "https://github.com/CadQuery/CQ-editor",
            "value": "CQ-editor repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9761.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9254",
        "start": "12:45",
        "duration": "00:30",
        "room": "H.2213",
        "slug": "kicad",
        "title": "KiCad: Back to the Future",
        "subtitle": "KiCad and it's role in the growing open hardware movement",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>I will talk about KiCad's role in the Open Hardware design movement and how it is remarkably similar to the early days of the Free, Libre, Open Source Software (FLOSS) movement and what it means for the future of Open Hardware.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2508",
            "value": "Wayne Stambaugh"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9254.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9770",
        "start": "13:20",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "psl",
        "title": "Pocket Science Lab from Development to Production",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we will cover the development path of the Pocket Science Lab (PSLab) board from version one in 2014 to today and outline how we use tools like KiCad to bring the device to large scale production. We will also share some major issues that we solved to get the device manufacturing ready and challenges that lie ahead of us like ensuring thorough device testing at production.<\/p>",
        "description": "<p>In this talk we will cover the development path of the Pocket Science Lab (PSLab) board from version one in 2014 to today and outline how we use tools like KiCad to bring the device to large scale production. We will also share some major issues that we solved to get the device manufacturing ready and challenges that lie ahead of us like ensuring thorough device testing at production. The goal of Pocket Science Lab is to create an Open Source hardware device (open on all layers) and software applications that can be used for experiments. The tiny pocket lab provides an array of instruments for doing science and engineering experiments. It provides functions of numerous measurement tools including an oscilloscope, a waveform generator, a frequency counter, a programmable voltage, current source and even a component to control robots with up to four servos.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2541",
            "value": "Mario Behling"
          }
        },
        "links":
        [
          {
            "_href": "https://pslab.io",
            "value": "Pocket Science Lab"
          },
          {
            "_href": "https://github.com/fossasia/pslab-hardware",
            "value": "PSLab Hardware"
          },
          {
            "_href": "https://github.com/fossasia?utf8=%E2%9C%93&q=pslab",
            "value": "PSLab Github Repositories"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9770.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9860",
        "start": "13:45",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "openscad",
        "title": "Designing functional objects with functional objects",
        "subtitle": "OpenSCAD: Past, present and/or future",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Reflecting on OpenSCAD's 10 years of history and what we've learned and discovered along the way. Discussion on opportunities and potential avenues forward, and some stories from the trenches.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6976",
            "value": "Marius Kintel"
          }
        },
        "links":
        [
          {
            "_href": "http://openscad.org",
            "value": "openscad.org"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9860.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9850",
        "start": "14:10",
        "duration": "00:10",
        "room": "H.2213",
        "slug": "kicadsearch",
        "title": "Leveraging Open Source Designs",
        "subtitle": "Creating a component search engine for reference designs used in practice",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Incorporating new components into PCBs is a difficult task that often requires reading multiple datasheets and creating prototypes to get it right. The funny thing is: every engineer needs to re-read reference designs! Even though there are tens of thousands of designs with new components documented and available on Github. The reason: it is almost impossible to find a relevant project. The solution? Instead of using Github search, which only retrieves files by filename, our approach creates a local database that takes the search results from Github, and then parses the used components inside the PCB designs to index them. That way, you can easily search a component and get the most relevant designs as a reference.<\/p>\n\n<p>This talk will give an overview of the software that was created, discusses the difficulties that were overcome and the potential for improvement in future work.<\/p>\n\n<p>Currently 300 of an estimated 30000 KiCad-projects on GitHub have been indexed as a proof-of-concept. We expect the data to be completed at the end of December. The project was kindly supported by AISLER with a server instance. The prototype of the search engine can be accessed at https://search-dev.aisler.net The release candidate should be ready at the end of December with the full dataset.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6973",
            "value": "Lasse Mönch"
          }
        },
        "links":
        [
          {
            "_href": "https://search-dev.aisler.net",
            "value": "Development prototype of the search engine"
          },
          {
            "_href": "https://github.com/KicadSearch/KicadSearch",
            "value": "Code on GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9850.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9538",
        "start": "14:25",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "fritzing",
        "title": "Fritzing - the past, the present and the future",
        "subtitle": "Restarting with 1100 technical issues, and a few legal ones",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Making electronics accessible to the broad public was mainly made possible by Arduino, Raspberry PI and last but not least Fritzing. Back in 2009, it was a pain to get from a loose wiring on a breadboard to a PCB. Fritzing came up first with a unique breadboard view and a simple to use PCB layout. Fast forward 10 years to Fosdem 2019, Fritzing was in a major crisis. Despite well over 200.000 users, thousands of downloads per day and an enthusiastic community, development had stalled. It has now been rebooted, and the project is back to gaining momentum. So what has happened between last year and this year?\nThis talk will give a rough introduction to Fritzing and its ecosystem, including how we overcame the problems, learned from our mistakes and how we plan to keep improving Fritzing in the future.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6799",
            "value": "Kjell Morgenstern"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9538.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9827",
        "start": "14:50",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "sparselizard",
        "title": "Sparselizard: a general purpose multiphysics FEM library",
        "subtitle": "Mechanics, fluids, electricity, magnetics, EM and more",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This presentation describes sparselizard: a fast, general, robust and user-friendly finite element c++ library with high potential for low-maintenance integration to open-source simulation tools. It is demonstrated with a large range of validated examples that the library has the ability to simulate heavily nonlinear multiphysics problems involving at least mechanic, fluid, electric, magnetic and electromagnetic physics. Its robustness, speed and user-friendliness are also demonstrated.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6963",
            "value": "Alexandre Halbach"
          }
        },
        "links":
        [
          {
            "_href": "http://www.sparselizard.org",
            "value": "http://www.sparselizard.org"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9827.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10068",
        "start": "15:15",
        "duration": "00:30",
        "room": "H.2213",
        "slug": "opencascade",
        "title": "Open CASCADE Technology - an introduction and overview",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Cascade Technology is a framework for B-Rep modeling. The presentation highlights key features available in the toolkits.\nThe following topics are covered:\n- What is OCCT?\n- License\n- OCCT in numbers\n- History\n- Modeling data\n- Modeling algorithms\n- Visualization\n- Data exchange<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7077",
            "value": "Alexander Malyshev"
          }
        },
        "links":
        [
          {
            "_href": "https://www.opencascade.com/content/overview",
            "value": "OpenCascade"
          },
          {
            "_href": "https://dev.opencascade.org/",
            "value": "Development Portal"
          },
          {
            "_href": "https://www.opencascade.com/forums",
            "value": "OpenCascade Forums"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10068.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9909",
        "start": "15:50",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "geda",
        "title": "News from gEDA/gaf",
        "subtitle": "including an introduction to gschem",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk gives an overview of the recent gEDA/gaf development and the new features in gEDA/gaf 1.10.0.  It is followed by an introduction to gschem and how to use it to create symbols and schematics.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4436",
            "value": "Roland Lutz"
          }
        },
        "links":
        [
          {
            "_href": "http://www.geda-project.org/",
            "value": "gEDA Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9909.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9270",
        "start": "16:15",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "gmsh",
        "title": "Gmsh",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Gmsh (http://gmsh.info) is an open source finite element mesh generator with built-in pre- and post-processing facilities. Under continuous development for the last two decades, it has become the de facto standard for open source finite element mesh generation, with a large user community in both academia and industry. In this talk I will present an overview of Gmsh, and highlight recent developments including the support for constructive solid geometry, new robust and parallel meshing algorithms, flexible solver integration and a new multi-language Application Programming Interface in C++, C, Python and Julia.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6587",
            "value": "Christophe Geuzaine"
          }
        },
        "links":
        [
          {
            "_href": "http://gmsh.info",
            "value": "http://gmsh.info"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9270.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9379",
        "start": "16:40",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "axiom",
        "title": "AXIOM - open source cinema camera",
        "subtitle": "Project Introduction and current state of development",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presentation will give a brief overview of the projects history &amp; lessons learned during the course of developing a high tech camera device as community project. We also want to demo and explain the produced hardware, enclosures and sample footage then look at the challenges still ahead. Last 10 minutes reserved for Q&amp;A<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6685",
            "value": "Sebastian Pichelhofer"
          }
        },
        "links":
        [
          {
            "_href": "https://www.apertus.org/axiom-beta",
            "value": "AXIOM Beta"
          },
          {
            "_href": "https://apertus.org/AXIOM_Beta_Brochure_02.04.pdf",
            "value": "AXIOM Brochure"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9379.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9480",
        "start": "17:05",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "horizon",
        "title": "Horizon EDA - Version 1.0",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk covers my motivation for starting a new EDA package in 2016 and the main ideas behind horizon as well as what has changed in the last year. I'll also go into my short- and long-term plans for the project.<\/p>",
        "description": "<p>Horizon EDA is a from-scratch EDA package with focus on useful parts management, rule-driven design and good usability. It has already proven its suitability for medium-complexity projects in the board design for my master thesis and in various hobby projects.<\/p>\n\n<p>This talk covers my motivation for starting a new EDA package in 2016 and the main ideas behind horizon as well as what has changed in the last year. I'll also go into my short- and long-term plans for the project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4800",
            "value": "Lukas Kramer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9480.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9931",
        "start": "17:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "openpiton",
        "title": "OpenPiton: An Open-Source Framework for EDA Tool Development",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As contemporary industrial ASIC designs have reached hundreds of billions transistor count, EDA tools must have the scalability to handle such large designs. However, few open-source RTL designs reflect the scale that industrial ASICs have reached. In this talk, we will present OpenPiton, a scalable, tiled manycore design that can reach as many as 65,536 cores in a single chip, and up to 500 million cores on a multi-chip design. The modularity and scalability of the OpenPiton design can enable EDA tool developers to test their tools' functionality at contemporary scales and adapt their development for future larger designs. With its many configurability options, extensive scalability, and heterogeneity, the OpenPiton platform is well placed to supercharge open-source EDA tool development and pave the way for a completely open-source ASIC synthesis and back-end flow tested using open-source designs.<\/p>",
        "description": "<p>Title:\nOpenPiton: An Open-Source Framework for EDA Tool Development<\/p>\n\n<p>Abstract:\nAs contemporary industrial ASIC designs have reached hundreds of billions transistor count, EDA tools must have the scalability to handle such large designs. However, few open-source RTL designs reflect the scale that industrial ASICs have reached. In this talk, we will present OpenPiton, a scalable, tiled manycore design that can reach as many as 65,536 cores in a single chip, and up to 500 million cores on a multi-chip design. The modularity and scalability of the OpenPiton design can enable EDA tool developers to test their tools' functionality at contemporary scales and adapt their development for future larger designs. With its many configurability options, extensive scalability, and heterogeneity, the OpenPiton platform is well placed to supercharge open-source EDA tool development and pave the way for a completely open-source ASIC synthesis and back-end flow tested using open-source designs.<\/p>\n\n<p>Preferred Session length:\nShort (20 minutes)<\/p>\n\n<p>Speaker: Prof. David Wentzlaff (Princeton University)<\/p>\n\n<p>Speaker bio:\nDavid Wentzlaff is an associate professor of electrical engineering at Princeton University. Wentzlaff's research has earned several awards, among them an NSF CAREER award, DARPA Young Faculty Award, AFOSR Young Investigator Prize, induction into the MICRO Hall of Fame, and the ASPLOS WACI Test-of-Time Award.  He received his M.S. and Ph.D. from MIT and received a B.S. in electrical engineering from the University of Illinois at Urbana-Champaign.  He was Lead Architect and Founder of Tilera Corporation, a multicore chip manufacturer now owned by Mellanox.  David's current research interests include how to create manycore microprocessors customized specifically for Cloud computing environments, how to design computer architectures in a post Moore’s Law world, and how to reduce the impact of computing on the environment by optimizing computer architecture for fully biodegradable substrates.  Many of the research projects created by Wentzlaff’s group have been open-sourced including the PriME simulator, OpenPiton, and PRGA.<\/p>\n\n<p>Link to any hardware / code / slides for the talk:\nhttps://parallel.princeton.edu/openpiton/\nhttps://github.com/PrincetonUniversity/openpiton<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7003",
            "value": "David Wentzlaff"
          }
        },
        "links":
        [
          {
            "_href": "https://parallel.princeton.edu/openpiton/",
            "value": "OpenPiton Website"
          },
          {
            "_href": "https://github.com/PrincetonUniversity/openpiton",
            "value": "OpenPiton Github Code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9931.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9861",
        "start": "17:55",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "openelectronicslab",
        "title": "Designing Hardware, Journey from Novice to Not Bad",
        "subtitle": "Reflections from the OpenElectronicsLab",
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The three main contributors to the OpenElectronicsLab projects started out as relative novices. The wealth of online resources and some trial-and-error opens the doors to the world of hardware design.<\/p>\n\n<p>This will reflect on what lowered the barriers, insights gained, what needed to be done to handle things which turned out to be harder than expected, and to encourage hesitant novices to get started designing their own hardware.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "6977",
            "value": "Eric Herman"
          },
          {
            "_id": "7406",
            "value": "Kendrick Shaw"
          },
          {
            "_id": "7413",
            "value": "Stephanie Medlock"
          }
        ],
        "links":
        [
          {
            "_href": "http://openelectronicslab.github.io/eeg-mouse/",
            "value": "eeg-mouse"
          },
          {
            "_href": "http://openelectronicslab.github.io/OpenHardwareExG/",
            "value": "OpenHardwareExG"
          },
          {
            "_href": "https://github.com/OpenElectronicsLab/OpenHardwareHolterMonitor",
            "value": "OpenHardwareHolterMonitor"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9861.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9642",
        "start": "18:20",
        "duration": "00:30",
        "room": "H.2213",
        "slug": "dealii",
        "title": "Finite element modeling with the deal.II software library",
        "subtitle": [],
        "track": "Open Source Computer Aided Modeling and Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The finite element method has been the method of choice to simulate the deformation of solids as well as the flow of many kinds of fluids for nearly 70 years now. In the case of solids, it provides a general framework to describe how a body reacts to external stimuli by modeling how deformation affects the internally stored energy. While most software that implements the method used to be homegrown for a particular purpose, the 2000s have seen the emergence of large and professionally developed. open source software libraries that provide a broad range of functionality that makes the implementation of such codes straightforward. I will give an overview of one of these libraries, deal.II, and how and where it is used.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6802",
            "value": "Wolfgang Bangerth"
          }
        },
        "links":
        [
          {
            "_href": "http://dealii.org",
            "value": "The homepage of the deal.II library"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9642.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.2214",
    "event":
    [
      {
        "_id": "10607",
        "start": "10:30",
        "duration": "00:10",
        "room": "H.2214",
        "slug": "mysql_mariadb_welcome",
        "title": "Welcome to the MySQL, MariaDB & Friends Devroom 2020",
        "subtitle": "Community Welcome",
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the FOSDEM MySQL, MariaDB &amp; Friends Devroom 2020<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "580",
            "value": "Frédéric Descamps"
          },
          {
            "_id": "5872",
            "value": "Ian Gilfillan"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10607.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9917",
        "start": "10:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql8_mariadb104",
        "title": "MySQL 8 vs MariaDB 10.4",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MySQL 8 and MariaDB 10.4 are the latest Major versions for MySQL and MariaDB.  While MariaDB started by being slightly different MySQL variant,  now it has grown into very much different database platforms which grows more different from every release.<\/p>\n\n<p>In this presentation, we will look into the differences between MySQL and MariaDB in the core areas such as SQL features, query optimizations, replication, storage engines, and security as well as discuss unique features and capabilities MySQL 8 and MariaDB 10.4 offers compared to each other.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4015",
            "value": "Peter Zaitsev"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9917.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9663",
        "start": "11:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "myrocks_www",
        "title": "MyRocks in the Wild Wild West!",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, we'll walk through RocksDB technology and look into areas where MyRocks is a good fit by comparison to other engines such as InnoDB. We will go over internals, benchmarks, and tuning of MyRocks engine. We also aim to explore the benefits of using MyRocks within the MySQL ecosystem. Attendees will be able to conclude with the latest development of tools and integration within MySQL.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4191",
            "value": "Alkin Tezuysal"
          }
        },
        "links":
        [
          {
            "_href": "http://https://www.slideshare.net/atezuysal/when-is-my-rocks-good-highload-2019",
            "value": "Upgraded version of this talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9663.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9708",
        "start": "11:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql_master_master",
        "title": "How Safe is Asynchronous Master-Master Setup?",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>It is common knowledge that built-in asynchronous master-master (active-active) replication is not safe. I remember times when the official MySQL User Reference Manual stated that such an installation is not recommended for production use. Some experts repeat this claim even now.<\/p>\n\n<p>While this statement is generally true, I worked with thousands of shops that successfully avoided asynchronous replication limitations in active-active setups.<\/p>\n\n<p>In this talk, I will show how they did it, demonstrate situations when asynchronous master-master replication is the best possible high availability option and beats such solutions as Galera or InnoDB Clusters. I will also cover common mistakes, leading to disasters.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2247",
            "value": "Sveta Smirnova"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9708.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9517",
        "start": "12:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "sync_binlog",
        "title": "The consequences of sync_binlog != 1.",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Have you ever needed to get some additional write throughput from MySQL ?  If yes, you probably found that setting sync_binlog to 0 (and trx_commit to 2) gives you an extra performance boost.  As all such easy optimisation, it comes at a cost.  This talk explains how this tuning works, presents its consequences and makes recommendations to avoid them.  This will bring us to the details of how MySQL commits transactions and how those are replicated to slaves.  Come to this talk to learn how to get the benefit of this tuning the right way and to learn some replication internals.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3380",
            "value": "Jean-François Gagné"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9517.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9684",
        "start": "12:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "msyql_ecryption",
        "title": "Overview of encryption features",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MariaDB/MySQL/Percona Server provide some features in this space, but currently there isn't one product that covers all the needs (at least not available as FOSS).\nThis talk will provide an overview of Data-at-Rest-Encryption features in MySQL, MariaDB and Percona Server for MySQL, their availability across versions, and status (experimental/GA).<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6819",
            "value": "Hrvoje Matijakovic"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9684.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9890",
        "start": "13:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "proxysql2",
        "title": "Whats new in ProxySQL 2.0?",
        "subtitle": "Exploring the latest features in ProxySQL 2.0",
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>ProxySQL, the high performance, high availability, protocol-aware proxy for MySQL is now GA in version 2.0. This version introduces several new features, like causal reads using GTID, better support for AWS Aurora, native support for Galera Cluster, LDAP authentication and SSL for client connections.<\/p>\n\n<p>This session provides an overview of the most important new features.<\/p>",
        "description": "<p>Slide agenda:<\/p>\n\n<ul>\n<li>Supported OSes &amp; Packaging<\/li>\n<li>Query Cache Tunables<\/li>\n<li>GTID Causal Reads<\/li>\n<li>Native Galera Support<\/li>\n<li>Amazon Aurora Features<\/li>\n<li>LDAP Integration<\/li>\n<li>SSL, Audit Log &amp; Security<\/li>\n<li>JSON Support<\/li>\n<li>Performance Enhancements<\/li>\n<li>MySQL 8<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6986",
            "value": "Nick Vyzas"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9890.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9190",
        "start": "13:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "selinux_mysql",
        "title": "SELinux fun with MySQL and friends",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>SELinux (Security Enhanced Linux) provides enhanced security mechanism for more advanced access control and auditing. It allows your application software and your system users to only access the resources it's been preconfigured to allow. Of course when you want to move your data- or log files to a non-standard location these policies will stop MySQL from starting.<\/p>\n\n<p>The easy way out is obviously to set SELinux to disabled or permissive. But someone once said: \"Every time you disable SELinux a kitten dies\". We'll show you a few ways how you can find out if it actually is SELinux that is blocking you and how to update the policies to properly keep you system secured.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "4684",
            "value": "Matthias C"
          },
          {
            "_id": "5860",
            "value": "Ivan Groenewold"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9190.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9864",
        "start": "14:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql_k8s",
        "title": "Running MySQL in Kubernetes in real life",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Running databases in Kubernetes has come a long way.<\/p>\n\n<p>Focusing on MySQL, we will explore the challenges and issues of running production databases in Kubernetes. We'll look at the opportunities and benefits of running in Kubernetes too.\nWhile rolling out a database is easy enough, things can get interesting when production tasks are undertaken.\nHow do you achieve scaling – whether that's scaling up or down? How do you know that your latest backup will restore safely?\nWe will also take a look at an open source solution for monitoring your database deployments, adding support for Kubernetes as a robust production environment.<\/p>",
        "description": "<p>Focusing on MySQL, we will explore the challenges and issues of running production databases in Kubernetes. We'll look at the opportunities and benefits of running in Kubernetes too.\nWhile rolling out a database is easy enough, things can get interesting when production tasks are undertaken.\nHow do you achieve scaling – whether that's scaling up or down? How do you know that your latest backup will restore safely?\nWe will also take a look at an open source solution for monitoring your database deployments, adding support for Kubernetes as a robust production environment.<\/p>\n\n<p>Outline:\n- Introduction\n- Installing MySQL in Kubernetes\n- Scaling up, scaling down\n- Backup, restore, verification\n- An open source monitoring solution\n- What could possibly go wrong?<\/p>\n\n<p>Takeaways:\nThis presentation should encourage the audience to embrace the possibilities of running production databases on Kubernetes, and will help attendees understand the \"do's and dont's\" of such a deployment.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6784",
            "value": "Sami Ahlroos"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9864.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9834",
        "start": "14:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "alter_mariadb",
        "title": "ALTER TABLE improvements in MariaDB Server",
        "subtitle": "Optimized or instantaneous schema changes, including ADD/DROP COLUMN",
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>ALTER TABLE in MySQL used to copy the table contents row by row. We can do much better; in the best case, allow instantaneous schema changes, even for nontrivial changes, such as ADD COLUMN…AFTER and DROP COLUMN. This talk describes how ALTER TABLE has been improved over the years for the InnoDB storage engine in MySQL 5.1, 5.5, 5.6, 5.7, and MariaDB Server 10.2, 10.3, 10.4, 10.5, mostly by the presenter.<\/p>",
        "description": "<p>The talk enumerates different classes of ALTER TABLE operations: (1) ones not involving other than metadata, (2) operations that can be performed instantly by introducing a backward-compatible data file format change and 'faking' the operation (ADD or DROP COLUMN), (3) operations that can avoid rebuilding a table, and (4) operations that must rebuild the table, and variants of (3) and (4) that allow concurrent modifications to the table. We also show how ALTER TABLE can be executed concurrently on multiple nodes in statement-based replication. Finally, we show the theoretical limits of what kind of ALTER TABLE operations can be supported without rebuilding the table, by introducing an optional validation step and on-demand conversion of records in previous schema versions of the table.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6968",
            "value": "Marko Mäkelä"
          }
        },
        "links":
        [
          {
            "_href": "https://mariadb.com/resources/blog/alter-table-improvements-in-mariadb-server-10-3/",
            "value": "ALTER TABLE Improvements in MariaDB Server 10.3"
          },
          {
            "_href": "https://mariadb.com/resources/blog/alter-table-improvements-in-mariadb-server-10-4/",
            "value": "ALTER TABLE Improvements in MariaDB Server 10.4"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9834.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9588",
        "start": "15:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mariadb_version_tables",
        "title": "Rewinding time with System Versioned Tables",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Imagine, you're given a time machine. A fairly limited one, it cannot transport you anywhere. Still, it can show you the past, what your tables looked like at any given point in time. This is exactly what the SQL:2011 standard and MariaDB 10.3+ are giving you. System versioned tables allow you to rewind time and see their content as it was in the past — all using normal SELECT statements. This talk will show how to create system versioned tables, how to use them and how not to kill the performance when doing that. It will present various new applications and use cases that became possible now. Having a time machine, what will you use it for?<\/p>",
        "description": "<p>Imagine, you're given a time machine. A fairly limited one, it cannot transport you anywhere. Still, it can show you the past, what your tables looked like at any given point in time. This is exactly what the SQL:2011 standard and MariaDB 10.3+ are giving you. System versioned tables allow you to rewind time and see their content as it was in the past — all using normal SELECT statements. This talk will show how to create system versioned tables, how to use them and how not to kill the performance when doing that. It will present numerous different applications and use cases that became possible now. Having a time machine, what will you use it for?<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1684",
            "value": "Sergei Golubchik"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9588.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9805",
        "start": "15:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mariadb_order_by_limit",
        "title": "Knocking down the barriers of ORDER BY LIMIT queries with MariaDB 10.5",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The talk will start with a recap of how MariaDB(or MySQL) handles the\nORDER BY LIMIT optimization and examples demonstrating why the current\noptimizer is not good enough.<\/p>\n\n<p>Further, the talk will describe how the optimizer in MariaDB 10.5 mostly\nsolves the issue, the remaining unresolved issues and how DBAs can tackle them.<\/p>",
        "description": "<p>FULL DESCRIPTION:<\/p>\n\n<p>For the first part of the talk, I will discuss the possible strategies by\nwhich ORDER BY LIMIT optimization is handled in MariaDB (or MySQL)<\/p>\n\n<p>The strategies are:\n1) Using an ordered index (ref, range or index scan)\n2) Using filesort on the first non-const table\n3) Using filesort on the temporary table, that stores the output of the join<\/p>\n\n<p>Then I will discuss how the current MariaDB/MySQL optimizer makes the choice between the strategies and show\nthe situations where it will never get a good query plan<\/p>\n\n<p>For the second part of the talk, I will describe how a new cost-based\noptimization in MariaDB 10.5 solves the above issue.\nThe talk will contain details about how the costs were taken into account\nduring the optimization phase. Further, with the help of examples\nI would demonstrate how the execution differs for this new optimization\nand how this leads to improved performance for ORDER BY LIMIT queries.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6865",
            "value": "Varun Gupta"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9805.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9912",
        "start": "16:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql_cpu_flames",
        "title": "CPU performance analysis for MySQL using Hot/Cold Flame Graph",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Come to see some real-life examples of how you can do CPU profiling with perf and eBPF/BCC, to create FlameGraphs and ColdGraphs visualizations of the on-CPU/off-CPU time spent by the database. Based on these visualizations and reading the database source code (this is why we love Open Source!) you can quickly gain insight about what's burning CPU (FlameGraphs) and what's causing CPU to wait (ColdGraphs), and with this knowledge you will be several steps closer to answering \"what's consuming all that CPU time\".<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6401",
            "value": "Vinicius Grippa"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9912.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9690",
        "start": "16:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql8_hash_join",
        "title": "Hash Join in MySQL 8",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>JOIN is one of the most common operation in a database system, and for a long time, the only algorithm for executing a join in MySQL has been variations of the nested loop algorithm. But starting from MySQL 8.0.18, it is now possible to execute joins using hash join. This presentation will walk you through how we were able to implement hash join using our new iterator executor, how hash join in MySQL works, when it is used, and everything else that is worth knowing about hash join in MySQL.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5870",
            "value": "Erik Frøseth"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9690.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9876",
        "start": "17:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql_hash_joins",
        "title": "Comparing Hash Join solution, the good, the bad and the worse.",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MySQL 8.0.18 comes (finally) with a long waited and desired hash-join implementation.\nThat was already present in other pseudo MySQL distributions like MariaDb.\nBut, what is has-join, how it works, what problems it solves, when and how to use it.\nLast but not least are all the different implementations doing the same things, or are they acting and performing differently.\nWe are going to perform a short journey in hash-join implementations and answer all these questions.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4696",
            "value": "Marco Tusa (the Grinch)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9876.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9843",
        "start": "17:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql8_secure_replication",
        "title": "MySQL 8.0: Secure your MySQL Replication Deployment",
        "subtitle": [],
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Data protection is an extensive and hot topic. Making sure that\nwhoever accesses your data has identity well established and is\nauthorized can be a complex and hard task. Moreover, nowadays\ndata tends to move around quickly between different instances of the\nsame service, different services and different data consumers.  This\noften implies that data traverses different administrative domains. It\nis key that MySQL handles, stores and replicates data complying\nwith the security requirements that business and regulations demand.<\/p>\n\n<p>This session showcases the new developments in MySQL 8.0 that tighten\nrelated replication security setups, and reduce the attack surface of\nthe different replication topologies. We will talk about secure\ninter-server communication, encryption of replication data at rest\nand the new features that make the replication applier run under a\nspecific security context. Come and learn about security related\nreplication features in MySQL 8.0.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6971",
            "value": "Pedro Figueiredo"
          }
        },
        "links":
        [
          {
            "_href": "https://mysqlhighavailability.com/binary-log-encryption-encryption-of-temporary-capture-files/",
            "value": "https://mysqlhighavailability.com/binary-log-encryption-encryption-of-temporary-capture-files/"
          },
          {
            "_href": "https://mysqlhighavailability.com/binary-log-encryption-at-rest/",
            "value": "https://mysqlhighavailability.com/binary-log-encryption-at-rest/"
          },
          {
            "_href": "https://mysqlhighavailability.com/support-for-tls-1-3-in-group-replication/",
            "value": "https://mysqlhighavailability.com/support-for-tls-1-3-in-group-replication/"
          },
          {
            "_href": "https://mysqlhighavailability.com/replication-with-restricted-privileges/",
            "value": "https://mysqlhighavailability.com/replication-with-restricted-privileges/"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9843.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9232",
        "start": "18:10",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "mysql_github_schema",
        "title": "Automating schema migration flow with GitHub Actions, skeema & gh-ost",
        "subtitle": "And end-to-end schema migration automation, from design to production, at GitHub",
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Schema migration is more than running an ALTER TABLE. It is about designing, reviewing, approving, queuing, scheduling, executing, auditing, controlling and versioning the changes.<\/p>\n\n<p>At GitHub we run multiple migrations per day, and much of this flow used to be manual, taking a significant toll from the databases team. In this session we illustrate how we automated away migration using free and open source solutions, and based on trusted development flow.<\/p>",
        "description": "<p>Schema migration is more than running an ALTER TABLE. It is about designing, reviewing, approving, queuing, scheduling, executing, auditing, controlling and versioning the changes.<\/p>\n\n<p>At GitHub we run multiple migrations per day, and much of this flow used to be manual, taking a significant toll from the databases team. In this session we illustrate how we automated away migration using free and open source solutions, and based on trusted development flow.<\/p>\n\n<p>We highlight the use of the skeema tool, with GitHub Actions, git flow and gh-ost.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2443",
            "value": "Shlomi Noach"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9232.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9233",
        "start": "18:40",
        "duration": "00:20",
        "room": "H.2214",
        "slug": "20_min_mysql_plugin",
        "title": "20 mins to write a MySQL Shell Plugin",
        "subtitle": "Extend the MySQL Shell with a plugin created from scratch",
        "track": "MySQL, MariaDB and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MySQL Shell is a new client for MySQL. It comes with multiple functionalities like the adminAPI commands to setup and operate a MySQL InnoDB Cluster but also check for upgrades, import JSON, parallel import and more... It also allows you to communicate with the MySQL Server in SQL, Python or Javascript !\nDuring this session we will write a plugin from scratch to extend the Shell using the MySQL Shell Plugin Framework. The code will be written live in Python.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "580",
            "value": "Frédéric Descamps"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9233.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.3242",
    "event":
    {
      "_id": "10783",
      "start": "11:00",
      "duration": "01:00",
      "room": "H.3242",
      "slug": "bof_apache_camel",
      "title": "Apache Camel BoF",
      "subtitle": "Meeting of the Apache Camel community",
      "track": "BOFs (Track B - in H.3242)",
      "type": "bof",
      "language": [],
      "abstract": "<p>Apache Camel is a free software integration framework from the Apache Software Foundation. This meetup is for anyone wishing to meet and discuss Apache Camel development, share experiences and meet in meat space other folk in the Apache Camel community.<\/p>",
      "description": "<p>Apache Camel has been around and its used quite widely for in all sorts of software integration projects. Camel version 3 was recently released and the community has kicked of several sub-projects: Camel K - a serverless, cloud native integration on top of Kubernetes, Camel Quarkus - low memory, fast startup support utilizing Quarkus, and Camel Kafka Connector - for running Camel inside of Kafka. Let's meet and discuss these initiatives or just talk and exchange ideas around Camel. Anyone wishing to share can present on any topic relating to Apache Camel is welcome to do so, though please be mindful of the time - we have one hour in this session and would like that everyone would have the chance to participate.<\/p>",
      "persons":
      {
        "person":
        {
          "_id": "5614",
          "value": "Zoran Regvart"
        }
      },
      "links":
      [
        {
          "_href": "https://camel.apache.org",
          "value": "Apache Camel website"
        },
        {
          "_href": "https://submission.fosdem.org/feedback/10783.php",
          "value": "Submit feedback"
        }
      ]
    }
  },
  {
    "_name": "H.3244"
  },
  {
    "_name": "J.1.106",
    "event":
    [
      {
        "_id": "10325",
        "start": "11:00",
        "duration": "01:00",
        "room": "J.1.106",
        "slug": "bof_tinygo",
        "title": "TinyGo",
        "subtitle": "TinyGo on microcontrollers and WebAssembly",
        "track": "BOFs (Track A - in J.1.106)",
        "type": "bof",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4480",
            "value": "Ron Evans"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10325.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9010",
        "start": "12:00",
        "duration": "01:00",
        "room": "J.1.106",
        "slug": "bof_sourcehut",
        "title": "Sourcehut & aerc meetup",
        "subtitle": "Email enthusiasts meet up to enthuse about email",
        "track": "BOFs (Track A - in J.1.106)",
        "type": "bof",
        "language": [],
        "abstract": "<p>Members of the closely linked <a href=\"https://sourcehut.org\">Sourcehut<\/a> and <a href=\"https://aerc-mail.org\">aerc<\/a> communities meet up to put faces to names and discuss the present and future of both projects, and to collect stickers.<\/p>",
        "description": "<p><a href=\"https://sourcehut.org\">Sourcehut<\/a> is a free/libre project hosting platform with sophisticated git hosting, mailing lists, continuous integration, and more. We'll be discussing the remaining tasks for the alpha, planning and seeking feedback for the beta, and showing off cool stuff added in the past year.<\/p>\n\n<p><a href=\"https://aerc-mail.org\">aerc<\/a> is a FOSS email client for your terminal designed especially for software developers which integrates nicely into the mailing list workflow endorsed by Sourcehut. Early in its development, you'll have a chance to discuss what you'd like to see in your dream email client and speculate wildly on the lofty goals it aims to achieve.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5905",
            "value": "Drew DeVault"
          }
        },
        "links":
        [
          {
            "_href": "https://sourcehut.org",
            "value": "Sourcehut"
          },
          {
            "_href": "https://aerc-mail.org",
            "value": "aerc"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9010.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10781",
        "start": "16:00",
        "duration": "01:30",
        "room": "J.1.106",
        "slug": "bof_replicant",
        "title": "Replicant Meetup",
        "subtitle": "Meeting for the Replicant community",
        "track": "BOFs (Track A - in J.1.106)",
        "type": "bof",
        "language": [],
        "abstract": "<p>Replicant is a fully free Android distribution running on several devices, a free software mobile operating system putting the emphasis on freedom and privacy/security.<\/p>\n\n<p>This meeting is for everyone interested in the Replicant project (users, developers, devices vendors, etc.). Among other things, we will present the ongoing efforts on Replicant 9 and discuss how we should move forward. Everyone's point of view is welcomed.<\/p>",
        "description": "<p>Here's a non-exhaustive list of the topics that will be up for debate:<\/p>\n\n<ul>\n<li>Replicant 9 status on the i9300/i9305: bootloader, modem, LCD, audio, graphics.<\/li>\n<li>Future targets: PinePhone, Librem5.<\/li>\n<li>WebView dependency on non-free Chromium.<\/li>\n<li>Android build system.<\/li>\n<li>Replicant infrastructure: servers, test benches, build machines.<\/li>\n<li>Long term project sustainability.<\/li>\n<li>Supported mainline kernel phones, what kernel versions brought what support and what is upcomming in the next kernel versions.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7048",
            "value": "dllud"
          }
        },
        "links":
        [
          {
            "_href": "https://replicant.us/",
            "value": "Project website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10781.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10664",
        "start": "17:30",
        "duration": "01:30",
        "room": "J.1.106",
        "slug": "bof_public_sector",
        "title": "Creating Sustainable Public Sector Open Source Communities",
        "subtitle": [],
        "track": "BOFs (Track A - in J.1.106)",
        "type": "bof",
        "language": [],
        "abstract": "<p>The Open Source Observatory (OSOR) of the European Commission is an online collection that provides its community with an information observatory, community building activities, as well as assistance and support services. On behalf of OSOR, we propose to make a presentation on the currently ongoing study towards a guidelines document for creating sustainable open source communities in the public sector.\nIn this context, OSOR is producing guidelines for creating sustainable open source communities within the public sector. The purpose of the guidelines is to act as a practical tool that can be used by public sector officials interested in establishing open source communities or by members of such communities. The production of the guidelines is a multi-step process, involving desk research, primary data collection, development of four case studies and conduction of interviews with key stakeholders.\nAfter presenting the objectives and approach to produce the guidelines, the OSOR representatives will present the preliminary findings related to the guidelines, including the key success factors associated with healthy communities. The audience will be also invited to further brainstorm in groups the key success factors of sustainable OSS communities as well as to identify the key components that our guidelines should contain.<\/p>",
        "description": "<p>The production of the guidelines is a multi-step process, involving both desk research and primary data collection. More specifically, our team has conducted an in-depth literature review, followed by a questionnaire targeting OSS communities in the public sector, which will be running between January and February 2020. Following the analysis of data collected from the questionnaire, our team will develop four case studies illustrating successful and failed OSS initiatives in the public sector. Interviews with key case study stakeholders are to be conducted within each case study.\nThe key objective of our workshop at FOSDEM is not only to present our preliminary findings to the audience but to also obtain their views on our findings and future guidelines. We want to ensure that OSOR puts forward truly community driven guidelines.\nDuring the workshop, we will recount the findings so far which are the data of the literature review and survey. More specifically, we will present the key success factors and their components associated with sustainable OSS communities as well as some interesting failed and successful public sector OSS initiatives. The audience will be then invited to further brainstorm in groups the key success factors of sustainable OSS communities as well as to identify the key components that our guidelines should contain.\nWe will also invite the audience to contribute to our ongoing survey and invite them to get in touch with the OSOR community for further ideas on our guidelines and case studies.<\/p>\n\n<p>The target group of OSOR is wide-ranging within the open source community. It includes policy makers, IT managers, IT developers, researchers and students, and OSS advocates and enthusiasts in general. OSOR invites members of the audience who are interested in the development of OSS within public administrations, community managers and members, developers and organisations who would like to learn more about the project of measuring the health and sustainability of an open source project. The audience is also invited to follow the work of OSOR and the European Commission on OSS more closely. OSOR promotes collaboration, sharing and digital development through various services provided to its community.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7349",
            "value": "OSOR team"
          }
        },
        "links":
        [
          {
            "_href": "https://joinup.ec.europa.eu/collection/open-source-observatory-osor",
            "value": "More information about OSOR"
          },
          {
            "_href": "https://joinup.ec.europa.eu/collection/open-source-observatory-osor/guidelines-creating-sustainable-open-source-communities",
            "value": "More information about the guidelines."
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10664.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "AW1.120",
    "event":
    [
      {
        "_id": "9184",
        "start": "10:30",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "cms_linked_data_knowledge_base",
        "title": "How a CMS system and linked data can make a distributed knowledge base",
        "subtitle": "Implementing the vision of the web of data",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6550",
            "value": "Sander Van Dooren"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9184.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10626",
        "start": "11:00",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "from_0_to_intranet_xwiki",
        "title": "From 0 to Intranet in 20 minutes with XWiki",
        "subtitle": [],
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Sharing knowledge in a team of people working together (company, association, study group or any other kind of project) is key for its long-term success. Even if this is not properly identified from the beginning as a main concern, setting up tools and processes that allow knowledge to be accumulated and organized correctly ends up being on the TODO list at some point, and may come with the wish to have done it earlier. Thus, the best solution is one that is quick enough to setup from the very beginning and versatile enough to be able to incrementally develop into a proper solid fortress of knowledge.<\/p>",
        "description": "<p>In this presentation I will use the XWiki platform to incrementally build a collaborative intranet from scratch and will try to address some frequent needs of knowledge sharing in a team, using already-made add-ons or new tools (list not exhaustive):\n* Blog, for unidirectional communication,\n* Meeting notes, for spoken knowledge not to be lost,\n* File Manager for just dropping files to share,\n* Task manager for lightweight ticketing,\n* Holiday requests and Recruitment applications for team management,\n* Unstructured free content sharing, using standard wiki pages and page templates,\n* Structured content tailored to fit your exact specific needs,\n* Multi-wiki separation for teams isolation,\n* Powerful search in all this,\n* Authentication add-ons to plug your own users management,\n* Easy look &amp; feel setup, to brand it as your own.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2114",
            "value": "Anca Luca"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10626.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9809",
        "start": "11:30",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "onlyoffice_securly_collaborate",
        "title": "ONLYOFFICE: How to securely collaborate on documents within content management applications",
        "subtitle": [],
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>ONLYOFFICE is an open-source HTML5-based office suite for editing and collaborating on text documents, spreadsheets, and presentations online. Here, maximizing format compatibility, establishing browser-agnostic content display and optimizing real-time data transfer in co-authoring are the core principles in building applicable editing software.<\/p>\n\n<p>End user-side demand indicates that deeper integration in productivity solutions and content management applications is one of the main directions for ONLYOFFICE. We would like to share our experience in building connectors that allow users to edit and co-author their documents securely right within a platform they use.<\/p>\n\n<p>Presentation milestones:<\/p>\n\n<ul>\n<li>Review of the technical basis of ONLYOFFICE editors (HTML5 Canvas, JavaScript, etc.);<\/li>\n<li>Open API that allows creating third-party connectors;<\/li>\n<li>Integration with content management platforms such as XWiki, Nextcloud, ownCloud (including connectors/integration apps development);<\/li>\n<li>Security measures (JSON Web Token, limited cache lifetime, etc.)<\/li>\n<li>Connecting desktop and mobile environments to content management platforms;<\/li>\n<li>ONLYOFFICE integration roadmap.<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6887",
            "value": "Alex Mikheev"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9809.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10661",
        "start": "12:00",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "dozen_more_things_nextcloud",
        "title": "A dozen more things you didn't know Nextcloud could do",
        "subtitle": "And a little of what you DID know",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With Nextcloud you can sync, share and collaborate on data, but you don't need to put your photos, calendars or chat logs on an American server. Nope, Nextcloud is self-hosted and 100% open source! Thanks to hundreds of apps, Nextcloud can do a lot and in this talk, I will highlight some cool things.<\/p>",
        "description": "<p>Consider this a follow-up from my talk about 200 things Nextcloud can do last year! An update on what's new and some cool new stuff. What, what is <code>Nextcloud<\/code>? Let's see. A private cloud is one way to put it, though that's a contradiction of course. It is a way to share your data, sync your files, communicate and collaborate with others - without giving your data to GAFAM! Keep it on your own server, or something close (like a local hosting provider or data center). Nextcloud is a PHP app that does all that, and more! Easy to use, secure (really) and fully open source of course.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "79",
            "value": "Jos Poortvliet"
          }
        },
        "links":
        [
          {
            "_href": "http://nextcloud.com",
            "value": "Nc home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10661.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10287",
        "start": "12:30",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "bringing_collabora_online_webapp",
        "title": "Bringing Collabora Online to your web app",
        "subtitle": "Its easy to add rich document collaboration to your web app",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Collabora Online code-base can bring the power of LibreOffice into\nan iframe inside your web app. Come and hear how this works, how to integrate\nsecure, collaborative document editing with your software, and about all the\nlatest greatest work going on there.<\/p>",
        "description": "<p>Collabora Online uses a WOPI-like protocol, and it is rather simple to integrate.\nCome hear about the total of three REST methods you need for a simple\nintegration, as well as the wealth of options to control how collaboration works.<\/p>\n\n<p>Hear about some of our integrations into Nextcloud, Kolab,\nMattermost, Moodle, ownCloud, and many more.<\/p>\n\n<p>See the internals of Collabora Online, and how you can get involved with\nbuilding, debugging, and developing it, and checkout some of the new features\nfor Mobile and PC browser that we've been working on to make life better\nfor our users.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "425",
            "value": "Michael Meeks"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10287.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10597",
        "start": "13:00",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "more_than_one_tool_tiki",
        "title": "More than one tool for collaborating on writing the Tiki CMS",
        "subtitle": "This talk reviews the many collaboration tools used by the Tiki community for writing knowledge management and collaboration software",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The <em>Tiki Wiki CMS Groupware<\/em> software community obviously uses Tiki itself for collaboration and knowledge management.\nYet, many other software tools or infrastructures are used. I will review and explain how and why.<\/p>",
        "description": "<p><em>Tiki Wiki CMS Groupware<\/em> was initially released in 2002 and is still very much alive with a vibrant community.\nWe obviously want to use Tiki itself for collaboration and knowledge management as much as possible, but the real situation is, we use a lot more tools.\nWe leverage the fact that Tiki is part of wikisuite by using the other wikisuite software, but these still don't cover everything we use.\nThe reasons vary from old habits to convenience or improved efficiency and they are different for each collaboration tool.\nI will review them and explain why we use them and how useful they are to us. Also, I will mention our plans for the future.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1713",
            "value": "Jean-Marc Libs"
          }
        },
        "links":
        [
          {
            "_href": "https://tiki.org",
            "value": "Main Tiki project site"
          },
          {
            "_href": "https://wikisuite.org/Software",
            "value": "Wikisuite site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10597.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9752",
        "start": "13:30",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "wikibase_ecosystem",
        "title": "Wikibase Ecosystem",
        "subtitle": "taking Wikidata further",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Wikidata, Wikimedia's knowledge base, has been very successful since its inception 7 years ago. Wikidata's general purpose data about the world is powering everything from Wikipedia to your digital personal assistant. Its linked, machine readable data is collected and maintained by a community of over 20000 people. But not all data should and can be in Wikidata. Instead we are taking the software powering Wikidata, Wikibase, to new places. We empower communities and institutions all around the world who want to collect structured, machine-readable data about a topic area of their choice to run their own Wikibase. These Wikibase instances are then connected to form a thriving ecosystem. In this talk we'll go over what Wikibase is, where it's coming from and what it is enabling right now.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "290",
            "value": "Lydia Pintscher"
          }
        },
        "links":
        [
          {
            "_href": "http://wikiba.se",
            "value": "Wikibase homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9752.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10529",
        "start": "14:00",
        "duration": "00:25",
        "room": "AW1.120",
        "slug": "decentralized_collab_apps",
        "title": "Decentralized collaborative applications",
        "subtitle": "Peer-to-peer collaboration, search & discovery",
        "track": "Collaborative Information and Content Management Applications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A data-centric, offline-first approach to decentralized collaborative application development focusing on data ownership and privacy.<\/p>",
        "description": "<p>Exploring replicated mergeable data structure stores as building blocks of decentralized applications that enable asynchronous collaboration and offline search in combination with peer-to-peer gossip-based protocols that provide pub/sub, dissemination, and recommendation services both over the internet as well as on local and mobile proximity networks, thereby forming interest-based networks that facilitate discovery of personally relevant content and people.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7267",
            "value": "TG x"
          }
        },
        "links":
        [
          {
            "_href": "https://p2pcollab.net",
            "value": "https://p2pcollab.net"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10529.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9409",
        "start": "15:00",
        "duration": "01:00",
        "room": "AW1.120",
        "slug": "clc_the_unsupervised_free_cat_for_low_resource_languages",
        "title": "The unsupervised free CAT for low resource languages",
        "subtitle": "Building a pipeline for the communities",
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We present: 1) a full pipeline for unsupervised machine translation training (making use of monolingual corpora) for languages with low available resources; 2) a translation server making use of that unsupervised MT with an API compatible with the EU funded free Computer Aided Translation (CAT) tool MateCAT; 3) a Docker packaged version of MateCAT for ease of deployment.\nThis full translation pipeline enables a non technical user, speaking a non-FIGS language for which there is scarcity of parallel corpora, to start translating documents and software following translation industry standards.<\/p>",
        "description": "<p>Localization within community suffers from the fragmentation of technologies (too wide wedge between commercial Computer Aided Translation tools and free ones), available language resources (making difficult to train a Machine Translation) and lack of clear and robust pipelines to get started.\nLow resource language communities suffer the most, since MT systems require training corpora of millions of words and industry has settled to expecting the massive corpora available to FIGS (French, Italian, German, Spanish) languages.\nMoreover, the community suffers from a lack of adoption of established technologies and workflows, leading to reinventing the wheel and suboptimal efforts’ outcomes.\nToday we would like to present a connector for the implementation of an unsupervised MT (made by Artetxe et al.), that claims a BLEU of 26 on limited language resources (which is enough as a support system) integrated with MateCAT, an industry level, free, web based tool funded by EU, in order to provide a more viable alternative to resorting to Google Translate and commercial LSPs.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5507",
            "value": "Alberto Massidda"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/artetxem/monoses",
            "value": "the MT system we'll use"
          },
          {
            "_href": "http://https://www.matecat.com/open-source/",
            "value": "the CAT tool we'll integrate to"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9409.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9751",
        "start": "16:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "clc_lexemes_in_wikidata",
        "title": "Lexemes in Wikidata",
        "subtitle": "structured lexicographical data for everyone",
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Wikidata, Wikimedia's knowledge base, has been collecting general purpose data about the world for 7 years now. This data powers Wikipedia but also many applications outside Wikimedia, like your digital personal assistant. In recent years Wikidata's community has also started collecting lexicographical data in order to provide a large data set of machine-readable data about words in hundreds of languages. In this talk we will explore how Wikidata enables thousands of volunteers to describe their languages and make it available as a source of data for systems that do automated translation, text generation and more.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "290",
            "value": "Lydia Pintscher"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9751.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9819",
        "start": "16:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "clc_nuspell_version_3_of_the_new_spell_checker",
        "title": "Nuspell: version 3 of the new spell checker",
        "subtitle": "FOSS spell checker implemented in C++17 with aid of Mozilla",
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Nuspell version 3 is a FOSS checker that is written in pure C++17. It extensively supports character encodings, locales, compounding, affixing and complex morphology. Existing spell checking in web browsers, office suits, IDEs and other text editors can use this as a drop-in replacement. Nuspell supports 90 languages, suggestions and personal dictionaries.<\/p>",
        "description": "<p>In this talk we will summarize the functionality of Nuspell version 3 and provide easy to follow examples on how to use it as a command-line tool or link to the C++ library. Newly made integrations in Firefox and Enchant will be discussed. The audience will be invited to further integrate Nuspell into their software, create new language bindings, port it to other operating systems and help grow its community. This new spell checker has outgrown from an MVP to a faster and more complete spell checker.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3055",
            "value": "Sander van Geloven"
          }
        },
        "links":
        [
          {
            "_href": "https://nuspell.github.io/",
            "value": "Nuspell homepage"
          },
          {
            "_href": "https://github.com/nuspell",
            "value": "Nuspell GitHub"
          },
          {
            "_href": "https://fosstodon.org/@nuspell",
            "value": "Nuspell Mastodon"
          },
          {
            "_href": "https://www.facebook.com/nuspell",
            "value": "Nuspell Facebook"
          },
          {
            "_href": "https://twitter.com/nuspell1",
            "value": "Nuspell Twitter"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9819.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10034",
        "start": "17:00",
        "duration": "01:00",
        "room": "AW1.120",
        "slug": "clc_weblate_localize_your_project_the_developer_way",
        "title": "Weblate! Localize your project the developer way: continously, flawlessly, community driven, and open-source",
        "subtitle": "Don’t bother your development process with manual work. Connect Weblate to your VCS and let the localization magic happen.",
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presentation will show you how to localize your project easily with little effort, open-source way. Why we started Weblate? We said no to repetitive work, no to manual work with translation files anymore. Weblate is unique for its tight integration to VCS. Set it up once and start engaging the community of translators. More languages translated means more happy users of your software. Be like openSUSE, Fedora, and many more, and speak your users' language now thanks to Weblate!<\/p>",
        "description": "<p>The presentation will show you how to localize your project easily with little effort, open-source way. Why we started Weblate? We said no to repetitive work, no to manual work with translation files anymore. Weblate is unique for its tight integration to VCS. Set it up once and start engaging the community of translators. More languages translated means more happy users of your software. Be like openSUSE, Fedora, and many more, and speak your users' language now thanks to Weblate! I will show you the main perks of Weblate and the setup of the project. If you have a project with open repo and you want to start translating it, take your git:// link, and we will set it up right on the spot. FOSDEM is a great time and place to found your translating community. And I am looking forward to answer all your questions!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7059",
            "value": "Václav Zbránek"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/WeblateOrg/",
            "value": "Weblate code"
          },
          {
            "_href": "https://weblate.org",
            "value": "Weblate project site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10034.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10348",
        "start": "18:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "clc_open_edge_hardware_and_software_for_language_translation_and_understanding",
        "title": "Open Edge Hardware and Software for Natural Language Translation and Understanding",
        "subtitle": [],
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The last half decade has seen a major increase in the accuracy of deep learning methods for natural language translation and understanding. However many users still interact with these systems through proprietary models served on specialized cloud hardware. In this talk we discuss co-design efforts between researchers in natural language processing and computer architecture to develop an open-source software/hardware system for natural language translation and understanding across languages. With this system, users can access state-of-the-art models for translation, speech, and classification, and also run these models efficiently on edge device open-hardware designs.<\/p>\n\n<p>Our work combines two open-source development efforts, OpenNMT and FlexNLP.  The OpenNMT project is a multi-year collaborative project for creating an ecosystem for neural machine translation and neural sequence learning. Started in December 2016 by the Harvard NLP group and SYSTRAN, the project has since been used in many research and industry applications. The project includes highly configurable model architectures and training procedures, efficient model serving capabilities for use in real world applications, and extensions to tasks such as text generation, tagging, summarization, image to text, and speech to text. FlexNLP is an open-source fully retargetable hardware accelerator targeted for natural language processing. Its hardware design is targeted to key NLP computational functions such as attention mechanisms and layer normalization that are often overlooked by today’s CNN or RNN hardware accelerators. FlexNLP’s rich instruction set architecture and microarchitecture enable a diverse set of computations and operations that are paramount for end-to-end inference on state-of-the-art attention-based NLP models. Together they provide an open pipeline for both model training and edge device deployment.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7212",
            "value": "Alexander Rush"
          },
          {
            "_id": "7407",
            "value": "Thierry Tambe"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10348.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10517",
        "start": "18:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "clc_poio_predictive_text",
        "title": "Poio Predictive Text",
        "subtitle": "Grassroots Technology for Language Diversity",
        "track": "Coding for Language Communities",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Poio project develops language technologies to support communication in lesser-used and under-resourced languages on and with electronic devices. Within the Poio project we develop text input services with text prediction and transliteration for mobile devices and desktop users to allow conversation between individuals and in online communities.<\/p>",
        "description": "<p>In this lightning talk I will present the current architecture of the Poio Corpus, our corpus collection and data management pipeline. I will show how to add a new language to the corpus and how you can use the pipeline to build language models for the predictive text technology. Our goal is to make collaboration with language communities as smoothless as possible, so that developers, data engineers and speakers of under-ressourced language can collaborate to build grassroots language technologies. Poio started as a language revitalization project at the Interdisciplinary Centre for Social and Language Documentation in Minde/Portugal, a non-profit organization dedicated to the documentation and preservation of linguistic heritage.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6478",
            "value": "Peter Bouda"
          }
        },
        "links":
        [
          {
            "_href": "https://www.poio.eu/",
            "value": "Poio Site"
          },
          {
            "_href": "https://github.com/Poio-NLP",
            "value": "Poio Code Repositories"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10517.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "AW1.121",
    "event":
    [
      {
        "_id": "9739",
        "start": "10:30",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_farwest_demo",
        "title": "Farwest Demo",
        "subtitle": "A website/API for a document oriented database in 20 minutes",
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Farwest is an Erlang framework for building RESTful Web applications and APIs.<\/p>\n\n<p>Well written Farwest applications apply the HATEOAS principles and as a result can be interacted with using a single client. This removes entirely the need to write a separate client per API and lets servers decide how the data is best consumed by everyone.<\/p>\n\n<p>This demo will show how to use Farwest to write a simple API to a document oriented database.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6920",
            "value": "Loïc Hoguin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9739.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10179",
        "start": "11:00",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_opentelemetry_xkcd_927_success_story",
        "title": "OpenTelemetry: an XKCD 927 Success Story",
        "subtitle": [],
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn how distributed tracing can revolutionize the way you troubleshoot errors and performance issues, in both monolithic and distributed micro-service architectures.<\/p>\n\n<p>OpenTelemetry is an industry standard for distributed tracing, merging the tech and communities of OpenCensus and OpenTracing.<\/p>",
        "description": "<ul>\n<li>Introduce the concepts of application tracing and the state of the ecosystem (Spans, Traces, Context Propagation, OpenTracing, OpenCensus, OpenTelemetry)<\/li>\n<li>Explain how this is different and complementary to Erlang’s built-in tracing tools<\/li>\n<li>Show what insights can be more easily gained from trace data as opposed to logs and metrics<\/li>\n<li>Give an overview of the tools and vendors available to start using this technology today<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7126",
            "value": "Greg Mefford"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10179.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9433",
        "start": "11:30",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_debugging_tracing_rabbitmq_node",
        "title": "Debugging and tracing a production RabbitMQ node",
        "subtitle": [],
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, we will see how to debug/trace on a running RabbitMQ node.\nErlang remote access and remote debugging are builtin features in Erlang/Elixir.<br/>\nWith these features, it is possible to see what's happening inside a BEAM node (as RabbitMQ).\nI will show also how to use \"dynamic loading\"  to add a not native code in a running beam.<\/p>",
        "description": "<p>Erlang remote access and remote debugging are builtin features in Erlang/Elixir.<br/>\nWith these features, it is possible to see what's happening inside a BEAM node (as RabbitMQ).\nThere are a set of tools inside the beam like etop, eprof, dbg, fprof ... that work in the same Linux way.\nIn this talk, we will see how to use some of these features on a running RabbitMQ node.\nI will show also how to use \"dynamic loading\"  to add a not native code in a running beam.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6675",
            "value": "Gabriele Santomaggio"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9433.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10118",
        "start": "12:00",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_keep_calm_use_nerves",
        "title": "Keep Calm and Use Nerves",
        "subtitle": [],
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Intended as a introduction to Nerves, the IoT platform for the BEAM, this talk is a journey through the land of library ecosystems, device drivers and pixel manipulators, in search for the holy grail: a stable and maintainable IoT device.<\/p>",
        "description": "<p>The Nerves project (https://nerves-project.org/) is a framework for building IoT devices with Elixir. In this talk I will explain how a Nerves project is structured and then move on to show and demonstrate one of the projects that I did with it, focussing on the development experience and the state of the Nerves ecosystem.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7098",
            "value": "Arjan Scherpenisse"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10118.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9275",
        "start": "12:30",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_lumen_elixir_browser",
        "title": "Lumen",
        "subtitle": "Elixir in the browser",
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Lumen is an alternative compiler, interpreter and runtime to the BEAM designed for WebAssembly.  Lumen allows Erlang and Elixir to run in the browser.<\/p>",
        "description": "<p>The Lumen project is a reimplementation of the BEAM in Rust.  Using Rust, Lumen is able to leverage the cutting edge tools of the Rust WASM ecosystem.  Compiling Elixir and Erlang from source to LLVM IR, the Lumen compiler is able to do whole program optimizations allowing for dead-code elimination of parts of the user application, OTP, and the runtime itself.  Eliminating the dead code makes shipping OTP size-competitive with JavaScript frameworks, while retaining the benefits of thousands of concurrent processes and supervision trees.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6591",
            "value": "Luke Imhoff"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/lumen/lumen",
            "value": "Lumen GitHub repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9275.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10379",
        "start": "13:00",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_coffeebeam_beam_vm_android",
        "title": "CoffeeBeam",
        "subtitle": "A BEAM VM for Android",
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The speaker started to experiment with running BEAM modules on Android during summer of 2019. A prototype called CoffeeBeam has been created that is capable of loading and running BEAM files on Android. The solution also contains a virtual machine that provides a lightweight Erlang runtime system. Most of the implemented functionality is independent of the source language of the BEAM files, so the platform is easily extensible to support further languages on the BEAM. During the talk, the speaker is going to present a real-life example of running a BEAM file on Android, while presenting the concepts of the implementation and sharing the story of this journey.<\/p>",
        "description": "<h1>CoffeeBeam: a BEAM VM for Android<\/h1>\n\n<h2>Goal<\/h2>\n\n<p>CoffeeBeam is a lightweight Erlang virtual machine that provides easy integration of BEAM files with Android applications. The current alternative solutions provide almost fully functional Erlang runtime systems in the form of Erlang shell on Android devices. However, CoffeeBeam follows a different approach, targeting easy integration of pre-compiled BEAM files into standalone Android applications. The characteristics of Android devices are in focus: they provide large amount of memory while CPU usage needs to be optimized to provide longer device lifetime. It is preferred to make the communication between Erlang and the Android application transparent to provide better user experience.<\/p>\n\n<h2>Use Case<\/h2>\n\n<p>Let's assume that you chose a language over the BEAM to implement an application logic efficiently. CoffeeBeam provides a framework to build on this logic and enable communication between the BEAM and the Android application with only minor changes to your original code. The demonstrated example is a <code>TicTacToe<\/code> game where the game logic is implemented in Erlang that is extended with a graphical user interface implemented as an Android activity in Java.<\/p>\n\n<h2>Application Architecture<\/h2>\n\n<h3>Android Activity<\/h3>\n\n<p>The <code>TicTacToe<\/code> game is implemented as an Android activity which is a common way of creating interactive applications. The activity contains the view for displaying textual information (game name and user instructions depending on the state of the game) and widgets (game board and new game button) for initiating user actions towards the game logic.<\/p>\n\n<h3>CoffeeBeam VM<\/h3>\n\n<p>The CoffeBeam VM provides the runtime system for the game logic. It is written in Java and included as a <code>.jar<\/code> library inside the Android application source code. Starting and stopping the VM is connected to the <code>onCreate()<\/code> and <code>onDestroy()<\/code> callbacks of the activity.<\/p>\n\n<h3>Game logic<\/h3>\n\n<p>The flow of the game and the computer player's intelligence is implemented as an Erlang module (approximately 250 lines of code) and the compiled <code>.beam<\/code> file is packaged into the Android application as resource.<\/p>\n\n<h2>Communication<\/h2>\n\n<p>The <code>BeamClient<\/code> class provides interface for starting and stopping the VM, and manages communication between the VM and the Android application through function calls and callback functions. The default behavior can be redefined by extending the <code>BeamClient<\/code> class. The forms of communication are described in detail below.<\/p>\n\n<h3>Function call in the VM<\/h3>\n\n<p>User actions in the Android application are translated into function calls in the VM using the <code>apply(String module, String function, ErlList args)<\/code> method of the <code>BeamClient<\/code> class. The function call implies creating a new process in the Erlang VM and applying <code>module:function<\/code> with the list of <code>args<\/code>. The <code>TicTacToe<\/code> game logic provides the following functions:<\/p>\n\n<ul>\n<li>Start the game process: <code>start()<\/code>. The game process is spawned that initializes the board for a new game.<\/li>\n<li>Start a new game: <code>new_game(GamePid)<\/code>. The game board is cleared and a new game starts in the game process identified by <code>GamePid<\/code>.<\/li>\n<li>The player selects a field: <code>put(GamePid, X, Y)<\/code>. The player marks the <code>(X,Y)<\/code> field of the game board with an <code>X<\/code> sign.<\/li>\n<\/ul>\n\n\n<h3>Handle function result in Android<\/h3>\n\n<p>When the Erlang function is executed in the VM, the result of the function initiates a callback in the <code>BeamClient<\/code> as <code>handleResult(ErlTerm result)<\/code>. In the <code>TicTacToe<\/code> example, the process identifier of the game process is returned as the result of the <code>tictactoe:start()<\/code> function. The returned value can be used to send Erlang messages to the game process during the game.<\/p>\n\n<h3>Handle function callback in Android<\/h3>\n\n<p>Each call in the form of <code>beamclient:function(arg)<\/code> in the Erlang modules results in a <code>BeamClient<\/code> callback <code>handleCall(String function, ErlTerm arg)<\/code>. Each game event invokes a <code>beamclient:update({Event, Board})<\/code> function call that is translated into <code>handleCall<\/code> callback in the Android application.<\/p>\n\n<h2>Summary and contribution<\/h2>\n\n<p>CoffeeBeam executes BEAM files in a lightweight VM that can be packaged into the Android application. The above <code>TicTacToe<\/code> example showed how to include the Erlang game logic in the Android application that provides the graphical user interface. The game flow runs in a separate process in the CoffeBeam VM, and the communication with Android is done through <code>BeamClient<\/code> function calls and callbacks.<\/p>\n\n<p>The CoffeeBeam VM is open source and available for further development to extend the VM functionality or implement customizations for other languages running on the BEAM. The source code with documented interface is available at: https://github.com/vikger/coffeebeam.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7227",
            "value": "Viktor Gergely"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/vikger/coffeebeam",
            "value": "CoffeeBeam on GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10379.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10362",
        "start": "13:30",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_going_meta_elixir_macros",
        "title": "Going Meta with Elixir's Macros",
        "subtitle": "Running at compile-time and compiling at runtime",
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Compilation and execution are as different as night and day. Or are they? By blurring the lines, Elixir (and the BEAM VM) enable some very powerful and useful meta-programming techniques.<\/p>\n\n<p>In this presentation, Marten will talk about running and generating code at compile-time, Elixir's hygienic macros, and how to compile and hot-reload altered or extra code, while your program is running!\nBesides explaining these concepts, their usefulness will be motivated using various practical real-world examples.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7216",
            "value": "Wiebe-Marten Wijnja"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10362.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10120",
        "start": "14:00",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "beam_processes_grains_journey_orleans",
        "title": "Processes & Grains",
        "subtitle": "A Journey in Orleans",
        "track": "Erlang, Elixir and Friends",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": "<p>A popular way to manage long-running state in Erlang and Elixir programs is by using processes; this model is well-understood and well-supported, but remains firmly rooted within known orthodoxy. Within this session, I shall demonstrate application of the Orleans model to existing Erlang and Elixir applications, review existing work done by the community, and compare this way of programming against other models. For maximum enjoyment, the audience is advised to possess working knowledge of Erlang and Elixir. Some background knowledge in Web applications will be helpful as well. The session will be presented with live demo in Elixir.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7099",
            "value": "Evadne Wu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10120.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10513",
        "start": "15:00",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_python_scalable_graph_processing",
        "title": "Designing a performant and scalable graph processing python package",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Python has proven to be a popular choice for data scientists in\nthe domain of graph analytics. The multitude of freely available\nframeworks and python packages allow to develop applications\nquickly through ease of expressibility and reuse of code.\nWith petabytes of data generated everyday and an ever evolving\nlandscape of hardware solutions, we observe a graph processing\nframework should expose the following characteristics: ease of\nuse, scalability, interoperability across data formats, and\nportability across hardware vendors.\nWhile existing python packages have been helping to drive\napplication development, our assessment is that none of the\npackages address all the aforementioned challenges.\nWe propose a community led, open source effort, to design and\nbuild  a graph processing python library to specifically address\nthese challenges.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7283",
            "value": "Vincent Cave"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10513.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9380",
        "start": "15:25",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_graffiti",
        "title": "Graffiti",
        "subtitle": "A historical, distributed graph engine",
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Graffiti is the graph engine of Skydive - an open source networking analysis tool. Graffiti was created from scratch to provide the features required by Skydive : distributed, replicated, store the whole history of the graph, allow subcribing to events on the graph using WebSocket and visualization.<\/p>",
        "description": "<p>Skydive (https://skydive.network) is an open source analysis tool. It collects information about an infrastructure topology - such as network interfaces, Linux bridges, network namespaces, containers, virtual machines, ... and store them into a graph database called Graffiti (https://github.com/skydive-project/skydive/tree/master/graffiti)<\/p>\n\n<p>The graph is :<\/p>\n\n<pre><code>- distributed : some agents only have a portion of the graph\n- replicated : for high availability and load distribution\n- historical : every change on the graph is archived, allowing retrieval of the graph at any point in time or getting all the revisions of a set of nodes and edges during a period of time\n<\/code><\/pre>\n\n<p>A custom implementation of the Gremlin language is used to query the graph, with some additional steps to specify the time context of the query for instance.<\/p>\n\n<p>In addition to the core engine, a WebSocket based user interface - based on D3JS - is available to visualize and interact with the graph.<\/p>\n\n<p>This presentation will showcase a demo of Graffiti and try to advocate its use in your own project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "476",
            "value": "Sylvain Baubeau"
          }
        },
        "links":
        [
          {
            "_href": "https://skydive.network",
            "value": "Project website"
          },
          {
            "_href": "https://github.com/skydive-project/skydive",
            "value": "Project source code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9380.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9826",
        "start": "15:50",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_neo4j_algos",
        "title": "The Neo4j Graph Algorithms Library: An Overview",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Graph algorithms play an increasingly important role in real-world applications. The Neo4j Graph Algorithms library contains a set of ~50 graph algorithms covering a lot of different problem domains. In our talk, we’ll present the architecture of the library and demonstrate the different execution phases using a real world example.<\/p>",
        "description": "<p>Graph algorithms play an increasingly important role in real-world applications. Use-cases that we see in the wild are related to fraud detection, fraud detection, retail recommendation and identifying influencers for marketing campaigns. The Neo4j Graph Algorithms library contains a set of ~50 graph algorithms covering the above-mentioned problem domains.<\/p>\n\n<p>Running a graph algorithm in Neo4j involves three essential steps: loading the graph from the database in an optimized in-memory format, executing the algorithm, and streaming or writing of results. For the user, these steps are hidden behind single procedure calls, integrated in the Cypher query language.<\/p>\n\n<p>In our talk, we will explain and demonstrate what happens in the system when a user calls an algorithm procedure. This involves scanning Neo4j store files, constructing our in-memory graph representation and executing an algorithm via our Java Graph API.<\/p>\n\n<p>Attendees will learn how to setup and use the Neo4j Graph Algorithms Library. Furthermore, they will get a good understanding of how the library works internally and how to tune it for specific use-cases.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7366",
            "value": "Paul Horn"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9826.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9905",
        "start": "16:15",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_gunrock",
        "title": "Gunrock: High-Performance Graph Analytics for the GPU",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Gunrock is a CUDA library for graph-processing designed specifically for the GPU. It uses a high-level, bulk-synchronous, data-centric abstraction focused on operations on vertex or edge frontiers. Gunrock achieves a balance between performance and expressiveness by coupling high-performance GPU computing primitives and optimization strategies, particularly in the area of fine-grained load balancing, with a high-level programming model that allows programmers to quickly develop new graph primitives that scale from one to many GPUs on a node with small code size and minimal GPU programming knowledge.<\/p>\n\n<p>Features of Gunrock include:\n- Best of class performance among GPU graph analytics frameworks\n- A large number of graph applications (28 at last count)\n- A data-centric programming model targeted at GPUs that offers advantages over other programming models\n- A programming model that scales to multiple GPUs with high performance while still using the same code as a single-GPU primitive<\/p>\n\n<p>Gunrock began in 2013 as a project under DARPA's XDATA program and is currently the performance reference in DARPA's HIVE program. Gunrock is also in development as a component in NVIDIA's RAPIDS platform for data analytics. The Gunrock team actively develops and improves Gunrock under an Apache 2.0 license.<\/p>\n\n<p>https://gunrock.github.io/<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7363",
            "value": "Muhammad Osama"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9905.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10471",
        "start": "16:40",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_hardware_software_co_design",
        "title": "Hardware-Software Co-Design for Efficient Graph Application Computations on Emerging Architectures",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Graph databases and applications have attracted much attention in the past few years due to the efficiency with which they can represent big data, connecting different layers of data structures and allowing analysis while preserving contextual relationships.\nThis has resulted in a fast-growing community that has been developing various database and algorithmic innovations in this area, many of which will be gathering together in this conference. We joined this field as computer architecture researchers and are currently building a complete hardware-software design, called DECADES, that aims to accelerate the execution of these algorithms.<\/p>\n\n<p>From a computer architecture point of view, applications involving dense matrix operations such as neural networks have garnered much attention for their acceleration through specialized hardware such as GPUs and TPUs, while graph applications remain difficult to improve even with modern specialized accelerator designs. The reason for this is the characteristic pointer-based data structures of graph applications and the resulting irregular memory accesses performed by many of these workloads. Such irregular memory accesses result in memory latency bottlenecks that dominate the total execution time. In this talk, as part of the DECADES infrastructure, we present an elegant hardware-software codesign solution, named FAST-LLAMAs, to overcome these memory-bottlenecks, and thus, accelerate graph and sparse applications in an energy efficient way.<\/p>",
        "description": "<p>Graph databases and applications have attracted much attention in the past few years due to the efficiency with which they can represent big data, connecting different layers of data structures and allowing analysis while preserving contextual relationships.\nThis has resulted in a fast-growing community that has been developing various database and algorithmic innovations in this area, many of which will be gathering together in this conference. We joined this field as computer architecture researchers and are currently building a complete hardware-software design, called DECADES, that aims to accelerate the execution of these algorithms.<\/p>\n\n<p>From a computer architecture point of view, applications involving dense matrix operations such as neural networks have garnered much attention for their acceleration through specialized hardware such as GPUs and TPUs, while graph applications remain difficult to improve even with modern specialized accelerator designs. The reason for this is the characteristic pointer-based data structures of graph applications and the resulting irregular memory accesses performed by many of these workloads. Such irregular memory accesses result in memory latency bottlenecks that dominate the total execution time. In this talk, as part of the DECADES infrastructure, we present an elegant hardware-software codesign solution, named FAST-LLAMAs, to overcome these memory-bottlenecks, and thus, accelerate graph and sparse applications in an energy efficient way.<\/p>\n\n<p>We propose a 40 minute talk which includes a rigorous characterization of the problem, and an in-depth analysis of our software-hardware co-design solution, FAST LLAMAs. We will present results based on a simulated model of our system which show significant performance improvements (up to 8x), as well as energy improvements (up to 20x) on a set of fundamental graph algorithms and important real-world datasets. Our system is completely open-source, and includes a compiler and cycle-accurate simulator. Our proposed system is compatible and easily extendable to many of the open-source graph analytic and database frameworks and we are excited to engage with the open-source community of this increasingly important domain.<\/p>\n\n<p>The work is part of a large collaboration from three academic groups: Margaret Martonosi (PI Princeton), David Wentzlaff (PI Princeton), Luca Carloni (PI Columbia) with students/researchers: Juan L. Aragón (U. of Murcia, Spain), Jonathan Balkind, Ting-Jung Chang, Fei Gao, Davide Giri, Paul J. Jackson, Aninda Manocha, Opeoluwa Matthews, Tyler Sorensen, Esin Türeci, Georgios Tziantzioulis, and Marcelo Orenes Vera. In addition to the submission author, portions of the talk may be offered by others in the collaboration.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7074",
            "value": "Margaret Martonosi"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/PrincetonUniversity/DecadesCompiler",
            "value": "LLVM-based Compiler framework for Graph Algorithms"
          },
          {
            "_href": "http://https://github.com/PrincetonUniversity/MosaicSim",
            "value": "LLVM bytecode simulator"
          },
          {
            "_href": "https://hub.docker.com/repository/docker/princetondecades/decades",
            "value": "Docker container"
          },
          {
            "_href": "https://github.com/PrincetonUniversity/decades_documentation",
            "value": "Jupyter notebooks"
          },
          {
            "_href": "https://github.com/amanocha/DECADES_Applications",
            "value": "Application tutorial"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10471.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10339",
        "start": "17:05",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_puma",
        "title": "Programmable Unified Memory Architecture (PUMA)",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Large scale graph analytics is essential to analyze relationships in big data sets. Thereto, the DARPA HIVE program targets a leap in power efficient graph analytics. In response to this program, Intel proposes the Programmable Unified Memory Architecture (PUMA). Based on graph workload analysis insights, PUMA consists of many multi-threaded cores, fine-grained memory and network accesses, a globally shared address space and powerful offload engines. In this talk, we will describe the PUMA architecture, both in terms of hardware and the software ecosystem. We will provide initial simulation based performance estimations, showing that for graph analysis applications, a PUMA node will outperform a conventional compute node by one to two orders of magnitude. Additionally, PUMA will continue to scale across multiple nodes, which is a challenge in conventional multinode setups.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7206",
            "value": "Stijn Eyerman"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10339.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10677",
        "start": "17:30",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_cypher_sharding",
        "title": "Cypher enhancements for sharded and federated graph databases",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we will introduce enhancements to the Cypher graph query language, enabling queries spanning multiple graphs, intended for use in sharding and federation scenarios.\nWe will also present our experience with sharding the LDBC Social Network Benchmark dataset.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "6341",
            "value": "Tobias Johansson"
          },
          {
            "_id": "7367",
            "value": "Petr Janouch"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10677.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10223",
        "start": "17:55",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_raphtory",
        "title": "Raphtory: Streaming analysis of distributed temporal graphs",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Temporal graphs capture the development of relationships within data throughout time. This model fits naturally within a streaming architecture, where new events can be inserted directly into the graph upon arrival from a data source, being compared to related entities or historical state. However, the vast majority of graph processing systems only consider traditional graph analysis on static data, with some outliers supporting batched updating and temporal analysis across graph snapshots. This talk will cover recent work defining a temporal graph model which can be updated via event streams and investigating the challenges of distribution and graph maintenance. Some notable challenges within this include partitioning a graph built from a stream, with the additional complexity of managing trade-offs between structural locality (proximity to neighbours) and temporal locality (proximity to an entities history). Synchronising graph state across the cluster and handling out-of-order updates, without a central ground truth limiting scalability. Managing memory constraints and performing analysis in parallel with ongoing update ingestion.\nTo address these challenges, we introduce Raphtory, a system which maintains temporal graphs over a distributed set of partitions, ingesting and processing parallel updates in near real-time. Raphtory's core components consist of Graph Routers and Graph Partition Managers. Graph Routers attach to a given input stream and convert raw data into graph updates, forwarding this to the Graph Partition Manager handling the affected entity. Graph Partition Managers contain a partition of the overall graph, inserting updates into the histories of affected entities at the correct chronological position. This removes the need for centralised synchronisation, as commands may be executed in any given arrival order whilst resulting in the same history. To deal with memory constraints, Partition Managers both compress older history and set an absolute threshold for memory usage. If this threshold is met a cut-off point is established, requiring all updates prior to this time to be transferred to offline storage. Once established and ingesting the selected input, analysis on the graph is permitted via Analysis Managers. These connect to the cluster, broadcasting requests to all Partition Managers who execute the algorithm. Analysis may be completed on the live graph (most up-to-date version), any point back through its history or as a temporal query over a range of time.  Additionally, multiple Analysis Managers may operate concurrently on the graph with previously unseen algorithms compiled at run-time, thus allowing modification of ongoing analysis without re-ingesting the data.\nRaphtory is an ongoing project, but is open source and available for use now. Raphtory is fully containerised for ease of installation and deployment and much work has gone into making it simple for users to ingest their own data sources, create custom routers and perform their desired analysis.\nThe proposed talk will discuss the benefits of viewing data as a temporal graph, the current version of Raphtory and how someone could get involved with the project. We shall also touch on several areas of possible expansion at the end for discussion with those interested.<\/p>",
        "description": "<p>The intended audience for this talk is a mixture of data scientists and graphy engineers. It is going to be quite high level, but introducing some interesting ideas of how to view data through the lens of a temporal graph as well as novel systems solutions for distribution, maintenance and processing.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6991",
            "value": "Ben Steer"
          }
        },
        "links":
        [
          {
            "_href": "https://www.sciencedirect.com/science/article/pii/S0167739X19301621",
            "value": "Latest Paper for Raphtory"
          },
          {
            "_href": "https://github.com/miratepuffin/raphtory",
            "value": "Open Source Repository for Raphtory"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10223.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10270",
        "start": "18:20",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_temporal_gradoop",
        "title": "Temporal Graph Analytics with GRADOOP",
        "subtitle": [],
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The temporal analysis of evolving graphs is an important requirement in many domains but hardly supported in current graph database and graph processing systems. We, therefore, extended the distributed graph analytics framework Gradoop for time-related graph analysis by introducing a new temporal property graph data model. Our model supports bitemporal time dimensions for vertices and edges to represent both rollback and historical information. In addition to the data model, we introduce several time-dependent operators (e.g, Snapshot, Diff and Grouping) that natively support the natural evolution of the graph. Since this is an extension of Gradoop, the temporal operators are compatible and can be combined with the already known operators to build complex analytical tasks in a declarative way. In our talk, we will give a brief overview of the Gradoop system, the temporal property graph model and how we support the time-dependent analysis of large graphs. Based on real-world use-cases, we show the expressiveness and flexibility of our temporal operators and how they can be composed to answer complex analytical questions.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7165",
            "value": "gomez"
          }
        },
        "links":
        [
          {
            "_href": "http://gradoop.com",
            "value": "Gradoop GitHub"
          },
          {
            "_href": "https://dbs.uni-leipzig.de/file/LEGECML-PKDD_2019_paper_9.pdf",
            "value": "TPGM@LEGECML-PKKD2019"
          },
          {
            "_href": "https://dl.gi.de/bitstream/handle/20.500.12116/21797/C2-1.pdf?sequence=1&isAllowed=y",
            "value": "TPGM@BTW2019"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10270.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9495",
        "start": "18:40",
        "duration": "00:20",
        "room": "AW1.121",
        "slug": "graph_weaviate",
        "title": "Weaviate OSS Smart Graph",
        "subtitle": "feature updates, demo and use cases",
        "track": "Graph Systems and Algorithms",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Weaviate is an open-source smart graph that aims to allow anyone, anywhere, any time to create their own semantic search engines, knowledge graphs or knowledge networks. Weaviate is RESTful and GraphQL API based and built on top of a semantic vector storage mechanism called the contextionary. Because all data is stored in the vector space, Weaviate is ideal for;\n- Semantically search through the knowledge graph.\n- Automatically classify entities in the graph.\n- Create easy to use knowledge mappings.<\/p>\n\n<p>Because the use of formal ontologies are optional, Weaviate can be used to create a P2P knowledge network which we want to present during this conference.<\/p>\n\n<p>This is a follow up after the initial design was shared during last year's FOSDEM.<\/p>",
        "description": "<h1>Problem<\/h1>\n\n<p>Creating a knowledge graph can be a complex endeavor, let alone the integration of semantic search models. Bain &amp; Company research under US enterprise CTO's shows that 59% of them believe they lack the capabilities to generate meaningful business insights from their data, and 85% said it would require substantial investments to improve their data platforms.<\/p>\n\n<h1>Solution<\/h1>\n\n<p>Weaviate aims anyone to create large, enterprise-scale knowledge graphs as straight forward as possible. Weaviate's feature set allows anyone to;\n- Semantically search through the knowledge graph.\n- Automatically classify entities in the knowledge graph.\n- Create easy to use knowledge mappings.<\/p>\n\n<h1>Weaviate's Contextionary<\/h1>\n\n<p>Weavite's Contextionary is the semantic vector storage mechanism that stores data -unlike traditional storage mechanisms- based on its semantic meaning. For example, if someone stores information about a company with the name Apple, this data object would be found closely related to concepts like the iPhone.<\/p>\n\n<p>Because of the algorithmic use (as opposed to retraining) of the pre-trained machine learning model, Weaviate is able to learn new concepts fast and near-realtime. This allows the user to update and manipulate the knowledge graph directly.<\/p>\n\n<h1>Demo &amp; Use cases<\/h1>\n\n<p>During the session, we want to show a few -recent- use cases to demo how Weaviate can be used. The demo will include;\nquerying;\nsemantic querying;\nadding concepts;\ngoing from an ontology to a schema;\nand more.<\/p>\n\n<h1>Knowledge network<\/h1>\n\n<p>Because of Weaviate's contextionary, a formal ontology is optional (e.g., \"a company with the name Netflix\" is semantically similar to \"a business with the identifier Netflix Inc.\") this allows multiple Weaviate to connect and communicate over a peer to peer (P2P) network to exchange knowledge. Aka, the knowledge network. During the session, we want to demonstrate the first prototype of this network.<\/p>\n\n<h1>more information<\/h1>\n\n<p>more information can be found on our website: https://www.semi.technology/documentation/weaviate/current/<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6158",
            "value": "Bob van Luijt"
          }
        },
        "links":
        [
          {
            "_href": "https://www.semi.technology/documentation/weaviate/current/",
            "value": "Weaviate docs & guides"
          },
          {
            "_href": "https://github.com/semi-technologies/weaviate",
            "value": "Weaviate on Github"
          },
          {
            "_href": "https://semi.technology",
            "value": "SeMI website (Weaviate maintainers)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9495.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "AW1.125",
    "event":
    [
      {
        "_id": "10682",
        "start": "10:30",
        "duration": "00:05",
        "room": "AW1.125",
        "slug": "ada_welcome",
        "title": "Welcome to the Ada DevRoom",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the Ada Developer Room at FOSDEM 2020, which is organized\nby Ada-Belgium in cooperation with Ada-Europe.<\/p>",
        "description": "<p>Ada-Belgium and Ada-Europe are non-profit organizations set up\nto promote the use of the Ada programming language and related\ntechnology, and to disseminate knowledge and experience into academia,\nresearch and industry in Belgium and Europe, resp.  Ada-Europe has\nmember-organizations, such as Ada-Belgium, in various countries,\nand direct members in many other countries.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "581",
            "value": "Dirk Craeynest"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#welcome",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10682.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10683",
        "start": "10:35",
        "duration": "00:45",
        "room": "AW1.125",
        "slug": "ada_intro",
        "title": "An Introduction to Ada for Beginning and Experienced Programmers",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An overview of the main features of the Ada language, with special\nemphasis on those features that make it especially attractive for\nfree software development.<\/p>",
        "description": "<p>Ada is a feature-rich language, but what really makes Ada stand-out is\nthat the features are nicely integrated towards serving the goals of\nsoftware engineering.  If you prefer to spend your time on designing\nelegant solutions rather than on low-level debugging, if you think\nthat software should not fail, if you like to build programs from\nreadily available components that you can trust, you should really\nconsider Ada<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "861",
            "value": "Jean-Pierre Rosen"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#intro",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10683.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10684",
        "start": "11:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_hac",
        "title": "HAC: the Compiler which will Never Become Big",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In the Ada world, we are surrounded by impressive and professional\ntools that can handle large and complex projects.  Did you ever\ndream of a tiny, incomplete but compatible system to play with?\nAre you too impatient, when developing small pieces of code, for\nlong compile-bind-link-run cycles?  Are you a beginner intimidated by\nproject files and sophisticated tools?  Then HAC (the HAC Ada Compiler,\nor the Hello-world Ada Compiler) is for you.<\/p>",
        "description": "<p>HAC is a revival of the SmallAda project, which supported the \"Pascal\nsubset\" plus tasking.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6295",
            "value": "Gautier de Montmollin"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#hac",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10684.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10685",
        "start": "12:00",
        "duration": "00:50",
        "room": "AW1.125",
        "slug": "ada_performance",
        "title": "Tracking Performance of a Big Application from Dev to Ops",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk describes how performance aspects of a big Air Traffic Flow\nManagement mission critical application are tracked from development\nto operations.<\/p>",
        "description": "<p>Tracking performance is needed when new functionality is added, to\nbalance the additional services versus the resource increase needed.\nMeasuring and tracking performance is also critical to ensure a new\nrelease can cope with the current or expected load.<\/p>\n\n<p>We will discuss various aspects such as which tools and techniques\nare used for performance tracking and measurements, what are the\ntraps and pitfalls encountered for these activities.  The application\nin question is using Ada, but most of the items discussed are not\nparticularly Ada related.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1402",
            "value": "Philippe Waroquiers"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#performance",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10685.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9112",
        "start": "13:00",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_bindings",
        "title": "Cappulada: What we've Learned",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Last year I presented Cappulada, a C++ binding generator for Ada that\nintended to overcome the shortcomings of existing solutions and to\nprovide usable bindings even for complex C++ code.<\/p>\n\n<p>This year I want to show our conclusions on why automatic bindings\nbetween C++ and Ada are hard (if not impossible) and where existing\nsolutions (including our own) fail.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6087",
            "value": "Johannes Kliemann"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#bindings",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://archive.fosdem.org/2019/schedule/event/ada_bindings/",
            "value": "Cappulada Talk on FOSDEM19"
          },
          {
            "_href": "https://github.com/Componolit/Cappulada",
            "value": "Cappulada on GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9112.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10686",
        "start": "13:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_ros2",
        "title": "Programming ROS2 Robots with RCLAda",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Robot Operating System (ROS) is one of the chief frameworks\nfor service robotics research and development.  The next iteration\nof this framework, ROS2, aims to improve critical shortcomings of\nits predecessor like deterministic memory allocation and real-time\ncharacteristics.<\/p>\n\n<p>RCLAda is a binding to the ROS2 framework that enables the programming\nof ROS2 nodes in pure Ada with seamless integration into the ROS2\nworkflow.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7355",
            "value": "Alejandro Mosteo"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#ros2",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10686.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10688",
        "start": "14:00",
        "duration": "00:50",
        "room": "AW1.125",
        "slug": "ada_distribution",
        "title": "Live Demo of Ada's Distribution Features",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ada incorporates in its standard a model for distributed execution.\nIt is an abstract model that does not depend on a particular kind of\nnetwork or any other communication mean, and that preserves full typing\ncontrol across partitions.  This presentation briefly exposes the\nprinciples of Ada's distribution model, then shows the possibilities\nwith life demos across different machines and operating systems.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "861",
            "value": "Jean-Pierre Rosen"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#distribution",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10688.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10689",
        "start": "15:00",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_parallel",
        "title": "Writing Shared Memory Parallel Programs in Ada",
        "subtitle": "Multitasked Newton's Method for Power Series",
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Tasks in Ada are effective to speed up computations on multicore\nprocessors.  In writing parallel programs we determine the granularity\nof the parallelism with respect to the memory management.  We have to\ndecide on the size of each job, the mapping of the jobs to the tasks,\nand on the location of the input and output data for each job.<\/p>\n\n<p>A multitasked Newton's method will show the effectiveness of Ada to\nspeed up the computation of power series.  This application belongs\nto the free and open source package PHCpack, a package to solve\npolynomial systems by polynomial homotopy continuation.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1899",
            "value": "Jan Verschelde"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#parallel",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10689.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9109",
        "start": "15:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_spunky",
        "title": "Spunky: a Genode Kernel in Ada/SPARK",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Genode OS framework is an open-source tool kit for building highly\nsecure component-based operating systems scaling from embedded devices\nto dynamic desktop systems.  It runs on a variety of microkernels\nlike SeL4, NOVA, and Fiasco OC as well as on Linux and the Muen SK.\nBut the project also features its own microkernel named \"base-hw\"\nwritten in C++ like most of the Genode framework.<\/p>\n\n<p>Spunky is a pet project of mine.  Simply put it's an approach to\nre-implement the design of the \"base-hw\" kernel first in Ada and\nlater in SPARK with the ultimate goal to prove its correctness.\nIt is also an opportunity to learn how Genode can benefit from Ada\nand SPARK in general and promote the use of safety-oriented languages\nin the project.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3625",
            "value": "Martin Stein"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#spunky",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9109.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10690",
        "start": "16:00",
        "duration": "00:50",
        "room": "AW1.125",
        "slug": "ada_alire",
        "title": "Alire: Ada Has a Package Manager",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Alire (Ada LIbrary REpository) is a package manager project for the\nAda/SPARK community.  The goal of a package manager is to facilitate\ncollaboration within the community and to lower the barrier of entry\nfor beginners.<\/p>",
        "description": "<p>In this talk we will present the Alire project, what it can do for\nyou and how you can contribute and give more visibility to your\nAda/SPARK projects.<\/p>\n\n<p>We will also provide a tutorial to show how to use Alire to create\na library and then publish it for others to use.<\/p>",
        "persons":
        [
          {
            "_id": "3897",
            "value": "Fabien Chouteau"
          },
          {
            "_id": "5346",
            "value": "Pierre-Marie de Rodat"
          },
          {
            "_id": "7355",
            "value": "Alejandro Mosteo"
          }
        ],
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#alire",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10690.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10691",
        "start": "17:00",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_keystore",
        "title": "Protect Sensitive Data with Ada Keystore",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Storing passwords and secret configuration is a challenge for an\napplication.  Ada Keystore is a library that stores arbitrary content\nby encrypting them in secure keystore (AES-256, HMAC-256).<\/p>",
        "description": "<p>The talk presents the project and shows how to use the Ada Keystore\nlibrary to get or store secret information in a secure manner.\nThe presentation explains how the Ada features such as types, protected\ntypes, tasks, pre/post conditions have helped during the development\nof this project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5344",
            "value": "Stephane Carrez"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#keystore",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10691.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10692",
        "start": "17:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_eugen",
        "title": "EUgen: a European Project Proposal Generator",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Whoever wrote a research project proposal knows how much unnerving it\ncan be.  The actual project description (made of work packages, tasks,\ndeliverable items, ...) has lots of redundancies and cross-references\nthat makes its coherency as frail as a house of cards.  For example,\nif the duration of a task is changed most probably you'll need to\nupdate the effort in person-months of the task and of the including\nwork package; you must update the start date of depending tasks and\nthe deliver date of any deliverable items; most probably also the\nWP efforts and length need update too; not to mention the need of\nupdating all the summary tables (summary of efforts, deliverable,\n..) and the GANTT too.  Any small changes is likely to start a ripple\nof updates and the probability of forgetting something and getting an\nincoherent project description is large.  Given the harsh competition\nin project funding, if your project is incoherent the probability of\ngetting funded is nil.<\/p>\n\n<p>One day I got sick of this state of affair and I wrote my own project\ngenerator: 10k lines of Ada code that reads a non-redundant project\ndescription from a simple-format text file and produces a set of files\nready to be imported in the proposal, GANNT chart included.  The user\ncan specify dependences between different items (e.g., this deliverable\nis produced at the end of this task, this milestone is reached when\nthis deliverable is available, this task must begin after this other\ntask...) and the program automatically computes all the dates.<\/p>",
        "description": "<p>Both input parser and output processors are implemented using a plugin\nstructure that makes it easy to write new parsers to read different\nformats or new output processors to produce output in different\nformats.  Currently a parser for a simple ad-hoc format and an output\nprocessor that produces LaTeX files are provided; a new processor based\non the template expander <em>protypo<\/em> is currently being implemented.<\/p>\n\n<p>Did I eat my own dog food?  Well, yes, I did.  I used it to write a\nproposal (still under evaluation) and it served me well.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "498",
            "value": "Riccardo Bernardini"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#eugen",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10692.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10693",
        "start": "18:00",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_rad",
        "title": "On Rapid Application Development in Ada",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In the Ada world we typically write mission critical software that\njust has to work, but in a way one could argue that a lot more software\nis mission critical than is usually admitted.<\/p>\n\n<p>What does it take to actually perform rapid application development\nin any language?  Can we do it in Ada and why would we do so?<\/p>",
        "description": "<p>A quick look into some language features that can be [ab]used for\nenabling quick development of 'just a prototype' - which, as practice\nshows is often deployed into production, usually without proper\nquality controls and predictable outcome.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7356",
            "value": "Tomasz Maluszycki"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#rad",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10693.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10694",
        "start": "18:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "ada_toml",
        "title": "Ada-TOML: a TOML Parser for Ada",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The world of generic structured data formats is full of contenders:\nthe mighty XML, the swift JSON, the awesome YAML, ...  Alas, there\nis no silver bullet: XML is very verbose, JSON is not convenient for\nhumans to write, YAML is known to be hard to parse, and so on.<\/p>\n\n<p>TOML is yet another format whose goal is to be a good configuration\nlanguage: obvious semantics, convenient to write and easy to parse\nin general-purpose programming languages.<\/p>\n\n<p>In this talk, I'll shortly describe the TOML format and show a few\nuse cases in the real world.  I'll then present the ada-toml library\nitself: its high-level architecture and examples.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5346",
            "value": "Pierre-Marie de Rodat"
          }
        },
        "links":
        [
          {
            "_href": "http://www.cs.kuleuven.be/~dirk/ada-belgium/events/20/200201-fosdem.html#toml",
            "value": "More info on Ada-Belgium web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10694.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10695",
        "start": "18:50",
        "duration": "00:10",
        "room": "AW1.125",
        "slug": "ada_wrapup",
        "title": "Informal Discussions & Closing",
        "subtitle": [],
        "track": "Ada",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "581",
            "value": "Dirk Craeynest"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10695.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "AW1.126",
    "event":
    [
      {
        "_id": "10438",
        "start": "10:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_oss_tools_neuro",
        "title": "The good and the bad sides of developing open source tools for neuroscience",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The reproducibility crisis has shocked the scientific\ncommunity. Different papers describe this issue and the scientific\ncommunity has taken steps to improve on it. For example, several\ninitiatives have been founded to foster openness and standardisation\nin different scientific communities (e.g. the INCF[1] for the\nneurosciences). Journals encourage sharing of the data underlying\nthe presented results, some even make it a requirement.<\/p>\n\n<p>What is the role of open source solutions in this respect? Where are the problems with\nopen source projects in (neuro-)sciences?<\/p>\n\n<p>In this presentation I will address these questions at the example\nof the entirely open-source based workflow in our laboratory[2] and\nour efforts in developing generic solutions for storing metadata[3]\nas well as unifying data and metadata storage[4] that we take together\nwith the German Neuroinformatics Node (G-Node[5]).<\/p>\n\n<p>[1] https://incf.org\n[2] https://github.com/bendalab\n[3] https://github.com/g-node/python-odml\n[4] https://github.com/g-node/nix\n[5] https://g-node.org<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7260",
            "value": "Jan Grewe"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10438.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10289",
        "start": "11:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_science_soft_dev",
        "title": "Challenges and opportunities in scientific software development",
        "subtitle": "An example from the neurosciences",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The approaches used in software development in an industry setting and a scientific environment are exhibit a number of fundamental differences. In the former industry setting modern team development tools and methods are used (version control, continuous integration, Scrum, ...) to develop software in teams with a focus on the final software product. In contrast, in the latter scientific environment a large fraction of scientific code is produced by individual scientists lacking thorough training in software development with a specific research goal in mind. Indeed, it is only in the last decades that scientific software development started to become a fully recognized part of scientific work. Still, formal training in software development is largely missing in the scientific curricula of many universities. Additionally, due to the exploratory nature of the scientific method at the frontier of knowledge, most projects require the implementation of custom code. The combination of these circumstances promotes the development of scientific code not suited for sharing and long term maintenance, limiting the reusability and reproducibility of scientific data and findings. The systematic development and adoption of open source packages by the scientific community can emend this situation. Here we present examplary open source packages from the field of neuroscience and discuss the special requirements for open source software development and services in this research area.<\/p>\n\n<p>Acknowledgements:\nThis project has received funding from the European Union’s Horizon 2020 Framework Programme for Research and Innovation under Specific Grant Agreement No. 785907 (Human Brain Project SGA2). Supported by the NFDI Neuroscience Initiative.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6547",
            "value": "Julia Sprenger"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10289.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10099",
        "start": "11:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_neurofedora",
        "title": "NeuroFedora: Enabling Free/Open Neuroscience",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NeuroFedora is an initiative to provide a ready to use Fedora-based Free/Open source software platform for neuroscience. We believe that similar to Free software; science should be free for all to use, share, modify, and study. The use of Free software also aids reproducibility, data sharing, and collaboration in the research community. By making the tools used in the scientific process more comfortable to use, NeuroFedora aims to take a step to enable this ideal.<\/p>",
        "description": "<p>The computer has become an indispensable resource in modern neuroscience. From the gathering of data, simulation of computational models, analysis of large amounts of information, collaboration, and communication tools for community development, software is now a necessary part of the research pipeline.<\/p>\n\n<p>The Neuroscience community is gradually moving to the use of Free/Open Source software (FOSS) <a href=\"Gleeson,\">1<\/a>; however, the software tools used in Neuroscience and research are generally complicated and sophisticated to use. Researchers that hail from a different field other than computing must spend considerable resources on setting up and managing the computing environment and the software tools. This limits the portability of the software, making the installation of software very time-consuming and sometimes tricky.<\/p>\n\n<p>We present NeuroFedora - A Fedora-based operating system for Neuroscientists.\nWe have leveraged the infrastructure resources of the FOSS Fedora community <a href=\"RedHat.\">2<\/a> to develop an operating system that includes a plethora of ready-to-use Neuroscience software.\nWe follow the standard software development and quality assurance practices set out by the Fedora community to provide an integrated platform for researchers to use.\nFurthermore, NeuroFedora is well integrated with other software such as desktop environments, text editors, and other daily use and development tools.<\/p>\n\n<p>A NeuroFedora lab image is now available, with over 130 neuroscience packages ready to use. With an up to date documentation at (neuro.fedoraproject.org) and about 120+ packages in the queue, we encourage more FOSS enthusiasts to join the team to help NeuroFedora better aid the open (neuro)-science and research community.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6894",
            "value": "Aniket Pradhan"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.fedoraproject.org/en-US/neurofedora/overview/",
            "value": "Documentation for NeuroFedora"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10099.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10414",
        "start": "12:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_secure_health_data",
        "title": "Spotlight on Free Software Building Blocks for a Secure Health Data Infrastructure",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Health Data is traditionally held and processed in large and complex mazes of hospital information systems. The market is dominated by vendors offering monolithic and proprietary software due to the critical nature of the supported processes and - in some cases - due to legal requirements. The “digital transformation”, “big data” and “artificial intelligence” are some of the hypes that demand for improved exchange of health care data in routine health care and medical research alike. Exchanging data at these scales requires open data formats and protocols, multi-stakeholder collaboration, and agile development. As an example, the de-facto messaging standard organization in medicine HL7 noticed a much more positive response from the medical research community regarding their openly available FHIR specification in comparison to the for-members-only and XML-based HL7v3 messaging standard specification.\nWhile some past (or rather: ongoing) projects on a national scale in the German health care system have tried centralized, top-down specification and development approaches, more recent infrastructure projects embrace the competitive collaboration of a decentralized, bottom-up strategy. As a result, importance and recognition of free software increase in the Medical Informatics research community. In a series of rapid spotlights, we present tools and frameworks that serve as cornerstones for the envisioned health data exchange infrastructure, including: Organization and collaboration tools; data extraction from clinical source systems, data transformation and de-identification; data management systems and long-term archival using persistent globally-unique object identifiers; federated queries across multiple independently managed clinical data integration centers.\nWe aim to encourage participants to actively add tools and frameworks within the discussion and highlight their experiences and challenges with using open systems in Medical Informatics.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7247",
            "value": "Markus Suhr"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10414.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10448",
        "start": "12:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_datalad",
        "title": "DataLad",
        "subtitle": "Perpetual decentralized management of digital objects for collaborative open science",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Contemporary sciences are heavily data-driven, but today's data management technologies and sharing practices fall at least a decade behind software ecosystem counterparts.\nMerely providing file access is insufficient for a simple reason: data are not static. Data often (and should!) continue to evolve; file formats can change, bugs will be fixed, new data are added, and derived data needs to be integrated.\nWhile (distributed) version control systems are a de-facto standard for open source software development, a similar level of tooling and culture is not present in the open data community.<\/p>\n\n<p>The lecture introduces DataLad, a software that aims to address this problem by providing a feature-rich API (command line and Python) for joint management of all digital objects of science: source code, data artifacts (as much as their derivatives), and essential utilities, such as container images of employed computational environments.\nA DataLad dataset represents a comprehensive and actionable unit that can be used privately, or be published on today's cyberinfrastructure (GitLab, GitHub, Figshare, S3, Google Drive, etc.) to facilitate large and small-scale collaborations.<\/p>\n\n<p>In addition to essential version control tasks, DataLad aids data discovery by supporting a plurality of evolving metadata description standards. Moreover, Datalad is able to capture data provenance information in a way that enables programmatic re-execution of computations, and as such provides a key feature for the implementation of reproducible science.\nDataLad is extensible and customizable to fine tune its functionality to specific domains (e.g., field of science or organizational requirements).<\/p>\n\n<p>DataLad is built on a few key principles:<\/p>\n\n<ol>\n<li><p><strong>DataLad only knows about two things: Datasets and files.<\/strong>\nA DataLad dataset is a collection of files in folders.\nAnd a file is the smallest unit any dataset can contain.\nAt its core, <strong>DataLad is a completely domain-agnostic, general-purpose tool to manage data<\/strong>.<\/p><\/li>\n<li><p><strong>A dataset is a Git repository<\/strong>.\nA dataset is a Git repository. All features of the version control system Git\nalso apply to everything managed by DataLad.<\/p><\/li>\n<li><p><strong>A DataLad dataset can take care of managing and version controlling arbitrarily large data<\/strong>.\nTo do this, it has an optional <em>annex<\/em> for (large) file content:\nThanks to this annex, DataLad can track files that are TBs in size\n(something that Git could not do, and that allows you to restore previous versions of data,\ntransform and work with it while capturing all provenance,\nor share it with whomever you want). At the same time, DataLad does all of the magic\nnecessary to get this important feature to work quietly in the background.\nThe annex is set-up automatically, and the tool <a href=\"https://git-annex.branchable.com\">git-annex<\/a> manages it all underneath the hood.<\/p><\/li>\n<li><p>DataLad follows the social principle to\n<strong>minimize custom procedures and data structures<\/strong>. DataLad will not transform\nyour files into something that only DataLad or a specialized tool can read.\nA PDF file (or any other type of\nfile) stays a PDF file (or whatever other type of file it was)\nwhether it is managed by DataLad or not. This guarantees that users will not loose\ndata or data access if DataLad would vanish from their system, or even when DataLad\nwould vanish from the face of Earth. Using DataLad thus does not require or generate\ndata structures that can only be used or read with DataLad -- DataLad does not\ntie you down, it liberates you.<\/p><\/li>\n<li><p>Furthermore, DataLad is developed for <strong>complete decentralization<\/strong>.\nThere is no required central server or service necessary to use DataLad. In this\nway, no central infrastructure needs to be maintained (or paid for) --\nyour own laptop is the perfect place to live for your DataLad project, as is your\ninstitutions webserver, or any other common computational infrastructure you\nmight be using.<\/p><\/li>\n<li><p>Simultaneously, though, DataLad aims to\n<strong>maximize the (re-)use of existing 3rd-party data resources and infrastructure<\/strong>.\nUsers <em>can<\/em> use existing central infrastructure should they want to.\nDataLad works with any infrastructure from GitHub to\nDropbox, Figshare, or institutional repositories,\nenabling users to harvest all of the advantages of their preferred\ninfrastructure without tying anyone down to central services.<\/p><\/li>\n<\/ol>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7265",
            "value": "Michael Hanke"
          }
        },
        "links":
        [
          {
            "_href": "http://datalad.org",
            "value": "Project website"
          },
          {
            "_href": "http://handbook.datalad.org",
            "value": "User documentation"
          },
          {
            "_href": "http://datasets.datalad.org",
            "value": "Open data portal"
          },
          {
            "_href": "http://handbook.datalad.org/en/latest/usecases/reproducible-paper.html",
            "value": "Demo of a fully reproducible scientific paper using DataLad"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10448.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9800",
        "start": "13:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_frictionless_data",
        "title": "Frictionless Data for Reproducible Research",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Generating insight and conclusions from research data is often not a straightforward process. Data can be hard to find, archived in difficult to use formats, poorly structured and/or incomplete. These issues create “friction” and make it difficult to use, publish and share data. The Frictionless Data initiative (https://frictionlessdata.io/) at Open Knowledge Foundation (http://okfn.org) aims to reduce friction in working with data, with a goal to make it effortless to transport data among different tools and platforms for further analysis, and with an emphasis on reproducible research and open data. The Frictionless Data project is comprised of a set of specifications (https://frictionlessdata.io/specs/) for data and metadata interoperability, accompanied by a collection of open source software libraries (https://frictionlessdata.io/software/) that implement these specifications, and a range of best practices for data management. Over the past year and a half, we have been working specifically with the researcher community to prototype using Frictionless Data’s open source tools to improve researchers’ data workflows and champion reproducibility. This talk will discuss the technical ideas behind Frictionless Data for research and will also showcase recent collaborative use cases, such as how oceanographers implemented Frictionless Data tooling into their data ingest pipelines to integrate disparate data while maintaining quality metadata in an easy to use interface.<\/p>",
        "description": "<h2>Expected prior knowledge / intended audience<\/h2>\n\n<p>The audience should be familiar with the themes of researching, using data in various forms from various sources, scientific computing, and the talk is intended for those that are interested in data management, data cleaning, metadata, and using open research data.<\/p>\n\n<h2>Speaker bio<\/h2>\n\n<p>Lilly Winfree is the Product Owner of the Frictionless Data for Reproducible Research Project at Open Knowledge Foundation, where she solves researchers’ technical data management issues. She has her PhD in neuroscience, and has been active in the open data, open source, and open science communities for four years. Lilly has given numerous conference presentations and workshops over the past decade, and enjoys presenting on technical topics to technical and non-technical audiences.<\/p>\n\n<h2>Links to code / slides / material for the talk (optional)<\/h2>\n\n<p>https://github.com/frictionlessdata/\nhttp://frictionlessdata.io/software/<\/p>\n\n<h2>Links to previous talks by the speaker<\/h2>\n\n<p>Workshop presentation: http://bit.ly/FDepfl\nTalk from a previous position: https://youtu.be/4Jqu8mBXcmA<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6947",
            "value": "Lilly Winfree"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/frictionlessdata/",
            "value": "GitHub repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9800.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10506",
        "start": "13:30",
        "duration": "00:15",
        "room": "AW1.126",
        "slug": "open_research_sustainable_soft",
        "title": "On the road to sustainable research software.",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>ELIXIR is an intergovernmental organization that brings together life science resources across Europe. These resources include databases, software tools, training materials, cloud storage, and supercomputers.<\/p>",
        "description": "<p>One of the goals of ELIXIR [1] is to coordinate these resources so that they form a single infrastructure. This infrastructure makes it easier for scientists to find and share data, exchange expertise, and agree on best practices. ELIXIR's activities are divided into the following five areas Data, Tools, Interoperability, Compute and Training known as “platforms”. The ELIXIR Tools Platform works to improve the discovery, quality and sustainability of software resources. Software Best Practices task of the Tools Platform aims to raise the quality and sustainability of research software by producing, adopting, promoting and measuring information standards and best practices applied to the software development life cycle. We have published four (4OSS) simple recommendations to encourage best practices in research software [2]  and the Top 10 metrics for life science software good practices [3].<\/p>\n\n<p>The 4OSS simple recommendations are as follows:\n- Develop a publicly accessible open-source code from day one.\n- Make software easy to discover by providing software metadata via a popular community registry.\n- Adopt a license and comply with the licence of third-party dependencies.\n- Have a clear and transparent contribution, governance and communication processes.<\/p>\n\n<p>In order to encourage researchers and developers to adopt the 4OSS recommendations and build FAIR (Findable, Accessible, Interoperable and Reusable) software, best practices group in partnership with the ELIXIR Training platform, The Carpentries [4][5], and other communities are creating a collection of training materials [6]. The next step is to adopt, promote, and recognise these information standards and best practices, by developing comprehensive guidelines for software curation, and through workshops for training researchers and developers towards the adoption of software best practices and improvement of the usability of research software tools.<\/p>\n\n<p>Additionally, the ELIXIR Software Best Practices WG is currently developing a Software Management Plan under the context of the necessary metrics for assessing adoption of good software development practices [7] and will subsequently develop practical guidelines to support its implementation in ELIXIR projects. We will work with the newly formed  ReSA (Research Software Alliance) to facilitate the adoption of this plan to the broader community.\nIn the past year, the Working Group has also been working on improving the tooling and practices around software citation. This work has been done in collaboration with the eLife journal, the Software Sustainability Institute, Datacite, and Software Heritage, over multiple sprint events: (i) BOSC CoFest, (ii) eLife Innovation Sprint, (iii) FORCE19 Research Software Hackathon, and (iv) BioHackathon.<\/p>\n\n<p>[1] “ELIXIR | A distributed infrastructure for life-science information” Internet: https://www.elixir-europe.org/, [Sep. 16, 2018]\n[2] Jiménez RC, Kuzak M, Alhamdoosh M et al. (2017) “Four simple recommendations to encourage best practices in research software” F1000Research [Online]. 6:876. https://doi.org/10.12688/f1000research.11407.1\n[3] Top 10 metrics for life science software good practices https://doi.org/10.12688/f1000research.9206.1\n[4] “carpentries.org” Internet: carpentries.org, Sep. 15, 2018 [Sep. 16, 2018]\n[5] “ELIXIR teams up with The Carpentries to boost its training programme | ELIXIR”, Internet: https://www.elixir-europe.org/news/elixir-carpentries-agreement, Aug. 17, 2018 [Sep. 16, 2018]\n[6] SoftDev4Research/4OSS-lesson https://doi.org/10.5281/zenodo.2565040\n[7] Top 10 metrics for life science software good practices https://doi.org/10.12688/f1000research.9206.1<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7282",
            "value": "Mateusz Kuzak"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10506.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10549",
        "start": "13:45",
        "duration": "00:15",
        "room": "AW1.126",
        "slug": "open_research_stylo",
        "title": "Stylo : a user friendly text editor for humanities scholars",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As an editor for WYSIWYM text, Stylo is designed to change the entire digital editorial chain of scholarly journals the field of human sciences.<\/p>\n\n<p>Stylo (https://stylo.ecrituresnumeriques.ca) is designed to simplify the writing and editing of scientific articles in the humanities and social sciences. It is intended for authors and publishers engaged in high quality scientific publishing. Although the structuring of documents is fundamental for digital distribution, this aspect is currently delayed until the end of the editorial process. This task should, however, be undertaken early on in the process; it must be considered by the author himself. The philosophy behind Stylo consists in returning the task of managing the publication markup to researchers. This repositioning of tasks relating to the editorial process relies on the author’s semantic rather than graphic skills.<\/p>\n\n<p>This lightning talk will be the opportunity to present this tool and several publishing projects realized with Stylo.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7298",
            "value": "Antoine Fauchié"
          }
        },
        "links":
        [
          {
            "_href": "https://stylo.ecrituresnumeriques.ca",
            "value": "tool"
          },
          {
            "_href": "https://github.com/EcrituresNumeriques/stylo/",
            "value": "code"
          },
          {
            "_href": "http://stylo-doc.ecrituresnumeriques.ca/fr_FR/#!index.md",
            "value": "doc"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10549.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10206",
        "start": "14:00",
        "duration": "00:15",
        "room": "AW1.126",
        "slug": "open_research_advene",
        "title": "Using Advene to accompany research in AudioVisual Digital Humanities",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Advene is a video annotation platform (free software) that aims at accompanying scholars in their audiovisual analyses workflow. It promotes flexible and evolving annotation structures and interfaces in order to deal with the inherent dynamic nature of analysis. In this presentation, I will present the platform itself, and illustrate its usage through existing Digital Humanities projects that use it, from structuring videos for interview analyses to implementing a workflow for semantic annotation of movies.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6901",
            "value": "Olivier Aubert"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10206.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10398",
        "start": "14:15",
        "duration": "00:15",
        "room": "AW1.126",
        "slug": "open_research_shrivelling_world",
        "title": "Shrivelling world",
        "subtitle": "A Three dimensional visualisation development for representing geographical time-space",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Representing geographical time-space is a fundamental issue in geography, addressing core questions of the discipline, i.e. where are places and what distance separate them. Yet, considering the properties of geographical time space shaped by transport means, no satisfying cartographic representation – including classical maps and plastic space approaches –  has been proposed so far.\nThe \"shriveling_world\" project aims at producing images of the global geographical time-space, using the third dimension, as in time-space relief maps. The word \"shriveling\" was introduced by Waldo Tobler in his comments of Mathis-L'Hostis time-space relief image, in order to describe the complex contraction process suggested by the model.\nThe FOSDEM presentation aims at opening the code to the scientific community, now that the application is close to a first functional version.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7109",
            "value": "Nicolas Roelandt"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/theworldisnotflat/shriveling_world",
            "value": "Shriveling world code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10398.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10036",
        "start": "14:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_web_mining",
        "title": "Empowering social scientists with web mining tools",
        "subtitle": "Why and how to enable researchers to perform complex web mining tasks",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Web mining, as represented mostly by the scraping &amp; crawling practices, is not a straightforward task and requires a variety of skills related to web technologies.\nHowever, web mining can be incredibly useful to social sciences since it enables researchers to tap into a formidable source of information about society.<\/p>\n\n<p>But researchers may not have the possibility to invest copious amount of times into learning web technologies in and out. They usually rely on engineers to collect data from the web.\nThe object of this talk is to explain how Sciences Po's <a href=\"https://medialab.sciencespo.fr/en\">médialab<\/a> designed &amp; developed tools to empower researchers and enable them to perform web mining tasks to answer their research questions. Here is an example of issues we will tackle during this talk:<\/p>\n\n<ul>\n<li>How a social sciences laboratory life can be a very fruitful context for tool R&amp;D regarding webmining<\/li>\n<li>How to create performant &amp; effective webmining tools that anyone can use (multithreading, parallelism, JS execution, complex spiders etc.)<\/li>\n<li>How to re-localize data collection: researchers should be able to conduct their own collections without being dependent on external servers or resources<\/li>\n<li>How to teach researchers the necessary skills: HTML, the DOM, CSS selection etc.<\/li>\n<\/ul>\n\n\n<p>Examples will be taken mainly from the <a href=\"https://github.com/medialab/minet\">minet<\/a> CLI tool and the <a href=\"https://medialab.github.io/artoo/\">artoo.js<\/a> bookmarklet.<\/p>\n\n<h2>Speaker<\/h2>\n\n<p><a href=\"https://github.com/Yomguithereal\">Guillaume Plique<\/a> is a research engineer working for SciencesPo's <a href=\"https://medialab.sciencespo.fr/en\">médialab<\/a>. He assists social sciences researchers daily with their methods and maintain a variety of FOSS tools geared toward the social sciences community and also developers.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3654",
            "value": "Guillaume Plique"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/medialab/minet)",
            "value": "minet"
          },
          {
            "_href": "https://medialab.github.io/artoo/",
            "value": "artoo.js"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10036.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10322",
        "start": "15:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_openrefine",
        "title": "Revamping OpenRefine",
        "subtitle": "a reproducible data wrangler",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OpenRefine is a data transformation tool popular in many communities: data journalism, semantic web, GLAMs, scientific research… In this talk I give an overview of our recent efforts to revamp this project as it approaches its 10th anniversary. We are working on exciting improvements which should help alleviate some of the most salient issues faced by our users. My intention is not to lecture the attendance about how to deal with technical debt or to grow a contributor community - I instead seek feedback and spark discussions about our choices. Let us know what you think and help us take good care of this fantastic tool!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7194",
            "value": "Antonin Delpeuch"
          }
        },
        "links":
        [
          {
            "_href": "http://openrefine.org",
            "value": "OpenRefine's website"
          },
          {
            "_href": "https://github.com/OpenRefine/OpenRefine",
            "value": "GitHub project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10322.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10382",
        "start": "15:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_pocket_infrastructures",
        "title": "Pocket infrastructures to bridge reproducible research, live coding, civic hacktivism and data feminism for/from the Global South",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We will showcase Grafoscopio, a flexible, extensible, self contained \"pocket infrastructure\", which simplifies infrastructure to amplify participation, so reproducible research and publishing, agile data storytelling and custom data visualization can be used in fields like investigative journalism, data feminism and civic hacktivism. We will show prototypes developed with Grafoscopio in the previously mentioned domains, the motivations behind Grafoscopio and the local community practices around it that deconstruct binary relations of power (software developer/user, data producer / consumer, software binary / source code, male/female) and approach reproducible research practices and tools from a perspective located and embodied in a particular place of the Global South in Latin America and in contrast/dialogue with Global North perspectives.<\/p>",
        "description": "<p>Reproducible research (and publishing) has been confined mostly to academic places. But it has a lot of potential in several other places like investigative journalism, data feminism and civic hacktivism, as we have showcased by building several prototypes, including: making the so called \"Panama Papers\" data leak story reproducible; creating domain specific visualizations for medicine information released by 16 governments; porting the Spanish Data Journalism Handbook and the Data Feminism book to our \"pocket infrastructures\" and the creation of agile and resilient tools and practices to write and publish together (see proposal links for a detailed view of such prototypes).<\/p>\n\n<p>To bridge reproducible research and publishing, agile data storytelling and custom data visualization, with the previously mentioned domains, we have co-designed, developed, used and extended a set of inclusive approaches and tools for/from the Global South, that we have called \"pocket infrastructures\". Our \"pocket infrastructures\" simplify infrastructure to amplify participation, and they are mostly self contained, flexible, extensible, and work well with good, low or non connectivity and run from a variety of hardware, from a USB drive, to low end computers, to servers and the \"cloud\" and anything in between and beyond.\nThis is in sharp contrast with exclusionary approaches like \"Big Data\" or others that start with big and/or overcomplex infrastructures and are getting traction in the Global North (or are being imported from there to the Global South as the \"only way\" forward regarding reproducibility).<\/p>\n\n<p>Grafoscopio is one of such pocket infrastructures for reproducible research and publishing, agile visualization and data storytelling and this lecture will showcase Grafoscopio, the motivations behind it, and some prototypes developed with it, and the community practices that allow the development of such projects and prototypes deconstructing also binary relations of power (software developer/user, data producer / consumer, software binary / source code, male/female).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7175",
            "value": "Offray Luna"
          }
        },
        "links":
        [
          {
            "_href": "https://mutabit.com/grafoscopio/en.html",
            "value": "Grafoscopio English Web Page"
          },
          {
            "_href": "https://mutabit.com/dataweek/",
            "value": "Data Week: Community regular workshop + (anti)Hackathon"
          },
          {
            "_href": "https://mutabit.com/repos.fossil/mapeda",
            "value": "Spanish Data Journalism Handbook, ported as a reproducible publication"
          },
          {
            "_href": "https://mutabit.com/repos.fossil/datafem/",
            "value": "Data Feminism book, ported as a reproducible publication to our pocket infrastructures"
          },
          {
            "_href": "https://mutabit.com/repos.fossil/documentaton/",
            "value": "Agile and resilient tools and techniques to write and publish together"
          },
          {
            "_href": "https://mutabit.com/offray/blog/en/entry/panama-papers-1",
            "value": "Panama Papers: a case for reproducible research, data activism and frictionless data"
          },
          {
            "_href": "https://mutabit.com/offray/blog/en/entry/sdv-infomed",
            "value": "Domain Specific Visualizations: a glimpse of medicine public data released by governments"
          },
          {
            "_href": "https://mutabit.com/grafoscopio/Docs/En/Talks/Overview/grafoscopio-mapa.svg",
            "value": "Grafoscopio exported mindmap (with some image missing)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10382.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9348",
        "start": "16:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_dharpa",
        "title": "Developing Open-Science Research Platforms",
        "subtitle": "Zotero, PressForward, Tropy, DHARPA",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>From Zotero to PressForward to Tropy, my research team has developed a wide range of open-science research tools over the last 13 years. I'll talk about how the availability and selection of our technology stacks has influenced humanities (and non-humanities) research methodologies, and I'll provide an update on my team's newest and most comprehensive research platform, DHARPA.<\/p>",
        "description": "<p>I'm flexible on the length of the talk and the format. No expected prior knowledge.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6654",
            "value": "Sean Takats"
          }
        },
        "links":
        [
          {
            "_href": "http://quintessenceofham.org/bio/",
            "value": "Speaker bio"
          },
          {
            "_href": "http://quintessenceofham.org/cv/",
            "value": "Previous talks"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9348.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9899",
        "start": "16:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_makers_practitioners",
        "title": "Developing from the field.",
        "subtitle": "Shifting design processes and roles between makers and practitioners around research tools development within an interdisciplinary research lab.",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Software design and development within interdisciplinary research teams is a specific activity which closely associates makers and practitioners in the equipment of experimental research methods and practices. This closeness allows practitioners to tackle research endeavours’ specific requirements, such as understanding the methodological assumptions encoded within the tools. It also induces a specific relationship between “makers” and their publics of “users” : a non-commercial, situated and case-based crafting process, implying shifting roles and complex decision making. How does this peculiar context affect the design and valorization practices around open research tools and their evolution ? What are the benefits and difficulties of such settings, in terms of work organization, pedagogical approaches, and scientific methodology ? What can be shared for other contexts such as activism or journalism ? Grounding on the presentation of several case studies of research tools’ design and development elaborated at the médialab of Sciences Po, this talk will offer an account of how an interdisciplinary research environment affects and dialogs with established methods of design (“participative design”, “user experience research”), development (“agile methods”), and tool valorization and socialization.<\/p>",
        "description": "<p>Audrey Baneyx has a PhD in artificial intelligence from Paris 6 university. She is a research engineer at the médialab (Sciences Po, Paris) where she works at the intersection of digital methods, knowledge modelling and designing pedagogical storytellings. She is teaching digital culture and methods and, as a mediator, developing médialab tools communities of practitioners. She is co-leading a research group focusing on gender issues online.<\/p>\n\n<p>Robin de Mourat is research designer at the médialab laboratory (Sciences Po, Paris). He works at the intersection between academic equipment and inquiry practices, combining a background in product design, design history &amp; theory, and human-computer interactions, with diverse material and discursive experiments in the Humanities and Social Sciences. He has participated to the making of texts, things and conversations about the epistemology of design activities, interdisciplinary methodologies, and social &amp; cultural studies of scholarly practices. He has been involved for several years in the development of advanced tools for academic writing and publishing in humanities and social sciences contexts.<\/p>",
        "persons":
        [
          {
            "_id": "4075",
            "value": "Audrey Baneyx"
          },
          {
            "_id": "6981",
            "value": "Robin De Mourat"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9899.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10323",
        "start": "17:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_shareable_workflow",
        "title": "Transforming scattered analyses into a documented, reproducible and shareable workflow",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This presentation is a feedback from experience on helping a researcher transforming a series of scattered analyses into a documented, reproducible and shareable workflow.<br/>\nTime allocated by researchers to program / code the analyses required to answer their scientific questions is usually low compared to other tasks. As a result, multiple small experiments are developed and outputs are gathered as best as possible to be presented in a scientific paper. However, science is not only about sharing results but also sharing methods. How can we make our results reproducible when we developed multiple, usually undocumented analyses? What do we do if the program is only applicable to our computer directory architecture? This is always possible to take time to rewrite, re-arrange and document analyses at the time we want/have to share them. Here, I will take the exemple of a \"collaboration fest\" where we dissected R scripts of a researcher in ecology. We started a reproducible, documented and open-source R-package along with its website, automatically built using continuous integration: <a href=\"https://cesco-lab.github.io/Vigie-Chiro_scripts/\">https://cesco-lab.github.io/Vigie-Chiro_scripts/<\/a>.<br/>\nHowever, can we think, earlier in the process, a better way to use our small programming time slots by adopting a method that will save time in our future? In this aim, I will present a documentation-first method using little time while writing analyses, but saving a lot when the time has come to share your work.<\/p>",
        "description": "<h2>Session type (Lecture or Lightning Talk)<\/h2>\n\n<p>Lecture<\/p>\n\n<h2>Session length (20-40 min, 10 min for a lightning talk)<\/h2>\n\n<p>30 min<\/p>\n\n<h2>Expected prior knowledge / intended audience<\/h2>\n\n<p>No prior knowledge expected. Example will be about building documentation for R software but any developper, using any programming language may be interested in the method adopted.<\/p>\n\n<h2>Speaker bio<\/h2>\n\n<p>Sébastien Rochette has a PhD in marine ecology. After a few years has a researcher in ecology, he joined ThinkR (https://rtask.thinkr.fr), a company giving courses and consultancy around the R-software. Along with commercial activities, he is highly involved in the development of open-source R packages. He also shares his experience with the R-community through free tutorials, blog posts, online help and other conferences. https://statnmap.com/<\/p>\n\n<h2>Links to code / slides / material for the talk (optional)<\/h2>\n\n<p>I wrote a blog post in French about what I am planning to present: https://thinkr.fr/transformer-plusieurs-scripts-eparpilles-en-beau-package-r/<br/>\nThis topic is also related to another blog post: https://rtask.thinkr.fr/when-development-starts-with-documentation/<\/p>\n\n<h2>Links to previous talks by the speaker<\/h2>\n\n<p>Talks about R are in my Github repository: https://github.com/statnmap/prez/. The \"README\" lists talks that have a live recorded video.<br/>\nAs a researcher, I also gave multiple talks about marine science, modelling and other topics related to my research.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7196",
            "value": "Sébastien Rochette"
          }
        },
        "links":
        [
          {
            "_href": "https://statnmap.com",
            "value": "Speaker personal website"
          },
          {
            "_href": "https://cesco-lab.github.io/Vigie-Chiro_scripts/",
            "value": "Website of the R-package created"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10323.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10341",
        "start": "17:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_elife",
        "title": "A community-driven approach towards open innovation for research communication",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The advancement of web technologies has created an opportunity for developing tools for real-time collaborations, text-mining, interactive data visualisations, sharing reproducible compute environments, etc. These tools can change the ways researchers share, discover, consume and evaluate research and help promote open science and encourage responsible research behaviours.<\/p>\n\n<p>Through its Innovation Initiative, eLife invests heavily in software development, new product design, collaboration and outreach so that the potential for improvements in the digital communication of new research can start to be realised. In particular, we support exclusively the development of open-source tools, with extensible capabilities, that can be used, adopted and modified by any interested party and actively engage the community of open innovators.<\/p>\n\n<p>In this talk, we will introduce the following projects:\n* Reproducible Document Stack (RDS), an open-tool stack capturing code, data and compute environment in a live paper to improve research reproducibility (see demo <a href=\"https://elifesci.org/reproducible-example\">here<\/a>)\n* Fostering collaboration and innovation through hacking: <a href=\"https://sprint.elifesciences.org\">eLife Innovation Sprint<\/a><\/p>\n\n<p>We believe that openness is crucial to the future of research, and by supporting the community and promoting open-source research software, we can help build a culture towards integral, collaborative, open and reusable research. We hope to share some of our visions and learnings, and invite feedback and contributions from the wider open-source community on the next steps forward.<\/p>",
        "description": "<h1>Speaker bio<\/h1>\n\n<p><em>Emmy Tsang<\/em> is the Innovation Community Manager at eLife, a non-profit organisation with the mission to accelerate research communication and discovery. She is responsible for the day-to-day running of the eLife Innovation Initiative, which supports the development of open-source tools, technologies and processes aimed at improving the discovery, sharing, consumption and evaluation of scientific research. Prior to joining eLife, Emmy completed a PhD in neuroscience at the European Molecular Biology Laboratory in Rome, Italy. She is passionate about building communities, fostering collaborations and developing technological solutions to make research more open, reproducible and user-friendly.<\/p>\n\n<p>Twitter: <a href=\"https://twitter.com/eLifeInnovation\">@eLifeInnovation<\/a> / <a href=\"https://twitter.com/emmy_ft\">@emmy_ft<\/a><\/p>\n\n<h1>Previous talks by speaker<\/h1>\n\n<ul>\n<li>Invited speaker, Biohackathon-Europe, November 2019 ( <a href=\"https://doi.org/10.6084/m9.figshare.11295032\">slides<\/a> )<\/li>\n<li>Mozilla Open Leaders X Launch party, October 2019 ( <a href=\"https://youtu.be/t7o3bEGTW8s?t=97\">video<\/a> )<\/li>\n<li>Invited panellist, EMBL Open Access Week panel on “How is scientific publishing changing?”, September 2019<\/li>\n<li>Invited speaker, SciLifeLab workshop on “Reproducibility and Data Reuse in Life Science”, September 2019 ( <a href=\"https://youtu.be/fKnef69wT3g?t=10668\">video<\/a>, <a href=\"https://figshare.com/articles/190919_SciLifeLab_eLife_workshop_talk_on_reproducible_publishing/9868625\">slides<\/a>)<\/li>\n<li>Tech talk, ISMB/ECCB, July 2019 (<a href=\"https://www.youtube.com/watch?v=7mOadlm7-WI\">video<\/a>, <a href=\"https://figshare.com/articles/190723_RDS_talk_at_ISMB_ECCB/8983640\">slides<\/a>)<\/li>\n<li>Speaker, OAI11, June 2019 (<a href=\"https://figshare.com/articles/190620_OAI11_Reproducibility/8299226\">slides<\/a>)<\/li>\n<li>Invited demo, SSI Collaboration Workshop, April 2019<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7198",
            "value": "Emmy Tsang"
          }
        },
        "links":
        [
          {
            "_href": "http://www.elifesciences.org/about/innovation",
            "value": "About eLife Innovation"
          },
          {
            "_href": "http://www.elifesci.org/labs",
            "value": "eLife Labs"
          },
          {
            "_href": "http://elifesci.org/reprodoc",
            "value": "Reproducible Document Stack"
          },
          {
            "_href": "http://sprint.elifesciences.org",
            "value": "eLife Innovation Sprint"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10341.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10592",
        "start": "18:00",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_joss",
        "title": "The Journal of Open Source Software:  credit for invisible work",
        "subtitle": [],
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Researchers rarely cite software they use as part of their research. As a result, research software and the time spent developing it have become invisible scholarly contributions. This lack of visibility reduces the incentives that are necessary to produce and share high quality software that are essential for the progress of science.  The Journal of Open Source Software (JOSS) is an open source, open access journal primarily designed to make it easier for those individuals authoring research software to gain career credit for their work by publishing short software papers. Software papers are a recognized mechanism for authors of research software to create a citable ‘entity’ which can easily be cited in journals and as such directly impact a researcher’s career via established metrics such as the h-index. JOSS is unique in that it only accepts very short (~ 1-2 pages) papers, with short summaries and links to the software repository. In that sense, the software papers are not the focus of the review. Instead, we ask reviewers to conduct a thorough review of the associated software (which must be open source) ensuring that it is well documented, straightforward to install and functions as expected. In this talk I will describe the origin and impact that JOSS has had on research open source and also touch upon issues such as sustainability and credit.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7315",
            "value": "Karthik Ram"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10592.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9371",
        "start": "18:30",
        "duration": "00:30",
        "room": "AW1.126",
        "slug": "open_research_dspace7",
        "title": "DSpace 7: A major leap forward for the leading institutional repository platform",
        "subtitle": "Tale of a mature, international FOSS community embracing Angular",
        "track": "Open Research Tools and Technologies",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The DSpace community is anticipating the largest release ever in 2020 with DSpace 7 ( https://wiki.duraspace.org/display/DSPACE/DSpace+Release+7.0+Status ). The platform is used in thousands of research institutions around the globe and powers systems including dspace.mit.edu, dash.harvard.edu and openknowledge.worldbank.org. If you download an academic paper through Google Scholar today, the chance is large that it is served to you thanks to a DSpace institutional repository.<\/p>\n\n<p>The talk aims to briefly introduce the scope and usage of the DSpace software. Attendees will learn how the governance of the DSpace community is structured, and what lead to the decision to drop the two legacy UIs, JSPUI and XMLUI, in favour of an endeavour to introduce Angular as the new UI layer.<\/p>\n\n<p>The most relevant piece of the presentation for the Fosdem audience, will be an outline of the tooling and best practices applied in the community, together with a pro and con evaluation.<\/p>\n\n<p>We are very keen on learning from other participants in the audience what they could advise, both on a technical and organisational level, going forward.<\/p>\n\n<h2>Previous presentations on DSpace 7<\/h2>\n\n<p><a href=\"https://lecture2go.uni-hamburg.de/l2go/-/get/v/24819\">Introducing DSpace 7<\/a>\n<a href=\"https://lecture2go.uni-hamburg.de/l2go/-/get/v/24831\">DSpace 7 Configurable Entities<\/a>\n<a href=\"https://lecture2go.uni-hamburg.de/l2go/-/get/v/24820\">The DSpace 7 Angular UI from a user perspective<\/a><\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6674",
            "value": "Bram Luyten"
          }
        },
        "links":
        [
          {
            "_href": "https://wiki.duraspace.org/display/DSPACE/DSpace+Release+7.0+Status",
            "value": "DSpace 7 Release Status and Prior Presentations"
          },
          {
            "_href": "https://github.com/bram-atmire",
            "value": "Presenter Github Profile"
          },
          {
            "_href": "https://twitter.com/luytenbram",
            "value": "Twitter"
          },
          {
            "_href": "http://www.dspace.org",
            "value": "DSpace"
          },
          {
            "_href": "https://github.com/DSpace/DSpace",
            "value": "Main DSpace codebase"
          },
          {
            "_href": "https://github.com/DSpace/dspace-angular",
            "value": "Angular DSpace codebase"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9371.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.3.201",
    "event":
    [
      {
        "_id": "10704",
        "start": "10:30",
        "duration": "00:10",
        "room": "K.3.201",
        "slug": "gamedev_welcome",
        "title": "Welcome to game development devroom",
        "subtitle": [],
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to FOSDEM game development devroom! We'll present what this is all about and invite you to participate.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "4403",
            "value": "Julian Murgia"
          },
          {
            "_id": "6467",
            "value": "George Marques"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10704.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10522",
        "start": "10:45",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "gamedev_python_for_godot",
        "title": "Python for Godot",
        "subtitle": [],
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Godot is an incredible open source game engine. Among it key features, it comes packed with a script language called GDscript and loosely based on Python.\nBut could it be even better ? Could we use the real Python to code our game on Godot ?<\/p>\n\n<p>And maybe even more important, is it really a good idea ?<\/p>",
        "description": "<p>Godot is an advanced, feature-packed, multi-platform 2D and 3D open source game engine.\nThe project has joined the Software Freedom Conservancy project and it growing community makes it hopes to become a real alternative to Unity&amp;GameMaker.<\/p>\n\n<p>This talk present the Godot-Python project aiming at bringing Python as a fully integrated language into Godot.<\/p>\n\n<p>We will have a look at Godot’s internal architecture as is it itself a real interpreter with it garbage collector, dynamic typing, introspection and even builtin custom scripting language.\nAll of this having to work next to our Python interpreter and communicate back and forth with it.<\/p>\n\n<p>We will then dig into Godot-Python design choices, both past and current, this project came through a looot of errors and trials ;-)<\/p>\n\n<p>Finally we will discuss the pros and cons about using Python as a script language for Godot vs the traditional GDscript.<\/p>\n\n<p>The audience should have some basic knowledge of C level computing (static vs dynamic language, compilation &amp; linking).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7285",
            "value": "Emmanuel Leblond"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10522.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9649",
        "start": "11:15",
        "duration": "00:45",
        "room": "K.3.201",
        "slug": "gamedev_0ad_graphics_pipeline",
        "title": "0 A.D.: Graphics Pipeline",
        "subtitle": "How open-source game graphics works",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A story about graphics pipeline of 0 A. D. (an open-source game of Wildfire Games) and its issues.<\/p>\n\n<p>Talking structure:<\/p>\n\n<ul>\n<li><p>A little history of 0AD (https://play0ad.com/about/the-story-of-0-a-d/)<\/p><\/li>\n<li><p>How our graphics pipeline works<\/p><\/li>\n<li><p>Used technologies (SDL, OpenGL 1/2, ARB/GLSL shaders)<\/p><\/li>\n<li><p>Known problems (old OpenGL, legacy support of OpenGL drivers on macOS 10.14)<\/p><\/li>\n<li><p>Future plans<\/p><\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6163",
            "value": "Vladislav Belov"
          }
        },
        "links":
        [
          {
            "_href": "https://play0ad.com",
            "value": "Official website of 0 A.D."
          },
          {
            "_href": "https://wildfiregames.com/",
            "value": "Official website of Wildfire Games"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9649.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9643",
        "start": "12:05",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "gamedev_veripeditus",
        "title": "Can anyone need Veripeditus?",
        "subtitle": "Reviving a Python AR gaming framework",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Veripeditus is a framework for teh creation of mobile augemented reality games in Python, designed, but not limited to, use in education. The project is currently sleeping due to various reasons. We would like to find out whether its technology is still current and if there is value in reviving it.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2214",
            "value": "Dominik George"
          }
        },
        "links":
        [
          {
            "_href": "https://edugit.org/Teckids/Veripeditus/veripeditus-server",
            "value": "Veripeditus source repositor"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9643.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10309",
        "start": "12:35",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "gamedev_openxr",
        "title": "Game development with OpenXR",
        "subtitle": [],
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Last year Khronos released OpenXR, an open API for using XR hardware. In this talk we will look at the practical side of creating VR applications and games with OpenXR.<\/p>",
        "description": "<p>Since the Oculus VR development kit started a resurgence of consumer VR, game development has largely been relegated to proprietary VR APIs and runtimes. Khronos reacted by creating an open API for using XR hardware and released it OpenXR 1.0 in July 2019. Collabora implemented the OpenXR API in a runtime nicknamed Monado, built on open source VR hardware drivers. With these building blocks VR applications can now use standardized APIs and run on a FOSS stack.<\/p>\n\n<p>In this talk, Christoph will give an overview of the feature set of the OpenXR API and the practical side of creating VR applications and games with OpenXR. We will look at low level code using the OpenXR API directly as well as an OpenXR plugin for the godot engine.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7189",
            "value": "Christoph Haag"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10309.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10702",
        "start": "13:05",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "gamedev_open_talks",
        "title": "Open lightning talks",
        "subtitle": "Showcase your open source project",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This hour is dedicated to people who want to come up and shortly present their project, without having to schedule a full talk.<\/p>",
        "description": "<p>Bring your open source game-related project (be it an engine, game, demo, tool, or something else) and showcase to our fellow gamedev friends. Talks should have at most five minutes with no time allotted for questions. If you want to bring a laptop to show something, keep it ready and install/uninstall it as fast as possible (will be part of your five minutes). Please be understanding so everyone can have a chance. Contact the room managers on the event day if you want to present something.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6467",
            "value": "George Marques"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10702.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9319",
        "start": "14:05",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "gamedev_java_games_doom3",
        "title": "Java & Games",
        "subtitle": "A rivalrous case-study from porting Doom 3",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>According to the interwebs, Java is one of the most popular programming languages in the multiverse.<br/>\nAnd yet, when it comes to games, its popularity seems to dwindle.<\/p>\n\n<p>Why though...<br/>\nIs it really not suited for game development?<br/>\nIs the language as bad as the critics claim??<br/>\nIs GC...EVIL!?<\/p>\n\n<p>I have this side-project of porting Doom 3 from C/C++ to Java. And even though Doom 3 is a ~15 year old game, it is still a massive AAA code-base. So I believe my experiences there can adequately answer a lot of the questions that come to mind when you think of Java &amp; Games.<\/p>\n\n<p>During this talk, I will try to convince you that Java is a very viable game prototyping/development tool.<br/>\nEither that, or will add more fuel to the flame...<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3780",
            "value": "Mahmoud Abdelghany"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9319.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10228",
        "start": "15:05",
        "duration": "00:30",
        "room": "K.3.201",
        "slug": "gamedev_double_contributors_tricks",
        "title": "Double your contributors using these 3 simple tricks!",
        "subtitle": "Why would someone work on your project?",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For some arcane reason contributors spend their precious time on open source game projects. Why do they do this? And more importantly: What can you do to make them do it on your project?<\/p>",
        "description": "<p>FOSS game projects live on the motivation of their contributors. This motivation usually consists of two parts: The desire to contribute to FOSS game development in general and the desire to contribute to a specific project. While the former is very interesting to discuss, our ability to affect it is negligible. Thankfully, the control of the latter is definitely possible, and it is crucial to the survival of our projects.\nIn this talk we will analyse different characteristics of FOSS game projects with regards to contributor recruitment and retention. We will try to present practical steps to lower the risk of your current or future projects dying to inactivity and obscurity.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7151",
            "value": "Eshed Shaham"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10228.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10756",
        "start": "15:45",
        "duration": "01:00",
        "room": "K.3.201",
        "slug": "benefits_porting_godot_engine_vulkan",
        "title": "Benefits of porting Godot Engine to Vulkan",
        "subtitle": "List of benefits observed from porting Godot Engine to Vulkan",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Godot 4.0 is in the process of being ported from OpenGL to a Vulkan rendering API.\nThis new technology provides new challenges and benefits for improving quality and performance,\nwhich will be explained and compared during this presentation.<\/p>",
        "description": "<p>Godot 4.0 is in the process of being ported from OpenGL to a Vulkan rendering API.\nThis new technology provides new challenges and benefits for improving quality and performance,\nwhich will be explained and compared during this presentation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3888",
            "value": "Juan Linietsky"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10756.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10663",
        "start": "16:55",
        "duration": "00:20",
        "room": "K.3.201",
        "slug": "gamedev_blender_projects",
        "title": "Blender projects for 2020",
        "subtitle": [],
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6621",
            "value": "Ton Roosendaal"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10663.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10711",
        "start": "17:15",
        "duration": "00:30",
        "room": "K.3.201",
        "slug": "gamedev_reloading_escoria",
        "title": "Reloading Escoria",
        "subtitle": "Make point and click adventure games under Godot great again",
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Escoria is a Libre framework for the creation of point-and-click adventure games with MIT-Licenced Godot Engine. Since its release, Godot Engine changed a lot at fast pace while Escoria code was still based on old Godot 1.x features.<\/p>\n\n<p>In this presentation, I'll present the current state of Escoria and discuss the process of rewrite as a Godot Engine plugin. It'll cover architecture and design, allowing adventure game creators to use Godot Engine as a full-featured editor for their adventure game.<\/p>",
        "description": "<p>Escoria is a Libre framework for the creation of point-and-click adventure games with MIT-Licenced Godot Engine. It was initially developed for the adventure game The Interactive Adventures of Dog Mendonça and Pizzaboy® and later streamlined for broader usages and open sourced as promised to the backers of the Dog Mendonça Kickstarter campaign. Since its release, Godot Engine changed a lot at fast pace while Escoria code was still based on old Godot 1.x features. It is more a collection of dedicated scripts than a proper Godot Engine layer designed for point and click adventure games. Evolving Escoria is quite a big task, so it might be better to actually start it over with a new project architecture while keeping its most interesting features in the process.<\/p>\n\n<p>In this presentation, I'll present the current state of Escoria and discuss the process of rewrite as a Godot Engine plugin. It'll cover architecture and design, allowing them to use Godot Engine as a full-featured editor for their adventure game.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4403",
            "value": "Julian Murgia"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10711.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10234",
        "start": "17:50",
        "duration": "00:40",
        "room": "K.3.201",
        "slug": "gamedev_spring_steam",
        "title": "Spring & Steam, an Odyssey",
        "subtitle": [],
        "track": "Game Development",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Spring RTS Engine has been in active development since 2005. In the past few years, two of its games, Evolution RTS and Zero-K, have been released on Steam. The journey to these releases was long and difficult. Let's regale ourselves with tales of the adventures of the devs, learn many things that you shouldn't do, and also learn what to do in case you've already done what you shouldn't have.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7151",
            "value": "Eshed Shaham"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10234.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.3.401",
    "event":
    [
      {
        "_id": "10126",
        "start": "10:30",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_lowrisc",
        "title": "How lowRISC made its Ibex RISC-V CPU core faster",
        "subtitle": "Using open source tools to improve an open source core",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ibex implements RISC-V 32-bit I/E MC M-Mode, U-Mode and PMP. It uses an in order 2 stage pipe and is best suited for area and power sensitive rather than high performance applications. However there is scope for meaningful performance gains without major impact to power or area. This talk describes work done at lowRISC to analyse and improve the performance of Ibex. The RTL of an Ibex system is simulated using Verilator to run CoreMark and Embench and the traces analysed to identify the major sources of stalls within them. This informs where improvements should be targeted. The open source implementation tools Yosys and openSTA are used to assess potential timing and area impacts of these improvements. In this talk you’ll learn about the pipeline of Ibex, methods to analyse the performance of CPU microarchitecture and how to use Yosys and openSTA to analyse what limits clock frequency in a design.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7015",
            "value": "Greg Chadwick"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/lowRISC/ibex",
            "value": "Ibex github repository"
          },
          {
            "_href": "http://lowrisc.org",
            "value": "lowRISC website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10126.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9656",
        "start": "10:50",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_blackparrot",
        "title": "BlackParrot",
        "subtitle": "An Open Source RISC-V Multicore For and By the World",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>BlackParrot is a Linux-capable, cache-coherent RISC-V multicore, designed for efficiency and ease of use.  In this talk, we will provide an architectural overview of BlackParrot, focusing on the design principles and development process as well as the software and hardware ecosystems surrounding the core. We will also discuss the project roadmap and our plans to engage the open-source community.  Last, we will demonstrate a multithreaded RISC-V program running on top of Linux on a multicore BlackParrot FPGA implementation.<\/p>",
        "description": "<p>BlackParrot aims to be the default open-source, Linux-capable, cache-coherent, RV64GC multicore used by the world. Although originally developed by the University of Washington and Boston University, BlackParrot strives to be community-driven and infrastructure agnostic, a core which is Pareto optimal in terms of power, performance, area and complexity. In order to ensure BlackParrot is easy to use, integrate, modify and most importantly trust, development is guided by three core principles: Be Tiny, Be Modular, and Be Friendly. Development efforts have prioritized ease of use and silicon validation as first order design metrics, so that users can quickly get started and trust that their results will be representative of state-of-the-art ASIC designs. BlackParrot is ideal as the basis for a research platform, a lightweight accelerator host or as a standalone Linux core.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6852",
            "value": "Dan Petrisko"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/black-parrot/pre-alpha-release",
            "value": "Code Repository"
          },
          {
            "_href": "https://github.com/black-parrot-examples",
            "value": "Tapeout Examples"
          },
          {
            "_href": "https://github.com/bespoke-silicon-group/basejump_stl",
            "value": "BaseJump STL"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9656.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9628",
        "start": "11:10",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_hammerblade",
        "title": "The HammerBlade RISC-V Manycore",
        "subtitle": "A programmable, scalable RISC-V fabric",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HammerBlade is an open source RISC-V manycore that has been under development since 2015 and has already been silicon validated with a 511-core chip in 16nm TSMC. It features extensions to the RISC-V ISA that target GPU-competitive performance for parallel programs (i.e. GPGPU) including graphs and ML workloads. In this talk we will overview the components of the HW and software ecosystem in the latest version, and show you how to get up and running as an open source user or contributor in either SW or HW on Amazon F1 cloud FPGAs.<\/p>",
        "description": "<p>HammerBlade is an open source RISC-V manycore that has been under development since 2015 and has already been silicon validated with a 511-core chip in 16nm TSMC. It features extensions to the RISC-V ISA that target GPU-competitive performance for parallel programs (i.e. GPGPU) including graphs and ML workloads. In this talk we will overview the components of the HW and software ecosystem in the latest version, and show you how to get up and running as an open source user or contributor in either SW or HW on Amazon F1 cloud FPGAs. We will overview the HW-architecture, the CUDA-like programming environment, the runtime software, the HW architecture, and our Amazon F1 cloud emulation and cosimulation environments, and our suite of performance analysis tools.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6851",
            "value": "Michael Taylor"
          }
        },
        "links":
        [
          {
            "_href": "http://http://bjump.org/manycore/",
            "value": "Github repo"
          },
          {
            "_href": "https://sampl.cs.washington.edu/tvmconf/slides/Michael-Taylor-HammerBlade.pdf",
            "value": "Older Vision talk"
          },
          {
            "_href": "http://cseweb.ucsd.edu/~mbtaylor/papers/HC29.21.430-Celerity-RISC-V-Davidson-UCSD.pdf",
            "value": "Older version of the architecture"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9628.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10061",
        "start": "11:30",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_openesp",
        "title": "Open ESP",
        "subtitle": "The Heterogeneous Open-Source Platform for Developing RISC-V Systems",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>ESP is an open-source research platform for RISC-V systems-on-chip that integrate many hardware accelerators.<br/>\nESP provides a vertically integrated design flow from software development and hardware integration to full-system prototyping on FPGA.  For application developers, ESP offers domain-specific automated solutions to synthesize new accelerators for their software and map it onto the heterogeneous SoC architecture.  For hardware engineers, ESP offers automated solutions to integrate their accelerator designs into the complete SoC.<br/>\nThe participants in this FOSDEM20 event will learn how to use ESP from the viewpoints of both application developers and hardware engineers by following a series of short hands-on tutorials embedded in the lecture.\nConceived as a heterogeneous integration platform and tested through years of teaching at Columbia University, ESP is intrinsically suited to foster collaborative engineering of RISC-V based SoCs across the open-source community.<\/p>",
        "description": "<ul>\n<li>What is ESP?<\/li>\n<\/ul>\n\n\n<p>ESP is an open-source research platform to design and program heterogeneous systems-on-chip (SoCs).  A heterogeneous SoC combines multiple general-purpose processor cores and many specialized hardware accelerators.<\/p>\n\n<ul>\n<li>What does ESP offer?<\/li>\n<\/ul>\n\n\n<p>ESP provides automated solutions to (a) synthesize new accelerators, (b) integrate them with RISC-V processors and other third party accelerators into a complete SoC, (c) rapidly prototype the SoC on an FPGA board, and (d) run software applications that take advantage of these accelerators.\nESP contributes to the open-source movement by supporting the realization of more scalable architectures for SoCs that integrate more heterogeneous components, thanks to a more flexible design methodology that accommodates different specification languages and design flows.<\/p>\n\n<ul>\n<li>What is an example of an SoC prototype realized with ESP?<\/li>\n<\/ul>\n\n\n<p>With ESP's automation capabilities, it is easy to realize FPGA-based prototypes of complete SoCs.  For example, an SoC may feature the Ariane RISC-V processor core booting Linux, a multi-plane network-on-chip supporting a partitioned memory hierarchy with multiple DRAM controllers, and tens of loosely-coupled accelerators that execute coarse-grained tasks exchanging large amount of data with DRAM through direct-memory access (DMA).  These accelerators can be third-party open-source hardware components that “speak” the AXI protocol (e.g. the NVIDIA NVDLA accelerator for deep learning) or new accelerators that can be synthesized with different design flows from specifications written in different languages, including: C with Xilinx Vivado HLS, SystemC with Cadence Stratus HLS, Keras TensorFlow and PyTorch with hls4ml, Chisel, SystemVerilog, Verilog, and VHDL.<\/p>\n\n<ul>\n<li>Why is ESP relevant now?<\/li>\n<\/ul>\n\n\n<p>Information technology has entered the age of heterogeneous computing.  Across a variety of application domains, computing systems rely on highly heterogeneous architectures that combine multiple general-purpose processors with specialized hardware accelerators.  The complexity of these systems, however, threatens to widen the gap between the capabilities provided by semiconductor technologies and the productivity of computer engineers.  ESP tackles this challenge by raising the level of abstraction in the design process, simplifying the domain-specific programming of heterogeneous architectures, and leveraging the potential of the emerging open-source hardware movement.<\/p>\n\n<ul>\n<li>What are some key ingredients of the ESP approach?<\/li>\n<\/ul>\n\n\n<p>Building on years of research on communication-based system-level design at Columbia University, ESP combines an architecture and a methodology.  The flexible tile-based architecture simplifies the integration of heterogeneous components by balancing regularity and specialization.  The companion methodology raises the level of abstraction to system-level design, thus promoting closer collaboration among software programmers and hardware engineers.  Through the automatic generation of device drivers from pre-designed templates, ESP simplifies the invocation of accelerators from user-level applications executing on top of Linux.  Through the automatic generation of a multi-plane network-on-chip from a parameterized model, the ESP architecture can scale to accommodate many processors, tens of accelerators, and a distributed memory hierarchy.  A set of ESP Platform Services provides pre-validated solutions for accelerators configuration, memory management, sharing of system resources, and dynamic frequency scaling, among others.<\/p>\n\n<ul>\n<li>How does ESP differ from other RISC-V based platforms?<\/li>\n<\/ul>\n\n\n<p>To date, the majority of the open-source hardware (OSH) efforts related to RISC-V have focused on the development of processor cores that implement the RISC-V ISA and small-scale SoCs that connect these cores with tightly-coupled functional units and coprocessors, typically through bus-based interconnects. Meanwhile, there have been less efforts in developing solutions for large-scale SoCs that combine RISC-V cores with many loosely-coupled components, such as coarse-grain accelerators, interconnected with a network-on-chip (NoC).  Compared to other RISC-V related projects, ESP is focused on scalability (with the NoC-based architecture), heterogeneity (with emphasis on loosely-coupled accelerators), and flexibility (with support of different design flows).  Just like the ESP architecture simplifies the integration of heterogeneous components developed by different teams, the ESP methodology embraces the use of heterogeneous design flows for component development.<\/p>\n\n<ul>\n<li>Who are the authors of ESP?<\/li>\n<\/ul>\n\n\n<p>ESP has been developed by the System-Level Design (SLD) group in the Department of Computer Science at Columbia University during the past seven years.  The SLD group has published over a dozen scientific papers in peer-reviewed conferences and journals to describe the most innovative aspects of ESP.  ESP has been released as an open-source project via GitHub in the summer 2019.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7058",
            "value": "Luca Carloni"
          }
        },
        "links":
        [
          {
            "_href": "https://www.esp.cs.columbia.edu/",
            "value": "Main website of the ESP project"
          },
          {
            "_href": "https://github.com/sld-columbia/esp",
            "value": "GitHub repository of the ESP project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10061.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10035",
        "start": "11:50",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_chisel",
        "title": "Building Loosely-coupled RISC-V Accelerators",
        "subtitle": "Using Chisel/FIRRTL to build accelerator templates and collateral for the ESP SoC platform",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The burgeoning RISC-V <em>hardware<\/em> ecosystem includes a number of microprocessor implementations [1, 3] and SoC generation frameworks [1, 2, 7]. However, while accelerator “sockets” have been defined and used (e.g., Rocket Chip’s custom coprocessor/RoCC), accelerators require <em>additional<\/em> collateral to be generated like structured metadata descriptions, hardware wrappers, and device drivers. Requiring manual effort to generate this collateral proves both time consuming and error prone and is at odds with an agile approach to hardware design. However, the existence and use of hardware construction languages and hardware compilers provides a means to automate this process. Through the use of the Chisel hardware description language [4] and the FIRRTL hardware compiler [5], we provide a definition of an abstract accelerator template which users then implement to integrate an accelerator with the Embedded Scalable Platform (ESP) System-on-Chip platform [2, 8]. Through the use of this template, we are able to automatically generate XML metadata necessary to integrate accelerators with the ESP platform and work on generating all collateral is in progress. Our accelerator template is open source software provided under an Apache 2.0 license [6].<\/p>\n\n<p>[1] CHIPS alliance Rocket-chip. <em>GitHub Repository<\/em>. Online: https://github.com/chipsalliance/rocket-chpi.\n[2] Columbia University Embedded scalable platform. <em>git repository<\/em>. Online: https://github.com/sld-columbia/esp.\n[3] ETH Zurich Ariane. <em>GitHub Repository<\/em>. Online: https://github.com/pulp-platform/ariane.\n[4] Freechips Project Chisel3. <em>GitHub Repository<\/em>. Online: https://github.com/freechipsproject/chisel3.\n[5] Freechips Project FIRRTL. <em>GitHub Repository<\/em>. Online: https://github.com/freechipsproject/firrtl.\n[6] IBM ESP chisel acclerators. <em>GitHub Repository<\/em>. Online: https://github.com/ibm/esp-chisel-accelerators.\n[7] Princeton University OpenPiton. <em>GitHub Repository<\/em>. Online: https://github.com/PrincetonUniversity/openpiton.\n[8] ESP: The open-source heterogeneous system-on-chip platform. Online: https://www.esp.cs.columbia.edu/.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6966",
            "value": "Schuyler Eldridge"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/ibm/esp-chisel-accelerators",
            "value": "GitHub: Project Repository"
          },
          {
            "_href": "https://www.esp.cs.columbia.edu/",
            "value": "ESP Website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10035.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10110",
        "start": "12:10",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_eraser",
        "title": "ERASER: Early-stage Reliability And Security Estimation for RISC-V",
        "subtitle": "An open source framework for resilience/security evaluation and validation in RISC-V processors",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>RISC-V processors have gained acceptance across a wide range of computing domains, from IoT to embedded/mobile class and even in server-class processing systems. In processing systems ranging from connected cars and autonomous vehicles, to those on-board satellites and spacecrafts, these processors are targeted to function in safety-critical systems, where Reliability, Availability and Serviceability (RAS)-based considerations are of paramount importance. Along with potential system vulnerabilities caused primarily due to random errors, these processors may also be sensitive to targeted errors, possibly from malicious entities, which raises serious concerns regarding the security and safety of the processing system. Consequently, such systems necessitate the incorporation of RAS-based considerations right from an early stage of processor design.<\/p>\n\n<p>While the hardware and software ecosystem around RISC-V has been steadily maturing, there have, however, been limited developments in early stage reliability-aware design and verification. The Early-stage Reliability And Security Estimation for RISC-V (ERASER) tool attempts to address this shortcoming. It consists of an open source framework aimed at providing directions to incorporate such reliability and security features at an early, pre-silicon stage of design. These features may include what kind of protection to be applied and which components within the processor should they be applied to. The proposed infrastructure comprises of an open source toolchain for early stage modeling of latch vulnerability in a RISC-V core (SERMiner [1]), a tool for automated generation of stress marks that maximize the likelihood of a transient-failure induced error (Microprobe (RISC-V) [2]), and verification by means of statistical and/or targeted fault injection (Chiffre [3]). While the infrastructure is targeted towards any core that uses the RISC-V ISA, the repository provides an end-to-end flow for the Rocket core [4].<\/p>\n\n<p>ERASER thus evaluates “RAS-readiness”, or the effectiveness of protection techniques in processor design such that processor vulnerability in terms of Failures-In-time (FIT) rate is minimized, for a specified power/performance overhead. FIT rate is defined as the number of failures in one billion hours of operation and is a standard vulnerability metric used in industry.<\/p>\n\n<p>ERASER is an open source tool available for download at https://github.com/IBM/eraser. The tool currently supports analysis of all latches in the design across a single Rocket core and the generation of stressmarks that can be used to evaluate the vulnerability of these latches. In addition to radiation-induced soft errors, we plan to extend ERASER to also model errors due to voltage noise, thermal and aging-induced failures, both in memory and logic, and generate representative stressmarks.<\/p>\n\n<p>ERASER is an initial effort to devise a comprehensive methodology for RAS analysis, particularly for open-source hardware, with the hope that it spurs further research and development into reliability-aware design both in industry and academia.<\/p>\n\n<p>References:<\/p>\n\n<ol>\n<li><p>K. Swaminathan, R. Bertran, H. Jacobson, P. Kudva, P. Bose, ‘Generation of Stressmarks for Early-stage Soft-error Modeling’, International Conference on Dependable Systems and Networks (DSN) 2019<\/p><\/li>\n<li><p>S. Eldridge R. Bertran, A. Buyuktosunoglu, P. Bose, ‘MicroProbe: An Open Source Microbenchmark Generator, ported to the RISC-V ISA, the 7th RISC-V workshop, 2017<\/p><\/li>\n<li><p>S. Eldridge, A. Buyuktosunoglu and P. Bose, ‘Chiffre A Configurable Hardware Fault Injection Framework for RISC-V Systems’ 2nd Workshop on Computer Architecture Research with RISC-V (CARRV), 2018<\/p><\/li>\n<li><p>Krste Asanović, Rimas Avižienis, Jonathan Bachrach, Scott Beamer, David Biancolin, Christopher Celio, Henry Cook, Palmer Dabbelt, John Hauser, Adam Izraelevitz, Sagar Karandikar, Benjamin Keller, Donggyu Kim, John Koenig, Yunsup Lee, Eric Love, Martin Maas, Albert Magyar, Howard Mao, Miquel Moreto, Albert Ou, David Patterson, Brian Richards, Colin Schmidt, Stephen Twigg, Huy Vo, and Andrew Waterman, The Rocket Chip Generator, Technical Report UCB/EECS-2016-17, EECS Department, University of California, Berkeley, April 2016<\/p><\/li>\n<\/ol>",
        "description": "<p>The attached figure shows a representative flow for the RAS estimation methodology. An initial characterization of all instructions in the RISC-V ISA is carried out via RTL simulation using an existing core model (eg. the Rocket core). The simulation is configured to generate VCD (Value- Change Dump) files for every single instruction testcase. The SERMiner tool parses these VCD files to determine latch activities across the core, aggregated at a macro (or RTL module) level. Based on these per-instruction latch activities, SERMiner outputs an instruction sequence, which forms the basis of the SER stressmark to be generated by Microprobe (RISC-V). Microprobe (RISC-V) is a microbenchmark generation tool that is capable of generating microbenchmarks geared towards specific architecture and micro-architecture level characterization. One of its key applications is in the generation of stressmarks, or viruses, that target various worst-case corners of processor operation. These stressmarks may be targeted at maximizing power, voltage noise, temperature, or soft-error vulnerability as in case of this tool. The generated stressmark is then used to generate a list of latches that show a high residency and hence a high SER vulnerability. These latches are the focus of fault injection-based validation experiments using the Chiffre tool. Chiffre provides a framework for automatically instrumenting a hardware design with run-time configurable fault injectors. The vulnerable latches obtained from running the generated stressmarks through the Rocket core model, and then through SERMiner, are earmarked for targeted fault injection experiments using Chiffre. The objective of these experiments is to further prune the list of vulnerable latches by eliminating those that are derated, that is, they do not affect the overall output even when a fault is injected in them. Focusing any and all protection strategies on this final list of latches would maximize RAS coverage across the entire core.<\/p>\n\n<p>Ongoing and future work:<\/p>\n\n<p>ERASER currently only supports analysis of all latches in the design across a single Rocket core and the generated stressmarks can be used to evaluate the vulnerability of these latches. Most on-chip memory structures such as register files and caches, are equipped with parity/ECC protection and are as such protected against most radiation-induced soft errors. However, they are still vulnerable to supply voltage noise, thermal and aging-induced failures, and other hard or permanent errors. We plan to extend ERASER to model such errors, both in memory and logic, and generate stressmarks representative of worst-case thermal emergencies and voltage noise, in addition to soft errors.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6941",
            "value": "Karthik Swaminathan"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/IBM/eraser",
            "value": "Github link to ERASER repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10110.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10122",
        "start": "12:30",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_openpiton",
        "title": "RISC-V Software and Firmware Development in the Cloud Using OpenPiton+Ariane on Amazon F1",
        "subtitle": [],
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>RISC-V application, OS, and firmware development has been slowed by the lack of \"real hardware\" available for developers to work with. With the rise of FPGAs in the cloud and the recent release of the OpenPiton+Ariane manycore platform on Amazon's F1 cloud FPGA platform, we propose using 1-12 core OpenPiton+Ariane processors emulated on F1 to develop RISC-V software and firmware. In this talk, we will give an accelerated tutorial on how to get started with OpenPiton+Ariane, the spec-compliant RISC-V platform it offers, and how the firmware and OS can be modified and run on top. We will show a number of applications built and running for our present Debian distribution and the software development environment that this offers. We will then highlight how hardware and software can be co-designed on OpenPiton+Ariane with the ability to recompile the hardware underlying the cloud FPGA image and deploy it for use by others. This platform is serving as a basis for software and hardware development for the DECADES project, a project investigating heterogenous manycore and hardware accelerator based designs with support for orchestrated data movement.<\/p>",
        "description": "<p>RISC-V Software and Firmware Development in the Cloud Using OpenPiton+Ariane on Amazon F1<\/p>\n\n<p>RISC-V application, OS, and firmware development has been slowed by the lack of \"real hardware\" available for developers to work with. With the rise of FPGAs in the cloud and the recent release of the OpenPiton+Ariane manycore platform on Amazon's F1 cloud FPGA platform, we propose using 1-12 core OpenPiton+Ariane processors emulated on F1 to develop RISC-V software and firmware. In this talk, we will give an accelerated tutorial on how to get started with OpenPiton+Ariane, the spec-compliant RISC-V platform it offers, and how the firmware and OS can be modified and run on top. We will show a number of applications built and running for our present Debian distribution and the software development environment that this offers. We will then highlight how hardware and software can be co-designed on OpenPiton+Ariane with the ability to recompile the hardware underlying the cloud FPGA image and deploy it for use by others. This platform is serving as a basis for software and hardware development for the DECADES project, a project investigating heterogenous manycore and hardware accelerator based designs with support for orchestrated data movement.<\/p>\n\n<p>http://openpiton.org\nhttps://openpiton-blog.princeton.edu/2019/10/bringing-openpiton-to-amazon-ec2-f1-fpgas/<\/p>\n\n<p>OpenPiton+Ariane contributors include:\nJonathan Balkind, Grigory Chirkov, Yaosheng Fu, Adi Fuchs, Fei Gao, Alexey Lavrov, Ang Li, Xiaohua Liang, Katie Lim, Matthew Matl, Michael McKeown, Tri Nguyen, Samuel Payne, Michael Schaffner, Mohammad Shahrad, Jinzheng Tu, Florian Zaruba, Yanqi Zhou, Georgios Tziantzioulis, Luca Benini, David Wentzlaff<\/p>\n\n<p>DECADES is a large collaboration from three academic groups: Margaret Martonosi (PI Princeton), David Wentzlaff (PI Princeton), Luca Carloni (PI Columbia) with students/researchers: Jonathan Balkind, Ting-Jung Chang, Fei Gao, Davide Giri, Paul Jackson, Paolo Mantovani, Luwa Matthews, Aninda Manocha, Tyler Sorensen, Jinzheng Tu, Esin Türeci, Georgios Tziantzioulis, and Marcelo Orenes Vera. In addition to the submission author, portions of the talk may be offered by others in the collaboration.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7003",
            "value": "David Wentzlaff"
          }
        },
        "links":
        [
          {
            "_href": "http://openpiton.org",
            "value": "OpenPiton Website"
          },
          {
            "_href": "https://openpiton-blog.princeton.edu/2019/10/bringing-openpiton-to-amazon-ec2-f1-fpgas/",
            "value": "OpenPiton on F1"
          },
          {
            "_href": "https://github.com/PrincetonUniversity/openpiton",
            "value": "OpenPiton GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10122.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9424",
        "start": "12:50",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_comrv",
        "title": "Cacheable Overlay Manager RISC-V",
        "subtitle": [],
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We would like to present and overlay technique for RISCV which will be open source by WD.\nThis FW feature acts as and “catchable” manager. It is to be threaded with the Real-Time code and to the toolchain.\nCacheable Overlay Manager RISC-V (ComRV), a technique which fits small devices (as IoT’s), and does not need any HW support.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6723",
            "value": "Ofer Shinaar"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9424.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10100",
        "start": "13:10",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_bootflow",
        "title": "RISC-V Boot flow: What's next ?",
        "subtitle": [],
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>RISC-V boot flow has come a long way since in recent times by leveraging the various opensource boot loaders/firmware projects. This also helped in achieving a well-supported and standard boot flow for RISC-V. As a result, developers can use the same boot loaders to boot Linux on RISC-V as they do in other architectures. Currently, U-Boot is used as the last stage boot loader and OpenSBI as the machine mode run time service provider, but there's more work to be done. A few of such future works includes U-boot SPL support, UEFI boot in RISC-V Linux and booting protocol improvements. This talk will focus on some of these ongoing works which are necessary to declare that RISC-V is truly ready for world domination.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5900",
            "value": "Atish Patra"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10100.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9315",
        "start": "13:30",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_oreboot",
        "title": "Oreboot",
        "subtitle": "RISC-V Firmware in Rust",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Oreboot = Coreboot - C. Oreboot is a fully open-source power-on-reset and romstage firmware written in Rust. Oreboot can boot a HiFive RISC-V processor to Linux with a Go user-mode.<\/p>\n\n<p>Oreboot rethinks the firmware driver models. Each driver is distilled to four basic functions: init, pread, pwrite and shutdown. This interface allows us to make convenient higher-level drivers such as a \"union driver\" which duplicates a single write operation to multiple drivers. This makes consoles which have multiple underlying UART drivers elegant.<\/p>\n\n<p>By using the Rust programming language, Oreboot has a leg-up in terms of security and reliability compared to contemporary firmware written in C or assembly. Rust's borrow-checker ensures pointers are not used after freed and proves that coroutines are thread-safe at compile time.<\/p>\n\n<p>In this talk, we will also present a short overview of the basics of Rust, how our driver model incorporates coroutines and the bootflow of Oreboot.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6624",
            "value": "Ryan O'Leary"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/oreboot/oreboot",
            "value": "Oreboot Source Code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9315.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10076",
        "start": "13:50",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_hypervisors",
        "title": "RISC-V Hypervisors",
        "subtitle": "Where are we ? What next ?",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The RISC-V H-extension (aka hypervisor extension) is suitable for both Type1 and Type2 hypervisor. We have ported two hypervisors for RISC-V: Xvisor (Type1) and KVM (Type2). We show the current state and furture work for both hypervisors.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7078",
            "value": "Anup Patel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10076.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10102",
        "start": "14:10",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "riscv_luajit",
        "title": "Port luajit to RISC-V",
        "subtitle": "Motivation, first steps and perspectives",
        "track": "RISC-V",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There is a need for a lightweight tools for experiments with RISC-V\ncustom extensions. Adding support for custom instructions in\nbinutils/gcc/llvm is out of range for many hardware architects. LuaJIT\nincludes a small and powerful assembler: dynasm, accessible from\nwithin Lua interpreter. Currently dynasm supports following 32 and 64-bit\ninstruction sets: x86, x64, ARM, PowerPC, and MIPS, and it is just\nreasonable to extend this support to RISC-V.<\/p>\n\n<p>Lua itself is a very compact and simple yet powerful dynamic language,\nits JIT compiler (luajit) makes it one of the fastest, if not the\nfastest, interpreted language, and it is used in many projects, so\nhaving it running on RISC-V would have use besides the mere internal\nneed for experimental platform.<\/p>",
        "description": "<h1>Outline<\/h1>\n\n<h2>Project scope<\/h2>\n\n<ul>\n<li>Lua 5.1, luajit 2.1 overview<\/li>\n<li>rv32/rv64<\/li>\n<li>dynasm<\/li>\n<li>interpreter/virtual machine<\/li>\n<li>jit<\/li>\n<li>gc<\/li>\n<li>bit manipulation ('B' extention and bitop in Lua 5.3)<\/li>\n<\/ul>\n\n\n<h2>Develpment platforms<\/h2>\n\n<ul>\n<li>spike (ISA simulator, 32 and 64-bit)<\/li>\n<li>rv64: SiFive Unleashed<\/li>\n<li>rv32: softcore CPU on FPGA<\/li>\n<\/ul>\n\n\n<h2>Benchmarks and baseline<\/h2>\n\n<h2>Deviation (side project)<\/h2>\n\n<p>Yet another Forth and yet another assembler<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6861",
            "value": "Anton Kuzmin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/ak-fau/LuaJIT-RV.git",
            "value": "LuaJIT repository mirror with RISC-V development branches"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10102.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10705",
        "start": "14:55",
        "duration": "00:05",
        "room": "K.3.401",
        "slug": "retro_devroom_welcome",
        "title": "Welcome to the Retrocomputing DevRoom 2020",
        "subtitle": [],
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A quick introduction to the 3rd edition of the retro-computing devroom.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "666",
            "value": "Pau Garcia Quiles (pgquiles)"
          },
          {
            "_id": "3587",
            "value": "François Revol (mmu_man)"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10705.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9153",
        "start": "15:00",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_alpha_waves_1st_3d_platformer_ever",
        "title": "Alpha Waves, the first 3D platformer ever",
        "subtitle": "How 3D graphics worked when there were no graphic cards",
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Alpha Waves is the first 3D platform game ever.\nInitially developed on Atari ST, it was then ported on Atari ST and on the IBM PC.\nThe technology later gave rise to Alone in the Dark, a major game that launched Infogrames in the big league.\nThis is the history of that game.<\/p>",
        "description": "<p>Alpha Waves is the first 3D platform game ever, according to the Guiness Book of Records.<\/p>\n\n<p>The game was initially developed on Atari ST, representing 17000 lines of 68K assembly code.\nIt was later ported on Atari ST and on the IBM PC, and was the first and only assembly program game that Infogrames ever ported to another CPU.\nThe technology developed for that game later inspired Frederick Raynal to develop Alone in the Dark, a major game that launched Infogrames in the big league.<\/p>\n\n<p>This talk is the history of that game by its developer. It will cover:\n* General principles of paleo-3D\n* How to draw polygons in software. Fast.\n* Computing 3D transforms using mostly additions\n* Music, graphics and other stuff\n* Funny stories and trivia around the game, including the stints of Infogrames in Artificial Intelligcence and the arch-genesis of Alone in the Dark<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5672",
            "value": "Christophe de Dinechin"
          }
        },
        "links":
        [
          {
            "_href": "https://en.wikipedia.org/wiki/Alpha_Waves",
            "value": "Wikipedia page for the game"
          },
          {
            "_href": "https://grenouille-bouillie.blogspot.com/2007/10/dawn-of-3d-games.html",
            "value": "A blog entry covering some of the topics to be presented"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9153.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10436",
        "start": "15:35",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_basicode_8_bit_programming_api",
        "title": "BASICODE: the 8-bit programming API that crossed the Berlin Wall",
        "subtitle": [],
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>At the height of the cold war, BASIC programs exchanged by radio and cassette tape provided young people of socialist Eastern and capitalist Western Europe a rare insight into each other's worlds. BASICODE was a transmission format and an API developed by the Dutch public broadcasting service to overcome the challenge of exchanging open source hobby programs in the highly fragmented 8-bit computing landscape of the early 1980s, which was dominated by mutually incompatible versions of BASIC. Somewhat improbably, the format was picked up across the iron curtain in the German Democratic Republic, where it experienced its age of greatest popularity. The need for programs to work on platforms with widely different capabilities and incompatible syntaxes forced it to be simply structured, highly regulated and relatively well documented. This makes it ideally suited for implementation in a web browser.<\/p>",
        "description": "<ul>\n<li>An early age of open source<\/li>\n<li>Modulating source code for radio transmission<\/li>\n<li>An API based on GOSUBs in BASIC<\/li>\n<li>East and West in the 1980s<\/li>\n<li>Implementing BASICODE in a web browser<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7259",
            "value": "Rob Hagemans"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/robhagemans/basicode",
            "value": "BASICODE programs"
          },
          {
            "_href": "https://github.com/robhagemans/basicode-interpreter",
            "value": "BASICODE implemented in JavaScript"
          },
          {
            "_href": "https://robhagemans.github.io/basicode/",
            "value": "Live demo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10436.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10423",
        "start": "16:10",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_music_open_cubic_player",
        "title": "Retro music - Open Cubic Player",
        "subtitle": [],
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This presentation includes multiple topics mixed together\n * Porting a DOS multimedia program into Linux/BSD\n * How music was composed/stored in old type of games from the 8bit era, up into the amiga (and partly the DOS world)\n * How does audio/music hardware work. C64 SID, ZX-Spectrum and alike, Amiga, Adlib FM-synth OPL2/3 and General Midi<\/p>",
        "description": "<p>As a child, I was exposed to Cubic Player. This program was a text-based music player. All the colors mesmerized me and it gave a Direct visual feedback of how the music was generated.<\/p>\n\n<p><img src=\"http://content.pouet.net/files/screenshots/00015/00015501.gif\" alt=\"Cubic Player screenshot\" /><\/p>\n\n<p>During teenage years I learned programming and got curiousity for Linux. All the sourcecode for everything was available. The kernel, multimedia libraries, multimedia tools. If there are anything you wonder how works, you can inspect it. You are unable to sort how a specific detail can be done in your own project, try to find another project that has done something similiar! But for playing this amiga style modules, there was no programs that had the same charm as Cubic Player. Programs like mikmod, XMMS, Audacious only displayed playlist, maybe instrument-names and maybe an spectrum analyzer.\n<img src=\"http://mikmod.sourceforge.net/images/mikmod-3.2.2-dynsamp.png\" alt=\"http://mikmod.sourceforge.net/images/mikmod-3.2.2-dynsamp.png\" />\n<img src=\"http://soft.softoogle.com/pimg/1955.png\" alt=\"XMMS screenshot\" /><\/p>\n\n<p>Then I discovered that Cubic Player had been released as Open Cubic Player - but nobody had touched it. Releasing a project does not automatically make it work in other systems. But it makes it possible. I grabbed the source code and started to study it. All of it was based on direct hardware access, as it was written for DOS. Direct access to video-memory/hardware, raw keyboard scan codes, hardware interrupts for timers allowing background rendering of audio if needed etc. A natural candidate for a novice programmer to port?<\/p>\n\n<p>Slowly I went through one and one single file of the original source code.\n* Lots of logic could be kept (just needed type fixing like replacing byte with uint8_t, a char is not guaranteed to be unsigned)\n* Some could be thrown away like direct audio hardware drivers\n* Some needed heavy rewrites like video output. The code already was abstracted with having functions for mixing colors and text rendering.\n* Assembler inlines took many weeks - months (watcom c++ and gcc has VERY different syntax and integration)\n* The timer interrupt was solved using SIGTIMER. But porting the code caused a zero-day kernel bug to be discovered <a href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-0554\">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-0554<\/a>\n* Text output was originally solved using ncurses\n* Filenames are not 8.3 format in Linux/BSD<\/p>\n\n<p>When text appears on the screen, and audio (highly distorted in the beginning) appeared, was a magical feeling. Progress was faster when the goal felt to be well within the reach.<\/p>\n\n<p>When you the make your code public, people start to use it... and you start to get feedback like:\n* Program is unable to compile on other platforms - assembler inlines is not portable - even when compiling for x86_64 - got to make C-replacement for all of them - A person submitted the full rework of the floating point version of the mixer from assembler into C!!! WOW\n* Nothing works when compiling for MacOS - Wait, you tried what? Endian is important when parsing binary file formats\n* Specific crashes that only happens for some few people - compiler bugs (these were more common back in the days)<\/p>\n\n<hr />\n\n<p>Music formats time, and their integration!<\/p>\n\n<p>So, what is a amiga style module?<\/p>\n\n<p>Let's take a look at the Amiga hardware. The sound-chip there is a 4 channel wave-mixer. Each channel is assigned a PCM audio source, volume and a wide range of possible samplerates. These three parameters can be adjusted anytime.\nAn Amiga style module is then a set of audio PCM (8bit) samples - a sound font, and then 4 tracks recipe of how these 3 parameters should be manipulated. These can be small adjustements, big adjustments, slow or fast - All imitating different kind of effects from playing real life instruments.\nPortamento - sliding between seminotes - sliding the finger on the strings along the neck of the guitar\nTremolo - small vibration of the pitch - tremolo arm on an electric guitar\n...\nWhen this later moved into the computer world, the entire mixer had to be done in software, the number of channels was no longer limited by the hardware mixer.\n....\nVarious editors, players, file-format tools etc. all do things slighly different. The exact result for a given file will have variations, but the overall impression should be the same. The most important reason why music was done in this format was file sizes. A typical song would be in the range 10-100 kilobyte only, and the same mixer/playback-routines can be used for playing the game sound-effects. The complete code needed for rendering a given fileformat is not very large.<\/p>\n\n<p>So, what if we can ditch the soundfont in the files to save space. Welcome to General Midi. General Midi defines a set of instruments - actually a full orchestra and a bunch of synth style sounds. But it only defines what they are, not the exact sounds. An electric guitar is not just a guitar. And a MIDI file contains a set of \"note-on including attack\", \"note-off\" and \"select instrument\" events on a timeline.<\/p>\n\n<p>Open Cubic Player had support for General Midi, and parsing of soundfont in a single file format: UltraSound DOS driver fileformat. The few ones you found online were mostly propetiary - not very compatible with open source. So people kept demanding support for more formats. So I made a parser for the timidity config files; so far good enough. Then it kept a forever race and need for new features discovered in these configuration files - and even worse - depending on parsing binary fileformats that might contain the needed samples. Eventually - as the sole maintainer of the project - throw out the entire midi parser and renderer, and just use the entire Timidity+ project almost as-is. There is no point in re-inventing the wheel if you do not intend to improve it. So currently the MIDI renderer in Open Cubic Player is (a fork of) Timidity+.<\/p>\n\n<p>Same for the MP2/MP3 renderer that was using the original AMP engine. Instead of trying to fix it - use libmad!<\/p>\n\n<p>Ogg Vorbis files - libogg<\/p>\n\n<p>FLAC files - libflac<\/p>\n\n<p>And then users starts to request support for other fileformats - luckily, integration of them are not so hard when there is open source libraries and players that can be used.<\/p>\n\n<p>C64 .SID files - libsidplay<\/p>\n\n<p>ZX-Spectrum 128 .AY files - Code chopped out from \"aylet\"<\/p>\n\n<p>Atari ST .YM files - Using a fork of STYMulator<\/p>\n\n<p>OPL2/OPL3 style - libadplug<\/p>\n\n<p>AHX Tracker / Hively Tracker - Hively Tracker source contains a .wav file renderer<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7249",
            "value": "Stian Sebastian Skjelstad"
          }
        },
        "links":
        [
          {
            "_href": "https://stian.cubic.org/project-ocp.php",
            "value": "Open Cubic Player for Unix homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10423.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9597",
        "start": "16:45",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_reviving_minitel",
        "title": "Reviving Minitel",
        "subtitle": "How web technologies make it easy to emulate Minitel",
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Using web technologies, one can easily emulate the Minitel ecosystem, not only the iconic french terminal but also its servers. This easiness has been made possible due to ES6 and websockets.<\/p>",
        "description": "<ul>\n<li>Brief history of the Minitel<\/li>\n<li>Minitel + VideoTex + X25 vs Browser + HTML + TCP/IP<\/li>\n<li>Technical aspects of Minitel emulation (ES6 + websockets)<\/li>\n<li>Creation of a VideoTex page (live demo)<\/li>\n<li>Surfing on Minitel (live demo)<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6837",
            "value": "Frédéric Bisson"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/zigazou/miedit",
            "value": "Repository of Minitel emulator and editor"
          },
          {
            "_href": "https://zigazou.github.io/miedit/",
            "value": "Online editor"
          },
          {
            "_href": "http://3615co.de/",
            "value": "3615 historical portal"
          },
          {
            "_href": "http://3614hacker.fr/",
            "value": "3614 hacker, an old service revived on web"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9597.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9574",
        "start": "17:20",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_reverse_engineering_vic_20_cartridge",
        "title": "Reverse engineering a VIC-20 expansion cartridge",
        "subtitle": [],
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Going from seeing an image of a cartridge that I would have loved to have had for my VIC-20 to working out how it was built and then making my own.<\/p>",
        "description": "<p>Starting with a brief overview of the VIC-20 and the capabilities, to then looking at the \"vixen\" 16KiB RAM expansion, the initial view of the internals made available on the internet to going to a full implementation.<\/p>\n\n<p>The initial overview will go through some of the identification of the components, the technologies involved (such as SRAM and DRAM) and the VIC-20 expansion bus. It will show what sort of technologies could go into implementing this sort of expansion and then how these can be discounted either by the age of the technology or the component complexity.<\/p>\n\n<p>Techniques for further reversing a circuit from the physical device and how the actual device circuit was then discovered, followed by the implementation and testing will be shown.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6828",
            "value": "Ben Dooks"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9574.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10586",
        "start": "17:55",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_mainframe_on_laptop",
        "title": "Running a mainframe on your laptop (for fun and profit)",
        "subtitle": [],
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Yes, this talk is about running your own mainframe on your own hardware. Mainframes are old, yes, but they are still very much alive. New hardware is still being developed and there are a lot of fresh jobs in this area too. A lot of mainframes run COBOL workloads. COBOL is far from a dead language. It processes an estimated 85% of all business transactions, and 5 billion lines of new COBOL code are written every year. In this session the speaker will help you in take your first steps towards running your own mainframe. If you like then after this session you can continue to build your knowledge of mainframe systems using the links provided during the talk. Come on in and learn the basics of a completely different computer system! And it will take you less than an hour to do that!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6179",
            "value": "Jeroen Baten"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10586.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9676",
        "start": "18:30",
        "duration": "00:30",
        "room": "K.3.401",
        "slug": "retro_arcade_game_port_zx",
        "title": "Arcade game port to ZX Spectrum",
        "subtitle": "A reverse engineering exercise",
        "track": "Retrocomputing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Reverse engineering an Arcade game and re-implementing it into an 8 bit system is an engineering exercise, where compromises have to be made in order to accomplish the goal, since the capabilities of the target machine are severely under powered when compared with the source machine.<\/p>\n\n<p>The processes of accomplishing this and all it involves, will be presented.<\/p>",
        "description": "<p>Making an Arcade Game remake (reverse engineering) into an 8 bit system is an engineering exercise, where compromises have to be made in order to accomplish the goal, since the capabilities of the target machine are severely under powered when compared with the source machine.<\/p>\n\n<p>Starting with graphic capabilities, passing through CPU limitations (clock speed and architecture) and ending with multimedia capabilities, every single one, needs to be addressed with a suitable compromise.\nSome ingenious \"hacks\" and extreme optimization need to be applied, to use the 8 bit hardware capabilities in a convenient way to overcome the huge handy cap between architectures.<\/p>\n\n<p>For practical and example purposes, the reverse engineering of the Arcade game \"Magical Drop II\" will be presented, and how it became \"Extruder\" ZX Spectrum game.<\/p>\n\n<p>The software was developed in Zilog Z80 Assembly, and several tips and tricks will be shown, that facilitate and help the conversion process.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5137",
            "value": "Rui Martins"
          }
        },
        "links":
        [
          {
            "_href": "https://drive.google.com/drive/folders/1rGQMWRUkiGjO-nWt8J2jGBtMIxwB3jna?usp=sharing",
            "value": "Arcade game port to ZX"
          },
          {
            "_href": "https://github.com/Rui1973Martins/Extruder",
            "value": "\"Extruder\" port to ZX Spectrum"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9676.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.4.201",
    "event":
    [
      {
        "_id": "9743",
        "start": "10:30",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "debugging_with_llvm",
        "title": "Debugging with LLVM",
        "subtitle": "A quick introduction to LLDB and LLVM sanitizers",
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The aim of this presentation is to showcase the technologies available in LLVM that aid debugging. We will focus on LLDB, the debugger, and sanitisers (e.g. AddressSanitizer and LeakSanitizer). No prior knowledge is required, but if you're familiar with GDB or Valgrind then this talk will introduce you to alternatives available within LLVM.<\/p>\n\n<p>LLDB is a very powerful and extensible command line debugger available on Linux, Mac OS, FreeBSD, Windows and Android. It is used internally in XCode and Android Studio and available on various hardware platforms (e.g. X86, ARM, AArch64, PowerPC, Mips). LLDB is built as a set of reusable components which highly leverage existing libraries in LLVM. It has a very powerful expression evaluation engine, intuitive CL interface (with tab-completion), easy to navigate help pages and a \"graphical\" user interface. In this presentation we will explore basic usage as well as some lesser known features. LLDB has come a long way and we want to present how intuitive, helpful and powerful it can be when used pragmatically.<\/p>\n\n<p>While LLDB will let you easily examine and debug a program at the point of failure, it can be harder to diagnose the underlying problem if it occurred before the program crashed or printed an incorrect result. LLVM provides some extra features in the form of 'sanitizers' to help find the root cause of some extra problems, like accessing a wrong-but-still-valid memory address or unintentionally wrapping a signed integer value. This presentation will explore how to use the sanitizers to debug programs and some examples of bugs they can catch.<\/p>",
        "description": "<p>TITLE: <em>Debugging with LLVM<\/em><\/p>\n\n<p>The aim of this presentation is to showcase the technologies available in LLVM that aid debugging. We will focus on LLDB, the debugger, and sanitisers (e.g. AddressSanitizer and LeakSanitizer). No prior knowledge is required, but if you're familiar with GDB or Valgrind then this talk will introduce you to alternatives available within LLVM.<\/p>\n\n<p>LLDB is a very powerful and extensible command line debugger available on Linux, Mac OS, FreeBSD, Windows and Android. It is used internally in XCode and Android Studio and available on various hardware platforms (e.g. X86, ARM, AArch64, PowerPC, Mips). LLDB is built as a set of reusable components which highly leverage existing libraries in LLVM. It has a very powerful expression evaluation engine, intuitive CL interface (with tab-completion), easy to navigate help pages and a \"graphical\" user interface. In this presentation we will explore basic usage as well as some lesser known features. LLDB has come a long way and we want to present how intuitive, helpful and powerful it can be when used pragmatically.<\/p>\n\n<p>While LLDB will let you easily examine and debug a program at the point of failure, it can be harder to diagnose the underlying problem if it occurred before the program crashed or printed an incorrect result. LLVM provides some extra features in the form of 'sanitizers' to help find the root cause of some extra problems, like accessing a wrong-but-still-valid memory address or unintentionally wrapping a signed integer value. This presentation will explore how to use the sanitizers to debug programs and some examples of bugs they can catch.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6875",
            "value": "Andrzej Warzynski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9743.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10163",
        "start": "11:15",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_benchmarking_embench",
        "title": "Benchmarking LLVM using Embench",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Dhrystone and Coremark have been the defacto standard microcontroller benchmark suites for the last thirty years, but these benchmarks no longer reflect the needs of modern embedded systems. Embench™ was explicitly designed to meet the requirements of modern connected embedded systems. The benchmarks are free, relevant, portable, and well implemented.<\/p>\n\n<p>In this talk we will present the results of benchmarking Clang/LLVM for various IoT class architectures using Embench. We shall look at\n- how code size and speed varies across architectures when compiling with Clang/LLVM.\n- how Clang/LLVM performance has evolved over time\n- how Clang/LLVM compares against other compilers, notably GCC\n- the effectiveness of various compilation techniques (LTO, Combined Elimination, Profile Guided Optimization)<\/p>\n\n<p>The aim is not to show which architecture or compiler is best, but to gain insight into the detail of the compilation process, so that all compilers and architectures can learn from each other.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1569",
            "value": "Jeremy Bennett"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10163.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9700",
        "start": "12:10",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "clang_fedora",
        "title": "Confronting Clang and Fedora",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GCC is the default toolchain to build C/C++ packages in Fedora. Meanwhile OpenMandrivia already builds most of its package with the LLVM toolchain, the Debian archive is regularly rebuilt with with a recent verion of clang... So could we try that for Fedora?<\/p>\n\n<p>This talk describes an on-going effort to achieve that goal while keeping the same compiler feature set as GCC.<\/p>",
        "description": "<p>Subtopics of the talk include:<\/p>\n\n<ul>\n<li>Creating a clang-based buildroot and use it to rebuild the fedora user-land (and more?)<\/li>\n<li>Support for missing security features such as -fstack-clash-protection or -D<em>FORTIFY<\/em>SOURCE=2<\/li>\n<li>Add missing features for the annobin tool within lld<\/li>\n<li>Python3 compatibity<\/li>\n<li>Package size<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "4847",
            "value": "Serge Guelton (serge-sans-paille)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9700.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10164",
        "start": "12:55",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_gcc_panel",
        "title": "LLVM and GCC",
        "subtitle": "Learning to work together",
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>At the GNU Tools Cauldron we held a panel discussion on how GCC and LLVM can work together. The video of that discussion can be seen at https://www.youtube.com/watch?v=PnbJOSZXynA.<\/p>\n\n<p>We proposed a similar discussion to be held at the LLVM Developers Meeting, but the reviewers suggested that such a discussion would be better held as part of the FOSDEM LLVM Devroom, since that was more likely to attract GNU developers as well.<\/p>\n\n<p>We wish to explore how Clang/LLVM and the GCC can work together effectively.<\/p>\n\n<p>The participants will explore opportunities for co-operation between the projects. Areas to be covered include:\n- collaboration on issues related to language standards, changes to existing standards or implementing new ones;\n- maintaining ABI compatibility between the compilers;\n- interoperability between tools and libraries e.g. building with clang and libstdc++ or building with gcc and linking with lld; and\n- communication channels for developers via bugzilla or mailing lists.<\/p>\n\n<p>We hope the output of the discussion will inform future work between the two communities.<\/p>\n\n<p>The panelists are yet to be confirmed, but I have invited those who offered to participate at the LLVM Developer Room: Tom Stellard of Red Hat, Nathan Sidwell of Facebook, Iain Sandoe, now independent.  All have been major contributors to GCC and/or LLVM for many years.  I shall act as moderator.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1569",
            "value": "Jeremy Bennett"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10164.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10093",
        "start": "13:50",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_cpg",
        "title": "LLVM meets Code Property Graphs",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The security of computer systems fundamentally depends on the quality of its underlying software. Despite a long series of research in academia and industry, security vulnerabilities regularly manifest in program code. Consequently, they remain one of the primary causes of security breaches today.\nThe discovery of software vulnerabilities is a classic yet challenging problem of the security domain. In the last decade, there appeared several production-graded solutions with a favorable outcome.<\/p>\n\n<p>Code Property Graph[1] (or CPG) is one such solution. CPG is a representation of a program that combines properties of abstract syntax trees, control flow graphs, and program dependence graphs in a joint data structure.\nThere exist two counterparts[2][3] that allow traversals over code property graphs in order to find vulnerabilities and to extract any other interesting properties.<\/p>\n\n<p>In this talk, we want to cover the following topics:<\/p>\n\n<ul>\n<li>an intro to the code property graphs<\/li>\n<li>how we built llvm2cpg, a tool that converts LLVM Bitcode to the CPG representation<\/li>\n<li>how we teach the tool to reason about properties of high-level languages (C/C++/ObjC) based on the low-level representation only<\/li>\n<li>interesting findings and some results<\/li>\n<\/ul>\n\n\n<p>[1] https://ieeexplore.ieee.org/document/6956589\n[2] https://github.com/ShiftLeftSecurity/codepropertygraph\n[3] https://ocular.shiftleft.io<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "3289",
            "value": "Alex Denisov"
          },
          {
            "_id": "7387",
            "value": "Fabian Yamaguchi"
          }
        ],
        "links":
        [
          {
            "_href": "https://ieeexplore.ieee.org/document/6956589",
            "value": "Modeling and Discovering Vulnerabilities with Code Property Graphs"
          },
          {
            "_href": "https://github.com/ShiftLeftSecurity/codepropertygraph",
            "value": "Code Property Graph implementation"
          },
          {
            "_href": "https://ocular.shiftleft.io",
            "value": "Shiftleft Ocular"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10093.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9791",
        "start": "14:35",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_python",
        "title": "LLVM and Python",
        "subtitle": "Past, Present, Future",
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Python with LLVM has at least one decade of history. This session will be going to cover-up how python implementations tried to use LLVM such as CPython's Unladen Swallow branch (PEP 3146) or attempts from PyPy and why they failed. After that it will show what are the current python projects that use LLVM for speed, such as numba and python libraries for working with LLVM IR. In the end, it will mention about new ideas that would unite the powers of both LLVM and Python.<\/p>",
        "description": "<p>This talk is about LLVM's influence over Python's ecosystem. It is targeted an audience of language developers who want to integrate LLVM and developers who are curious about why dont dynamic languages can unite their power with LLVM to speed-up. It will start with python's implementations and the approaches they take. The Unladen Swallow branch which basically tries to integrate LLVM to CPython (under google sponsored) is a good example of these approaches. There are attempts from the PyPy side but they are also failed because of the dynamic nature of Python. After this fails, we'll swap back to our current time and show projects that are benefiting from LLVM to speed up python especially on the scientific side such as numba (which offers JITting via LLVM). Besides these projects, there are also a few projects that offer an interface to LLVM. Such as llvmpy and llvmlite. I've been using llvmlite about 1 year in my side projects and toy languages so these projects has the potential to inspire developers to work with LLVM and build languages a-top on it. In the end, it will show what is the future of these two big projects (LLVM &amp; Python) and how we can participate.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6076",
            "value": "Batuhan Taşkaya"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9791.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10147",
        "start": "15:20",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_flang",
        "title": "Flang : The Fortran frontend of LLVM",
        "subtitle": "This technical talk introduces the new Fortran fronted of LLVM.",
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk introduces Flang (F18), the new Fortran frontend of LLVM being written in modern C++. The talk will provide a brief introduction to Flang, motivation for writing this new compiler, design principles, architecture, status, and an invitation to contribute.<\/p>",
        "description": "<p>F18 project started at PGI/Nvidia as a new Fortran frontend designed to work with LLVM. The aim of the project is to create a modern Fortran frontend (Fortran 2018 standard) in modern C++. In April of this year, it was accepted as an LLVM project (https://lists.llvm.org/pipermail/llvm-dev/2019-April/131703.html).<\/p>\n\n<p>The parser and semantic analysis are implemented in a way that provides a strong correspondence to the standards document. It is hoped that this correspondence will help in the development of new features and will become the testbed for deciding future Fortran standard features. The frontend also embraces the newly open-source MLIR framework for language-specific optimisations. This will be through a new dialect call FIR (https://www.youtube.com/watch?v=ff3ngdvUang). MLIR will also be used for creating an OpenMP dialect. The project also hopes to share code with the Clang frontend. While the parser/AST will not be shared, code will be shared in the Driver, OpenMP codegen etc.<\/p>\n\n<p>In this presentation, we hope to cover the technical details mentioned in the paragraph above, the status of implementation and also give an invitation to contribute.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6022",
            "value": "Kiran Chandramohan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10147.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9986",
        "start": "16:05",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_alda_panel",
        "title": "Ask LLVM developers Anything Panel",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ever wondered how the LLVM project and community works?\nWant to get some advice on how to most effectively contribute?\nNow is your chance at FOSDEM to ask experienced developers directly.  This\npanel will host a number of experienced LLVM developers, answering any\nrelevant questions from the audience.<\/p>",
        "description": "<p>In case questions from the audience do not fill the entire slot, a set of\nprepared questions focussed on how to get started working with and contributing\nto LLVM will be raised for the panelists to answer.<\/p>\n\n<p>The panel will consist of at least the following 2 experienced contributors to\nLLVM, and will be expanded with other experienced contributors who are planning\nto come to the dev room:\n- Kristof Beyls\n- Peter Smith<\/p>",
        "persons":
        [
          {
            "_id": "3445",
            "value": "Kristof Beyls"
          },
          {
            "_id": "4378",
            "value": "Peter Smith"
          },
          {
            "_id": "6036",
            "value": "Nick Desaulniers"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9986.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9966",
        "start": "17:00",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_aut_prog_het_soc",
        "title": "Automating Programming and Development of Heterogeneous SoCs with LLVM Tools",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Historically, programming heterogeneous systems has been quite a challenge. While programming support for basic general-purpose accelerators such as GPUs has become quite mature in many ways, general heterogeneous SoCs in particular can feature a much broader range of accelerators in their efforts to minimize power consumption while maximizing performance. Many SoCs, though, are designed with accelerators tailored for the domain -- such as signal processing --  in which they’ll be used: Domain-Specific SoCs. As SoC platforms become ever-more heterogeneous, we think that application developers shouldn’t need to waste time reading datasheets or APIs for SoC-specific kernel extensions just to take full advantage of their hardware. With this in mind, in this talk we will discuss strategies we are using to automate mapping of LLVM-compatible languages to heterogeneous platforms with no intervention (not even #pragmas) from the programmer.<\/p>\n\n<p>To this end, we present our prototype of a software stack that seeks to address both of these needs. To meet the first need, we developed an LLVM-based hybrid compile/run-time toolchain to extract the semantic operations being performed in a given application. With these semantic operations extracted, we can link in additional libraries that enable dispatch of certain kernels (such as a Fast Fourier Transform) to accelerators on the SoC without user intervention. To evaluate the functionality of this toolchain, we developed a runtime system built on top of QEMU+Linux that includes scheduling and task dispatch capabilities targeting hypothetical SoC configurations. This enables behavioral modeling of these accelerators before silicon (or even FPGA) implementations are available.  The focus here will be on the LLVM-mapping aspects, but a brief overview of our SoC simulation environment will be presented as well.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7026",
            "value": "Joshua Mack"
          },
          {
            "_id": "7402",
            "value": "Nirmal Kumbhare"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9966.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10158",
        "start": "17:45",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "llvm_hpvm",
        "title": "HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems",
        "subtitle": [],
        "track": "LLVM",
        "type": "devroom",
        "language": [],
        "abstract": "<p>TITLE: HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems<\/p>\n\n<p>SPEAKER: Vikram Adve, University of Illinois at Urbana-Champaign<\/p>\n\n<p>Abstract:<\/p>\n\n<p>We will present a detailed description of HPVM, an extension to LLVM for\ncompiling to heterogeneous parallel systems.  HPVM aims to make it much\neasier to develop compilers for diverse parallel hardware, and to implement\nparallel languages (including domain-specific languages) for such hardware.\nWe will briefly describe at a high-level the key parallel abstraction of\nhierarchical dataflow graphs used in HPVM, and then focus on on how HPVM is\nintegrated on top of LLVM.  A second part of the talk will briefly describe\nhow we are extending HPVM to enable greater energy efficiency and\nperformance by taking advantage of <em>approximation<\/em> opportunities in\napplication domains such as machine learning and image processing.  To\nconclude, I will briefly discuss how HPVM might be added as a dialect in\nMLIR so that other MLIR dialects and MLIR-based compilers can use HPVM for\ncode generation to diverse heterogeneous hardware targets, including GPUs,\nFPGAs, and custom accelerators.<\/p>",
        "description": "<p>TITLE: HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems<\/p>\n\n<p>SPEAKER: Vikram Adve, University of Illinois at Urbana-Champaign<\/p>\n\n<p>Background<\/p>\n\n<p>LLVM has been extraordinarily successful as a compiler infrastructure for\nenabling a wide range of compilers and compiler-based tools for scalar and\nvector processors, and for supporting GPU compilers for OpenCL and CUDA.\nLLVM has seen only limited use, however, for other classes of target\narchitectures, such as reconfigurable hardware (FPGAs) and domain-specific\naccelerators such as for machine learning, image processing, signal\nprocessing, graph processing, and other emerging domains.  More generally,\nheterogeneous system-on-chip (SoC) architectures are becoming increasingly\nimportant, especially in \"edge computing,\" but LLVM has largely been\nlimited to the host CPU and GPU on such SoCs, even though the number of\nother programmable components on these systems has been steadily increasing.<\/p>\n\n<p>Overview<\/p>\n\n<p>In this talk, I will describe an extension of LLVM for developing a compiler\ninfrastructure -- Heterogeneous Parallel Virtual Machine, or HPVM -- for\nheterogeneous parallel systems [1].  I will briefly describe at a high-level\nthe key parallel abstraction of hierarchical dataflow graphs used in HPVM to\ndescribe heterogeneous parallelism, where ordinary LLVM code is used to\nrepresent the computatational tasks.  The main focus of this part of the\ntalk is how HPVM is integrated on top of LLVM.  First, HPVM has been\nimplemented as a set of intrinsic functions that extend the LLVM\ninfrastructure.  Second, the HPVM code generation framework reuses existing\nLLVM (and other) back-ends, in order to leverage existing (often well-tuned)\ncode generators for individual programmable hardware elements, such as NVPTX\nfor NVIDIA GPUs, Intel's SPIR-V code generator for Intel SSE and AVX vector\nhardware, and Altera's AOCL compiler for targeting Altera's FPGAs.<\/p>\n\n<p>A second part of the talk will briefly describe how we are extending\nHPVM to enable greater energy efficiency and performance by taking\nadvantage of <em>approximation<\/em> opportunities in application domains such\nas machine learning and image processing.  In particular, we are\ncurrently developing ApproxHPVM, an extension of HPVM that supports a\nrange of algorithmic and hardware-level approximation mechanisms [2].\nMoreover, ApproxHPVM only requires application programmers to specify\nhigh-level, \"end-to-end\" design goals such as the maximum allowable\naccuracy loss in a neural network or loss of image quality (e.g.,\nPSNR) and the system automatically selects, optimizes and maps\napproximation choices for individual coarse-grain tensor operations in\nthe application.  The goal is to make sophisticated and well-tested\napproximation techniques widely accessible to application developers.<\/p>\n\n<p>To conclude, I will briefly discuss how HPVM and ApproxHPVM might be added\nas a dialect in MLIR so that other MLIR dialects and MLIR-based compilers\ncan use HPVM for diverse heterogeneous hardware targets, including GPUs,\nFPGAs, and custom accelerators.<\/p>\n\n<p>Target Audience<\/p>\n\n<p>The intended target audience for this talk falls into broadly two classes.\nThe first includes compiler practitioners and researchers interested in\ncompiling to heterogeneous systems, such as SoCs, FPGAs, and other\n\"edge-compute\" hardware.  The second includes language implementers\ninterested in implementing or porting domain-specific languages such as\nTensorFlow, Halide, SPIRAL, and others to heterogeneous parallel systems.<\/p>\n\n<p>Takeaways<\/p>\n\n<p>We envision several takeaways for the audience: (1) Understand how to\ndevelop an extension of LLVM that makes it easier to target emerging\nhardware platforms not sufficiently well-supported by the existing LLVM IR\nand code generation framework. (2) Expose attendees to the opportunities and\nchallenges in supporting and reasoning about approximate computations in a\ncompiler framework. (3) Discuss the opportunities and limitations of using\nHPVM for supporting heterogeneous parallel systems in the context of MLIR.<\/p>\n\n<p>Web Site and Software Availability<\/p>\n\n<p>More information about HPVM is available at http://hpvm.cs.illinois.edu/.\nThe HPVM infrastructure is implemented as an extension to LLVM.  To date,\nthe software is being developed using an internal Git repository at Illinois\nand has been shared with collaborators at IBM and at Harvard University.\nWe will make it available publicly in open-source form on Github before the\nFOSDEM conference.<\/p>\n\n<p>REFERENCES<\/p>\n\n<p>[1] Maria Kotsifakou, Prakalp Srivastava, Matthew D. Sinclair,\nRakesh Komuravelli, Vikram S. Adve and Sarita V. Adve, “HPVM:\nHeterogeneous Parallel Virtual Machine.” Proceedings of Principles and\nPractice of Parallel Programming (PPoPP), Feb 2018, Vösendorf / Wien,\nAustria.<\/p>\n\n<p>[2] Hashim Sharif, Prakalp Srivastava, Mohammed Huzaifa, Maria\nKotsifakou, Yasmin Sarita, Nathan Zhou, Keyur Joshi, Vikram S. Adve,\nSasa Misailovic and Sarita V. Adve, “ApproxHPVM: A Portable Compiler\nIR for Accuracy-aware Optimizations,” OOPSLA 2019, October 2019,\nAthens, Greece.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7116",
            "value": "Vikram Adve"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10158.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.4.401",
    "event":
    [
      {
        "_id": "10389",
        "start": "11:00",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "kms_planes",
        "title": "libliftoff status update",
        "subtitle": "Taking advantage of KMS planes",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will explain some basics about KMS, introduce libliftoff, describe the library's current status and outline the next steps.<\/p>",
        "description": "<p>Many DRM drivers have been exposing overlay planes for quite some time. Overlay planes can improve battery consumption by scanning out directly client buffers, skipping composition. While Wayland compositors and the X server usually take advantage of the cursor plane (and sometimes are able to use the primary plane to directly scan out a client's buffer), overlay planes are under-used. The exception is Weston, which tries to use overlay planes. Other compositors ignore them.<\/p>\n\n<p>The main challenge is to figure out how to assign buffers coming from clients to hardware planes. The only API exposed by KMS is atomic test commits, so user-space needs to try different combinations. It would be nice to have a common library shared between compositors to de-duplicate the work.<\/p>\n\n<p>During the XDC 2019 conference we discussed about <a href=\"https://github.com/emersion/libliftoff\">libliftoff<\/a>, an attempt at designing such a library. Feedback was positive from both compositor writers and driver developers. We discussed about the API, the potential pitfalls and future goals. The scope of the library has been expanded: libliftoff could also provide some feedback to clients so that they allocate buffers suitable for hardware planes. Additionally, because the KMS API makes it tricky to find the best way to make use of hardware planes, libliftoff could grow some vendor-specific plugins.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6347",
            "value": "Simon Ser"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/emersion/libliftoff",
            "value": "libliftoff repository"
          },
          {
            "_href": "https://emersion.fr/blog/2019/xdc2019-wrap-up/#libliftoff",
            "value": "XDC 2019 summary"
          },
          {
            "_href": "https://github.com/emersion/glider",
            "value": "glider repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10389.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10002",
        "start": "11:30",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "zink",
        "title": "Zink Update",
        "subtitle": "OpenGL on Vulkan upstream in mesa",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A short update on the state of Zink, and OpenGL implementation on top of vulkan, now that it's upstream in Mesa.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1639",
            "value": "Erik Faye-Lund"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10002.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10001",
        "start": "12:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "mesa3d_website",
        "title": "Modernizing mesa3d.org",
        "subtitle": "Let's bring mesa3d.org past web 1.0",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>mesa3d.org is stuck on web 1.0 technology, but let's see what we can do about it.<\/p>",
        "description": "<p>This is a Birds-Of-a-Feather session, which starts off with a short presentation as an introduction about the current state of affairs.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1639",
            "value": "Erik Faye-Lund"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10001.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9695",
        "start": "13:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "8k_display",
        "title": "Enabling 8K displays",
        "subtitle": "A story of 33M pixels, 2 CRTCs and no Tears!",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will cover enabling 8k display by tying 2 display pipelines together over 2 displayport connections.<\/p>",
        "description": "<p>Ever seen a true 33 million pixel 8K display? The maximum display link bandwidth available with DisplayPort’s highest bit rate of 8.1 Gbps/lane limits the resolution to 5K@60 over a single DP connector. Hence the only true 8K displays allowing up to full 60 frames per second are the tiled displays enabled using 2 DP connectors running at their highest bit rate across 2 CRTCs in the display graphics pipeline. Enabling tiled displays across dual CRTC dual connector configuration has always resulted in screen tearing artifacts due to synchronization issues between the two tiles and their vertical blanking interrupts.<\/p>\n\n<p>Transcoder port synchronization is a new feature supported on Intel’s Linux Graphics kernel driver for platforms starting Gen 11 that fixes the tearing issue on tiled displays. In this talk Manasi will explain how port synchronization is plumbed into the existing atomic KMS implementation. She will deep dive into the DRM and i915 code changes required to handle tiled atomic modesets through master and slave CRTCs lockstep mode operation to enable tearfree 8K display output across 2 CRTCs and 2 ports in the graphics pipeline. She will conclude by showing the 8K display results using Intel GPU Tools test suite.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5238",
            "value": "Manasi Navare"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9695.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9606",
        "start": "14:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "openxr",
        "title": "FOSS Virtual & Augmented Reality",
        "subtitle": "The Monado project & OpenXR",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk will cover Monado and Khronos' OpenXR standard, and give an overview about the current state of open source VR and what lies ahead. Also go into some details of how tracking is done inside of Monado and show of the current state.<\/p>",
        "description": "<p>VR took off for the consumer with the release of Oculus consumer hardware. But the hardware lacked open source drivers and Linux support in general. The consumer VR space has now grown from a kickstarter campaign into a large industry. But this growth has its down sides, multiple companies have their own APIs competing. Luckily these companies have agreed to work on a single API under the Khronos umbrella. Now that OpenXR has been released and and the Monado project has been getting more stable it is now possible to do good VR on a completely open stack.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5151",
            "value": "Jakob Bornecrantz"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9606.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9067",
        "start": "15:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "fbdev",
        "title": "Back to the Linux Framebuffer!",
        "subtitle": "Linux Framebuffer support in free software",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Although KMS/DRM can replace the Linux Framebuffer, there are a number of programs and libraries that can be built on top of the Linux Framebuffer (without X11 or Wayland dependencies) and that might still be worth considering. The Linux Framebuffer allows direct access to pixels: we will illustrate it with various rendering tools (Fbpad, Fbi, NetSurf, MPlayer, ...), but also with drawing libraries such as Cairo or Evas, and multimedia frameworks like FFmpeg or GStreamer.\nThe Mesa 3D project makes OpenGL rendering possible using only the Linux Framebuffer with GLFBDev or EGL: mesa-demos and yagears programs will be shown.\nWe will then cover graphics libraries (GLUT, SDL, EFL, GTK, Qt) that allow to integrate high level applications running directly on top of the Linux Framebuffer with no compositor. An example will be described using either WebKitGTK or QtWebKit for the rendering of a HTML5 media player and a WebGL sample, using the Linux Framebuffer port of those libraries and toolkits.\nThis talk is inspired by the HiGFXback project which aims at preserving historical backends used for graphics on GNU/Linux systems.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6436",
            "value": "Nicolas Caramelli"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/caramelli/higfxback/wiki/Linux-Framebuffer",
            "value": "HiGFXback with the Linux Framebuffer"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9067.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9525",
        "start": "16:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "ttm",
        "title": "The TTM memory manager",
        "subtitle": "A general overview and an update on graphics memory  management in the kernel",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>TTM is the memory manager in the Linux kernel used by graphics drivers with dedicated VRAM.<\/p>\n\n<p>It was added to the mainline kernel in June 2009 and has seen numerous changes and we are now more or less running into a dead-end with it's design.<\/p>\n\n<p>This talk outlines TTMs current functionality, what design problems we ran into and what can we do to fix this.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6770",
            "value": "Christian König"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9525.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9640",
        "start": "17:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "gpu_patterns",
        "title": "Pattern Based Code Generation for GPUs",
        "subtitle": [],
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Automatic, pattern-based code generation for Mesa's compiler infrastructure has been a long standing dream. Nearly a decade ago experiments were conducted using systems like BURS and lburg. Each of these attempts encountered various insurmountable road blocks. In the intervening years, both software and GPU architectures have changed significantly. These changes have enabled a code-generator generator to be a reality. The design and implementation of one system will be presented. In addition to the successes, various difficulties and rough edges will be detailed.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3306",
            "value": "Ian Romanick"
          }
        },
        "links":
        [
          {
            "_href": "https://gitlab.freedesktop.org/mesa/mesa/merge_requests/2680",
            "value": "Merge request for the code-generator generator."
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9640.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9727",
        "start": "18:00",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "rpi4_vulkan",
        "title": "A Vulkan driver for the RPI4",
        "subtitle": "A lesson in futility",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For the Raspberry PI 4 I started implementing a Vulkan driver. This talk will give a guide of how to approach such a task, what my expectations are and what I learned so far.<\/p>",
        "description": "<p>With the release of Raspberry PI 4 it becomes theoretically more viable to use it in GPU heavy scenarios. Even ordinary software like Gnome Shell, Chromium and games fall into that category.\nSadly, neither Broadcom nor Raspberry PI Foundation currently provide a Vulkan driver. Since I want as much performance (and little overheating) as possible, I started writing a Vulkan driver.\nThis entails learning kernel and mesa internals as well as trying to understand Gallium. All that I have learned so far, I will try to share in this talk.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6921",
            "value": "Andreas Bergmeier"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/abergmeier/mesa-vulkan-broadcom",
            "value": "Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9727.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10765",
        "start": "18:30",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "libratbag",
        "title": "libratbag",
        "subtitle": "A way to configure your input devices",
        "track": "Graphics",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will give an update on the progress being done in libratbag as well as present the new projects we have planned. If there's time I will also show how you should be able to write your own driver and debug existing drivers. This is a talk about libratbag updates, planned projects and a code demo.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6486",
            "value": "Filipe Laíns"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/libratbag/libratbag",
            "value": "https://github.com/libratbag/libratbag"
          },
          {
            "_href": "https://github.com/libratbag/piper",
            "value": "https://github.com/libratbag/piper"
          },
          {
            "_href": "https://github.com/libratbag/ratbag-emu",
            "value": "https://github.com/libratbag/ratbag-emu"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10765.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.4.601",
    "event":
    [
      {
        "_id": "9228",
        "start": "10:30",
        "duration": "00:10",
        "room": "K.4.601",
        "slug": "intro",
        "title": "Openning",
        "subtitle": [],
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>abstract<\/p>",
        "description": "<p>description<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1138",
            "value": "Vasily A. Sartakov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9228.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9478",
        "start": "10:40",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "cosmix",
        "title": "Introduction to the CoSMIX Compiler",
        "subtitle": "Compiler-based techniques for secure memory instrumentation in enclaves",
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Hardware secure enclaves are increasingly used to run complex applications. Unfortunately, existing and emerging en- clave architectures do not allow secure and efficient implementation of custom page fault handlers. This limitation impedes in-enclave use of secure memory-mapped files and prevents extensions of the application memory layer commonly used in untrusted systems, such as transparent memory compression or access to remote memory.\nCoSMIX is a Compiler-based system for Secure Memory Instrumentation and eXecution of applications in secure enclaves. A novel memory store abstraction allows the implementation of application-level secure page fault handlers that are invoked by a lightweight enclave runtime. The CoSMIX compiler instruments the application memory accesses to use one or more memory stores, guided by a global instrumentation policy or code annotations without changing application code.\nThe CoSMIX prototype runs on Intel SGX and is compatible with popular SGX execution environments, including SCONE and Graphene. Our evaluation of several production applications shows how CoSMIX improves their security and performance by recompiling them with appropriate memory stores. For example, unmodified Redis and Memcached key-value stores achieve about 2× speedup by using a self-paging memory store while working on datasets up to 6× larger than the enclave’s secure memory. Similarly, annotating a single line of code in a biometric verification server changes it to store its sensitive data in Oblivious RAM and makes it resilient against SGX side-channel attacks.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6750",
            "value": "Yan Michalevsky"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9478.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9248",
        "start": "11:15",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "rustsgx",
        "title": "Be secure with Rust & Intel SGX",
        "subtitle": [],
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Intel Software Guard Extensions (SGX) makes software secure from the outside. Rust makes it secure from the inside. This workshop will introduce you to Rust and the Fortanix® Enclave Development Platform (EDP) for Rust: how it works, what you can do with it, and why Rust is such a good fit for SGX.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6574",
            "value": "Jethro G. Beekman"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9248.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10330",
        "start": "11:50",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "ccf",
        "title": "The Confidential Consortium Framework",
        "subtitle": "A framework to build secure, highly available, and performant applications that focus on multi-party compute and data",
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Confidential Consortium Framework is an open-source framework for building permissioned confidential multi-party services. It leverages hardware trusted execution environments to provide strong confidentiality, integrity, and high performance. CCF implements consortium-based programmable and auditable governance mechanism.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7200",
            "value": "Amaury Chamayou"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/Microsoft/CCF",
            "value": "Source repository"
          },
          {
            "_href": "https://microsoft.github.io/CCF/",
            "value": "Documentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10330.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10636",
        "start": "12:25",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "eactors",
        "title": "EActors: an actor-based programming framework for Intel SGX",
        "subtitle": [],
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I will present EActors, an actor framework that is tailored to SGX and offers a more seamless, flexible and efficient use of trusted execution – especially for applications demanding multiple enclaves. EActors disentangles the interaction with enclaves and, among them, from costly execution mode transitions. It features lightweight fine-grained parallelism based on the concept of actors, thereby avoiding costly SGX SDK provided synchronisation constructs. Finally, EActors offers a high degree of freedom to execute actors, either untrusted or trusted, depending on security requirements and performance demands.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1138",
            "value": "Vasily A. Sartakov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10636.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10293",
        "start": "13:00",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "tale",
        "title": "A Tale of Two Worlds: Assessing the Vulnerability of Enclave Shielding Runtimes",
        "subtitle": [],
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk analyzes the vulnerability space arising in Trusted\nExecution Environments (TEEs) when interfacing a trusted enclave\napplication with untrusted, potentially malicious code. Considerable\nresearch and industry effort has gone into developing TEE runtime\nlibraries with the purpose of transparently shielding enclave\napplication code from an adversarial environment. However, our analysis\nreveals that shielding requirements are generally not well-understood in\nreal-world TEE runtime implementations. We expose several sanitization\nvulnerabilities at the level of the Application Binary Interface (ABI)\nand the Application Programming Interface (API) that can lead to\nexploitable memory safety and side-channel vulnerabilities in the\ncompiled enclave. Mitigation of these vulnerabilities is not as simple\nas ensuring that pointers are outside enclave memory. In fact, we\ndemonstrate that state-of-the-art mitigation techniques such as Intel’s\nedger8r, Microsoft’s “deep copy marshalling”, or even memory-safe\nlanguages like Rust fail to fully eliminate this attack surface. Our\nanalysis reveals 35 enclave interface sanitization vulnerabilities in 8\nmajor open-source shielding frameworks for Intel SGX, RISC-V, and Sancus\nTEEs. We practically exploit these vulnerabilities in several attack\nscenarios to leak secret keys from the enclave or enable remote code\nreuse. We have responsibly disclosed our findings, leading to 5\ndesignated CVE records and numerous security patches in the vulnerable\nopen-source projects, including the Intel SGX-SDK, Microsoft Open\nEnclave, Google Asylo, and the Rust compiler.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6115",
            "value": "Jo Van Bulck"
          }
        },
        "links":
        [
          {
            "_href": "https://www.zdnet.com/article/manual-code-review-finds-35-vulnerabilities-in-8-enclave-sdks/",
            "value": "https://www.zdnet.com/article/manual-code-review-finds-35-vulnerabilities-in-8-enclave-sdks/"
          },
          {
            "_href": "https://people.cs.kuleuven.be/~jo.vanbulck/ccs19-tale.pdf",
            "value": "https://people.cs.kuleuven.be/~jo.vanbulck/ccs19-tale.pdf"
          },
          {
            "_href": "https://people.cs.kuleuven.be/~jo.vanbulck/ccs19-slides.pdf",
            "value": "https://people.cs.kuleuven.be/~jo.vanbulck/ccs19-slides.pdf"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10293.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10604",
        "start": "13:35",
        "duration": "00:30",
        "room": "K.4.601",
        "slug": "optee",
        "title": "HOWTO build a product with OP-TEE",
        "subtitle": [],
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OP-TEE is an open source implementation of the GPD TEE specifications. However deploying OP-TEE inside\na real world product requires more than just the integration into the system, since the integrator needs\nto ensure that all security requirements are met. This talk will outline a common set of these requirements\nand show the necessary changes based on NXP i.MX6 platforms.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7325",
            "value": "Rouven Czerwinski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10604.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10635",
        "start": "14:10",
        "duration": "00:20",
        "room": "K.4.601",
        "slug": "sgxlkl",
        "title": "Demo: SGX-LKL",
        "subtitle": "Running unmodified Linux applications inside Intel SGX's enclaves",
        "track": "Hardware-aided Trusted Computing",
        "type": "devroom",
        "language": [],
        "abstract": "<p>SGX-LKL is a library OS designed to run unmodified Linux binaries inside SGX enclaves. It uses the Linux Kernel Library (LKL) and a modified version of musl to provide system support for complex applications within the enclave.  SGX-LKL has support for in-enclave user-level threading, signal handling, and paging. This demo presents an overview of SGX-LKL and demonstrates how popular applications can be ported and executed within SGX-LKL.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7339",
            "value": "Thiago Zagatti"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10635.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10411",
        "start": "15:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_osuat",
        "title": "Open source UEFI and TianoCore",
        "subtitle": [],
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Historically, the UEFI forum has been a bit rubbish at interacting with open source development, but this is improving.<\/p>\n\n<p>This talk gives a background on <em>why<\/em> (both the rubbish and the improvement) and what is being done.<\/p>\n\n<p>Also, a brief update on news for the TianoCore/EDK2 project.<\/p>",
        "description": "<p>After much lawyerly fun, the UEFI Self-Certification Testsuite (SCT) was released under an OSI license (BSD2) at the end of 2018.\nWe will explain why this is useful, and how this has helped with the addition of UEFI support in U-Boot, as well as helped improving EDK2 code quality.<\/p>\n\n<p>We have a new process, referred to as \"code first\" for drafting changes to the UEFI spefication in public.\nThis will give an overview of the process, as well as one of the first exercises of it - the definition of audio APIs (for accessibility or, you know, DOOM).<\/p>\n\n<p>Also, an update on changes in the EDK2 reference implementation, including dropping the CLA and upcoming RISC-V support.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1936",
            "value": "Leif Lindholm"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10411.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10192",
        "start": "15:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_duwu",
        "title": "Discover UEFI with U-Boot",
        "subtitle": [],
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Unified Extensible Firmware Interface (UEFI) is the default for booting most Linux and BSD distributions. But the complexity of the UEFI standard does not offer an easy entry point for new developers. The U-Boot firmware provides a lightweight UEFI implementation. Using booting from iSCSI with U-Boot and iPXE as an example let's delve into the UEFI API.<\/p>\n\n<p>The UEFI sub-system in U-Boot has developed from barely starting GRUB to supporting complex UEFI applications like iPXE and the EFI shell and passing most of the UEFI compliance tests for the implemented protocols and services.<\/p>\n\n<p>The session gives an overview of the boottime and runtime services of UEFI with a focus on driver binding. The challenges of integrating the UEFI subsystem with U-Boot's infrastructure are described and an outlook is provided.<\/p>\n\n<p>Questions this talk should answer:\n- How does the UEFI driver model work?\n- How does this integrate with U-Boot?\n- What to expect next in U-Boot's UEFI implementation?<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4537",
            "value": "Heinrich Schuchardt"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10192.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10524",
        "start": "16:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_hodorateatria",
        "title": "Heads OEM device ownership/reownership : A tamper evident approach to remote integrity attestation",
        "subtitle": "Current status and future plan : A call for collaboration",
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Insurgo had engaged itself in the adventure of facilitating security accessibility and received NlNet funding to do exactly that. Now it wants to get developers involved and expand funding.<\/p>\n\n<p>The goal of this is to bridge the gap between reasonably secure OS (QubesOS) and slightly more secure hardware (Heads) to help privacy-focused users and those that are vulnerable. But we need to prepare for the future now!<\/p>\n\n<p>Insurgo has challenged the status quo that has been prevalent since 2015 and has made it possible for OEMs to preinstall QubesOS, thanks to the Heads Open Source Firmware (OSF) and his own PrivacyBeast QubesOS certified branch, not yet merged upstream, due to the lack of time and resources of a single man effort needing additional collaboration.<\/p>\n\n<p>The integrity of the firmware and boot files is already remotely sealed and can be attested over smartphone (TPMTOTP) and from the bundled Librem Keys/Nitrokey Pro 2 (HOTP), prior to shipping. Thanks to HOTP-enabled USB security dongles bounded to shipped products, the user can visually validate that the hardware they've received is in OEM attested state, prior to complete reownership which is regenerating all required secrets from a trustable recovery environment (Heads OSF) thanks to a re-ownership wizard that guides the user until completion.<\/p>\n\n<p>This is just the beginning of the adventure and the road ahead requires your help. Insurgo wants to propel this movement forward.<\/p>\n\n<p>Today's secure hardware (REAL open source initialized hardware, eg. the RYF KGPE-D16, replicant supported phones, Sandy bridge/Ivy bridge based boards, eg. x230) struggle to stay current with upstream code and compliance requirements. LineageOS dropped support of the i9300. Coreboot dropped support of the KGPE-D16 platform. And the list will expand if no measures are taken to support maintainership of privacy focused projects that are taken for granted until support is finally dropped. This is a real problem requiring real solutions.<\/p>\n\n<p>New efforts to support future, REAL Open Source Hardware (newly Respect Your Freedom [RYF] certified hardware, eg. Talos II from RaptorEngineering, future Power10 based hardware) are neither currently under active development nor currently supported by QubesOS. This needs to change. Now.<\/p>\n\n<p>There is an opportunity for transition. This requires leadership, developers and funding.\nThis is why we've created the Insurgo Initiative on the OpenCollective platform.<\/p>\n\n<p>This is where transparent funding will be available to the public for open source R&amp;D. Please consider participating through code contributions!<\/p>",
        "description": "<p>Insurgo is making today's most trustworthy hardware available (TRUELY Neutered+Deactivated Intel ME, no FSP, no binary blobs whatsoever but EC firmware in the Root of Trust) to the masses through remote attestation over Heads OSF.<\/p>\n\n<p>NlNet is helping Heads to be compatible on the T530, T430, T420 and X220, which are widely available, binary blob-free hardware platforms, thanks to a partnership with 9element under NlNet grant.\nNlNet funds is also permitting development of remote administration of QubesOS over tor hidden services when needed, thanks to an ongoing partnership with both the Qubes OS Project &amp; Whonix.<\/p>\n\n<p>But what about other work needed to ease accessibility of tomorrow's secure hardware and technologies?<\/p>\n\n<p>Insurgo decided to give back to Open Source Firmware (OSF) related communities and will publicly announce novel approach to support required open source projects.\nIn premiere, we plan to give back 25% of Insurgo's net profit on sales to the Insurgo Initiative, hosted on OpenCollective.<\/p>\n\n<p>Those funds will be available to Open Source projects in the form of bounties, to be paid out upon proof of work of agreed contributions.<\/p>\n\n<p>The idea here is that open source tickets (issues) can be used as bounties and if knowledgeable people knew funds were available for needed work, they'd be more incentivized to address them.\nDevelopers could then be rewarded for their efforts and paid for completing tasks similiar to how Open Source Funds (OpenTech, NlNet, etc) provides funds for larger projects.<\/p>\n\n<p>The Insurgo Initiative will be self funded and potentially expanded through international partnerships, while the goal stays the same: supporting a future where security is more accessible to the public.<\/p>\n\n<p>Here are some projects needing additional funding and more developer awareness, right now. Big funds and grant application are great. But the funding process has issues.\nNot every developer wants to go through the application process, which requires management skills and requires a process that is not just about coding.\nThere are awesome developers out there whose help would be greatly needed.<\/p>\n\n<p>How do we appropriately match developers with pertinent issues? We can fix this with the right mission and funding.\nInsurgo's mission is for accessible security.<\/p>\n\n<p>Bounty tags are being added to projects that lack the funding and to help address the current problems they face for completion:\n-   PPC64le QubesOS support for upcoming Power10 laptop and Talos II RYF hardware: https://github.com/QubesOS/qubes-issues/issues/4318#issuecomment-547487583\n-   Heads needs more community developers and maintainers: https://github.com/osresearch/heads/issues\n-   QubesOS bounty tagged issues: https://github.com/QubesOS/qubes-issues/labels/bounty\n-   Whonix needs more collaborators or it might die: https://forums.whonix.org/t/focus-on-whonix-core-development/5036<\/p>\n\n<p>The main problem we seem to face with many projects can be seen over and over again: a lack of maintainership.<\/p>\n\n<p>No one can carry on a project for too long without becoming overwhelmed/drained by it.\nWe need to fairly distribute this work and make sure contributions are incentivized and fairly paid.<\/p>\n\n<p>In this talk, I will go quickly over past work. The current situation. And where Insurgo wants to go.<\/p>\n\n<p>Welcome aboard!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7253",
            "value": "Thierry Laurion"
          }
        },
        "links":
        [
          {
            "_href": "https://insurgo.ca/",
            "value": "Insurgo Open Technologies Website"
          },
          {
            "_href": "https://www.qubes-os.org/doc/certified-hardware/",
            "value": "Insurgo's PrivacyBeast QubesOS Certified hardware"
          },
          {
            "_href": "https://www.platformsecuritysummit.com/2019/#laurion",
            "value": "PlatformSecurity2019 given talk"
          },
          {
            "_href": "https://nlnet.nl/project/AccessibleSecurity/",
            "value": "NlNet funded Accessible Security Project"
          },
          {
            "_href": "https://gitlab.com/tlaurion/heads/tree/PrivacyBeast_X230_QubesOS_Certified",
            "value": "GitLabCI PrivacyBeast X230 branch"
          },
          {
            "_href": "https://github.com/tlaurion/",
            "value": "Github profile"
          },
          {
            "_href": "https://www.linkedin.com/in/thierry-laurion-40b4128/",
            "value": "LinkedIn profile"
          },
          {
            "_href": "https://twitter.com/Tlaurion",
            "value": "Twitter profile"
          },
          {
            "_href": "https://www.facebook.com/InsurgoTech/",
            "value": "Facebook page"
          },
          {
            "_href": "https://github.com/osresearch/heads",
            "value": "Heads project Github Page"
          },
          {
            "_href": "https://github.com/osresearch/heads-wiki/",
            "value": "Heads-wiki project page"
          },
          {
            "_href": "https://archive.org/details/oemuserreownership",
            "value": "Re-ownership wizard technology preview"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10524.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10450",
        "start": "16:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_itsoecs",
        "title": "Improving the Security of Edge Computing Services",
        "subtitle": "Update status of the support for AMD processors",
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For the last several years, hypervisors have played a key role in platform\nsecurity by reducing the possible attack surface. At the same time, the hype\nsurrounding computing and Internet of Things Gateways has led to an increase in\nnetwork appliance devices. Our target was to create a less-insecure virtual\nnetwork appliance using TrenchBoot, Trusted Platform Module 2.0 and AMD SKINIT\nDynamic Root of Trust for Measurement to establish a Xen hypervisor with a\nmeta-virtualized pfSense firewall. We are going to present it with an update\nof the status of support of TrenchBoot for AMD processors.\nThis appliance is supported by are supported by apu2, a reliable low-SWaP x86\ndevice from Swiss OEM PC Engines. It can be used as a Single Office / Home\nOffice firewall or an industrial edge device and has mostly open-source\nhardware, coreboot firmware, mPCIe extensibility and an extended support\nlifecycle for the embedded Central Processing Unit and motherboard.\nIn this talk, we will show how to create a system, which enables a significant\nportion of computations to the edge devices while maintaining security. Using\na simple, well-known platform, we will conduct a secure boot using the Static\nRoot of Trust for Measurement with coreboot, move to the Dynamic Root of Trust\nfor Measurement by SKINIT in TrenchBoot and use all of this to provide a\ncomplete chain of trust for the Xen hypervisor, a virtual firewall appliance\nisolated by an input–output memory management unit (IOMMU) from the physical\nnetwork interface controller (NIC) devices. We will present benchmark data\non virtualization overhead, explain how this complexity can still be practical\nand outline the value of this stack.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "5202",
            "value": "Daniel Kiper"
          },
          {
            "_id": "6960",
            "value": "Piotr Król"
          }
        ],
        "links":
        [
          {
            "_href": "https://3mdeb.com/",
            "value": "3mdeb site"
          },
          {
            "_href": "https://github.com/TrenchBoot",
            "value": "Trenchboot"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10450.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10327",
        "start": "17:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_ia",
        "title": "Introducing AUTOREV",
        "subtitle": "An automatic reverse-engineering framework for firmware BLOBs",
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Modern Open Source boot firmware ships with an increasing amount of BLOBs. While it's often claimed that it eases the integration,\nit makes life of Open Source developers harder, as it's not documented what is done inside BLOBs and what should be done outside of\nthe same.<\/p>\n\n<p>We will show how to trace the MMIO access of BLOBs in firmware by using Open Source tools. As analysing the traces for possible\nbranches and loops is hard and stressful work, we created our own framework for automatic reverse engineering.\nOur framework allows to capture and analyse MMIO traces, fuzz the BLOB under test and finally generates readable code in a high level language,\nlike C, for easy analysing.<\/p>\n\n<p>During this talk, we will discuss the legal side, the motivation behind reverse engineering, and the benefit for the Open Source community.\nWe will explain the problems we faced, and explain the basic concept used, with examples from the real world.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7138",
            "value": "Patrick Rudolph"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10327.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10416",
        "start": "17:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_lam",
        "title": "Look at ME!",
        "subtitle": "Intel ME firmware investigation",
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With Intel's Firmware Support Package (FSP) and the recent release of a\n<a href=\"https://edk2.groups.io/g/devel/message/50920\">redistributable firmware binary<\/a>\nfor the Management Engine, it has become possible to share full firmware images\nfor modern x86 platforms and potentially audit the binaries. Yet, reverse\nengineering, decompilation and disassembly are still not permitted. However,\nthanks to previous research, we can have a closer look at the binary data and\ncome to a few conclusions. This talk briefly summarizes the fundamentals of\ndeveloping custom and open source firmware, followed by a quick guide through\nthe process of analyzing the binaries without actually violating the terms to\nunderstand a few bits, and finally poses a statement on the political issues\nthat researchers, repair technicians and software developers are facing\nnowadays, taking into account how consumers are affected and how they perceive\nthe situtation eventually.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7248",
            "value": "Daniel Maslowski (CyReVolt)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10416.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10467",
        "start": "18:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_culisfu",
        "title": "Capsule Update & LVFS: Improving system firmware updates",
        "subtitle": "Improving reliability and security by simplifying distribution of firmware updates",
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As the rich capabilities of platforms increase, so does their complexity. As hypervisors and operating systems harden their attack surfaces, malware has been moving deeper into the platform. For example, a modern laptop may have over 15 updatable firmware elements, each with low-level access to a specific hardware domain. From the early days of proprietary BIOS in the 1980’s and 1990’s, to the world of standards in the 2000’s, to the post-PC world of the last few years, the nature of firmware has changed. In order to provide security guarantees for platform firmware, the servicing model of the platform takes center stage.<\/p>\n\n<p>This session discusses the evolution of platform servicing using examples based on device firmware, non-host/system on a chip (SOC) firmware, and implementation of the Unified Extensible Firmware Interface (UEFI). A modern servicing model features elements for component-based update, resiliency in case unexpected conditions, a more seamless user experience, lowering the friction of update integration, and telemetry for a view into platform health and firmware inventory.<\/p>\n\n<p>This talk will discuss current trends in standards such as UEFI and associated EDK II firmware, and how the Linux Vendor Firmware System (LVFS) used these components as part of a holistic, open source approach to seamless firmware updates.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5817",
            "value": "Brian Richardson"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10467.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10394",
        "start": "18:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "firmware_oisfbooe",
        "title": "Opening Intel Server firmware based on OpenBMC example",
        "subtitle": [],
        "track": "Open Source Firmware, BMC and Bootloader",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Have you ever heard of Board Management Controller? It has been black box firmware to manage servers since last century … now it’s open. OpenBMC is a  Linux Foundation project with a goal to produce an open source implementation of BMC firmware stack. It is a vendor independent Linux distribution created using Yocto project that provides complete set of manageability features. Backbone technologies in OpenBMC include D-Bus and systemd. With embedded web server it provides user friendly WebUI and Redfish interface for easy server management using modern RESTful APIs. Intel as one of the founding  companies offers additional functionalities on top of OpenBMC implementation which will be presented as a part of this presentation.<\/p>\n\n<p>In this talk we will:\n- tell you a short history and overview of OpenBMC\n- have a quick view on OpenBMC architecture (Yocto, Dbus, systemd)\n- show what’s new in latest 2.7 releases and what is planned for 2.8 (Feb 2020)\n- talk about Intel specific features available in OpenBMC\n- tell you how to contribute to OpenBMC project\n- give you a guide on how to modify, build and run the project on target BMC on Intel server<\/p>\n\n<p>Audience: software engineers, validation engineer, embedded software architects, data center administrators<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7233",
            "value": "Maciej Lawniczak"
          },
          {
            "_id": "7423",
            "value": "Przemyslaw Czarnowski"
          }
        ],
        "links":
        [
          {
            "_href": "https://github.com/openbmc",
            "value": "OpenBMC github repository"
          },
          {
            "_href": "https://www.openbmc.org/",
            "value": "OpenBMC web page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10394.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UA2.114 (Baudoux)",
    "event":
    [
      {
        "_id": "9349",
        "start": "10:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_threat_modelling_for_developers",
        "title": "Threat Modelling for Developers",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>What threats do we need to take into account when building a system? A key method for answering this question is an approach called threat modelling, whereby security problems can be anticipated during the design phase. This talk discusses major threat-modelling approaches, and includes concrete examples of how to apply them to software-intensive systems.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6658",
            "value": "Arne Padmos"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9349.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10280",
        "start": "11:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_osint",
        "title": "OSINT",
        "subtitle": "do you really know what data you are leaking to the public?",
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open source intelligence. That almost sounds like a technique described in a movie plot – purely fictional right ?\nAs it turns out, it is alarmingly much more simple than you may think and in some cases we walk the fine line between intelligence and creepy stalker-like activity.\nIn this talk we'll look at some examples, and discuss practical applications from an adversarial point of view. Hopefully you'll leave with an increased appreciation for the data you may be leaking to the world.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7173",
            "value": "David Busby"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10280.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10272",
        "start": "11:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_securing_existing_software_using_formally_verified_libraries",
        "title": "Securing Existing Software using Formally Verified Libraries",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Security vulnerabilities are still very common in todays software. Formal methods could improve the situation, but program verification remains a complex and time-consuming task. Often, the verification of existing software is infeasible and a complete rewrite can be prohibitively expensive. Both, however, is not necessarily required to improve on the current state. By replacing critical parts of an existing software by verified code, security can be strengthened significantly with moderate effort.<\/p>\n\n<p>We show the feasibility of this approach by the example of a FLOSS TLS implementation. The basis of our PoC is the TLS 1.3 library Fizz [1] which is written in C++. The existing message parser was replaced by a verified version implemented in the SPARK language [2]. Our RecordFlux toolkit [3] was used to automatically generate the parser based on a formal message specification. With the SPARK tools we can prove automatically that an attacker cannot cause any overflows, runtime errors or undefined state by sending malformed messages to the modified library. Because of mismatches in the data structures used in C++ and SPARK, some glue code had to be written manually to integrate the verified parser into Fizz. Still, the modified TLS implementation shows only a slight performance loss while providing higher security.<\/p>\n\n<p>[1] https://github.com/facebookincubator/fizz\n[2] https://www.adacore.com/about-spark\n[3] https://github.com/Componolit/RecordFlux<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6098",
            "value": "Tobias Reiher"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10272.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10390",
        "start": "12:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_specfuzz_bringing_spectre_type_vulnerabilities_to_the_surface",
        "title": "SpecFuzz: Bringing Spectre-type vulnerabilities to the surface",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Spectre-type attacks are a real threat to secure systems because a successful attack can undermine even an application that would be traditionally considered safe.\nSpecFuzz is the first tool that enables fuzzing for such vulnerabilities.<\/p>",
        "description": "<p>The key is a novel concept of speculation exposure:\nThe program is instrumented to simulate speculative execution in software by forcefully executing the code paths that could be triggered due to mispredictions, thereby making the speculative memory accesses visible to integrity checkers (e.g., AddressSanitizer).\nCombined with the conventional fuzzing techniques, speculation exposure enables more precise identification of potential vulnerabilities compared to state-of-the-art static analyzers.<\/p>\n\n<p>Technical report: https://arxiv.org/abs/1905.10311<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7211",
            "value": "Oleksii Oleksenko"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10390.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9182",
        "start": "12:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_falco_internals_101",
        "title": "Falco Internals 101 : Syscalls processing for security analysis",
        "subtitle": "What happens when you have: syscalls, a kernel module, an eBPF probe and a Ring Buffer?",
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Linux Syscalls can be used as an entrypoint to do security analysis on Linux. However reading and processing every system call in userspace creates a very unique set of challenges.\nIn this talk we are going to see exactly what those challenges are and how we solved them in the Falco project.<\/p>",
        "description": "<p>One of the ways to have broad visibility into our systems, when doing security analysis is to go and ask our questions directly to the Linux kernel.\nFor this purpose, at a very foundational level, in every Linux system we find the syscalls interface. It’s certain that every user space process goes through this part of the kernel.<\/p>\n\n<p>Starting with this assumption, the immediate conclusion is that we can just go and ask the syscalls “Yo syscalls! What’s happening in my system?”. While this reasoning might seem very simple, reading and processing every single syscall in userspace can result in a set of very unique challenges to this domain.<\/p>\n\n<p>In this talk we are going to see exactly what those challenges are and how we solved them in the Falco project.<\/p>\n\n<p>Part of the solution for Falco is to have two alternative drivers, a Kernel module and an eBPF driver talking to userspace using a Ring buffer but you have to come to this talk to hear the rest!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5502",
            "value": "Lorenzo Fontana"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9182.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10218",
        "start": "13:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_docker_security_considerations_incident_analysis",
        "title": "Docker Security considerations & Incident Analysis",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this presentation we take under consideration the increased use of Docker in corporate environments.\nIt is a fact that Docker has found wide spread of use during the past years, mostly because of it\nbeing very easy to use , economic w.r.t resources used, fast and easy to deploy when compared with\na full blown virtual machine. More and more servers are being operated as Docker hosts on which\nmicro-services run in containers. From a security point of view, two aspects of it arise in the\ncontext of this talk and the inherent time-limitations it has. Firstly, the aspect of the already\nquite talked-through question, “is it secure ?”.Secondly the less analyzed aspect of incident analysis\nand the changes introduced with respect  to known methods and evidence.In this presentation we will\nbriefly outline some security considerations about Docker and the average user and then we will try\nto examine how Docker introduces changes to the workflow related to incident analysis and forensics in its environment.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7111",
            "value": "John Lionis"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10218.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10370",
        "start": "13:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_incrementality_and_deck_functions",
        "title": "Incrementality and deck functions",
        "subtitle": "Simple protocols and efficient constructions in symmetric cryptography",
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Protocols in symmetric cryptography are often built from block ciphers, with a fixed input and output size, while variable sizes are handled through their modes of use. Incrementality, namely, the ability to efficiently compute the output for increasing inputs, or to request longer outputs, is often a property of the implementation rather than an explicit feature of a mode.<\/p>\n\n<p>A doubly-extendable cryptographic keyed (or deck) function is a new kind of object that makes incrementality an integral part of its definition. Writing modes for various applications, such as authenticated encryption of a network channel or disk encryption with a wide block cipher, on top of a deck function turns out to be a simple exercise and leads to less error-prone implementations than on top of a block cipher. We illustrate this with the session-supporting authenticated encryption modes SANE and SANSE. (Sessions naturally protect a continuous flow of messages or a client-server dialog.)<\/p>\n\n<p>While a deck function can be constructed from existing primitives, like a block cipher, we show two more natural ways of making a deck function in practice.<\/p>\n\n<ul>\n<li><p>The first one is based on the well-known permutation-based duplex construction, of which a nice instantiation is the <a href=\"https://strobe.sourceforge.io/\">Strobe protocol framework<\/a>. Strobe was showcased in <a href=\"https://www.discocrypto.com/\">Noise+Strobe=Disco<\/a> as an advantageous replacement to all kinds of primitives in the <a href=\"https://noiseprotocol.org/\">Noise protocol framework<\/a>, resulting in <a href=\"https://permutationbasedcrypto.org/2018/slides/David_Wong.pdf\">much simpler specifications and a lighter implementation<\/a>. Xoodyak, our candidate to the NIST Lightweight Cryptography competition, is another example.<\/p><\/li>\n<li><p>The second one is based on the recent Farfalle construction, which relies on the parallel application of a permutation. Farfalle's inherent parallelism yields deck functions that are at the same time simple and efficient on a wide range of platforms. In particular, we point out the nice performance of Kravatte and Xoofff, two deck functions based on the Keccak-p and the Xoodoo permutation, respectively. It is worth noting that Kravatte and Xoofff are much faster than AES-128 in software, and at least competitive with and often faster than AES-128 using dedicated AES instructions <a href=\"https://keccak.team/sw_performance.html\">on the more recent Intel and AMD processors<\/a>!<\/p><\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1105",
            "value": "Gilles Van Assche"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10370.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9895",
        "start": "14:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_how_transparent_data_encryption_is_built_in_mysql_and_percona_server",
        "title": "How Transparent Data Encryption is built in MySQL and Percona Server ?",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How Transparent Data Encryption is built in MySQL and Percona Server ?\n- keyrings – what are they used for ? What is the difference between using a server back-end (keyring<em>vault) versus file back-end (keyring<\/em>file). How it affects server startup and why? Why per server separation is needed in Vault Server?\n- How Master Key encryption works ? How it is build on page level ? How do we know which key we should fetch to decrypt a table ? How do we know that used key is the correct one ? How do we make sure that we can decrypt a table when we need it ?\n- What crypto algorithms are used ?\n- How Master Key rotation works ? Why is it needed ?\n- What is KEYRING encryption and what are encryption threads?\n- How binlog encryption works in 5.7 and how it works in 8.0 ?\n- How undo log/redo log encryption works ?<\/p>",
        "description": "<p>How Transparent Data Encryption is Built in MySQL and Percona Server ?<\/p>\n\n<p>In this presentation, we'll take a deep dive into the world of transparent data encryption for open source databases. We'll be looking at how transparent data encryption is implemented in MySQL and Percona Server for MySQL:\n- keyrings – what are they used for ? What is the difference between using a server back-end (keyring<em>vault) versus file back-end (keyring<\/em>file). How it affects server startup and why? Why per server separation is needed in Vault Server?\n- How Master Key encryption works ? How it is build on page level ? How do we know which key we should fetch to decrypt a table ? How do we know that used key is the correct one ? How do we make sure that we can decrypt a table when we need it ?\n- How Master Key rotation works ? Why is it needed ?\nBy the end of the talk, you'll have a better understanding of the transparent data encryption and will be aware of things to take into account when interacting with encrypted databases in your applications.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6989",
            "value": "Robert Golebiowski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9895.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10210",
        "start": "14:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_secure_logging_with_syslog_ng",
        "title": "Secure logging with syslog-ng",
        "subtitle": "Forward integrity and confidentiality of system logs",
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The design, implementation, and configuration of the secure logging service. Its aim is to provide tamper evident logging, i.e., to adequately protect log records of an information system against tampering and to provide a sensor indicating attack attempts. The secure logging service achieves this by authentically encrypting each log record with an individual cryptographic key used only once and protects integrity of the whole log archive by a cipher{based message authentication\ncode. Each attempt to tamper with either an individual log record or the log archive itself will be immediately detected during log archive verification. Therefore, an attacker can no longer tamper with log records without being detected which greatly enhances the use of log archives in forensic investigations.<\/p>",
        "description": "<p>Log records are normally produced by any information system in order to perform monitoring during normal operations and for troubleshooting in case of technical problems. Log information is equally important for retaining the security of an information system, as security relevant events are recorded and can later be monitored for unusual patterns which may indicate an attack attempt. Examples include log on and log off, startup and shutdown, network service access, network filter rule application, storage access, etc. Log records may also contain valuable information about a system that a potential attacker intends to compromise. If an attacker is able to successfully compromise a system, they are also able to tamper with log records, potentially hiding their traces. This makes forensic analysis extremely difficult, as no reliable data source about system behavior immediately before the attack is available to a security analyst performing incident investigation. Therefore, log information should be appropriately protected. The aim of the secure logging service is to provide tamper evident logging, i.e., to adequately protect log records of an information system and to provide a sensor indicating attack attempts. The secure logging service achieves this by authentically encrypting each log record with an individual cryptographic key used only once and protects integrity of the whole log archive by a cryptographic authentication code. Each attempt to tamper with either an individual log record or the log archive itself will be immediately detected during log archive verification. Therefore, an attacker can no longer tamper with log records\nwithout being detected. ost information systems rely on standards in order to provide logging services. One of the most widely adopted standards is the syslog protocol which is specified in RFC 5424. Many implementations of this\nprotocol are available. A popular extensible implementation with additional features is syslog-ng, which is an enhanced logging daemon with advanced features for input and output. Furthermore, it features capabilities for log message filtering, rewriting, and routing. It can be used as a drop-in replacement for existing log daemons on UNIX systems. The implementation of the secure logging service providing tamper evidence and confidentiality of system logs based on the template mechanism of syslog-ng is presented together with an application example.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6800",
            "value": "Stephan Marwedel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10210.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9444",
        "start": "15:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_protecting_plaintext_secrets_in_configuration_files",
        "title": "Protecting plaintext secrets in configuration files",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Applications and services rely on configuration data in order to be customized and we will talk about how to keep them in a safer place other than plaintext configuration files.<\/p>",
        "description": "<p>The configparser module is Python's standard configuration file parser and many projects rely on it to achieve easy configuration with plaintext files. OpenStack Common Libraries (Oslo) has an alternative called oslo.config with additional sources of input like command line arguments or environment variables. With the addition of a feature called source drivers last year, we are now able to increase the security of configuration values storing them in a safer place.<\/p>\n\n<p>This talk focuses on the new source driver that integrates Oslo.Config and Castellan, another Olso module specialized in talking to secret managers, and how we can store our sensitive configuration data using HashiCorp Vault.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5949",
            "value": "Moisés Guimarães"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9444.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10388",
        "start": "15:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_application_whitelisting_in_linux_environment",
        "title": "Application Whitelisting in Linux Environment",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Are you a sysadmin and feeling paranoid? Let's promote security hardening to another level.\nPerhaps, with the concept of Application Whitelisting you will be able to sleep again.<\/p>",
        "description": "<p>In this session we are going to explain the Application Whitelisting idea and its implementation, what benefits are there from a security point of view and how it differs from competitors.\nWe are going to show how to create a new set of rules based on distribution default for given examples.\nAs a result, an attendee should be able to setup the Application Whitelisting framework on his server or workstation.<\/p>\n\n<p>This presentation is based on Red Hat/Fedora Linux environment.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6813",
            "value": "Radovan Sroka"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/linux-application-whitelisting/fapolicyd",
            "value": "https://github.com/linux-application-whitelisting/fapolicyd"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10388.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10188",
        "start": "16:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_seccomp",
        "title": "seccomp — Your Next Layer of Defense",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Why should you allow all possible system calls from your application when you know that you only need some? If you have ever wondered the same then this is the right talk for you. We are covering:<\/p>\n\n<ul>\n<li>What is seccomp in a nutshell and where could you use it.<\/li>\n<li>Practical example with Elasticsearch and Beats.<\/li>\n<li>How to collect seccomp violations with Auditd.<\/li>\n<\/ul>\n\n\n<p>Because your security approach can always use an additional layer of protection.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4028",
            "value": "Philipp Krenn"
          }
        },
        "links":
        [
          {
            "_href": "https://xeraa.net/talks/seccomp-next-layer-defense/",
            "value": "Slides"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10188.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10585",
        "start": "16:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_kernel_runtime_security_instrumentation",
        "title": "Kernel Runtime Security Instrumentation",
        "subtitle": "LSM+BPF=KRSI",
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>KRSI (Kernel Runtime Security Instrumentation) is an ongoing effort at Google to upstream an LSM (Linux Security Module) instrumentable using eBPF (extended Berkeley Packet Filter) to the Linux kernel.<\/p>\n\n<p>KRSI allows system owners to dynamically attach eBPF programs to security hooks and write MAC and audit policies without having to reboot or patch the kernel thereby enabling a new class of system security and auditing software.<\/p>\n\n<p>This talk presents the main concepts behind KRSI: it introduces the technologies leveraged and presents the API exposed to users.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3601",
            "value": "Florent Revest"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10585.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9050",
        "start": "17:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_using_selinux_with_container_runtimes",
        "title": "Using SELinux with container runtimes",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Lukas Vrabec built a new standalone tool, udica, for generating SELinux policy profiles for containers based on automatic inspecting these containers. We will focus on why udica is needed in the container world and how it can make SELinux and containers work better together.  We will show real examples where SELinux separation for containers had to be turned off because the generic SELinux type container_t was too tight. With a tool like “udica”, users and developers can easily customize the policy with limited SELnux policy writing skills. Come to see how easy also you can create custom SELinux policy for your containers!<\/p>",
        "description": "<p>This talk will explain how SELinux works with containers.  We will show how to enable/disable SElinux using multiple different container runtimes and define the default types.  One issue with these types is that they are tough to customize.  The two default types for running containers are container<em>t which is a fully confined domain, which eliminates any use of the host files unless they are relabeled.  Or spc<\/em>t, which is the type containers run with when SELinux is disabled for container separation, --privileged mode.  As an example, If you had a container that you wanted to be able to gather the logs from /var/log on the host and send them to a centralized server, you have to disable SELinux separation.<\/p>\n\n<p>Writing custom policy for each container that needed additional access would be very difficult and require a container policy writer.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5476",
            "value": "Lukas Vrabec"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9050.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10535",
        "start": "17:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_the_hairy_issue_of_e2e_encryption_in_instant_messaging",
        "title": "The hairy issue of e2e encryption in instant messaging",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>End-to-end encryption is often regarded as the holy grail of security. But when you start implementing it soon becomes a security hell. Does it really protect against the threats it should protect against? And watch out for the pitfalls when implementing it: almost everybody fails there!<\/p>",
        "description": "<p>Lets start with the conclusion of this talk: after twenty years of designing and analyzing high security instant messaging systems, I came to the conclusion that end-to-end encryption (e2ee) in instant messaging is snake-oil. It creates a false sense of security.<\/p>\n\n<p>First of all the threat model underneath e2ee has fundamental flaws, it doesn’t deliver protection against the threats commonly named to justify it. And if that isn’t enough, there a lot of issues that make a proper implementation very hard to get right. To name a few: key verification, one-to-many messages, store and forward and archiving.<\/p>\n\n<p>But lets not end this talk all in black. Though we aren’t there yet, there are some developments that may solve these issues. I will name those too.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3348",
            "value": "Winfried Tilanus"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10535.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9865",
        "start": "18:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "security_what_you_most_likely_did_not_know_about_sudo",
        "title": "What you most likely did not know about sudo…",
        "subtitle": [],
        "track": "Security",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Everybody knows sudo, right? Sudo allows a system administrator to give certain users  the ability to run some commands as root, while logging the executed commands and their arguments. It is installed by default on almost all Linux systems, and is available for most commercial UNIX systems. Still, even system administrators often only know it is the “prefix” to use before entering a command requiring root privileges. Learn how much more this simple looking tool can do!<\/p>",
        "description": "<p>Everybody knows sudo, right? Sudo allows a system administrator to give certain users  the ability to run some commands as root, while logging the executed commands and their arguments. It is installed by default on almost all Linux systems, and is available for most commercial UNIX systems. Still, even system administrators often only know it is the “prefix” to use before entering a command requiring root privileges. Learn how much more this simple looking tool can do!\nMost of the times the default configuration allows a group of users to run any commands:\n%wheel  ALL=(ALL)   ALL\nIt’s a good first step, better than using the root account directly. This way you can trace who ran what commands on the system. But there are a lot more possibilities when configuring sudo, making your system more secure.\nLife is simple when when you have to give access a single user to a single command. But as soon as  you have multiple users with the same access rights, it is not just shorter but also easier to maintain, if you use aliases.\nFor added security, you can add a hash of binaries to sudo. This way if the binary changes for any reasons, like modifying it through a successful exploit, you can prevent it from being used.<\/p>\n\n<p>Using sudo does not make much sense without proper logging and alerting. There are three major possibilities:\n- syslog: all events are logged to syslog. For additional security, collect sudo logs  centrally, so a malicious user cannot delete them easily.\n- e-mail: sudo can send e-mail alerts on different kinds of failures\n- debug: in depth logging of subsystems, mostly useful for developers\nSession recording is a fourth possibility. The terminal output can be saved in a local file and played back. You can play back what happened, even if the user started up an interactive shell.<\/p>\n\n<p>Instead of maintaining the sudoers file on each of your systems, you can use LDAP to configure sudo. It has some differences compared to a sudoers file, but also many advantages:\n- local users cannot manipulate the rules,\n- is easier to maintain,\n- goes live immediately.<\/p>\n\n<p>Starting with version 1.8, sudo has a plugin-based architecture. You can replace or extend sudo functionality using plugins. This way users can keep starting applications the usual way using sudo, but have a different configuration or policy engine behind the sudo command. There are both open source and commercial plugins available. For example the sudo_pair plugin – developed in Rust – enables monitoring and makes it possible to require interactive approval of sessions.<\/p>\n\n<p>As you can see, sudo has several lesser-known features that can make monitoring and access management easier for large organizations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "828",
            "value": "Peter Czanik"
          }
        },
        "links":
        [
          {
            "_href": "https://blog.sudo.ws/",
            "value": "sudo blog"
          },
          {
            "_href": "https://www.sudo.ws/",
            "value": "sudo website"
          },
          {
            "_href": "https://www.linkedin.com/in/peterczanik/",
            "value": "speaker LinkedIn"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9865.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UA2.220 (Guillissen)",
    "event":
    [
      {
        "_id": "10290",
        "start": "10:30",
        "duration": "00:05",
        "room": "UA2.220 (Guillissen)",
        "slug": "legal_welcome",
        "title": "Welcome to the Legal & Policy Issues DevRoom",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the Legal &amp; Policy Issues DevRoom including and overview of how the new Collaboration and Debate sessions will work.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "418",
            "value": "Tom Marble"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10290.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9763",
        "start": "10:35",
        "duration": "00:25",
        "room": "UA2.220 (Guillissen)",
        "slug": "challenges_for_privacy",
        "title": "Technology challenges for privacy: the case of decentralized social media",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As decentralized social media gathers more users, the privacy by design and default principles from the GDPR are in accordance to the design model it proposes. This talk is going to tackle the main advantages and challenges this approach brings, from the perspective of the data protection legislation and privacy architectural strategies.<\/p>",
        "description": "<p>Social media platforms have been a central feature in our generation and as we grow more toward understanding their power and taking part in their evolution, we realize the challenges they impose. One of those is how to protect personal data of users, and ensure that the processing is done in accordance with legislation such as GDPR.\nDecentralized social media has developed as a space where personal data ownership is a priority, coming as an alternative to centralized platforms. Not coincidentally, they are mostly open source software, as transparency and offering control of the data to the users go hand in hand with this ambition. Blockchain based social media networks, and projects built on top of the ActivityPub protocol are some of the most popular examples of alternatives which have gathered significant numbers of users or data subjects, under the GDPR.\nOne of the main architectural strategies in building software which is privacy by default and design is data separation. It states that the processing of personal data should be performed whenever possible in a distributed manner. As the GDPR lists privacy by design and default as core principles, decentralized social networking poses a significant advantage compared to centralized solutions. One heuristic to take from this is if the future is privacy-oriented, then social media will be decentralized.\nThis talk is going to offer an analysis of the main benefits and challenges that decentralized social medial pose, from the points of view of personal data protection legislation and privacy design patterns for software architecture.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5091",
            "value": "Cristina DeLisle"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9763.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9759",
        "start": "11:00",
        "duration": "00:50",
        "room": "UA2.220 (Guillissen)",
        "slug": "debate_enforce_licenses",
        "title": "DEBATE: Should FOSS licenses be enforced at all?  What means are acceptable if so?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In a perfect world, lawyers (and the entire legal system) should not be necessary. And in a perfect FOSS world, everyone respects each and every provision of every license. The reality is, however, very different, and enforcement may be a necessary evil. This need does not mean we have to open the gates to be flooded by \"copyleft trolls\", but to establish a sound enforcement policy, in order to unleash the lawyers only for the most blatant and repeated violations<\/p>",
        "description": "<p>Affirmative position: FOSS licenses should not be enforced.<\/p>\n\n<ol>\n<li>First Affirmative Constructive (1AC) = 7 minutes\na. Cross-examination of First Affirmative by Second Negative = 3 minutes<\/li>\n<li>First Negative Constructive (1NC)  = 7 minutes\na. Cross-examination of First Negative by First Affirmative = 3 minutes<\/li>\n<li>Second Affirmative Constructive (2AC)  = 7 minutes\na. Cross-examination of Second Affirmative by First Negative = 3 minutes<\/li>\n<li>Second Negative Constructive (2NC)  = 7 minutes\na. Cross-examination of Second Negative by Second Affirmative = 3 minutes<\/li>\n<li>First Negative Rebuttal (1NR)  = 3 minutes<\/li>\n<li>First Affirmative Rebuttal (1AR)  = 3 minutes<\/li>\n<li>Second Negative Rebuttal (2NR)  = 3 minutes<\/li>\n<li>Second Affirmative Rebuttal (2AR)  = 3 minutes<\/li>\n<\/ol>",
        "persons":
        [
          {
            "_id": "1245",
            "value": "Pamela Chestek"
          },
          {
            "_id": "3467",
            "value": "Giovanni Battista Gallus"
          },
          {
            "_id": "3893",
            "value": "Marc Jones"
          },
          {
            "_id": "7181",
            "value": "McCoy Smith"
          }
        ],
        "links":
        [
          {
            "_href": "https://en.wikipedia.org/wiki/Structure_of_policy_debate",
            "value": "Structure_of_policy_debate"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9759.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10737",
        "start": "12:00",
        "duration": "00:50",
        "room": "UA2.220 (Guillissen)",
        "slug": "debate_license_compliance",
        "title": "DEBATE: Does Careful Inventory of Licensing Bill of Materials Have Real Impact on FOSS License Compliance?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Projects today often have thousands of FOSS dependencies. Since risk\nflows downstream in the supply chain; projects inherit and pass on the\nrisks of all their dependencies. In response, licensing bill of\nmaterials tools often seek to push well-formed licensing inventory\ndata upstream in an effort to ease downstream compliance\nchallenges. At the same time, there has been a stark increase in\nlicense violations, especially, though not exclusively, on copyleft\nlicenses. Is this approach to improving compliance working?<\/p>",
        "description": "<p>Affirmative position: Compliance at scale through tool-driven assembly of bills of materials is essential for FOSS<\/p>\n\n<ol>\n<li>First Affirmative Constructive (1AC) = 7 minutes\na. Cross-examination of First Affirmative by Second Negative = 3 minutes<\/li>\n<li>First Negative Constructive (1NC)  = 7 minutes\na. Cross-examination of First Negative by First Affirmative = 3 minutes<\/li>\n<li>Second Affirmative Constructive (2AC)  = 7 minutes\na. Cross-examination of Second Affirmative by First Negative = 3 minutes<\/li>\n<li>Second Negative Constructive (2NC)  = 7 minutes\na. Cross-examination of Second Negative by Second Affirmative = 3 minutes<\/li>\n<li>First Negative Rebuttal (1NR)  = 3 minutes<\/li>\n<li>First Affirmative Rebuttal (1AR)  = 3 minutes<\/li>\n<li>Second Negative Rebuttal (2NR)  = 3 minutes<\/li>\n<li>Second Affirmative Rebuttal (2AR)  = 3 minutes<\/li>\n<\/ol>",
        "persons":
        [
          {
            "_id": "441",
            "value": "Bradley M. Kuhn"
          },
          {
            "_id": "5041",
            "value": "Carol Smith"
          },
          {
            "_id": "5990",
            "value": "Jeff McAffer"
          }
        ],
        "links":
        [
          {
            "_href": "https://en.wikipedia.org/wiki/Structure_of_policy_debate",
            "value": "Structure_of_policy_debate"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10737.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9762",
        "start": "13:00",
        "duration": "00:25",
        "room": "UA2.220 (Guillissen)",
        "slug": "user_standing",
        "title": "COLLAB: How can we give users standing in free/open software/hardware?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How can we give users standing in free/open software/hardware?\nHow can we motivate end users to care about FOSS if\nthey can't express their preference? What tools do we have beyond\nthe \"court of public opinion\"? Can we invent a NEW legal hack?<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "312",
            "value": "Italo Vignoli"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9762.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9756",
        "start": "13:30",
        "duration": "00:25",
        "room": "UA2.220 (Guillissen)",
        "slug": "optics_of_the_policy",
        "title": "COLLAB: The optics of the policy",
        "subtitle": "And vice-versa",
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Photography policies have begun to appear at free-software events in recent years. These policies typically seek to address personal privacy concerns for event attendees, but they sometimes conflict with the event's desire to record talks, Q&amp;A periods, and social gatherings in public spaces. If not drafted with care, photo policies also run the risk of creating ambiguities for journalists, other attendees making personal photo or video recordings, and members of event-hosting organizations or the public. This session will be an open discussion about photo and video-recording policies, online tagging policies, and related personal-privacy policies, with the goal of clarifying the requirements, needs, and intents of all stakeholders in the FOSS community, so that future event organizers have a solid framework from which to draft clear policies that fit their situations.<\/p>",
        "description": "<p>Free-software events, like free-software projects, have to maintain a delicate balance between openness as a broad principle and privacy as an individual concern. In the past few years, more and more free-software events and community projects have developed \"photo policies\" that are intended to define when and how individuals and groups should be captured in media from the event and when and how those same people should be identified in the media. But a haphazard approach to policy writing can create unintentional ambiguities, such as how to define when an individual is the \"subject' of a photograph or merely in the background. And free-software communities must also take care to write policies that do not come into conflict with local law, especially when events take place in public spaces. Finally, event organizers need to ensure that their photo policies, real-name policies, press policies, and session-recording consent policies work in concern with one another, not in conflict.<\/p>\n\n<p>This session will be a broad discussion of photography policies and how they interact with other policy concerns. The intent will be to enumerate the concerns of all stakeholders, identify potential areas of confusion, note best practices, and — most importantly — establish resources and spaces for further discussion for project and community members creating photo policies in the future.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4935",
            "value": "Nathan Willis"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9756.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9664",
        "start": "14:00",
        "duration": "00:50",
        "room": "UA2.220 (Guillissen)",
        "slug": "debate_fsd_osd_irrelevant",
        "title": "DEBATE: The 4 Freedoms and OSD are outdated and no longer relevant in 2020",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Are the FSF's 4 Freedoms and the OSI's Open Source Definition out\nof date in 2020 and should be replaced.<\/p>",
        "description": "<p>Affirmative position: OSD/FSD is now irrelevant<\/p>\n\n<ol>\n<li>First Affirmative Constructive (1AC) = 7 minutes\na. Cross-examination of First Affirmative by Second Negative = 3 minutes<\/li>\n<li>First Negative Constructive (1NC)  = 7 minutes\na. Cross-examination of First Negative by First Affirmative = 3 minutes<\/li>\n<li>Second Affirmative Constructive (2AC)  = 7 minutes\na. Cross-examination of Second Affirmative by First Negative = 3 minutes<\/li>\n<li>Second Negative Constructive (2NC)  = 7 minutes\na. Cross-examination of Second Negative by Second Affirmative = 3 minutes<\/li>\n<li>First Negative Rebuttal (1NR)  = 3 minutes<\/li>\n<li>First Affirmative Rebuttal (1AR)  = 3 minutes<\/li>\n<li>Second Negative Rebuttal (2NR)  = 3 minutes<\/li>\n<li>Second Affirmative Rebuttal (2AR)  = 3 minutes<\/li>\n<\/ol>",
        "persons":
        [
          {
            "_id": "829",
            "value": "Neil McGovern"
          },
          {
            "_id": "3462",
            "value": "Andrew Katz"
          },
          {
            "_id": "4794",
            "value": "Matt Jarvis"
          },
          {
            "_id": "5034",
            "value": "Luis Villa"
          },
          {
            "_id": "6495",
            "value": "Frank Karlitschek"
          },
          {
            "_id": "6847",
            "value": "Amanda Brock"
          }
        ],
        "links":
        [
          {
            "_href": "https://en.wikipedia.org/wiki/Structure_of_policy_debate",
            "value": "Structure_of_policy_debate"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9664.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9775",
        "start": "15:00",
        "duration": "00:25",
        "room": "UA2.220 (Guillissen)",
        "slug": "debate_socal_goal_licenses",
        "title": "DEBATE: Should licenses be designed to advance general social goals?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We have seen several licenses proposed as \"open source\" that\ncarry some obligation or restriction related to ethics or\nother social goals. Is this a good direction for FOSS license drafting?<\/p>",
        "description": "<p>Affirmative position: FOSS licenses should advance social goals<\/p>\n\n<ol>\n<li>First Affirmative Constructive (1AC) = 7 minutes\na. Cross-examination of First Affirmative by Second Negative = 3 minutes<\/li>\n<li>First Negative Constructive (1NC)  = 7 minutes\na. Cross-examination of First Negative by First Affirmative = 3 minutes<\/li>\n<li>Second Affirmative Constructive (2AC)  = 7 minutes\na. Cross-examination of Second Affirmative by First Negative = 3 minutes<\/li>\n<li>Second Negative Constructive (2NC)  = 7 minutes\na. Cross-examination of Second Negative by Second Affirmative = 3 minutes<\/li>\n<li>First Negative Rebuttal (1NR)  = 3 minutes<\/li>\n<li>First Affirmative Rebuttal (1AR)  = 3 minutes<\/li>\n<li>Second Negative Rebuttal (2NR)  = 3 minutes<\/li>\n<li>Second Affirmative Rebuttal (2AR)  = 3 minutes<\/li>\n<\/ol>",
        "persons":
        [
          {
            "_id": "1577",
            "value": "John Sullivan"
          },
          {
            "_id": "4180",
            "value": "Molly de Blanc"
          },
          {
            "_id": "4569",
            "value": "James Vasile"
          },
          {
            "_id": "5967",
            "value": "Josh Simmons"
          },
          {
            "_id": "6771",
            "value": "Dashiell Renaud"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9775.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10738",
        "start": "16:00",
        "duration": "00:50",
        "room": "UA2.220 (Guillissen)",
        "slug": "debate_foss_sustainability",
        "title": "DEBATE: Does FOSS need sustainability?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Several prominent FOSS projects have changed their FOSS licenses to\nalternate licenses that make software available, but with additional\nrestrictions intended to help financially sustain FOSS development and\ncombat \"strip mining\" by software-as-a-service providers. Additionally,\nrecently several related organizations have jumped into the the role of\nhelping sustain open source by providing (for a fee) funding conduits,\nfundraising services, or other mechanisms to route money to maintainers.<\/p>",
        "description": "<p>Affirmative position: FOSS benefits from sustainability efforts<\/p>\n\n<ol>\n<li>First Affirmative Constructive (1AC) = 7 minutes\na. Cross-examination of First Affirmative by Second Negative = 3 minutes<\/li>\n<li>First Negative Constructive (1NC)  = 7 minutes\na. Cross-examination of First Negative by First Affirmative = 3 minutes<\/li>\n<li>Second Affirmative Constructive (2AC)  = 7 minutes\na. Cross-examination of Second Affirmative by First Negative = 3 minutes<\/li>\n<li>Second Negative Constructive (2NC)  = 7 minutes\na. Cross-examination of Second Negative by Second Affirmative = 3 minutes<\/li>\n<li>First Negative Rebuttal (1NR)  = 3 minutes<\/li>\n<li>First Affirmative Rebuttal (1AR)  = 3 minutes<\/li>\n<li>Second Negative Rebuttal (2NR)  = 3 minutes<\/li>\n<li>Second Affirmative Rebuttal (2AR)  = 3 minutes<\/li>\n<\/ol>",
        "persons":
        [
          {
            "_id": "418",
            "value": "Tom Marble"
          },
          {
            "_id": "4271",
            "value": "Philippe Ombredanne"
          },
          {
            "_id": "5034",
            "value": "Luis Villa"
          },
          {
            "_id": "6518",
            "value": "Mehdi Medjaoui"
          }
        ],
        "links":
        [
          {
            "_href": "https://en.wikipedia.org/wiki/Structure_of_policy_debate",
            "value": "Structure_of_policy_debate"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10738.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9786",
        "start": "17:00",
        "duration": "00:25",
        "room": "UA2.220 (Guillissen)",
        "slug": "oracle_v_google",
        "title": "Oracle v. Google: What are the implications for FOSS?",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>All the merits briefs for Oracle v. Google will be filed a couple weeks before FOSDEM 2020. This will be a rundown of the positions argued by various groups - how are the parties positioning the questions presented? What are the various amici arguing? Are there any positions that will be particularly impactful for FOSS groups and users?<\/p>",
        "description": "<p>On Friday, Nov. 15, the U.S. Supreme Court agreed to hear Oracle v. Google. It is hard to overstate how impactful this decision will be on FOSS. For the first time in a generation, the Supreme Court will be evaluating how copyright and software interact - and they will be discussing it in the context of GPL-licensed Java.<\/p>\n\n<p>Right before FOSDEM, all the briefs by all parties will be due. As we sit in Brussels, the court clerks will be reading the various briefs and creating a \"bench memo\" for each justice, summarizing the arguments being advanced by both Oracle and Google, as well as the points raised by different amici.<\/p>\n\n<p>This presentation will be a verbal \"bench memo\" for those in the FOSS community. Rather than advance a particular view, we will try to understand the scope of issues being argued, and how they may affect Free and Open Source Software in the United States - and worldwide.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5973",
            "value": "Van Lindberg"
          }
        },
        "links":
        [
          {
            "_href": "http://www.supremecourt.gov/DocketPDF/18/18-956/89548/20190225155816527_18-956%20Amici%20Brief%20Python.pdf",
            "value": "Amicus Brief Supporting Cert filed last year"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9786.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10739",
        "start": "17:30",
        "duration": "00:50",
        "room": "UA2.220 (Guillissen)",
        "slug": "legal_organizers_panel",
        "title": "Legal Organizer's Panel",
        "subtitle": [],
        "track": "Legal and Policy Issues",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Legal &amp; Policy Issues DevRoom Organizers gather to reflect on our DevRoom talks and FOSS issues of the day<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "418",
            "value": "Tom Marble"
          },
          {
            "_id": "441",
            "value": "Bradley M. Kuhn"
          },
          {
            "_id": "448",
            "value": "Karen Sandler"
          },
          {
            "_id": "583",
            "value": "Richard Fontana"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10739.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB2.147",
    "event":
    [
      {
        "_id": "9818",
        "start": "10:30",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_improving_culture_automated_testing_foss",
        "title": "Improving the culture of automated testing in FOSS",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we will explore some of the FOSS specific mentalities and\npractices that may discourage adoption of comprehensive automated testing, and\npresent advice for promoting and sustaining automated testing in FOSS projects.<\/p>",
        "description": "<p>Automated testing is on the rise in the FOSS world, but there is still ample\nroom for improvement when it comes to sufficiently comprehensive automated\ntests. The test suites of many FOSS projects leave a lot to be desired,\na result that's often affected by useful FOSS practices that are\ntaken too far. Identifying such practices, like placing excessive trust in code\nreviews because \"given enough eyeballs, all bugs are shallow\", or leaving tests\nfor later in the spirit of \"release often, release early\", is a first step in\nhaving a discussion that will hopefully convince more projects to embrace\nautomated testing, and improve the quality of FOSS overall.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4989",
            "value": "Alexandros Frantzis"
          }
        },
        "links":
        [
          {
            "_href": "https://afrantzis.com/posts/on-the-low-adoption-of-automated-testing-in-foss/",
            "value": "Related blog post #1"
          },
          {
            "_href": "https://afrantzis.com/posts/metrics-for-test-suite-comprehensiveness/",
            "value": "Related blog post #2"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9818.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10643",
        "start": "11:05",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_welcome_kernelci",
        "title": "Welcome to KernelCI",
        "subtitle": "You're all welcome to the KernelCI project's new home",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>KernelCI is a project dedicated to testing the upstream Linux kernel.\nOriginally created by Linaro in 2014, it started a new chapter by\nbecoming a Linux Foundation project in October 2019.  Its future looks\nbright, with plenty of opportunities for new contributors to join.<\/p>",
        "description": "<h2>The chosen one<\/h2>\n\n<p>The upstream kernel testing landscape is pretty wide, rich and\ndiverse, in the same ways that the Linux kernel is.  But as there is\nonly one upstream kernel, it became clear that there should also be\none main test system associated with it.  KernelCI was chosen to\nfulfil this role, being rather neutral, versatile and based on a\ndistributed architecture.<\/p>\n\n<h2>A welcoming place<\/h2>\n\n<p>While the project now has a governing board via the Linux Foundation\nmembership, its involvement with the kernel community is only getting\nstronger.  It is of utmost importance to keep the roadmap aligned with\nexpectations from maintainers and developers to preserve the integrity\nand overall purpose of project.  In fact, it now needs to become an\neasy tool to use by anyone who wants to add tests for their subsystem\nor their hardware and for anyone to reproduce those tests locally.<\/p>\n\n<h2>An exciting year ahead<\/h2>\n\n<p>This is a new beginning for KernelCI, with many of its prior\nlimitations now being removed thanks to the framework provided by the\nLinux Foundation.  Contributors to the code, tests, hardware labs and\nnew project members will all have a great influence by joining the\nproject at this very special point in time.  Now is the time to come\nand help shape it as a successful project for the years to come.<\/p>\n\n<p>Slides: https://people.collabora.com/~gtucker/kernelci/doc/gtucker-kernelci-fosdem-2020.pdf<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4997",
            "value": "Guillaume Tucker"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10643.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10271",
        "start": "11:40",
        "duration": "00:40",
        "room": "UB2.147",
        "slug": "testing_abusing_gitlabci_test_kernel",
        "title": "Abusing GitLab CI to Test Kernel Patches",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>See how Red Hat’s CKI project uses GitLab CI to test kernel patches as soon as they're posted to maillists.<\/p>",
        "description": "<p>Red Hat's CKI project uses GitLab CI to organize and track its pipelines, lint, patch, and build Linux kernels, and oversee testing. It also uses a number of supporting systems to discover kernel patches and commits, maintain hardware inventory, provision hardware and VMs, run tests, and finally record and report results.<\/p>\n\n<p>See which tricks the project is pulling to tie all these parts together, and test patches posted to several maillists, commits to 15+ git repos, builds done by other build systems, as well as weird things like stable kernel patch queue, and parts of its own software stack.<\/p>\n\n<p>Making such extensive use of a CI system inevitably uncovers its limitations, and a list of these will also be presented along with some possible solutions.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3164",
            "value": "Nikolai Kondrashov"
          }
        },
        "links":
        [
          {
            "_href": "https://cki-project.org/",
            "value": "CKI project's website"
          },
          {
            "_href": "https://gitlab.com/cki-project",
            "value": "GitLab group"
          },
          {
            "_href": "https://github.com/cki-project/",
            "value": "GitHub organization"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10271.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9336",
        "start": "12:25",
        "duration": "00:50",
        "room": "UB2.147",
        "slug": "testing_openqa_jdp",
        "title": "OpenQA with the JDP data analyses framework",
        "subtitle": "Bug tag propagation on 2M+ test results using Julia",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Overview of SUSE's Linux kernel testing in OpenQA, how we keep track of known issues, explore test results and other features of JDP. The JDP framework is written in Julia, uses Redis as a distributed data cache and Jupyter for interactive reporting. OpenQA is a large application used for testing operating systems and displaying the results.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5048",
            "value": "Richard Palethorpe"
          }
        },
        "links":
        [
          {
            "_href": "https://palethorpe.gitlab.io/jdp/",
            "value": "JDP"
          },
          {
            "_href": "https://openqa.opensuse.org/group_overview/32",
            "value": "OpenSUSE kernel testing"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9336.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9888",
        "start": "13:20",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_automated_performance_testing_virtualization",
        "title": "Automated Performance Testing for Virtualization with MMTests",
        "subtitle": "The Tools, the Challenges and also some War-Stories about Performance Testing Hypervisors and VMs",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>What benchmark? How many VMs? How big each VM is? Are they all equal or are they different? What's the host OS? What are the guest OSes? I.e., when wanting to do virtualization performance testing, the matrix of test cases tends to explode pretty quickly. This talk will show how we enhanced an existing benchmarking suite, MMTests, in order to be able to deal a little bit better with such complexity. And what our further activities and plans are, for even more and better automation.<\/p>",
        "description": "<p>Functional testing is already hard enough, in virtualization. For instance, because we need to make sure that things work with different combinations of versions of the OSes in hosts and guests. Doing performance testing, even more so. In fact, there are much more things to consider, such as how many VMs we use, how big they are, whether or not they are equally big or different, what to run in them, how to partition the host resources for them... And this is true either in case you have a specific (virtualized) workload and some KPI to meet, in which case you need testing and benchmarking to figure out whether or not the tuning you have done has brought you there, or in case you wonder how good (or how bad) a certain configuration of both your host and your guests works, for a number of workloads,<\/p>\n\n<p>This talk will introduce the problem, showing how the size and the complexity of a typical 'virtualization performance testing matrix' really tend to explode. We will, as an example, show how some specific characteristics of a virtualized system were, despite tuning, causing us to not be able to achieve the desired performance levels. Then we illustrate how, at SUSE, we do automated performance benchmarking, how we enhanced the tool that was in use the most for baremetal benchmarks (the MMTests suite) in order for it to be much more useful in virtualized systems and how we are integrating it with other tools to bring the level of automation even further and achieve something that really resembles a Virtualization Performance CI system.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3513",
            "value": "Dario Faggioli"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/gormanm/mmtests",
            "value": "MMTests upstream"
          },
          {
            "_href": "https://github.com/dfaggioli/mmtests/commits/bench-virt",
            "value": "MMTests with virt extensions"
          },
          {
            "_href": "https://github.com/dfaggioli/mmtests/commits/wip/bench-virt",
            "value": "MMTests with virt extensions WiP/development branch"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9888.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9136",
        "start": "13:55",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "testing_autohealing_negative_testing",
        "title": "Auto-healing cluster through negative testing",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OCS stands for Openshift Container storage. It provides container-based storage for OCP(Openshift container platform). It’s easily scalable to bare metal, VMs and cloud platforms.\nAuto healing is a property of OCS cluster that auto heals a cluster component automatically when passes through an unexpected condition. A component can be a node, a network interface, a service, etc. To make sure auto heals just fine, we introduced negative testing.\nNegative Testing is defined as, a testing type that checks a system for unexpected conditions. In this presentation, We’re going to talk, what role negative testing plays, how to negative test components like node by shutting it down, deploying a heavy workload, etc. Similarly, for the network component, we are going to see what happens when the public network is disconnected along with many more scenarios.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6523",
            "value": "Rajat Singh"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9136.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10645",
        "start": "14:25",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_introducing_opentap",
        "title": "Introducing OpenTAP - Open Test Automation Project",
        "subtitle": "A developer-first extensible test and measurement automation project",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OpenTAP is a project aimed at automation in the test and measurement space. It is designed for test and measurement of hardware in R&amp;D and manufacturing, but is moving more towards software testing e.g. with usage in cloud infrastructure testing. The project started as an internal product by Keysight Technologies and is used as the core of many products and solutions deployed around the world. As of 2019, we have released OpenTAP under the Mozilla Public License v2 and are working on building a community around it. The release was influenced by the team attending FOSDEM over the last few years, we will also welcome you for more detailed discussion at our booth on Saturday.<\/p>\n\n<p>What we want is to grow an environment for people to share, leverage and co-develop test system plugins and solutions.<\/p>\n\n<p>In this short talk, we will explain the basic concepts of OpenTAP, what it can be used for, and how to get started.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7344",
            "value": "Rolf Madsen"
          }
        },
        "links":
        [
          {
            "_href": "https://www.opentap.io",
            "value": "Home page"
          },
          {
            "_href": "https://gitlab.com/OpenTAP/opentap",
            "value": "Source repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10645.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10647",
        "start": "15:00",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_one_test_output_format",
        "title": "One test output format to unite them all",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Since several years, software quality tools have evolved, CI systems are more and more scalable, there are more testing libraries than ever and they are more mature than ever and we have seen the rise of new tools to improve the quality of code we craft.<\/p>\n\n<p>Unfortunately, most of our CI system still launch a script and check the return code, most of the testing libraries don't allow to select finely which tests to launch and most of CI advanced innovations, parallel running, and remote execution, are not available to developers on their workstation.<\/p>\n\n<p>Each language community has its own set of tools, libraries, and command-line and visual interfaces increasing the effort for developers to learn or learn again how to write, run and debug tests in each language.<\/p>\n\n<p>How to improve the situation? In this talk, I will present one of my project LITF (https://github.com/Lothiraldan/litf) a new protocol for test running and test output as well as BALTO (https://github.com/lothiraldan/balto), a test orchestrator using this new format. Thanks to this new format, BALTO can execute several test suites in different languages, remotely on a Kubernetes cluster and all in parallel. In any case, this is the goal of the stable version.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2751",
            "value": "Boris Feld"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10647.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9205",
        "start": "15:35",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_releasing_software_gitops",
        "title": "Releasing Software with GitOps",
        "subtitle": "How OpenStack manages releases using Git based automation",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Overview of the process the OpenStack community uses to manage all software releases through automation around Git commits.<\/p>",
        "description": "<p>The OpenStack community has enabled a lot of automation around releasing their software. This presentation will give an overview of how code reviews are used to manage release activity. It will step through the use of Zuul CI jobs to perform validation of requests before they are accepted, and how commits are used to trigger jobs to tag and release the software, update documentation, trigger requirements updates, and other follow on work that needs to happen whenever new code is released.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5652",
            "value": "Sean McGinnis"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9205.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10576",
        "start": "16:10",
        "duration": "00:45",
        "room": "UB2.147",
        "slug": "testing_writing_go_tests",
        "title": "Writing Go(od) Tests",
        "subtitle": "Writing good tests in golang",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Every year we hear great content about how to <em>develop<\/em> in Go, but rarely do we focus on how to <em>test<\/em> in Go. Well written tests are critical to the success of a project, and more often than not, they can help drive developers to design features in more simple and concise ways.<\/p>",
        "description": "<p>In this talk, I'll explain the importance of test driven development and provide some tactics for how to implement the practice in your daily work and on your respective team. I'll dive into the <code>testing<\/code>, <code>require<\/code>, and <code>assert<\/code> packages to dissect which function calls are appropriate for different use cases, and present multiple different ways to write Go tests for each scope, including unit, integration and e2e. I'll also discuss how to refactor code to make it more testable (with examples), so you can optimize and simplify Go code for robust and reliable Go tests. Lastly, I will cover race conditions to help you debug concurrency related problems. Let's write Go(od) tests!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7316",
            "value": "Nikki Attea"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10576.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10639",
        "start": "17:00",
        "duration": "00:10",
        "room": "UB2.147",
        "slug": "testing_apps_with_3rd_party_api",
        "title": "Testing apps with third-party API integrations",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As reliance on third-party services becomes more prevalent in our ecosystem, developers need cost-effective, secure and reliable ways to mock these services. In this talk, we will briefly examine strategies and best practices for testing apps that make heavy use of third-party API integrations.<\/p>",
        "description": "<p>With such a short session, I want to focus on the bits that are the most useful for developers today. Whether you’re working in a hip startup or traditional company with legacy code, you’re likely going to need ways to mock services for both dev/staging environments and testing. So this will include a (very short) demo of Unmock, the fuzz testing library that I maintain, with references to other tools like Nock and PollyJS. After this session, audience members should walk away with practical ways to improve their testing practices for REST APIs and third-party integrations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7341",
            "value": "Carolyn Stransky (carostran)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10639.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10632",
        "start": "17:15",
        "duration": "00:30",
        "room": "UB2.147",
        "slug": "testing_large_testing_software",
        "title": "Testing a large testing software",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LAVA is an automated validation architecture primarily aimed at testing deployments of systems based around the Linux kernel on ARM devices, specifically ARMv7 and later.\nLAVA is becoming the de facto standard to test software (bootloader, kernel, userspace) on development boards (rpi, juno, beagle, ...). It's used by many projects to build large testing systems like kernelci.<\/p>\n\n<p>Testing a testing system like LAVA is sometimes a tricky task. In order to test LAVA we had to develop some specific tools (meta-lava, DummySYS, lavafed, ...) that I will present during this talk.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5625",
            "value": "Rémi Duraffort"
          }
        },
        "links":
        [
          {
            "_href": "https://linaroconnectsandiego.sched.com/event/SueM/san19-422-advanced-testing-in-python",
            "value": "Will be extend one part of this presentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10632.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10584",
        "start": "17:50",
        "duration": "00:20",
        "room": "UB2.147",
        "slug": "testing_correlation_analysis_automated_testing",
        "title": "Correlation analysis in automated testing",
        "subtitle": [],
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Correlation Analysis is a statistical method that is used to discover if there\nis a relationship between two variables, and how strong that relationship might\nbe. A correlation coefficient is a numerical measure of such correlation.\nAccording to the Cauchy–Schwarz inequality it has a value between +1 and −1,\nwhere 1 is total positive linear correlation, 0 is no linear correlation, and −1\nis total negative linear correlation. One of the axioms of automated testing is\nthat tests are independent and in spite of that correlation coefficient should\nbe equal to 0. But often it isn't. In this work, we are going to present\na method of evaluation of tests suites quality based on correlation coefficient\nand finding their weak points. Using PC Engines open-source firmware regression\ntest results, which are based on over 140 automated tests run with 2 flavors of\nsoftware on 4 different platforms, we will show how its quality can be described\nnumerically, and how that results can be used to optimize test criteria.<\/p>",
        "description": "<p>As far as automated testing is considered all the tests can have only two\nexpected output values - pass or fail. Originally Pearson's correlation\ncoefficient is the covariance of the two variables divided by the product of\ntheir standard deviations - the first question was how to do it for Boolean\nvariables. We assumed that the only value that matters can be a failure of a\ntest. During the lecture, we will present how mathematical analysis can reveal\npotential flaws in test criteria by targeting cases that have a large chance to\nfail simultaneously.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6372",
            "value": "Łukasz Wcisło"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/spreadsheets/d/1_uRhVo9eYeZONnelymonYp444zYHT_Q_qmJEJ8_XqJc",
            "value": "PC Engines regression tests results"
          },
          {
            "_href": "https://www.sciencedirect.com/topics/medicine-and-dentistry/correlation-analysis",
            "value": "Correlation Analysis by sciencedirect.com"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10584.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9358",
        "start": "18:15",
        "duration": "00:45",
        "room": "UB2.147",
        "slug": "testing_fail_successfully_reliably",
        "title": "How to fail successfully and reliably",
        "subtitle": "And look good while doing it",
        "track": "Testing and Automation",
        "type": "devroom",
        "language": [],
        "abstract": "<ul>\n<li>Introduction<\/li>\n<li>Activity: what's \"failure\", anyway?<\/li>\n<li>Impact of failure\n  Resources spent before failure is made\n  Resources spent to detect failure\n  Resources spent after failure is detected<\/li>\n<li>So what is \"fail fast\"?\n*The art and science of satisficing<\/li>\n<li>Activity: how would you design to fail in these scenarios?<\/li>\n<li>Documentation - the power of story-telling<\/li>\n<li>Summary: the successful way to fail fast<\/li>\n<li>Q/A<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6663",
            "value": "Saleem Siddiqui"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9358.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB2.252A (Lameere)",
    "event":
    [
      {
        "_id": "9949",
        "start": "10:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_sudo",
        "title": "Extending sudo in Python",
        "subtitle": "Best of both worlds",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>From my talk you will learn about some lesser-known features of sudo, and how you can make your security more flexible by extending sudo using Python.<\/p>",
        "description": "<p>Everybody knows sudo, right? Sudo allows a system administrator to give certain users the ability to run some commands as root, while logging the executed commands and their arguments. It is installed by default on almost all Linux systems, and is available for most commercial UNIX systems. Sudo allows you to fine-tune access policies, record sessions, and do extensive logging. Still, even system administrators often only know it is the “prefix” to use before entering a command requiring root privileges, and don’t realize its true powers.<\/p>\n\n<p>Did you know that with version 1.8 sudo changed to a plugin-based architecture? You can extend or even replace basic functionality through plugins. While plugins provide the ultimate flexibility – and there are both open source and commercial plugins for sudo available – it is not easy to extend sudo. This is why the Python plugin is under way to sudo (and will be released before FOSDEM).<\/p>\n\n<p>Sudo has a number of well defined APIs for plugins (https://www.sudo.ws/man/sudo_plugin.man.html). The Python plugin builds on these APIs. For example, you can set your own policies using the policy API, or access what is happening on the screen using the I/O API (used by session recording).<\/p>\n\n<p>Using Python for extending sudo makes development not just easier (no development environment necessary), but opens up many new possibilities. For example, you can develop a plugin which analyzes on-screen activity in real-time, and breaks the session if the infamous “rm -fr /” command appears on screen. As multiple I/O plugins can work in parallel, you do not have to give up session recording to analyze sessions in real-time from Python.<\/p>\n\n<p>From my talk you will learn about some lesser-known features of sudo, and how you can make your security more flexible by extending sudo using Python.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "828",
            "value": "Peter Czanik"
          }
        },
        "links":
        [
          {
            "_href": "https://blog.sudo.ws/",
            "value": "sudo blog"
          },
          {
            "_href": "https://www.sudo.ws/",
            "value": "sudo website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9949.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10213",
        "start": "11:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_rust",
        "title": "Boosting Python with Rust",
        "subtitle": "The case of Mercurial",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While working on the Mercurial version control system, we hit our heads against the limits of Python's performance. In this talk we will see how Python and Rust can cohabit to play off of each other's strenghts to improve a big open-source project, and what advances have been made in bridging the two languages.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7143",
            "value": "Raphaël Gomès"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10213.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9504",
        "start": "11:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_scikit_learn_estimator",
        "title": "How to write a scikit-learn compatible estimator/transformer",
        "subtitle": "Tips and tricks, testing your estimator, and must-watch related current developments",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This is a hands-on short tutorial on how to write your own estimator or transformer\nwhich can be used in a scikit-learn pipeline, and works seamlessly with the other\nmeta-estimators of the library.<\/p>\n\n<p>It also includes how they can be conveniently tested with a simple set of tests.<\/p>",
        "description": "<p>In many data science related tasks, the use-case specific requirements require us to\nslightly manipulate the behavior of some of the estimators or transformers present\nin scikit-learn. Some of the tips and requirements are not necessarily well documented\nby the library, and it can be cumbersome to find those details.<\/p>\n\n<p>In this short tutorial, we go through an example of writing our own estimator,\ntest it against the scikit-learn's common tests, and see how it behaves inside\na pipeline and a grid search.<\/p>\n\n<p>There has also been recent developments related to the general API of the estimators\nwhich require slight modifications by the third party developers. I will cover these\nchanges and point you to the activities to watch as well as some of the private utilities\nwhich you can use to improve your experience of developing an estimator.<\/p>\n\n<p>The materials of the talk will be available on github as a jupyter notebook.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6765",
            "value": "Adrin Jalali"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9504.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9671",
        "start": "12:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_django_3",
        "title": "Why is Django 3.0 a revolution for building websites with Python?",
        "subtitle": "From WSGI to ASGI and why it matters",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For almost 20 years, we relied on a CGI based protocol called WSGI to use Python to handle HTTP requests and responses software.\nBecause Python is singled threaded we relied on a couple of hacks such as Gunicorn or uWSGI to share a socket through multiple processes.\nHowever the cost of all these multiple processes was a bit heavy and error prone.<\/p>\n\n<p>Through Django Channels Andrew Godwin paved the way for a better way of creating web services with Python. This work landed in Django 3.0.\nLet's explore how it works and why it worth it!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6891",
            "value": "Rémy Hubscher"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9671.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10081",
        "start": "12:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_manage_change",
        "title": "Will somebody *please* tell me what's going on?",
        "subtitle": "Managing change in Python projects",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How does one manage and document change in Python projects, be that new features or deprecation or removal of a feature? Let's explore some of the tools a Python developer can keep in their toolbox for just this purpose.<\/p>",
        "description": "<p>Software rarely stands still (unless it's TeX). Things are added, things are removed, things break and are then hopefully fixed. Managing this, from both the developer and user perspective, can be tough. In this talk we examine and compare some of the tools that one can use to make this process easier, such as 'debtcollector', 'reno' and 'towncrier', and contrast these with alternatives used in other projects. This talk would mainly be of interest to developers of open source libraries, though the same tooling can be used for any Python library or application that wishes to maintain stable interfaces and/or document changes in their product.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4186",
            "value": "Stephen Finucane"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10081.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9874",
        "start": "13:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_coala",
        "title": "Discover Static Code Analysis in Python with Coala Framework",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We, as developer, aim to provide code that, almost matches our team code style, looks better and behaves right. Static code analysis (SCA) tools are one of the way to achieves that. But, with multi-programming languages projects and all kinds of code related needs, It's difficult to address all thoses usecases without dealing with a vast majority of SCA tools.<\/p>\n\n<p><strong>Coala<\/strong> is a — language agnostic — static code analysis framework that provides a common command-line interface for linting and fixing all your code.<\/p>\n\n<p>It is written in Python and supports way over 50 languages in addition to language independent routines. So, instead of building new analysis tools from scratch you can now build your own custom logic and let let coala deal with the rest.<\/p>\n\n<p>This talk introduces the audience to the Coala Framework and guides them through how the can use it to build routines to do almost anything you want with your code.<\/p>",
        "description": "<h6>AUDIENCE<\/h6>\n\n<p>Python Developers<\/p>\n\n<h6>LEVEL<\/h6>\n\n<p>Beginner / Intermediate / Advanced<\/p>\n\n<h3>Notes<\/h3>\n\n<p>This talk is for python developers with any level of experience.<\/p>\n\n<p>At the en of the talk, the attendees will learn :<\/p>\n\n<ul>\n<li>Some Basics concepts of static code analysis<\/li>\n<li>The purpose and usage of Coala Framework<\/li>\n<li>How to create custom routines either lint, or fix their code<\/li>\n<\/ul>\n\n\n<h3>Abstract<\/h3>\n\n<p>We, as developer, aim to provide code that, almost matches our team code style, looks better and behaves right. Static code analysis (SCA) tools are one of the way to achieves that. But, with multi-programming languages projects and all kinds of code related needs, It's difficult to address all thoses usecases without dealing with a vast majority of SCA tools.<\/p>\n\n<p><strong>Coala<\/strong> is a — language agnostic — static code analysis framework that provides a common command-line interface for linting and fixing all your code.<\/p>\n\n<p>It is written in Python and supports way over 50 languages in addition to language independent routines. So, instead of building new analysis tools from scratch you can now build your own custom logic and let let coala deal with the rest.<\/p>\n\n<p>This talk introduces the audience to the Coala Framework and guides them through how the can use it to build routines to do almost anything you want with your code.<\/p>\n\n<h3>Agenda<\/h3>\n\n<ul>\n<li>Static Code Analysis : Quick overview<\/li>\n<li>Introduction to Coala and Coala-bears<\/li>\n<li>Coala-bears : How to build your own coala routines<\/li>\n<li>Going Further : What's next ?<\/li>\n<li>Q &amp; A<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6123",
            "value": "Lionel Lonkap Tsamba"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9874.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9901",
        "start": "13:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_graphql",
        "title": "When Python meets GraphQL: Managing contributors identities in your open source project",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>SortingHat is an open source Python tool that helps to manage the different contributor identities within an open source project. Under the hood SortingHat relies on a relational database, which can be queried via SQL, command line or directly via its Python interface. However, these ways of interacting with SortingHat hinder its integration with external tools, web interfaces and new web technologies (e.g., Django, REST services). To overcome these obstacles, we have evolved SortingHat's architecture using a GraphQL model based on the Graphene-Django implementation.<\/p>\n\n<p>This talk describes our experience in migrating to GraphQL, from adapting the SortingHat functionalities to refactoring the unit tests. Furthermore, we comment also on lesson learned, advantages and drawbacks of using this new approach<\/p>\n\n<p>SortingHat is one of the core tools of GrimoireLab, an open-source software analytics platform part of CHAOSS project (Community Health Analytics Open Source Software) under the umbrella of the Linux Foundation.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6013",
            "value": "Miguel-Ángel Fernández"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9901.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10031",
        "start": "14:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_celery",
        "title": "Follow Your Celery Tasks",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>All Python developer who want to run asynchronous tasks should know Celery. If you have already used it, you know how great it is ! But you also discovered how it can be complicated to follow the state of a complex workflow. Celery Director is a tool  we created at OVH to fix this problem : using some concepts of Event Sourcing, Celery Director helps us to follow the whole lifecycle of our workflows. It allows us to check when a problem occurred and relaunch the whole DAG (or just a subpart if tasks are not completely idempotent). During this talk we will introduce you the different concepts of Celery Director then we'll make a demonstration of it.<\/p>",
        "description": "<p>All Python developer who want to run asynchronous tasks should know Celery. If you have already used it, you know how great it is ! But you also discovered how it can be complicated to follow the state of a complex workflow. Celery Director is a tool  we created at OVH to fix this problem : using some concepts of Event Sourcing, Celery Director helps us to follow the whole lifecycle of our workflows. It allows us to check when a problem occurred and relaunch the whole DAG (or just a subpart if tasks are not completely idempotent). During this talk we will introduce you the different concepts of Celery Director then we'll make a demonstration of it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6064",
            "value": "Nicolas Crocfer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10031.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9842",
        "start": "14:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_asyncio",
        "title": "Asyncio: understanding async and await in Python",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Often when asyncio is discussed, people think of it as a high performance concurrency programming paradigm for Python. In this talk however, we approach asyncio from a different angle, one that will possibly help some of you to finally get what asyncio is about. it's not only about performance, but at least as much about correctness and readability of concurrent applications.<\/p>",
        "description": "<p>Concurrency is hard to get right.<\/p>\n\n<p>Often when asyncio is discussed, people think of it as a high performance concurrency programming paradigm for Python. In this talk however, we approach asyncio from a different angle, one that will possibly help some of you to finally get what asyncio is about. it's not only about performance, but at least as much about correctness and readability of concurrent applications.<\/p>\n\n<p>It is known that for multithreaded applications, synchronization is hard to get right. Doing it wrong can either lead to deadlocks or broken data structures.<\/p>\n\n<p>We will have a look at how using asyncio is different from using threads, when it's better and what pitfalls we have.<\/p>\n\n<p>This talk should be a good introduction for anyone just starting with asyncio, but can also clarify things for people that are using asyncio already. I expect people to have at least used some form of concurrency, either threads or an event loop like we have in JavaScript.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4289",
            "value": "Jonathan Slenders"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9842.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9935",
        "start": "15:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_profiling",
        "title": "Production-time Profiling for Python",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn how to scrutinize your Python application in order to optimize them and make them run faster.<\/p>",
        "description": "<p>Getting inside knowledge of how your Python application runs is critical in order to achieve the best performance. Profiling is a mean to achieve this: by gathering all the runtime information available about the execution of your program, you might be able to understand how to optimize it. However, profiling running code in production might be a real challenge as it requires the profiler to be noninvasive and having low overhead.<\/p>\n\n<p>Therefore, to profile production services, statistical profiling is the favorite analysis method. By regularly checking your program activity, you’ll be able to find production code bottlenecks down to the line of code. Profiling services that are running with real workload makes sure that you are collecting valuable data and that you are not guessing what the performance barrier might be.<\/p>\n\n<p>This talk explains how it’s possible to build a statistical profiler that collects information about CPU time usage, memory allocation, and other information — all that while respecting the need for low overhead, data export format, and granularity. We’ll dig into some of the operating systems and CPython internals to understand how to build the best profiler possible.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3077",
            "value": "Julien Danjou"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9935.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9318",
        "start": "15:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_reactive_programming",
        "title": "Introduction to Reactive Programming with RxPY",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Reactive Programming is an event based programming method. ReactiveX is a cross-platform implementation of Reactive Programming. It is heavily inspired from functional programming and contains many operators that allow to create, modify, and combine streams of events. Moreover it is composable and extensible. This short introduction presents Reactive Programming through RxPY, the Python implementation of ReactiveX.<\/p>",
        "description": "<p>The aim of this talk is to present RxPY to people that never used it, or used RxPY v1:<\/p>\n\n<ul>\n<li>Principles of Reactive Programming<\/li>\n<li>What is ReactiveX and RxPY<\/li>\n<li>Short history of RxPY<\/li>\n<li>How to deal with errors<\/li>\n<li>how to deal with concurrency<\/li>\n<li>How to document your code with marble and reactivity diagrams<\/li>\n<\/ul>\n\n\n<p>The examples of the presentations are done with RxPY v3, that has been released this summer. This release contains major improvements over RxPY v1 (v2 has never been released).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6631",
            "value": "Romain Picard"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/reactivex/rxpy",
            "value": "RxPY GitHub"
          },
          {
            "_href": "http://reactivex.io/",
            "value": "ReactiveX website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9318.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10545",
        "start": "16:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_httpx",
        "title": "Introducing HTTPX",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HTTPX is a next generation HTTP client, that supports HTTP/2 and HTTP/1.1.<\/p>\n\n<p>It can be used in high-performance async web frameworks, using either asyncio or trio, and is able to support making large numbers of requests concurrently.<\/p>\n\n<p>This talk will introduce HTTPX, demonstrate some of its features, and talk through the motivation and aims for the project.<\/p>",
        "description": "<p>The talk will cover:<\/p>\n\n<ul>\n<li>Why HTTPX exists &amp; what new functionality HTTPX brings to the table.<\/li>\n<li>How and where HTTPX differs from the existing <code>Requests<\/code> package.<\/li>\n<li>Examples of making parallel HTTP requests.<\/li>\n<li>Examples of making HTTP/2 requests.<\/li>\n<li>Examples of making requests directly to a web application, rather than over the network.<\/li>\n<li>Using Asyncio vs using Trio.<\/li>\n<li>A quick architecture overview.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7294",
            "value": "Tom Christie"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10545.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9990",
        "start": "16:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_foxdot",
        "title": "FoxDot and the Summer of 2019",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Yeah, this is about my last summer. But I promise to focus on the story of how I was able to do four amazing lightning talks with Python and a harmonica.<\/p>\n\n<p>This one is not about technical stuff, it is about finding something that python overlaps with your hobbies and sharing it back to the community.<\/p>",
        "description": "<p>This talk is about writing songs and playing music with python. Back in 2017 I came to know FoxDot, a python wrapper around SuperCollider, which is a super popular open source synthesizer. Since then, I have been using it to create entertaining lighting talks and would like to cover a bit more than just a lightning talk this time.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5949",
            "value": "Moisés Guimarães"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9990.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9672",
        "start": "17:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_monads",
        "title": "Monads in Python: why and how?",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I would give some motivating examples behind the idea of monads in Python, and show some implementation examples. I'd also show how we can leverage AST transformations to make the Python syntax more amenable to the use of monads. I have already given a talk on this topic during Pycon France 2018 in Lille. Unfortunately, the video footage has been lost, but the original slides can be found here: https://slides.com/v-perez/pythonic-monads-in-real-life#/<\/p>\n\n<p>If this talk was selected, I'd probably update it a bit to account for the feedback I received, and new ideas I may have.<\/p>",
        "description": "<p>In this talk I would give some motivating examples behind the idea of monads in Python, and show some implementation examples. I'd also show how we can leverage AST transformations to make the Python syntax more amenable to the use of monads. I have already given a talk on this topic during Pycon France 2018 in Lille. Unfortunately, the video footage has been lost, but the original slides can be found here: https://slides.com/v-perez/pythonic-monads-in-real-life#/<\/p>\n\n<p>If this talk was selected, I'd probably update it a bit to account for the feedback I received, and new ideas I may have.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6893",
            "value": "Vincent Perez"
          }
        },
        "links":
        [
          {
            "_href": "https://slides.com/v-perez/pythonic-monads-in-real-life#/",
            "value": "slides for PyconFR"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9672.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9094",
        "start": "17:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_repacker",
        "title": "repcloud",
        "subtitle": "A repacker for PostgreSQL in cloud",
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>repcloud is a tool for repacking postgresql databases in cloud written in python3.<\/p>",
        "description": "<p>repcloud is a tool for repacking postgresql databases hosted in cloud.\nas pgrepack is a far better approach for repacking tables online, there are situations where is not possible to install the extension on a postgresql if it's hosted in cloud (e.g. Heroku).\nHence comes repcloud which can help in rebuilding the tables on line with the use of simple SQL and some postgreSQL magic.\nThe author will explain how the project started, the functionalities and the limitations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5052",
            "value": "Federico Campoli"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/the4thdoctor/repcloud",
            "value": "repcloud on github"
          },
          {
            "_href": "https://pypi.org/project/repcloud/",
            "value": "repcloud on pypi"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9094.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9614",
        "start": "18:00",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_thot",
        "title": "Thoth - a recommendation engine for Python applications",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Project Thoth is a recommendation engine that collects information about software packages, container images such as installation, assembling issues, runtime crashes or information about performance. This information is subsequently used in a recommendation engine that searches large state space of libraries and recommends the best possible combination of libraries suitable for your application. Let’s have a look at how such information is collected and how the large state space is explored to resolve the best application stack for your Python application based on different aspects.<\/p>",
        "description": "<p>Python ecosystem is experiencing significant growth and popularity especially with the hype machine learning, data science and AI are creating. As the ecosystem grows its many times not straightforward and easy to decide which libraries in which versions are the most suitable ones for an application. Project Thoth is a recommendation engine which aggregates various characteristics of Python packages, called \"observations\", and uses them to recommend the best possible software stack (a fully pinned down list of dependencies) suitable for user's runtime environment and the application purpose. In this talk, we give an overview of the project Thoth, main ideas in data aggregation and its recommendation engine. We will also show how you can benefit from Thoth's recommendations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3993",
            "value": "Fridolín Pokorný"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/thoth-station",
            "value": "GitHub organization with all the sources"
          },
          {
            "_href": "https://thoth-station.ninja",
            "value": "Project home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9614.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9701",
        "start": "18:30",
        "duration": "00:25",
        "room": "UB2.252A (Lameere)",
        "slug": "python2020_pythran",
        "title": "The Pythran compiler, 7 years later",
        "subtitle": [],
        "track": "Python",
        "type": "devroom",
        "language": [],
        "abstract": "<p>7 years ago, a first file was commited in the Pythran git repo in order to create a compiler from Python to C++. The project now has hundreds of downloads per day on PyPI and has moved to a cross-platform compiler for scientific programs. This talks walks through the initial ideas, sorting out the good and the bad ones and compares the approach with other major Pythran compilers for scientific programs, most notably Cython, Pypy and Numba.<\/p>",
        "description": "<p>Relevant topics include :<\/p>\n\n<ul>\n<li>Numpy compatibility<\/li>\n<li>Abstraction level<\/li>\n<li>Backward compatibility with Python<\/li>\n<li>Taking advantage of hardware<\/li>\n<li>Translating or optimizing<\/li>\n<li>Community interaction<\/li>\n<li>Multi-platform support<\/li>\n<li>Benchmarking<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "4847",
            "value": "Serge Guelton (serge-sans-paille)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9701.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.132",
    "event":
    [
      {
        "_id": "9882",
        "start": "13:00",
        "duration": "02:00",
        "room": "UB4.132",
        "slug": "cert_lpi_1",
        "title": "LPI Exam Session 1",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<h3>LPI offers discounted certification exams at FOSDEM<\/h3>",
        "description": "<p>As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.\nLPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost <strong>50% discount<\/strong>.<\/p>\n\n<p>For further information and instructions see <a href=\"https://fosdem.org/certification\">https://fosdem.org/certification<\/a>.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1083",
            "value": "LPI Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9882.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9883",
        "start": "15:30",
        "duration": "02:00",
        "room": "UB4.132",
        "slug": "cert_lpi_2",
        "title": "LPI Exam Session 2",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<h3>LPI offers discounted certification exams at FOSDEM<\/h3>",
        "description": "<p>As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.\nLPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost <strong>50% discount<\/strong>.<\/p>\n\n<p>For further information and instructions see <a href=\"https://fosdem.org/certification\">https://fosdem.org/certification<\/a>.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1083",
            "value": "LPI Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9883.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.136",
    "event":
    [
      {
        "_id": "9345",
        "start": "10:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "openoffice_build_system",
        "title": "Openoffice Build system",
        "subtitle": "A walk through building OpenOffice",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will be about the OpenOffice Build system. We will talk about how it works today's, issues with it. And the talk will highlight current development in this field plus where it might moves in the future. (plans of development)<\/p>\n\n<p>Sheduled length will be 20 min +question<\/p>",
        "description": "<p>Currently the build system is a mixture of dmake, gmake, ant and other tools. After a short going through I like to describe the vision we have for the future build system we are working towards.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5243",
            "value": "Peter Kovacs"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9345.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9831",
        "start": "11:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "contributing_to_libreoffice_without_c_knowledge",
        "title": "Contributing to LibreOffice without C++ knowledge",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A good grasp of C++ is rather useful when it comes to improving LibreOffice. However, in the project there are vital roles and tasks that do not involve writing C++. This talk explores these other ways of contributing.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6939",
            "value": "Ilmari Lauhakangas"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9831.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10315",
        "start": "11:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "coverity_and_oss_fuzz_issue_solving",
        "title": "coverity and oss-fuzz issue solving",
        "subtitle": "common patterns for solving reported issues",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2068",
            "value": "Caolán McNamara"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10315.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10485",
        "start": "12:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "libreoffice_lockdown_and_encryption_improvements",
        "title": "LibreOffice lockdown and encryption improvements",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LibreOffice has builtin support for working with encrypted documents since a long time (with some recent improvements adding OpenPGP support). Further support for more fine-grained control of <em>what<\/em> a user can do with access-restricted documents was though missing.\nCome and see what recent improvements we implemented for LibreOffice 6.4 and 6.5, to permit fine-grained access controls to individual LibreOffice documents, matching the feature set of MS Rights Management Solution.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2006",
            "value": "Thorsten Behrens"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10485.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10472",
        "start": "12:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "prioritizing_is_key",
        "title": "Prioritizing is key",
        "subtitle": "How to prioritize thousands of bugs without dying in the attempt",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4341",
            "value": "Xisco Fauli"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10472.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9807",
        "start": "13:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "proposal_to_inspect_and_highlight_styles_in_writer",
        "title": "Proposal to inspect and highlight styles in Writer",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Styles are the essence of a text processor. And while experts love to unleash the power of LibreOffice Writer, it’s at the same time a major source of nuisance. In particular when you receive documents from other people, it can be quite difficult to understand the applied formatting and to fix issues around. This talk presents two ideas for an improved feedback.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4331",
            "value": "Heiko Tietze"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9807.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9801",
        "start": "13:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "libreoffice_theme_changer",
        "title": "LibreOffice Theme Changer",
        "subtitle": "An Extension for Customize LibreOffice Appearance in Easy Way",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LibreOffice is free and open source office suite software that is very popular today. LibreOffice is almost used in various user segments, ranging from personal, community, education, and even companies. It would be very interesting to be able to have LibreOffice specific themes for each segment. For this reason, we (LibreOffice Indonesia Community) took the initiative to create a special extension to manage themes in LibreOffice, we call it LO-TC (read: Lotis) LibreOffice Theme Changer.<\/p>",
        "description": "<p>LibreOffice is free and open source office suite software that is very popular today. LibreOffice is almost used in various user segments, ranging from personal, community, education, and even companies. It would be very interesting to be able to have LibreOffice specific themes for each segment. This of course will also further strengthen the fact LibreOffice is truly free software.\nUnfortunately, the features to set themes in LibreOffice are currently limited. As of now, LibreOffice only provides 6 theme choices for users. In the previous version, although there were many bug and problems, there was a persona theme menu that was quite interesting to me. For this reason, I and my friends in the LibreOffice Indonesia Community took the initiative to create a special extension to manage themes in LibreOffice, we call it LO-TC (read: Lotis) LibreOffice Theme Changer.\nLO-TC was originally just a simple bash script that allows users to change some visual components in LibreOffice, some of which are:<\/p>\n\n<pre><code>• Images in headers and footers\n• Intro or splash screen\n• Colors in the application, and\n• Icons (optional)\n<\/code><\/pre>\n\n<p>Because it is only based on bash scripts, LO-TC can only be used for Linux and Mac (with a few adjustments). Because of this limitation, we finally decided to rewrite LO-TC in the form of extensions so that it could later be used on many operating systems.\nThe various LibreOffice installation models (via repositories of distributions, snap, flatpak, etc.) pose quite daunting challenges for developers. In addition, this is our first extension project, so we need a lot of new things that we must understand in the process of working on this latest LO-TC. Current status of LO-TC development can be found here: https://github.com/libreofficeid/LO-TC-GUI<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6948",
            "value": "Rania Amina"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/libreofficeid/LO-TC-GUI",
            "value": "Development Repository"
          },
          {
            "_href": "http://docs.libreoffice.id/lotc",
            "value": "Project Documentations"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9801.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10482",
        "start": "14:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "creating_word_clouds_with_openoffice",
        "title": "Creating Word Clouds with OpenOffice",
        "subtitle": "Text mining and visualization in Writer",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OpenOffice Writer offers all features needed for basic frequency analysis and visualization. We'll see how to do automated text analysis and simple word clouds without using specialized external tools.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1275",
            "value": "Andrea Pescetti"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10482.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9862",
        "start": "14:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "crowdfunding_to_advance_open_document_editors",
        "title": "Crowdfunding to advance open document editors",
        "subtitle": "A status report",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Productivity software like LibreOffice has long been sustained by the commercial activities of community members as well as the contributions of countless volunteers. That's also driven standards engagement, like the work around Open Document Format (ODF). But the cloud is slowly strangling the desktop support business, and spare-time volunteers may not be enough for complex, mature software. The Document Foundation has been innovating to sustain LibreOffice and ODF; this talk will describe the COSM and TDC projects, and ask whether similar approaches might sustain other open source desktop software.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "228",
            "value": "Simon Phipps"
          }
        },
        "links":
        [
          {
            "_href": "https://publicsoftware.eu/members/cosm-project/",
            "value": "About the COSM Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9862.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10468",
        "start": "15:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "online_open_document_editing_new_possibilities",
        "title": "Online Open Document Editing New Possibilities",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Document editing is, as many things in life, more and more an online action. Collabora introduced the important first steps in 2015. Since then much work has been done and LibreOffice and Collabora Online grew enormously in possibilities. This presentation will guide you trough the various areas. And in the Q&amp;A, lets talk about expectations for the future.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7270",
            "value": "Cor Nouws"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10468.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10286",
        "start": "15:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "make_online_yours",
        "title": "Make Online yours",
        "subtitle": "How to customize Collabora Online",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Collabora Online - The driving force behind putting LibreOffice in the cloud -is quite flexible in the means that you can alter to your personal taste without the need to change other core components.<\/p>",
        "description": "<p>Collabora Online - The driving force behind putting LibreOffice in the cloud - is quite flexible in the means that you can alter to your personal taste without the need to change other core components.\nTag along and see how can you customize Online's look and feel without a sweat and using mainly CSS, SVG! Don't know much about web technologies? No problem! There is no requirement to be eligible to attend, as I'll be talking in a casual fashion and with examples and hopefully illustrate each step of the way.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5882",
            "value": "Pedro Pinto Silva"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10286.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10288",
        "start": "16:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "online_wrestling_web_copy_paste_to_usability",
        "title": "Online: wrestling web Copy/Paste to usability",
        "subtitle": "Defeating the API and implementation disasters in copy/paste",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Overcoming the synchronous web copy/paste API's limitations in real\nbrowsers is extremely non-trivial. Come &amp; hear how we provide rich\ncopy/paste support across browsers, inside our app and hear a bit\nabout how this mess should be fixed.<\/p>",
        "description": "<p>Collabora has been working to provide a good user-experience for Collabora\nOnline - bringing LibreOffice to the web, and a particularly\nchallenging aspect of this has been copy/paste. One of our challenges\nis that by design we keep our document data on the server, which is at\nthe end of an asynchronous web-socket. Another challenge is the\nimpossibly baroque and arguably mis-designed set of clipboard APIs\nthat we have to work with.<\/p>\n\n<p>Hear a story of how we defeated the issues, as well as the somewhat\nsad UX compromises we were forced to make for the hard cases.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "425",
            "value": "Michael Meeks"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10288.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10342",
        "start": "16:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "integrate_collabora_online_with_web_applications",
        "title": "Integrate Collabora Online with web applications",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Come and hear how to integrate Collabora Online – a powerful online office suite based on LibreOffice code – with web applications. Learn about how Collabora developers helped to develop solutions by extending the WOPI-like API and PostMessage API of Collabora Online.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "313",
            "value": "Andras Timar"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10342.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9659",
        "start": "17:00",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "libreoffice_online_adoption_into_1_and_1_mail_and_media_ecosystem",
        "title": "LibreOffice Online adoption into 1&1 Mail&Media ecosystem",
        "subtitle": "Brief overview of the open-source adoption of project LibreOffice Online into 1&1 Mail&Media ecosystem: WEB.DE, GMX, mail.com brands",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6872",
            "value": "Eduard Ardeleanu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9659.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10349",
        "start": "17:30",
        "duration": "00:25",
        "room": "UB4.136",
        "slug": "collabora_office_android_app_gory_details",
        "title": "Collabora Office Android app gory details",
        "subtitle": "How we tweaked LibreOffice & the Online to get an Android app",
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The LibreOffice Android app consists of the LibreOffice core as the native code and Java part that takes care of compositing of the tiles, input handling, etc.  It is hard to maintain, because everything that has been implemented in LibreOfficeKit for the Online has to be ported to Java - which is a huge amount of work.<\/p>\n\n<p>For the Collabora Office Android app, we have tried a new approach - to build on top of work pioneered by Tor Lillqvist for iOS: Using the native code for the rendering, the Online JavaScript for the composition of tiles, input handling, etc. and only a thin Java layer to instantiate a WebView where the JS lives.<\/p>\n\n<p>Come and see the current state!  And don't worry, all the work is contributed back to the LibreOffice code too :-)<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "317",
            "value": "Jan Holesovsky"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10349.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10483",
        "start": "18:00",
        "duration": "00:55",
        "room": "UB4.136",
        "slug": "lightning_talk_session",
        "title": "Lightning talk session",
        "subtitle": [],
        "track": "Open Document Editors",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2006",
            "value": "Thorsten Behrens"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10483.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.228",
    "event":
    {
      "_id": "9063",
      "start": "10:30",
      "duration": "08:30",
      "room": "UB4.228",
      "slug": "soldering_workshop_saturday",
      "title": "Open Source Hardware and Soldering Workshop",
      "subtitle": [],
      "track": "Workshops",
      "type": "workshop",
      "language": [],
      "abstract": "<p>Open Source Hardware room with two day soldering workshops.\nDay 1 soldering workshop will be dedicated to Through Hole Technology and is good for beginners which has no experience with component soldering.<\/p>\n\n<p>Beside the soldering workshop we will show our latest OSHW boards we work on, you are welcome to join and show your own OSHW projects too.<\/p>",
      "description": "<p>With this soldering workshop we will show that assembling printed circuit boards is not hard to learn.<\/p>\n\n<p>We designed special board with through holes components for FOSDEM - the FOSDEM MUSIC BOX which is Arduino programmable and can play music.<\/p>\n\n<p>During the soldering workshop we will introduce the electronic components used in the PCB and how to identify them and how components with polarity is to be recognized.<\/p>\n\n<p>We will teach you the basics of soldering, how good and bad solder joints look like and what is cold solder joint.\nAt the end of the workshop you will build your own Music Box and could program it with Arduino IDE to play music.<\/p>",
      "persons":
      {
        "person":
        {
          "_id": "1641",
          "value": "Tsvetan Usunov"
        }
      },
      "links":
      {
        "link":
        {
          "_href": "https://submission.fosdem.org/feedback/9063.php",
          "value": "Submit feedback"
        }
      }
    }
  },
  {
    "_name": "UB5.132"
  },
  {
    "_name": "UB5.230"
  },
  {
    "_name": "UD2.119",
    "event":
    [
      {
        "_id": "9544",
        "start": "10:30",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "drlm",
        "title": "Past, Present and Future of DRLM project",
        "subtitle": [],
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Brief introduction to DRLM project, it's features and news in the 2.3.x release and the presentation of the new DRLM version 3 architecture and its development state.<\/p>",
        "description": "<p>This talk is going to explain our vision on the future of the DRLM project, that will continue evolving in DRLM 2.x while the new DRLMv3 is being developed.<\/p>\n\n<p>For DRLMv3 we've prepared a complete development environment on Docker to provide an easy and fast way to contribute to the project.<\/p>\n\n<p>In this session we'll show all interesting new features on DRLMv2, a DRLMv3 preview of what is developed at time of this presentation, and how easy is to have a complete DRLMv3 development\nenvironment with a couple of commands.<\/p>\n\n<p>We don't want to spoil anything, but this talk may be of interest for developers looking for a FLOSS project to contribute to ;).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3920",
            "value": "Didac Oliveira"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9544.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9598",
        "start": "11:05",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "basicrear",
        "title": "Relax-and-Recover (ReaR) Basics",
        "subtitle": "with Demo on Real Hardware",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Introducing Relax-and-Recover (ReaR) for the novice users. What is it and what can it mean for you? Is Disaster Recovery useful to consider it or not? How can ReaR assist you with DR?\nReaR can store the details about your systems on disks (NAS, USB, SAN,...) or network (PXE, NFS, CIFS,...) including the complete backup. It also creates a bootable image which you need to recreate your system from scratch.\nFurthermore, thanks to the modular concept, ReaR integrates perfectly with external backup solutions (be commercial and/or open source ones) to do the backup and restore part which makes ReaR very scalable in big enterprises. ReaR scales even with Cloud solutions and is the heart of another great project (DRLM or Disaster Recovery Linux Manager).<\/p>",
        "description": "<p>Relax-and-Recover (ReaR) is the de facto standard generic (bare metal) disaster recovery framework for all kind of Linux systems.\nReaR is in common use by admins for disaster recovery on thousands and thousands of Linux server systems.\nThe first part of the \"ReaR Basics\" talk will be presented by Gratien D'haese (one of the co-founders of ReaR).<\/p>\n\n<p>In the second part of the talk Johannes Meixner (one of the main developers of ReaR) will use his own laptop to demonstrate the ReaR disaster recovery framework.\nTherefore, Johannes will show a real live demo without safety net how ReaR is used to recover his own laptop from soft errors like deleted essential files\n(rm -r /lib...) and/or destroyed partitioning/bootloader (dd if=/dev/zero of=/dev/sdX). Come and see for yourself how ReaR can save your day!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "8",
            "value": "Gratien D'haese"
          }
        },
        "links":
        [
          {
            "_href": "http://relax-and-recover.org",
            "value": "Relax-and-Recover"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9598.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9373",
        "start": "11:40",
        "duration": "00:25",
        "room": "UD2.119",
        "slug": "massrear",
        "title": "Relax-and-Recover (ReaR) Mass Deployment",
        "subtitle": [],
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Installing and configuring ReaR on thousands of Linux systems might become a nightmare to keep track what/where was done with success. Luckily using configuration management software we can do this quite easily.\nIn this talk we will guide you through a recipe on how we have done this for a multi-national company.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "8",
            "value": "Gratien D'haese"
          }
        },
        "links":
        [
          {
            "_href": "http://relax-and-recover.org/",
            "value": "Relax-and-Recover"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9373.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10699",
        "start": "12:10",
        "duration": "00:25",
        "room": "UD2.119",
        "slug": "bareosintro",
        "title": "Overview of Bareos",
        "subtitle": "What is Bareos and what is new in 19.2?",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will give quick overview of Bareos and the new features in Bareos 19.2.<\/p>",
        "description": "<p>This talk will give quick overview of Bareos and the new features in Bareos 19.2.<\/p>",
        "persons": [],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10699.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10700",
        "start": "12:40",
        "duration": "00:15",
        "room": "UD2.119",
        "slug": "bareosovirt",
        "title": "oVirt-Plugin for Bareos",
        "subtitle": "Backing up oVirt using Bareos",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Backing up virtual machines in larger environments is usually not a simple task. With the new oVirt-Plugin for Bareos you can now easily backup and restore your oVirt virtual machines.\nThis talk will give a short introduction how Bareos backs up oVirt virtual machines.<\/p>",
        "description": [],
        "persons": [],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10700.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10038",
        "start": "13:00",
        "duration": "00:15",
        "room": "UD2.119",
        "slug": "velero",
        "title": "Preserve kubernetes state using heptio velero",
        "subtitle": [],
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Stateful applications like databases needs to preserve their state as they need to save client data of one session for use in next session in persistent storage. Managing state in Kubernetes is difficult because the system’s dynamism is too chaotic for most databases to handle. So backup of data is very important especially in case of node failures, disk failures etc.\nVelero is an open source tool to safely backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes.\nIn this talk, I will elaborate on why, how and when to use velero for your Kubernetes cluster and volumes.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6836",
            "value": "Harshita Sharma"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10038.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10646",
        "start": "13:20",
        "duration": "00:15",
        "room": "UD2.119",
        "slug": "xtrabackup",
        "title": "Percona XtraBackup Current and Future State",
        "subtitle": "What's the future for the open-source industry standard for MySQL hot backup?",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A brief overview of the current state of the backup tool, architecture, MySQL 8.0 support, new cloud native features, and the roadmap.<\/p>",
        "description": "<p>During this brief lecture, I will present the roadmap for Percona XtraBackup, talk about the importance of our Cloud direction, why PXB 8.0 is a separate binary, and how PXB fits into our Percona Distribution model for 2020.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7346",
            "value": "Tyler Duzan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10646.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9357",
        "start": "13:40",
        "duration": "00:15",
        "room": "UD2.119",
        "slug": "perconamongodb",
        "title": "Percona Backup for MongoDB: Status and Plans",
        "subtitle": "Open Source solution for consistent backups of multi-shard MongoDB",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A brief overview of the current state of backup tool, architecture, existing features, and the roadmap.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4801",
            "value": "Mykola Marzhan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9357.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9607",
        "start": "14:00",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "borg",
        "title": "Self-hosted server backups for the paranoid",
        "subtitle": "Using Borg, SSH, Python and FreeNAS to securely backup Linux servers",
        "track": "Backup and Recovery",
        "type": "devroom",
        "language": [],
        "abstract": "<p><a href=\"https://quarkslab.com/en/\">Quarkslab<\/a> is a French company specializing in information security R&amp;D, consulting and software development.<\/p>\n\n<p>Due to strong data security constraints imposing self-hosted solutions coupled with limited resources in a fast-growth environment, data safety has been a pain point in our infrastructure.<\/p>\n\n<p>After our backup server failed, we decided to recreate a new backup system from scratch, adapted to our needs and using technologies we were familiar with, to backup 30+ Linux servers.<\/p>\n\n<hr />\n\n<p>In this talk, we will present how our old backup system failed, the key requirements we learned from this failure, and how we designed and implemented a new backup system based on <a href=\"https://borgbackup.readthedocs.io/en/stable/\">Borg Backup<\/a>, <a href=\"https://github.com/witten/borgmatic\">borgmatic<\/a>, SSH, Python and <a href=\"https://www.freenas.org/\">FreeNAS<\/a> to solve those requirements.<\/p>\n\n<p>We will conclude by listing the shortcomings and improvement points of our approach, as well as comparing our solution to seven important properties every backup system should have.<\/p>\n\n<hr />\n\n<p>Some interesting features of our new backup solution are strong data safety and security, fully self-hosted, using only open-source tools, simple to set up and easy to understand.<\/p>\n\n<p>One specific requirement we solved was for the sysadmin team to be blind to the data they backup, managing only the process itself.<\/p>\n\n<p>This lets people working on confidential project on dedicated and access-restricted servers to still use a centralized and resilient backup system without compromising data and server security.<\/p>\n\n<hr />\n\n<p>We will open-source our Ansible roles and Python scripts on <a href=\"https://github.com/quarkslab\">Github<\/a> before FOSDEM.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6806",
            "value": "Axel Tripier"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9607.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10536",
        "start": "15:00",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "fasten_scaling_static_analyses_to_ecosystems",
        "title": "FASTEN: Scaling static analyses to ecosystems",
        "subtitle": [],
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As recent events, such as the leftpad incident and the Equifax data breach, have demonstrated, dependencies on networks of external libraries can introduce projects to significant operational and\ncompliance risks as well as difficult to assess security implications. FASTEN introduces fine-grained, method-level, tracking of dependencies on top of existing dependency management networks. In our talk, we will present how FASTEN works on top of the Rust/Cargo and Java/Maven ecosystems.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3845",
            "value": "Georgios Gousios"
          }
        },
        "links":
        [
          {
            "_href": "https://www.fasten-project.eu/view/Main/Introduction",
            "value": "fine-grained and method-level tracking of dependencies with FASTEN project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10536.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9526",
        "start": "15:30",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "foss_sustainability_issues",
        "title": "There's no sustainability problem in FOSS",
        "subtitle": "Except that there is.",
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The community seems to be rife with conversations about our sustainability problems. Do we actually have one? We’ll lead a discussion and debate around how we as a community can think about these issues, while drawing out the nuanced aspects of each as well as their potential solutions.<\/p>",
        "description": "<p>When something like left-pad or event-stream happens, how much responsibility should be taken on by companies who deployed a dependency that was critical enough to their operations that removing it created immediate crisis, but not well supported or understood enough that there was any kind of mitigation strategy or backup plan?<\/p>\n\n<p>And yet, when you look at OpenSSL, curl, and other pieces of open source infrastructure that live in our dependency chains, there are many examples of projects that are important enough to be critical, but are under-resourced to the point that maintainers are having to make quality-of-life tradeoffs to stay on top of the project. We are responsible for ensuring that our shared dependencies are sustainably developed. But who is holding us accountable?<\/p>\n\n<p>If a maintainer is driving themselves to burnout because they are supporting too many of their open source projects, don’t they bear some responsibility for that choice?<\/p>\n\n<p>But how are we supposed to untangle which of the thousands of dependencies that we use are in most need of support - and what kind of support they prefer?<\/p>\n\n<p>Is there a sustainability problem in FOSS after all?<\/p>\n\n<p>This presentation will be co-presented with Duane O'Brien, Head of Open Source at Indeed.com, the world’s #1 jobs site.<\/p>",
        "persons":
        [
          {
            "_id": "5041",
            "value": "Carol Smith"
          },
          {
            "_id": "5854",
            "value": "Duane O'Brien"
          }
        ],
        "links":
        [
          {
            "_href": "http://fossygirl.com",
            "value": "Carol Smith's personal website"
          },
          {
            "_href": "http://duaneobrien.com",
            "value": "Duane O'Brien's github account"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9526.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9669",
        "start": "16:00",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "comparing_dependency_management_issues",
        "title": "Comparing dependency management issues across packaging ecosystems",
        "subtitle": [],
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In the last couple of years, the Software Engineering Lab of the University of Mons has extensively studied different aspects of dependency management within and across different package management ecosystems, including Cargo, npm, Packagist, Rubygems, CPAN, CRAN and NuGet. These ecosystems contain a large number of package releases with many interdependencies. They face challenges related to their scale, complexity, and rate of evolution. Typical problems are backward incompatible package updates, and the increasing proportion of fragile packages due to an excessive number of transitive dependencies.<\/p>",
        "description": "<p>This talk reports on our findings based on multiple empirical studies that we have conducted to understand different aspects of dependency management and their practical implications. This includes:\n- the outdatedness of package dependencies, the transitive impact of such \"technical lag\", and its relation to the presence of bugs and security vulnerabilities.\n- the impact of using either more permissive or more restrictive version contraints on dependencies.\n- the virtues and limitations of being compliant to semantic versioning, a common policy to inform dependents whether new releases of software packages introduce possibly backward incompatible changes.\n- the impact of specific characteristics, policies and tools used by the packaging ecosystem and its supporting community on all of the above.<\/p>\n\n<p>The contents of the talk will be adapted to the target audience of open source software practitioners, but will be primarily based on the following peer-reviewed scientific articles:\n- What do package dependencies tell us about semantic versioning? Alexandre Decan, Tom Mens. IEEE Transactions on Software Engineering, 2019. https://doi.org/10.1109/TSE.2019.2918315\n- An empirical comparison of dependency network evolution in seven software packaging ecosystems. Alexandre Decan, Tom Mens, Philippe Grosjean. Empirical Software Engineering 24(1):381-416, 2019. https://doi.org/10.1007/s10664-017-9589-y\n- A formal framework for measuring technical lag in component repositories and its application to npm. Ahmed Zerouali, Tom Mens, Jesus Gonzalez‐Barahona, Alexandre Decan, Eleni Constantinou, Gregorio Robles. Journal of Software: Evolution and Process 31(8), 2019. https://doi.org/10.1002/smr.2157\n- On the Impact of Security Vulnerabilities in the npm Package Dependency Network. Alexandre Decan, Tom Mens, Eleni Constantinou. International Conference on Mining Software Repositories, 2018. https://doi.org/10.1145/3196398.3196401\n- On the Evolution of Technical Lag in the npm Package Dependency Network.  Alexandre Decan, Tom Mens, Eleni Constantinou. International Conference on Software Maintenance and Evolution, 2018. https://doi.org/10.1109/ICSME.2018.00050<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6889",
            "value": "Tom Mens"
          }
        },
        "links":
        [
          {
            "_href": "https://doi.org/10.1109/TSE.2019.2918315",
            "value": "What do package dependencies tell us about semantic versioning?"
          },
          {
            "_href": "https://doi.org/10.1007/s10664-017-9589-y",
            "value": "An empirical comparison of dependency network evolution in seven software packaging ecosystems"
          },
          {
            "_href": "https://doi.org/10.1002/smr.2157",
            "value": "A formal framework for measuring technical lag in component repositories and its application to npm"
          },
          {
            "_href": "https://doi.org/10.1145/3196398.3196401",
            "value": "On the Impact of Security Vulnerabilities in the npm Package Dependency Network"
          },
          {
            "_href": "https://doi.org/10.1109/ICSME.2018.00050",
            "value": "On the Evolution of Technical Lag in the npm Package Dependency Network"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9669.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10064",
        "start": "16:30",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "building_confidence_in_security",
        "title": "Building Confidence & Overcoming Insecurity",
        "subtitle": "The ultimate software supply chain self-help guide",
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": "<p>The days of having only a few open source dependencies are over. Projects often have thousands of open source dependencies in their supply chain and companies may have millions. Even worse, risk is viral -- projects inherit and pass on the risks of all their dependencies. At the same time, software is shipping more frequently.<\/p>\n\n<p>This creates numerous challenges for commercial and open source projects of any size -- how to discover the myriad of components being used across a range of ecosystems and scenarios, where to get high quality data to drive smart decisions, how to capture and evaluate comprehensive policies.<\/p>\n\n<p>Enabling high-confidence, rapid delivery, requires integrating supply chain management automation deep into the engineering system. Core to this is accurate discovery and identification of dependencies and trustworthy, high-quality compliance and security data about the discovered components.<\/p>\n\n<p>In this talk we detail the challenges in this space, look at various approaches such as ClearlyDefined, a crowd-sourced, open source project aimed at discovering and curating compliance data about open source components, and relate experiences running high performance, massive scale compliance systems for a wide range of open source and commercial projects.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5990",
            "value": "Jeff McAffer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10064.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10574",
        "start": "17:00",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "github_cross_project_code_navigation",
        "title": "Precise, cross-project code navigation at GitHub scale",
        "subtitle": [],
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GitHub has recently added Code Navigation features (jump to definition and find all references) that let you navigate code directly on <a href=\"github.com\">github.com<\/a>. For the languages that we support, we extract and store symbol information for every named branch and tag, of every repository, public or private, with no configuration necessary. The compute and storage requirements to do this for all of the code on GitHub are quite large. In this talk, we'll discuss some of the trade-offs we've made to make this tractable at GitHub's scale, to be able to operate and monitor this service effectively, and to let us add support for new languages quickly and easily. We'll also talk about our ongoing work to extend Code Navigation to handle links that cross package and repository boundaries.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7314",
            "value": "Douglas Creager"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10574.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10581",
        "start": "17:30",
        "duration": "00:30",
        "room": "UD2.119",
        "slug": "dependency_solving_not_just_sat",
        "title": "Spack's new Concretizer",
        "subtitle": "Dependency solving is more than just SAT!",
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Dependency resolution is deceptively complex; simply selecting a set of compatible versions for an arbitrary network of dependencies is NP-hard.  Much effort has been spent on this problem for modern single-language ecosystems, but many of these ecosystems rely on natively compiled libraries, and dependency mangers often fail at managing the additional complexities that native libraries entail.  Further, dependency resolution has traditionally been modeled as a SAT problem, where the package manager should find <em>any<\/em> workable solution to satisfy package constraints.  However, <em>any<\/em> solution may not be good enough.  Users want the most tested, most optimized, or most secure configuration, and this is a SAT problem coupled with complex optimization.<\/p>\n\n<p>Spack is a package/dependency manager rapidly gaining popularity in High Performance Computing (HPC) that aims to address many of the complexities of native, multi-language, cross-platform dependency management.  Spack has recently been reworked to use Answer Set Programming (ASP), a declarative logic programming paradigm that also provides sophisticated facilities for optimization.  This talk will cover how we’ve been able to model the compiler toolchain, ISA, build options, ABI, and other constraints on native libraries. We’ll also talk about how ASP has been a useful tool for finding <em>optimized<\/em> dependency configurations.  This work can be used to improve dependency resolvers in general — so that they can prefer more secure or tested configurations instead of simply selecting the most recent workable versions.<\/p>",
        "description": "<p>Expected prior knowledge / intended audience:\nAudience should have basic knowledge of build systems and compiled languages, but we'll explain this up front with some brief background. The talk is aimed broadly -- for users, developers, packagers, researchers, package manager implementors, and HPC administrators.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4884",
            "value": "Todd Gamblin"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=DRuyPDdNr0M",
            "value": "Presentation at HPCKP'19, Barcelona"
          },
          {
            "_href": "https://www.youtube.com/watch?v=edpgwyOD79E&t=2891s",
            "value": "Recent webinar on Spack for NCSA"
          },
          {
            "_href": "https://www.youtube.com/watch?v=BxNOxHu6FAI",
            "value": "Dinner talk at Argonne Training Program on Extreme-Scale Computing"
          },
          {
            "_href": "https://insidehpc.com/2019/03/spack-a-package-manager-for-hpc/",
            "value": "Talk at Stanford HPC conference"
          },
          {
            "_href": "https://www.youtube.com/watch?v=iTLBkpHskzA",
            "value": "PyBay 2019 Lightning talk (5 min)"
          },
          {
            "_href": "http://spack.io",
            "value": "Spack website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10581.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10063",
        "start": "18:00",
        "duration": "00:45",
        "room": "UD2.119",
        "slug": "package_management_panel",
        "title": "Package managers: resolve differences",
        "subtitle": "Lively panel discussion on package management",
        "track": "Dependency Management",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Package managers have become the default way for managing dependencies for most projects but they’re not without their challenges and risks. In this panel we bring together experts representing several popular package managers for a lively discussion on package management best practices, the state of package management communities, and a look forward at what we can expect to see in the future.<\/p>",
        "description": "<p>Join our facilitators as they put representatives of popular package managers on the spot with difficult questions on package management infrastructure, security, and compliance.<\/p>\n\n<p>We’ll tackle topics such as:\n* Versioning and naming\n* Knowing the full graph of packages you’re consuming\n* Best practices for securing your use of package managers\n* Finding and resolving vulnerabilities in packages you’re using\n* Malicious packages and typo-squatting\n* Meeting your open source license obligations\n* Dealing with dependencies that aren’t packages<\/p>\n\n<p>With package managers becoming the default way for managing dependencies, they are now a critical part of the software supply chain and while at first each package manager appears quite different, they share common requirements, are used in similar workflows, and are all targets for malicious actors.<\/p>\n\n<p>In this panel we will focus on those common problems so that regardless of which package manager you use, you’ll come away with a breadth of knowledge on how to securely use package managers in your software supply chain.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6899",
            "value": "William Bartholomew"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10063.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.120 (Chavanne)",
    "event":
    [
      {
        "_id": "10713",
        "start": "10:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "tanka",
        "title": "Introducing Tanka",
        "subtitle": "a scalable Jsonnet based tool for deploying and managing Kubernetes Infrastructure",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Introducing Tanka, a scalable Jsonnet based tool for deploying and managing Kubernetes Infrastructure<\/p>",
        "description": "<p>There are various tools available for managing Kubernetes resources. Whether they be Helm, Kustomize or others. Ksonnet offered a powerful approach with tremendous promise, but was discontinued by developers. In this presentation we will introduce Tanka, a drop in replacement for Ksonnet developed at Grafana labs and available on GitHub. For those not familiar with Ksonnet, we will introduce the Jsonnet language, and demonstrate its power as a way of interacting with Kubernetes. We will then demonstrate some of the enhancements we have already made to Tanka, and then explain our roadmap for the tooling, and how we believe it is already the best of breed configuration management solution for Kubernetes.<\/p>",
        "persons": [],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10713.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10558",
        "start": "11:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "openapi",
        "title": "Using OpenAPI to Maximise Your Pulp 3 Experience",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Pulp (https://pulpproject.org) enables users to organize and distribute software. Now that Pulp 3.0 is generally available, it’s time to integrate it into your software delivery workflows. While the REST API is the primary integration point, it is the OpenAPI schema definition of that API that enables users to build client libraries in various languages. These clients simplify the integration with Pulp 3.<\/p>\n\n<p>This talk will provide a brief introduction to OpenAPI. This will be followed by a demonstration of how to use the Pulp’s OpenAPI schema to generate a Python client for Pulp’s REST API. The Python client will then be used to perform various workflows in Pulp 3.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4708",
            "value": "Dennis Kliban"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10558.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10421",
        "start": "11:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "doomed",
        "title": "Doomed are the dinosaurs!",
        "subtitle": "Dealing with diversity by utilizing the versatility of Ansible and open source",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>It may be hard to image, but some sysadmins do not operate in ideal, tightly controlled circumstances. Apparently, not every developer, application or organization is ready for Kubernetes…<\/p>\n\n<p>In this presentation we will share a real world use case: deploying and configuring a brand new natural history museum. We’ll show how we built the museum with open source software and config management tools, dealing with a broad set of technologies, a tight schedule, a sector dominated by traditional organizations fixated on proprietary solutions and a whole bunch of actual fossils. We’ll show how far we’ve come, and what choices we made along the way.<\/p>\n\n<p>Check out this talk if you want to see how Ansible, MAAS, PlatformIO, Nextcloud and other tools were used to not just automatically deploy and configure Linux based media players, games and digital signage screens, but also to manage Cumulus Linux-based switches, OPNsense firewalls, show controllers, Arduino microcontrollers, KNX gateways, projectors and even the odd OSX machine.<\/p>",
        "description": "<p>It may be hard to image, but some sysadmins do not operate in ideal, tightly controlled circumstances. Apparently, not every developer, application or organization is ready for Kubernetes…<\/p>\n\n<p>In this presentation we will share a real world use case: deploying and configuring a brand new natural history museum. We’ll show how we built the museum with open source software and config management tools, dealing with a broad set of technologies, a tight schedule, a sector dominated by traditional organizations fixated on proprietary solutions and a whole bunch of actual fossils. We’ll show how far we’ve come, and what choices we made along the way.<\/p>\n\n<p>Check out this talk if you want to see how Ansible, MAAS, PlatformIO, Nextcloud and other tools were used to not just automatically deploy and configure Linux based media players, games and digital signage screens, but also to manage Cumulus Linux-based switches, OPNsense firewalls, show controllers, Arduino microcontrollers, KNX gateways, projectors and even the odd OSX machine.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7205",
            "value": "David Heijkamp"
          }
        },
        "links":
        [
          {
            "_href": "http://naturalis.nl",
            "value": "Naturalis Biodiversity Center"
          },
          {
            "_href": "http://gitlab.com/naturalis",
            "value": "Naturalis at Gitlab"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10421.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9936",
        "start": "12:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "openscap",
        "title": "Compliance management with OpenSCAP and Ansible",
        "subtitle": "Using OpenSCAP and Ansible for compliance management of large computing environments",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Managing compliance of large IT environment is complex and challenging task. Today's hybrid cloud environments are having different life cycles, when considering many short lived system like cloud instances its difficult to manage compliance on the go. This talk focuses on how OpenSCAP policies, tools and Ansible can be used to have greater control of compliance of large environments.<\/p>",
        "description": "<p>Compliance management with OpenSCAP<\/p>\n\n<p>Enterprise computing environments may consist of thousands of computer systems, having multiple applications and services. These systems are accessed by large and diverse set of users and applications. To have a greater control over security of these vast environments a standard and unified way to scan systems for compliance with security policies is needed.<\/p>\n\n<p>This talk focuses on using SCAP tools to retain control over large environments, scan compliance with desired policy, and use Ansible to remediate detected problems,<\/p>\n\n<pre><code>Install and use the SCAP Security Guide.\nEvaluate a server's compliance with the requirements specified by a policy from the SCAP Security Guide using OpenSCAP tools.\nCreate a tailoring file to adjust the policy's security checks so that they’re relevant and correct for a specific system and its use case.\nRun Ansible Playbooks, included in the SCAP Security Guide, to remediate compliance checks that failed an OpenSCAP scan.\nDemonstration\n<\/code><\/pre>",
        "persons":
        {
          "person":
          {
            "_id": "6531",
            "value": "Amit Upadhye"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9936.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10304",
        "start": "12:30",
        "duration": "00:55",
        "room": "UD2.120 (Chavanne)",
        "slug": "metal",
        "title": "Introduction to Metal³",
        "subtitle": "Kubernetes-native bare metal infrastructure management",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An introduction to Metal³, bare metal server provisioning in Kubernetes<\/p>",
        "description": "<p>Metal³ (https://metal3.io/) (pronounced “metal cubed”) is an open source bare metal provisioning project built on cloud-native technologies like Kubernetes and the Machine API from Kubernetes' SIG ClusterLifecycle. Metal³ can provision an operating system, manage the machine's life cycle, and ultimately decommission the machine. Metal³ can be used to provision any OS, but along with the cluster-api-provider, it can be used to install and scale bare metal Kuberentes clusters.<\/p>\n\n<p>We'll explain the motivations behind the project and what has been accomplished so far. This will be followed by an architectural overview and description of the Custom Resource Definitions (CRDs) for describing bare metal hosts, leading to a demonstration of using Metal³ in a cluster.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7188",
            "value": "Stephen Benjamin"
          }
        },
        "links":
        [
          {
            "_href": "http://metal3.io/",
            "value": "Metal3 Web Site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10304.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10352",
        "start": "13:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "ephemeral",
        "title": "Ephemeral Environments For Developers In Kubernetes",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A key aspect of a microservice architecture is to make sure individual services work in isolation. But as a developer its also important to make sure the service works in the full system. Providing developers a way to run pre-production code in a multi-service environment is challenging.<\/p>\n\n<p>Making use of existing Helm charts and defaulting to production configuration does part of the work. Also important is being able to extend upon tools like Telepresence/Ksync for debugging in k8s. But while these great tools are available, what has been lacking is the \"easy to use\", single command that gives a developer a place to work with their own full, self-contained system. There are now a few open source solutions to do just that (like Garden, Acyl, &amp; Armador). In this talk, Jeff will break down how these tools work, and what makes them different.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6208",
            "value": "Jeff Knurek"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10352.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10493",
        "start": "14:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "codeworkload",
        "title": "Code Workload Management into the Control Plane",
        "subtitle": "What it means to be \"Kubernetes Native\"",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Join us to learn why Operators are the leading and default approach for managing workloads on Kubernetes. We will pull back the curtain to show you exactly what an Operator is, how to make one, and what it means to be “Kubernetes Native”.<\/p>",
        "description": "<p>SREs automate every aspect of workload management. Applying this mentality to the Kubernetes space, a pattern has emerged for coding such automation directly into the control plane. By adding native extensions to the Kubernetes API that are tailored to individual workloads, the Operator pattern enables infrastructure and workloads to be managed side-by-side with one set of tooling and access control.<\/p>\n\n<p>Join us to learn why Operators are the leading and default approach for managing workloads on Kubernetes. We will pull back the curtain to show you exactly what an Operator is, how to make one, and what it means to be “Kubernetes Native”. To close we will discuss use cases from the field; how real organizations have created and/or re-used Operators to automate their operations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3493",
            "value": "Michael Hrivnak"
          }
        },
        "links":
        [
          {
            "_href": "https://www.linkedin.com/in/mhrivnak/",
            "value": "Michael Hrivnak linkedin page"
          },
          {
            "_href": "https://www.linkedin.com/in/matthewdorn/",
            "value": "Matt Dorn linkedin page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10493.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9938",
        "start": "14:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "immutable",
        "title": "Immutable deployments: the new classic way for service deployment",
        "subtitle": "Adopt the new immutable infrastructure paradigm using your old toolbox.",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Immutable infrastructure paradigm is often associated with relative new concept like containers and orchestrators like kubernetes. In this talk will be illustrate how to obtain the same result but using most of the classic concepts, tools and simple cloud platforms.<\/p>",
        "description": "<p>In particular will be shown the usage of:<\/p>\n\n<ul>\n<li>Terraform for the orchestration<\/li>\n<li>Packer for the creation of the instance image<\/li>\n<li>Simple shell scripts for the provisioning<\/li>\n<li>DigitalOcean as cloud platform<\/li>\n<\/ul>\n\n\n<p>The illustrated approach is based on lessons learned in almost two years of using this methodology on a production service.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5705",
            "value": "Matteo Valentini"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9938.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9471",
        "start": "15:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "foremanansible",
        "title": "Foreman meets Ansible",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk focuses on how Ansible and Foreman integrate with each other and what\nadded value can the users get when using Ansible from Foreman. It describes two\nprimary approaches of using Ansible from Foreman. The first is a traditional\nconfiguration management approach, where hosts are kept in a predefined state,\nwhile the other works in a more remote execution fashion. The talk goes over\nseveral scenarios and demonstrates how Foreman can leverage Ansible to\neffortlessly solve the issues present in the given scenarios.<\/p>",
        "description": "<p>This talk focuses on how Ansible and Foreman integrate with each other and what\nadded value can the users get when using Ansible from Foreman. It describes two\nprimary approaches of using Ansible from Foreman. The first is a traditional\nconfiguration management approach, where hosts are kept in a predefined state,\nwhile the other works in a more remote execution fashion. The talk goes over\nseveral scenarios and demonstrates how Foreman can leverage Ansible to\neffortlessly solve the issues present in the given scenarios.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6736",
            "value": "Adam Růžička"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9471.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9331",
        "start": "15:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "terraform",
        "title": "Hacking Terraform for fun and profit",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Using Terraform is often simple, extending it to do what YOU want, can be challenging (or “impossible”). Want to manage unsupported resources? Maintain lots of resources? Integrate non-integrable? The talk is an advanced guide about HOW to extend, integrate and execute Terraform to get things DONE.<\/p>",
        "description": "<p>If you’ve been using Terraform just by following the official documentation, you are not getting all from it.<\/p>\n\n<p>As soon as one cloud provider announces a new service or a feature, you dream that Terraform has zero-day support for it. Well, it is not always like this, and I will show what we can do about it.<\/p>\n\n<p>Are you using Terraform and keep asking yourself why I should copy-paste so much? What if you need to manage more than a dozen resources with Terraform (e.g., hundreds of GitHub repositories with permissions, or hundreds of IAM users and their permissions)? How can I use Terraform to manage absolutely ANY type of resource? What is beyond Terraform modules? What is a really dynamic module and what Terraform 0.12 will help us with?<\/p>\n\n<p>Let's see the advanced and very unusual solutions of how Terraform can be extended, integrated, executed, or merely hacked to get the job done with the help of external open-source services and integrations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5521",
            "value": "Anton Babenko"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/antonbabenko",
            "value": "My GitHub profile"
          },
          {
            "_href": "https://medium.com/@anton.babenko",
            "value": "My blog about Terraform and AWS"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9331.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10302",
        "start": "16:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "selfhealing",
        "title": "Building a self healing system with SaltStack",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As the number of servers that we are responsible for increases, the ability to manage issues on those systems becomes more and more difficult.  Situations arise like log files filling up disks, failed login attempts that could be brute force attacks, and unwanted processes and services running.  Using the Beacon and Reactor systems of SaltStack, we can monitor a system for these have SaltStack restore those systems to the desired state.  In this talk, we’ll look at some real-life examples of these scenarios and how Saltstack can help to automatically heal the systems.<\/p>",
        "description": "<p>As the number of servers that we are responsible for increases, the ability to manage issues on those systems becomes more and more difficult.\nSituations arise like log files filling up disks, failed login attempts that could be brute force attacks, and unwanted processes and services running.<\/p>\n\n<p>Using the Beacon system of SaltStack, we can monitor a system for these &amp; other scenarios.\nPairing this with the Reactor system, we can have SaltStack restore those systems to the desired state.<\/p>\n\n<p>In this talk, we’ll look at some real-life examples of these scenarios and how Saltstack can help to automatically heal the systems.<\/p>\n\n<p>The talk will include:<\/p>\n\n<ul>\n<li>A brief introduction to Salt Stack.<\/li>\n<li>Using Salt Beacons to monitor aspects of a system.<\/li>\n<li>Using Salt Reactors to react to events from the Salt Beacons.<\/li>\n<li>Using those reactors to re-mediate issues as they occur.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7187",
            "value": "Gareth J Greenaway"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10302.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10284",
        "start": "16:30",
        "duration": "00:55",
        "room": "UD2.120 (Chavanne)",
        "slug": "infratesting",
        "title": "Infrastructure testing, it's a real thing!",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Software developers have been testing their code for years. Why is it still not a common thing for infrastructure and operations people? We are in an era where it is expected everyone moves fast. Moving too fast can negatively affect our customers so it's vital that we ensure the changes we make to our infrastructure are tested like other code changes would be.<\/p>\n\n<p>In this talk, Paul is going to demonstrate some of the methods for testing infrastructure code. The talk will demonstrate how to establish fast feedback loops that provisions infrastructure, as well as being able to check that the code adheres to company policies, and has not drifted from the plan of record as specified in our infrastructure as code repository.<\/p>",
        "description": "<p>Software developers have been testing their code for years. Why is it still not a common thing for infrastructure and operations people? We are in an era where it is expected everyone moves fast. Moving too fast can negatively affect our customers so it's vital that we ensure the changes we make to our infrastructure are tested like other code changes would be.<\/p>\n\n<p>In this talk, Paul is going to demonstrate some of the methods for testing infrastructure code. The talk will demonstrate how to establish fast feedback loops that provisions infrastructure, as well as being able to check that the code adheres to company policies, and has not drifted from the plan of record as specified in our infrastructure as code repository.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7176",
            "value": "Paul Stack"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10284.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9679",
        "start": "17:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "mgmt",
        "title": "Mgmt Config: Autonomous Datacentres",
        "subtitle": "Real-time, autonomous, automation",
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Mgmt is a real-time automation tool that is fast and safe. One goal of the tool is to allow users to model and manage infrastructure that was previously very difficult or impossible to do so previously.<\/p>\n\n<p>The tool has two main parts: the engine, and the language. This presentation will have a large number of demos of the language.<\/p>\n\n<p>To showcase this future, we'll show some exciting real-time demos that include scheduling, distributed state machines, and reversible resources.<\/p>\n\n<p>As we get closer to a 0.1 release that we'll recommend as \"production ready\", we'll look at the last remaining features that we're aiming to land by then.<\/p>\n\n<p>Finally we'll talk about some of the future designs we're planning and discuss our free mentoring program that helps interested hackers get involved and improve their coding, sysadmin, and devops abilities.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2026",
            "value": "James Shubin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/purpleidea/mgmt/",
            "value": "project homepage"
          },
          {
            "_href": "https://twitter.com/mgmtconfig",
            "value": "twitter homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9679.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9209",
        "start": "18:00",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "gofish",
        "title": "Gofish - a Go library for Redfish and Swordfish",
        "subtitle": [],
        "track": "Infra Management Devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Gofish is a Golang library for interacting with Redfish and Swordfish enabled devices.<\/p>",
        "description": "<p>Gofish is a Golang library for interacting with Redfish and Swordfish enabled devices. This presentation will give an overview of the current state of the library and how it can be used to manage compute and storage resources using a common, standard API.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5652",
            "value": "Sean McGinnis"
          }
        },
        "links":
        [
          {
            "_href": "https://redfish.dmtf.org/",
            "value": "Redfish Standard"
          },
          {
            "_href": "https://www.snia.org/forums/smi/swordfish",
            "value": "Swordfish Standard"
          },
          {
            "_href": "https://github.com/stmcginnis/gofish",
            "value": "Gofish source"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9209.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UD2.208 (Decroly)",
    "event":
    [
      {
        "_id": "10255",
        "start": "10:30",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_podman",
        "title": "Podman - The Powerful Container Multi-Tool",
        "subtitle": "An use case driven hands-on to the container management tool Podman",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Podman is the container management tool of your choice when it comes to boosting\nday-to-day development tasks around containers. The journey of Podman started as\na drop-in replacement for docker, but nowadays it’s even more than just that.\nFor example, Podman is capable of managing pods, running containers without\nbeing root and supports fine granular configuration possibilities.<\/p>",
        "description": "<p>In this presentation, we will deep dive into the exciting world of Podman. We\ndiscover how Podman fits into the containers ecosystem, learn about the\narchitecture behind the project and utilize practical examples for daily\ndevelopment tasks.<\/p>\n\n<p>For example, we will learn how rootless containers work technically, how to\nsafely share resources within multiple containers and which benefits a\ndaemon-less container management tool like Podman provides. All these exciting\nfeatures will be explained by utilizing live demos which leaves room for an open\ndiscussion at the end of the talk.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7162",
            "value": "Sascha Grunert"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10255.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10316",
        "start": "10:55",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_lazy_image_distribution",
        "title": "Lazy distribution of container images",
        "subtitle": "Current implementation status of containerd remote snapshotter",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The biggest problem of the OCI Image Spec is that a container cannot be started until all the tarball layers are downloaded, even though more than 90% of the tarball contents are often unneeded for the actual workload.<\/p>\n\n<p>This session will show state-of-the-art alternative image formats, which allow runtime implementations to start a container without waiting for all its image contents to be locally available.<\/p>\n\n<p>Especially, this session will put focus on CRFS/stargz and its implementation status in containerd (https://github.com/containerd/containerd/issues/3731).\nThe plan for BuildKit integration will be shown as well.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3608",
            "value": "Akihiro Suda"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10316.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10501",
        "start": "11:20",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_bpf",
        "title": "BPF as a revolutionary technology for the container landscape",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>BPF as a foundational technology in the Linux kernel provides a powerful tool for systems developers and users to dynamically reprogram and customize the kernel to meet their needs in order to solve real-world problems and without having to be a kernel expert. Thanks to BPF we have come to the point to overcome having to carry legacy accumulated over decades of development grounded in a more traditional networking environment that is typically far more static than your average Kubernetes cluster. In the age of containers, they are no longer the best tool for the job, especially in terms of performance, reliability, scalability, and operations. This talk provides a few examples on how BPF allows to rethink container networking based on recent work we did in Cilium. Among others, the audience will learn about running a fully functioning Kubernetes cluster without iptables, Netfilter and thus without kube-proxy in a scalable and secure way with the help of BPF and Cilium.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3753",
            "value": "Daniel Borkmann"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10501.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10335",
        "start": "11:55",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_kata",
        "title": "Kata Containers on openSUSE",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kata Containers provide a secure container runtime offering an experience close to that of native containers, while providing stronger workload isolation and host infrastructure security by using hardware virtualization technology. This is particularly useful when containers are used to host and run third-party applications. In this presentation, after a short intro to Kata, we will demonstrate how easy it is to install and use on openSUSE. We will show it in action both as part of a podman setup as well as within a full-featured Kubernetes environment.<\/p>",
        "description": "<p>With containers becoming not only the preferred way of deploying applications, but also the building blocks of microservice architectures, infrastructure security and workload isolation concerns are being raised. The Kata Containers Open Source project addresses these concerns by using virtualization technology, in compliance with the \"defense in depth\" design principles. It is also a very flexible, dynamic and fast-moving project, with many components that need to be integrated among each others.<\/p>\n\n<p>This presentation will illustrate how easy it can already be to use Kata as a container runtime on top of the openSUSE distribution. In fact, after giving a short introduction of Kata Containers and its architecture, we will provide a DEMO of how we have integrated Kata into openSUSE and how it can be used with podman to run containers in a secure and isolated fashion. As Kata is compatible with the OCI (Open Container Initiative) runtime specification, it can be used to seamlessly replace or coexist with other runtimes (e.g. runc) in existing Container Engines (podman, CRI-O, docker, ...), even inside a Kubernetes cluster. We will therefore be able to show how native containers and strongly isolated Kata containers can run together on the same platform. Finally, we will also demonstrate how to set Kata Containers up as an alternative runtime inside of a Kubernetes Cluster.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7139",
            "value": "Ralf Haferkamp"
          }
        },
        "links":
        [
          {
            "_href": "https://katacontainers.io/",
            "value": "Kata Containers"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10335.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10418",
        "start": "12:20",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_k8s_kube_proxy",
        "title": "Evolution of kube-proxy",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kube-proxy enables access to Kubernetes services (virtual IPs backed by pods) by configuring client-side load-balancing on nodes. The first implementation relied on a userspace proxy which was not very performant. The second implementation used iptables and is still the one used in most Kubernetes clusters. Recently, the community introduced an alternative based on IPVS.\nThis talk will start with a description of the different modes and how they work. It will then focus on the IPVS implementation, the improvements it brings, the issues we encountered and how we fixed them as well as the remaining challenges and how they could be addressed. Finally, the talk will present alternative solutions based on eBPF such as Cilium.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7242",
            "value": "Laurent Bernaille"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10418.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9288",
        "start": "12:55",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_live_migration",
        "title": "Container Live Migration",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The difficult task to checkpoint and restore a process is used in many container runtimes to implement container live migration. This talk will give details how CRIU is able to checkpoint and restore processes, how it is integrated in different container runtimes and which optimizations CRIU offers to decrease the downtime during container migration.<\/p>\n\n<p>In this talk I want to provide details how CRIU checkpoints and restores a process. Starting from ptrace() to pause the process, how parasite code is injected into the process to checkpoint the process from its own address space. How CRIU transforms itself to the restored process during restore. How SELinux and seccomp is restored.<\/p>\n\n<p>I want to end this talk with an overview about how CRIU is integrated in different container runtimes to implement container live migration.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5257",
            "value": "Adrian Reber"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9288.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10542",
        "start": "13:20",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_syscall_emulation",
        "title": "Supervising and emulating syscalls",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Recently the kernel landed seccomp support for SECCOMP<em>RET<\/em>USER_NOTIF which enables a process (supervisee) to retrieve a fd for its seccomp filter. This fd can then be handed to another (usually more privileged) process (supervisor). The supervisor will then be able to receive seccomp messages about the syscalls having been performed by the supervisee.<\/p>\n\n<p>We have integrated this feature into userspace and currently make heavy use of this to intercept mknod(), mount(), and other syscalls in user namespaces aka in containers.\nFor example, if the mknod() syscall matches a device in a pre-determined whitelist the privileged supervisor will perform the mknod syscall in lieu of the unprivileged supervisee and report back to the supervisee on the success or failure of its attempt. If the syscall does not match a device in a whitelist we simply report an error.<\/p>\n\n<p>This talk is going to show how this works and what limitations we run into and what future improvements we plan on doing in the kernel.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5245",
            "value": "Christian Brauner"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10542.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10149",
        "start": "13:45",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_k8s_runtimes",
        "title": "Below Kubernetes: Demystifying container runtimes",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Today, the task of running containers involves a lot of technologies and levels of abstraction, and it can be difficult to understand, or just to keep up. How do CRI-O and containerd overlap ? Does Kata containers compete with Firecracker ? Is there any relationship between OCI and CRI ? How many different meanings can \"container runtime\" have ?<\/p>\n\n<p>In this talk, we will navigate this treacherous sea of overlapping technologies and acronyms that take care of running container workloads, below Kubernetes all the way down to the Linux kernel. We will present at a high-level how these technologies, interfaces and levels of abstraction combine and overlap, and hopefully clarify which are spec vs. implementation, which are complementary, and which are alternative solutions.<\/p>",
        "description": "<p>This talk will cover the following points:<\/p>\n\n<ul>\n<li>The world used to be simple: the case of Docker<\/li>\n<li>Interfaces: OCI and CRI<\/li>\n<li>More puzzle pieces: Podman, Containerd and CRI-O<\/li>\n<li>Workload isolation: Kata Containers, GVisor and Firecracker<\/li>\n<li>Q&amp;A<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "427",
            "value": "Thierry Carrez"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10149.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9662",
        "start": "14:10",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_memory_management",
        "title": "Linux memory management at scale",
        "subtitle": "Building the future of kernel resource management",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Memory management is an extraordinarily complex and widely misunderstood topic. It is also one of the most fundamental concepts to understand in order to produce coherent, stable, and efficient systems and containers, especially at scale. In this talk, we will go over how to compose reliable memory heavy, multi container systems that can withstand production incidents, and go over examples of how Facebook is achieving this in production at the cutting edge. We'll also go over the open-source technologies we're building to make this work at scale in a density that has never been achieved before.<\/p>\n\n<p>We will go over widely-misunderstood Linux memory management concepts which are important to site reliability and container management with an engineer who works on the Linux kernel's memory subsystem, busting commonly held misconceptions about things like swap and memory constraints, and giving advice on key and bleeding-edge kernel concepts like PSI, cgroup v2, memory protection, and other important container-related topics along the way.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3621",
            "value": "Chris Down"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9662.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10578",
        "start": "14:45",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_lxd",
        "title": "Running full Linux systems in containers, at scale",
        "subtitle": "A look at LXD and its clustering capabilities",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LXD is a system container manager, its goal is to safely run full Linux systems at very high density and low overhead.\nContainers may be created from pre-made images, covering most Linux distributions, or by importing an existing virtual machine or physical system.<\/p>\n\n<p>Advanced resource control and device passthrough is available to expose as much or as little system resources to those containers.\nSnapshot and backup tooling is available to safeguard those containers and data.\nStorage pools and networks can be used to offer a variety of storage and network options to the containers.<\/p>\n\n<p>Management happens through a REST API with a default CLI client.\nLXD has built-in support for clustering which makes it trivial to scale a deployment to dozens of servers, all acting as one virtual LXD server.<\/p>\n\n<p>In this presentation, we'll go over LXD's main features through a demonstration including usage of LXD's clustering abilities, running a variety of Linux distributions and converting existing systems to containers.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3310",
            "value": "Stéphane Graber"
          }
        },
        "links":
        [
          {
            "_href": "https://linuxcontainers.org/lxd",
            "value": "LXD - system container manager"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10578.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10424",
        "start": "15:10",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_k8s_security",
        "title": "How (Not) To Containerise Securely",
        "subtitle": "Lessons Learned the Hard Way",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk details low level exploitable issues with container and Kubernetes deployments. We focus on lessons learned, and show attendees how to ensure that they do not fall victim to avoidable attacks.<\/p>",
        "description": "<p>Andy has made mistakes. He's seen even more. And in this talk he details the best and the worst of the container and Kubernetes security problems he's experienced, exploited, and remediated.<\/p>\n\n<p>See how to bypass security controls, exploit insecure defaults, evade detection, and root clusters externally (and more!) in this interactive and highly technical appraisal of the container and cluster security landscape.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5693",
            "value": "Andrew Martin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10424.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10138",
        "start": "15:45",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_k8s_crio_lxc",
        "title": "Using crio-lxc with Kubernetes",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Running application containers within Kubernetes presents a challenge to the operator for quickly handling security updates - every container must be patched, rebuilt and re-tested, and then updated separately. The slowest dev turnaround of all your containers is the fastest you can fully update your cluster.<\/p>\n\n<p>However, for many fixes, the application likely will not care which compatible version of a system library it is using.\nUsing AtomFS, operators can update individual libraries inside app containers without a rebuild. Containers using an AtomFS storage backend can simply be restarted after a fix is applied, and they will see it reflected in their filesystems.<\/p>\n\n<p>The AtomFS storage backend requires minor changes to your container runtime, and we demonstrate it with the LXC runtime and crio-lxc, an adapter to enable using LXC-based containers in Kubernetes using CRI-O.<\/p>\n\n<p>In this talk Tycho will cover how AtomFS works, what changes are needed to make application container builds work with AtomFS, and fix an exploit live without a rebuild.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "3187",
            "value": "Tycho Andersen"
          },
          {
            "_id": "7371",
            "value": "Mike McCracken"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10138.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10338",
        "start": "16:20",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_steam",
        "title": "Containers and Steam",
        "subtitle": "Putting games under pressure",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The availability of namespaces inside user sessions is increasing, and Valve's Steam game distribution platform is taking advantage of this for better gaming on Linux.<\/p>\n\n<p>A recent beta of Steam for Linux adds pressure-vessel, an experimental mechanism developed by Collabora to put games in containers. This gives the game partial isolation from various aspects of the host system, and in particular allows it to use a runtime library stack that is not entangled with the host's, with different games using different runtimes.<\/p>\n\n<p>Meanwhile, the unofficial Steam Flatpak app distributed on Flathub puts the entire Steam client and all of its games in a container. This gives the Steam client more thorough isolation from the host system, but all the games have to share that single container.<\/p>\n\n<p>In this talk, pressure-vessel developer and Flatpak contributor Simon McVittie will compare the two approaches and the challenges they encounter, and look at where Steam containers might go in the future.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5205",
            "value": "Simon McVittie"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10338.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10187",
        "start": "16:45",
        "duration": "00:30",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_hpc_unprivileged",
        "title": "Distributed HPC Applications with Unprivileged Containers",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We will present the challenges in doing distributed deep learning training at scale on shared heterogeneous infrastructure. At NVIDIA, we use containers extensively in our GPU clusters for both HPC and deep learning applications. We love containers for how they simplify software packaging and enable reproducibility without sacrificing performance. Docker is a popular tool for running application containers on Linux, and while it is possible to enable container workflows for users by granting them access to the docker daemon, the security impact needs to be carefully considered, especially in a shared environment. Relying on docker for the container runtime also requires a large amount of complicated boilerplate code to start multi-node jobs using the Message Passing Interface (MPI) for communication. In this presentation, we will introduce a new lightweight container runtime inspired from LXC and an associated plugin for the Slurm Workload Manager. Together, these two open-source projects enable a more secure architecture for our clusters, while also enabling a smoother user experience with containers on multi-node clusters.<\/p>",
        "description": "<p>There are many container runtimes available, but none met all of our needs for running distributed applications with no performance overhead and no privileged helper tools. For our use case, we built a simple container runtime called enroot - it's a tool to turn traditional container images into lightweight unprivileged sandboxes; a modern chroot. One key feature is that enroot remaps all UIDs inside the container to a single UID on the host. So, unlike runtimes which rely on <code>/etc/subuid<\/code> and <code>/etc/subgid<\/code>, with enroot there is no risk of overlapping UID ranges on a node, and no need to synchronize ranges across the cluster. It is also trivial to remap to UID 0 inside the container which enables users to safely run <code>apt-get install<\/code> to add their own packages. Enroot is also configured to automatically mount drivers and devices for accelerators from NVIDIA and Mellanox using enroot's flexible plugin system. Finally, enroot is highly optimized to download and unpack large docker images, which is particularly useful for images containing large applications.<\/p>\n\n<p>We also created a new plugin for the Slurm Workload manager which adds command-line flags for job submission. When the “--container-image” flag is set, our plugin imports a container image, unpacks it on the local filesystem, creates namespaces for the container, and then attaches the current job to these new namespaces. Therefore, tasks transparently land inside of the container with minimal friction. Users can even make use of the PMI2 or PMIx APIs to coordinate workloads inside the containers without needing to invoke mpirun, further streamlining the user experience. Currently, the plugin works with two different tools - enroot and LXC. It could be extended to other container runtimes in the future.<\/p>",
        "persons":
        [
          {
            "_id": "7007",
            "value": "Felix Abecassis"
          },
          {
            "_id": "7287",
            "value": "Jonathan Calmels"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10187.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9091",
        "start": "17:20",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_k8s_arm64",
        "title": "Kubernetes on ARM64",
        "subtitle": "Raspberry PI 4 Kubernetes cloud for a few Euros!!",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Building a Kubernetes cloud using Raspberry PI 4.\nThe RPI4/4G offers enough memory and cpu to build an educative Kubernetes cluster.\nThe presentation will show how to put the pieces togother to get an Apache Tomcat\noperator to deploy a small web application in the build RPI4 Kubernetes cloud.<\/p>",
        "description": "<p>We will show:\n- how to build a kernel for RPI4, use it to make a bootable SD card for a RPI4.\n- how to configure it to use the WIFI board\n- how to prepare Docker images for ARM64\n- how to join the Kubernetes master\n- how to use weave plugin to get the Kernetes internal network\n- how to build and install the operator for Apache Tomcat.\n- then run a small webapp using the operator.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6475",
            "value": "Jean-Frederic Clere"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9091.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10400",
        "start": "17:45",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_bpf_tracing",
        "title": "Inspektor Gadget and traceloop",
        "subtitle": "Tracing containers syscalls using BPF",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>I will present Inspektor Gadget and traceloop, a tracing tool to trace system calls in cgroups or in containers using BPF and overwritable ring buffers.<\/p>",
        "description": "<p>Many people use the “strace” tool to synchronously trace system calls using ptrace. Traceloop similarly traces system calls but asynchronously in the background, using BPF and tracing per cgroup. I’ll show how it can be integrated with systemd and with Kubernetes via Inspektor Gadget.<\/p>\n\n<p>Traceloop's traces are recorded in a fast, in-memory, overwritable ring buffer like a flight recorder. As opposed to “strace”, the tracing could be permanently enabled on systemd services or Kubernetes pods and inspected in case of a crash. This is like a always-on “strace in the past”.<\/p>\n\n<p>Traceloop uses BPF through the gobpf library. Several new features have been added in gobpf for the needs of traceloop: support for overwritable ring buffers and swapping buffers when the userspace utility dumps the buffer.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3478",
            "value": "Alban Crequy"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/kinvolk/inspektor-gadget",
            "value": "Inspektor Gadget"
          },
          {
            "_href": "https://github.com/kinvolk/traceloop",
            "value": "traceloop"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10400.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10222",
        "start": "18:10",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_containerd",
        "title": "Extending and embedding: containerd project use cases",
        "subtitle": "A 2020 containerd project update and description of uses",
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Over the past year, projects looking to extend and embed core container runtime functionality have looked to containerd and its clean API and extension points as a valuable resource. In this talk we'll look at the projects which have extended or embedded containerd for specific use cases and how containerd has enabled these uses via its design. We will also do a brief project update for the broader container ecosystem and community.<\/p>",
        "description": "<p>As containerd reaches its fourth birthday, it has already been adopted as a container runtime underneath Kubernetes in public cloud providers and various developer tools and platforms. In this talk we'll look deeper at the architecture choices and clean API layer which has enabled further use of containerd as an embedded and extensible runtime in additional projects, like Amazon's Firecracker integration, Kata's use of the v2 shim API, and Microsoft Azure's creation of the Teleport registry feature. We'll also look at in-flight work with CERN, Google, and others around remote \"pre-seeded\" snapshotters which allow for significant speedups in container startup time with special-case clusters like CERN's compute cloud.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4780",
            "value": "Phil Estes"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10222.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9386",
        "start": "18:35",
        "duration": "00:25",
        "room": "UD2.208 (Decroly)",
        "slug": "containers_gpu_virtualization",
        "title": "A way of GPU virtualization for container",
        "subtitle": [],
        "track": "Containers",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Containers are widely used in clouds due to their lightweight and scalability. GPUs have powerful parallel processing capabilities that are adopted to accelerate the execution of applications. In a cloud environment, containers may require one or more GPUs to fulfill the resource requirement of application execution, while on the other hand exclusive GPU resource of a container usually results in underutilized resource. Therefore, how to share GPUs among containers becomes an attractive problem to cloud providers. In this presentation, we propose an approach, called vCUDA, to sharing GPU memory and computing resources among containers. vCUDA partitions physical GPUs into multiple virtual GPUs and assigns the virtual GPUs to containers as request. Elastic resource allocation and dynamic resource allocation are adopted to improve resource utilization. The experimental results show that vCUDA only causes 1.015% of overhead by average and it effectively allocates and isolates GPU resources among containers.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6689",
            "value": "Shengbo Song"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9386.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.218A",
    "event":
    [
      {
        "_id": "10204",
        "start": "10:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_integrating_julius",
        "title": "Integrating Julius Speech Recognition Engine",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This presentation deals with the integration of Julius Speech Recognition Engine.<\/p>\n\n<p>The aim of this Proof of Concept is to have a connectionless speech engine, working on an embedded device,\nintegrated as a binding of the AGL Application Framework.\nThe recognition uses Deep Neural Network realtime decoding, and for safer results and performances purpose,\nuses a grammar.<\/p>\n\n<p>Julius does not support wakewords out of the box, some hacking has been done to enable it in an efficient way.\nTests have been done on Renesas' H3, and UPSquare boards.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7012",
            "value": "Thierry Bultel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10204.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10590",
        "start": "11:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_homebridge_with_yocto",
        "title": "Building Homebridge with the Yocto Project",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Homebridge is a lightweight NodeJS server that emulates Apple HomeKit API. Combined with versatile plugins it allows you to make any device Homekit-compatible.\nIn the presentation you will understand how Homebridge works and how to integrated it in a custom embedded Linux distribution built with the Yocto Project and OpenEmbedded. We will go through the exact steps for leveraging the latest release of Poky, the reference system of the Yocto Project, with systemd, X11, openbox, surf web browser, nodejs, npm, Homebridge and some of its most popular plugins. Only open source software will be used, without any commercial licenses.\nPractical examples for home automation with Homebridge on Raspberry Pi and the new STM32MP1 development boards will be demonstrated. The end result is an embedded device mounted in rack with a DIN rail that provides simple and user-friendly way to manage and configure Homebridge out of the box. The talk is appropriate for beginners.<\/p>",
        "description": "<p>Homebridge is a lightweight NodeJS server that you can run on your home network and emulate Apple HomeKit API. Started more than 5 years ago and available at GitHub under Apache License 2.0, Homebridge has a large and vibrant open source community.\nMultiple plugins allow Homebridge to handle user's requests either via Siri or the Home app and this way to make any device Homekit-compatible. Raspberry Pi is the perfect platforms for hobbyists to install a local Homebridge instance. However, the installation of  Homebridge on Raspbian requires numerous steps and despite the excellent tutorials, users without previous Linux experience face difficulties. Another disadvantage is that Raspbian is available only as 32-bit images which doesn’t use the full capabilities of the ARMv8 64-bit processors on Raspberry Pi 3 and 4.\nThe Yocto Project and OpenEmbedded provide all required tools to create a custom Linux distribution that out of the box offers user-friendly experience for configuring Homebridge in just a few easy steps. In the this presentation we do a code review of meta-homebridge Yocto/OE layer and we will walk through the exact steps for creating a lightweight Linux distribution with graphical user interface and a web browser that acts like a kiosk. We will integrated and configure popular open source software tools such as the Linux kernel, systemd,  X11, openbox, surf web browser, nodejs, npm and of course Homebridge. Thanks to the meta-raspberrypi BSP Yocto/OE layer we will be able to unleash the full power of Raspberry Pi 3 and 4 by building 64-bit images.\nAt the end of the presentation demonstrations and tips for making an embedded device mounted in rack with a DIN rail will be shared. We will also mention the new STM32MP1 industrial grade development boards as alternatives of Raspberry Pi for this and similar projects in the maker community.\nThis talk brings benefits to the ecosystems of several open source communities. It will spread the word about Homebridge and significantly improve the getting started experience for user. Practical examples for using the Yocto Project and OpenEmbedded for makers will be revealed. As part of the development efforts for meta-homebridge Yocto/OE, a couple of new recipes, surf (simple web browser) and stalonetray (X11 system tray), have been contributed to the upstream of meta-openembedded.\nThe talk is appropriate for beginners. No previous experience is required. Hopefully, this presentation will encourage the audience to try out Homebridge and leverage their knowledge about the Yocto Project and OpenEmbedded with the example of this real-world entirely open source project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1603",
            "value": "Leon Anavi"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/leon-anavi/meta-homebridge",
            "value": "meta-homebridge Yocto/OE layer"
          },
          {
            "_href": "https://homebridge.io/",
            "value": "Homebridge"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10590.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10614",
        "start": "11:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_embedded_voip",
        "title": "Building an embedded VoIP network for video intercom systems",
        "subtitle": "How to leverage open standards to bring voice and video capabilities to IP hardware intercom solutions",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>IP video intercom systems combined with smartphones can leverage regular RTP/SIP VoIP technology to offer a new set of services to end-users: getting a notification when visitors press the door bell, seeing them on video before answering the call, interacting with them via voice and video and deciding to open the door, at home or anywhere else via wifi or 3G coverage.<\/p>\n\n<p>Linphone (a SIP user-agent) and Flexisip (a SIP proxy server) can be integrated into IP video door phones, in-house panels and video surveillance devices to build a complete VoIP network.<\/p>\n\n<p>Linphone and Flexisip use open standards to reliably send the audio and video streams captured from IP video intercoms to in-house devices, including smartphones and tablets, connected either to a local network or to the public internet.\nThese open source SIP-based software solutions can run perfectly on small hardware devices with reduced footprint, and can easily be integrated into GNU/Linux embedded systems, thanks to their Yocto packages.<\/p>\n\n<p>This lecture will describe how Linphone and Flexisip can be used together to build an embedded SIP network dedicated to home automation or video surveillance.\nThe network architecture used in these contexts can also be deployed in other areas, such as the emergency services or the Internet of Things.<\/p>",
        "description": "<p>Linphone and Flexisip can be integrated into IP video intercom systems to make the audio and video capabilities of a door entry panel accessible by in-house control screens and smartphones, connected either to a local network or to the public internet.<\/p>\n\n<p>Indeed, the linphone software fits well in embedded systems, which makes it a good candidate for being used in home automation devices, such as outdoor panels or indoor monitors, where video is to be capture or displayed.\nHowever a SIP user-agent itself is not sufficient for setting up a fully functional SIP network: we propose the use of Flexisip, which is also able to run with reduced footprint on embedded devices as well as on a large scale cloud deployment, to fork incoming calls to in-house monitoring panels, smartphones or tablets.<\/p>\n\n<p>When used together, Linphone and Flexisip offer advanced features for IP door phones and video monitoring systems, such as :\n-   HD video and HD voice (with support for H.264 and H.265 hardware accelerated codecs, and Opus codec)\n-   Call forking with early media video\n-   ICE, STUN and TURN support for optimised NAT traversal allowing peer-to-peer audio and video connections whenever possible\n-   secure user authentication with TLS client certificates\n-   Interconnection with push notifications systems, for reliably notifying of people ringing the door<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5169",
            "value": "Elisa Nectoux"
          }
        },
        "links":
        [
          {
            "_href": "https://www.linphone.org/solutions",
            "value": "Linphone and Flexisip standard deployment"
          },
          {
            "_href": "http://gitlab.linphone.org/BC/public/linphone",
            "value": "liblinphone gitlab repository"
          },
          {
            "_href": "https://gitlab.linphone.org/BC/public/flexisip",
            "value": "flexisip gitlab repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10614.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10596",
        "start": "12:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_ros2_evolution",
        "title": "ROS2: The evolution of Robot Operative System",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In FOSDEM 2013, Open Robotics introduced an overview of the Robot Operating System (ROS), an open software integration framework for robots created in 2007. After more than a decade of great success, powering from Robocup teams to NASA robots in space, ROS2 was born to break any limitation detected previously by roboticians all around the globe. It's an exciting time.<\/p>\n\n<p>This talk will explain the design changes and technical motivations that lead to the creation of ROS2 giving a quick overview of new features present on it: multi-platform, embedded devices, real time, etc.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3281",
            "value": "Jose Luis Rivero"
          }
        },
        "links":
        [
          {
            "_href": "https://archive.fosdem.org/2013/schedule/event/ros_open_sourcet_sobotics/",
            "value": "ROS at FOSDEM"
          },
          {
            "_href": "https://design.ros2.org/articles/why_ros2.html",
            "value": "why ros2"
          },
          {
            "_href": "http://design.ros2.org/articles/realtime_background.html",
            "value": "realtime ros2"
          },
          {
            "_href": "https://www.omg.org/omg-dds-portal/",
            "value": "DDS standard"
          },
          {
            "_href": "https://vimeo.com/187696091",
            "value": "State of ROS2"
          },
          {
            "_href": "https://vimeo.com/236161417",
            "value": "Vision of ROS2"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10596.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9459",
        "start": "12:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_iceoryx",
        "title": "Introduction to Eclipse iceoryx",
        "subtitle": "Writing a safe IPC framework for autonomous robots and cars",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Bosch has open sourced a true zero-copy middleware for inter-process communication\non modern robotics and vehicle computers. The shared memory based\nsolution is compatible with Linux/QNX and achieves data independent communication\nin constant time without serializing data. We would like to present our\nrecent development towards an open-source release and demonstrate our performance\nand timing benchmarks on a privately developed embedded robot.<\/p>",
        "description": "<p>On FOSDEM 2018 Bosch presented OpenADx, an initiative to collaborate and accelerate\nthe development of automated driving with the open source community.\nOn FOSDEM 2020 we would like to present the first project under the OpenADx\numbrella called Eclipse iceoryx TM.\nOver the course of its company history, Bosch could establish a solid understanding\nof the needs and requirements of the automotive domain in terms of liability,\nreliability, safety and determinism. In a time where highly automated driving hits\nthe road, these aspects become more and more important. An automated driving\nkit is a networked system that processes a sensor data stream in the range\nof GBytes/s. This naturally arises the need of an efficient and lightweight data\ntransfer mechanism. Our group at Bosch has its main focus on tackling exactly\nthis challenge. In order to approach the problem of distributing the high frequency,\nhigh throughput data streams on fusion and planning computers, we’ve developed\na solution which can guarantee a time constant communication channel independently\nof the size of data to be transported. Our approach is based on shared\nmemory which allows for transparently connecting the same range of memory\nbetween multiple processes and thus enables a true zero-copy communication.\nGiven the nature of shared memory, an efficient data transport can thus be realized\nsolely by passing pointers to memory addresses from publishers to subscribers.\niceoryx is fully compatible with the ROS2 and Adaptive AUTOSAR APIs\nand can be used as an implementation for both.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6620",
            "value": "Simon Hoinkis"
          }
        },
        "links":
        [
          {
            "_href": "https://archive.fosdem.org/2018/schedule/event/automated_driving/",
            "value": "2018 FOSDEM OpenADx talk"
          },
          {
            "_href": "https://github.com/eclipse/iceoryx",
            "value": "Eclipse iceoryx at Github"
          },
          {
            "_href": "https://github.com/ros2/rmw_iceoryx",
            "value": "ROS2 RMW binding"
          },
          {
            "_href": "https://projects.eclipse.org/projects/technology.iceoryx",
            "value": "Eclipse iceoryx project page"
          },
          {
            "_href": "https://github.com/eclipse/iceoryx/wiki/Eclipse-iceoryx%E2%84%A2-in-1000-words",
            "value": "Eclipse iceoryx in 1000 words"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9459.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10537",
        "start": "13:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_low_cost_test_fixture",
        "title": "Building a low-cost test fixture",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>When printed circuit boards come out of the assembly line, a test fixture is required to perform functional testing and program the firmware.\nThese fixtures, called bed of nails, are sturdy setups usually built for high volume production, and can be quite costly.\nThe goal of this talk is to describe how you can build your own low cost fixture with basic PCB design skills and off the shelves components.<\/p>",
        "description": "<p>Functional testing of printed circuit boards (PCB) is typically done with a bed of nails fixture. The fixture holds the PCB in place over spring-loaded probes that make contact with the board’s test points.\nThe probes can be connected to an acquisition system that runs functional tests and to a programmer that flashes production firmware.\nThe Internet has tutorials and DIY kits suitable for PCBs with large test points (on a 2.54 mm grid). However as PCBs get smaller and more crowded, test points have to be smaller and closer to each other.\nThe goal of this talk is to describe how to build a test fixture with tighter requirements (test points with 0.6 mm diameter and 1.27 mm spacing) on a tight budget.<\/p>\n\n<p>Main talking points:\n- Making a PCB (with Kicad) to hold the probes in place and align the device under test (DUT),\n- Using a Raspberry Pi Zero to instrument the setup and communicate with the DUT,\n- Running OpenOCD on the Raspberry Pi Zero to flash the production firmware.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7291",
            "value": "Guillaume Vier"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10537.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9398",
        "start": "13:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_secure_elements",
        "title": "How to integrate secure elements",
        "subtitle": "A visually annotated summary of Opensource compatible secure elements with instructions to integrate",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this half hour we study aspects of physically and cryptographically secure hardware (often termed secure element or SE) and the integration into existing circuits. We illustrate utility of such integration by inspecting a cryptocurrency wallet design, and explain the difficulty presented by nondisclosure agreements (NDA) common to industry closed adversaries. We examine several hardware devices, study their parts under a close range circuit camera, and suggest instructions on their use.<\/p>",
        "description": "<p>Building secure applications involves research of new technology while leveraging well known practices, for example when using ECDSA to secure systems with low power devices.<\/p>\n\n<p>In this half hour lecture, we study an in depth example of using cryptoaccelerated hardware to research such secure applications.<\/p>\n\n<p>We review common cryptography practices.<\/p>\n\n<ul>\n<li>Applied security paradigms<\/li>\n<li>Asymetric public key exchange<\/li>\n<li>Encryption and signing algorithms<\/li>\n<li>Challenges of low power computing<\/li>\n<li>Noncomputational security features\n...for example mechanical UI constructs<\/li>\n<\/ul>\n\n\n<p>We proposes new hardware supported techniques.<\/p>\n\n<ul>\n<li>Open FPGA platforms<\/li>\n<li>NDA unencumbered SE<\/li>\n<li>Circumventing black boxes<\/li>\n<li>Benchmark measurements<\/li>\n<li>Hardened serial interfaces<\/li>\n<\/ul>\n\n\n<p>We end by viewing a number of real device hardware circuits under a close range microscope, and possibly offer a device petting zoo to encourage exploration of hardware.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2380",
            "value": "Michael Schloh von Bennewitz"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9398.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9577",
        "start": "14:00",
        "duration": "00:50",
        "room": "UD2.218A",
        "slug": "ema_early_boot",
        "title": "Embedded systems, the road to Linux",
        "subtitle": "Early boot, comparing and explaining different systems.",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As soon as you are on Linux you are generally confident with the embedded system, whatever it is.\nBut often the boot process may hide some misteries, and understanding the details may help to recover a\nbricked board or to upgrade or replace a bootloader. The explained path would start from comparing some different\nSoC's, passing from the ROM boot loader, static RAM, sdram init, secondary bootloader, and so on,\nuntil the last \"jump\" to Linux. Most common non volatile boot devices would be introduced. A basic\nknowledge would be ok for the audience.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6310",
            "value": "Angelo Dureghello"
          }
        },
        "links":
        [
          {
            "_href": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&q=dureghello",
            "value": "kernel contrib"
          },
          {
            "_href": "https://gitlab.com/u-boot/u-boot/commits/master?utf8=%E2%9C%93&search=dureghello",
            "value": "u-boot contrib"
          },
          {
            "_href": "http://sysam.it/cff_stmark2.html",
            "value": "hardware designed"
          },
          {
            "_href": "http://sysam.it/cff_amcore.html",
            "value": "hardware designed"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9577.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9688",
        "start": "15:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_boot_linux_only",
        "title": "boot/loader — How to boot Linux and nothing else",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>To boot Linux on a new ARM/ARM64 platform we have to port Linux to that platform and a bootloader. Aside from the platform setup code, we need to add and maintain some device drivers to both Linux and the bootloader. We decided to avoid the extra effort and get rid of the dedicated bootloader. With a few dozen lines of assembly code, Linux Kernel and a pinch of userland tools the \"boot\" kernel was running with all the cool features we wanted! Then we used kexec(2) to start a \"full\" Linux kernel.<\/p>",
        "description": "<h1>How to boot Linux and nothing else<\/h1>\n\n<p>To boot Linux on a new ARM/ARM64 platform we have to port Linux to that platform and a bootloader. Aside from the platform setup code, we need to add at least some platform specific device drivers both Linux and the bootloader and maintain the drivers in both trees. We decided to avoid the extra effort and get rid of the dedicated bootloader.<\/p>\n\n<p>We took a widely available Odroid XU4 board and replaced bootloader (U-Boot) with a few dozen lines of assembly code, Linux Kernel and a pinch of userland tools. The \"boot\" kernel was running with all the cool features we wanted! Then we used kexec(2) to start a \"full\" Linux kernel.<\/p>\n\n<p>Dedicated bootloaders perform two types of tasks: platform specific setup and management (starting an OS, managing OS updates). We show that Linux is a better environment to implement management proccedures.<\/p>\n\n<p>We want to share our experience and encourage others to join our effort to use Linux Kernel as a bootloader on ARM/ARM64 platforms.<\/p>\n\n<h1>Target audience<\/h1>\n\n<p>The presentation is meant for everyone interested in how the Linux Kernel handles the boot process and especially developers who commit to arch/* directories, and bootloader developers. We present our experience with ARM Odroid XU4 board, but we expect people working on other platforms will benefit too.<\/p>\n\n<h1>How we want to improve the ecosystem<\/h1>\n\n<p>Development of new bootloading code for ARM and other embedded platforms. We believe using Linux kernel for this task is beneficial in three different ways. Less platform specific code needs to be created and maintained in different repositories.  General purpose code like filesystem drivers or network stack are maintained better in Linux than in U-Boot. This, as well as wide verity of libraries makes Linux better environment to develop advanced management functions (e.g OS updates, security checks etc.) in contemporary bootloader.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6761",
            "value": "Łukasz Stelmach"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9688.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10616",
        "start": "15:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_pipewire",
        "title": "PipeWire in the Automotive Industry",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>PipeWire has recently been adopted by Automotive Grade Linux for its implementation of the low-level platform audio service, replacing entirely previous solutions. Getting there had, of course, many challenges. In this talk, George is going to talk about how PipeWire has managed to overcome these challenges and has evolved to support automotive use cases and hardware through the design and implementation of a new, reusable, session &amp; policy management component, WirePlumber.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4105",
            "value": "George Kiagiadakis"
          }
        },
        "links":
        [
          {
            "_href": "https://gstreamer.freedesktop.org/conference/2019/talks-and-speakers.html#pipewire-automotive-industry",
            "value": "Previous talk at the GStreamer Conference 2019"
          },
          {
            "_href": "https://gstconf.ubicast.tv/videos/pipewire-in-the-automotive-industry/",
            "value": "Previous talk at the GStreamer Conference 2019 (video)"
          },
          {
            "_href": "https://ossalsjp19.sched.com/event/OT1B/pipewire-in-the-heart-of-future-car-multimedia-george-kiagiadakis-collabora",
            "value": "Previous talk at the Automotive Linux Summit 2019"
          },
          {
            "_href": "https://gitlab.freedesktop.org/pipewire/wireplumber",
            "value": "WirePlumber project"
          },
          {
            "_href": "https://gitlab.collabora.com/gkiagia/pipewire-agl-presentations",
            "value": "All my previous presentations on this topic"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10616.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10498",
        "start": "16:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_wpe",
        "title": "WPE, The WebKit port for Embedded platforms",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>WPEWebKit is a WebKit flavour (also known as port) specially crafted for embedded platforms and use-cases. During this talk I would present WPEWebKit's architecture with a special emphasis on its multimedia backend based on GStreamer. I would also demonstrate various use-cases for WPE, spanning from Kiosk apps and Set-top-box user-interfaces to advanced scenarios such as Web overlays for live TV broadcasting.<\/p>",
        "description": "<p>WPEWebKit is designed for simplicity and performance. It allows application developers to easily deploy hardware-accelerated fullscreen (or not) browsers with multimedia support, small (both in memory usage and disk space) and light as possible, and implementing the most relevant HTML specifications.<\/p>\n\n<p>Traditionally WebKit ports are associated with a specific widget toolkit library (GTK, Qt, Cocoa,...) but WPEWebKit breaks with this monolithic design and thus enables a new range of use-cases. By delegating the final web page rendering to dedicated view-backends, WPEWebKit allows flexible and tight integration in a wide range of hardware platforms. We also provide a Qt5 QML plugin that can easily replace the deprecated QtWebKit-based module.<\/p>\n\n<p>WPEWebKit leverages GStreamer for its multiple multimedia backends, ensuring your WPEWebKit-based browser supports zero-copy hardware video decoding on the most common embedded platforms such as the Raspberry Pi, i.MX6 and i.MX8M SoCS.<\/p>\n\n<p>WPEWebKit can also be used in pure GStreamer applications! Thanks to the GstWPE plugin, web-pages can be \"injected\" in GStreamer pipelines as audio and video streams. This new plugin thus enables use-cases such has HTML overlays.<\/p>\n\n<p>WPEWebKit is an open source project with a growing community, and it is developed within the ecosystem of the WebKit project, which powers many open source and proprietary web browsers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6088",
            "value": "Philippe Normand"
          }
        },
        "links":
        [
          {
            "_href": "http://wpewebkit.org",
            "value": "Main WPEWebKit website"
          },
          {
            "_href": "https://webkit.org/wpe/",
            "value": "Upstream WebKit.org WPE landing page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10498.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9515",
        "start": "16:30",
        "duration": "00:50",
        "room": "UD2.218A",
        "slug": "ema_yocto_extra_tools",
        "title": "How Yocto extra tools help industrial project",
        "subtitle": "Yocto is not (only) bitbake",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Yocto is the most famous \"build system\" for embedded Linux. During this conference we'll study how to use some Yocto  features to help the development of a free industrial project. We will study the eSDK (extended cross-toolchain), Ptest and Testimage (CI), Devtool and Devshell (recipe modification). We will also learn how to be in compliance with the GPLv3 / LGPLv3 licenses thanks to the \"archiver\" class (and more).<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1663",
            "value": "Pierre Ficheux"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9515.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10606",
        "start": "17:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_ptxdist",
        "title": "The State of PTXdist",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>PTXdist has been around as a build tool for embedded systems for more than 16 years now, but many new features were added in the recent time. Most importantly this includes support for kconfig diffs and layered BSPs, infrastructure for code signing and license compliance, a homepage with online documentation and a cute logo, as well as several small improvements. This talk gives an overview for new and old users over the current feature set and the core concepts behind PTXdist.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7327",
            "value": "Roland Hieber"
          }
        },
        "links":
        [
          {
            "_href": "https://ptxdist.org",
            "value": "PTXdist homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10606.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10562",
        "start": "18:00",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_lognplot",
        "title": "lognplot - logging and plotting data from micro's",
        "subtitle": "Tracing data on a modern laptop",
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Embedded systems are hard to debug. Complex systems have a lot of variables.\nWhen debugging those systems, we often log data into some files, and visualize\nthem later on, using excel, matplotlib or something else.<\/p>\n\n<p>This talk is about tracing and logging. What are the options we have as embedded\nsoftware developers? I will present the lognplot tool, a project to plot incoming data\non the fly.<\/p>",
        "description": "<p>Embedded systems are hard to debug. Complex systems have a lot of variables.\nWhen debugging those systems, we often log data into some files, and visualize\nthem later on, using excel, matplotlib or something else.<\/p>\n\n<p>This talk is about tracing and logging. What are the options we have as embedded\nsoftware developers? I will present the lognplot tool, a project to plot incoming data\non the fly. There are two implementations, one in python, and one in rust\nwith gtk-rs. The data is stored internally in a zoomable format, allowing\nlarge sets of data to be browsed easily.<\/p>\n\n<p>During the talk you will learn how to draw a chart, and how to aggregate\nlarge sets of data into summaries.<\/p>\n\n<p>I will demo a STM32 serial wire viewer output connected to this tool\nto enable live tracing of an embedded system.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5053",
            "value": "Windel Bouwman"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/windelbouwman/lognplot",
            "value": "lognplot repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10562.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9143",
        "start": "18:30",
        "duration": "00:25",
        "room": "UD2.218A",
        "slug": "ema_smoke_detector",
        "title": "U:Kit: Open-source software and hardware smoke detector",
        "subtitle": [],
        "track": "Embedded, Mobile and Automotive",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presenter will show the audience U:Kit ( https://github.com/attachix/ukit).\nU:Kit is an open source (software and hardware) smoke and motion detector with the help of open source tools.\nU:Kit is easy to assemble, has a plastic case, and can be attached to the ceiling and used with minimum efforts also from non-technical savvy people. But that is just the tip of the iceberg.\nThe presenter will share with the audience his experience in creating the devices and talk about some of the software and hardware challenges with which he and his team had to solve.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6444",
            "value": "Slavey Karadzhov"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/attachix/ukit",
            "value": "U:Kit project on GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9143.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UD2.Corridor"
  }
]