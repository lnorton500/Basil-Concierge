[
  {
    "_name": "Janson",
    "event":
    [
      {
        "_id": "9394",
        "start": "09:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "osi",
        "title": "Open Source Under Attack",
        "subtitle": "How we, the OSI and others can defend it",
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Whether it is \"Open Core\", the Mongo SSPL or the Common Clause, the core ethos of open source has been under attack for some time. As those parties who seek to limit the promise of free software enjoys more and more success, the community will need stronger and more forceful tools to defend ourselves. Presenters: Michael Cheng (Facebook), Max Sills (Google), Chris Aniszczyk (Linux Foundation)<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "4620",
            "value": "Chris Aniszczyk"
          },
          {
            "_id": "5412",
            "value": "Max Sills"
          },
          {
            "_id": "6309",
            "value": "Michael Cheng"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9394.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9047",
        "start": "10:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "open_door_closing",
        "title": "Is the Open door closing?",
        "subtitle": "Past 15 years review and a glimpse into the future.",
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>\"Open Source\" has been wildly successful, no doubt.<\/p>\n\n<p>Yet, in recent years, we have seen a massive amount of failed 'open' projects.<\/p>\n\n<p>Why is that?<\/p>\n\n<p>I have identified 10+ scenarios in which the 'Open' approach works. But what is most interesting, is that those scenarios have enabling conditions, and while those conditions are taken for granted, they are not.<\/p>\n\n<p>Not every 'Open' project is sustainable. Not every project is worth adopting or contributing to.<\/p>\n\n<p>During the presentation, we will look into what works and why, and what to expect from different 'Open' initiatives. We will cover almost everything that can be open - starting from hardware, through software, education, and we will end up covering Open Governments.<\/p>\n\n<p>Each sector is different, and for some of them, the 'Open' approach will not work. Come and see what I have found out in this space during my research, and evaluate whether you are working on the right project.<\/p>\n\n<p>Because the only resource you will never get back is time.<\/p>",
        "description": "<p>If you are using or contributing to a software projects, especially on your own, you certainly want to know whether your project has a chance of slipping into oblivion.\nDescribed scenarios will not only help you to answer that question, but will also help you to figure out what is most important for your project, right now.<\/p>\n\n<h1>The scenarios that will be covered include:<\/h1>\n\n<ul>\n<li>Open Hardware - DIY movements, when 'Open' is used quite cunningly to explore possibilities.<\/li>\n<li>Open Hardware - farming and ecology - a noble idea which is deeply flawed because it does not take into account basic economic rules.<\/li>\n<li>Open Content - beneficial to many people and organisation, but not necessarily for content creators.<\/li>\n<li>Open Education - yet another great idea, which has a hidden catch that makes or breaks it, depending on how the idea is executed.<\/li>\n<li>Open Access &amp;  Science - a rebellion against corporations that slow down the growth of humanity.<\/li>\n<li>Open Collaboration - projects run in this spirit let us advance knowledge and technical capabilities, but they do not promise financial returns.<\/li>\n<li>Bypass high cost of adoption - the idea that you can use software without going through a 3 months approval process was appealing in 1990. But today... that business model is going away thanks to the security folks.<\/li>\n<li>Open as a marketing tool - if it has 'Open' in the name, it is not open.<\/li>\n<li>Open Pet Projects - that deserves only mention, because there are so many such projects, but almost none of them is sustainable.<\/li>\n<li>Open Legislations and Governments - a futile attempt to increase transparency<\/li>\n<li>Open Data - very difficult to monetise, increasingly dangerous to consume<\/li>\n<li>Open Standards - a lot of legal uncertainties<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "4655",
            "value": "Krzysztof Daniel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9047.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9367",
        "start": "11:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "software_freedom",
        "title": "The core values of software freedom",
        "subtitle": [],
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>If you are a Free Software (Open Source Software) developer, do you have to follow an open development model or a certain business model? Do you have to believe in or be a supporter of socialism, capitalism, or liberalism? Do we, when we work for software freedom, have to agree on certain positions on privacy, intelligence services, the military, the climate catastrophe, nuclear power, vaccinations, or animal rights?<\/p>\n\n<p>Or should we accept to have different views or even allow each other not to discuss certain views, because what brings us together are other values?<\/p>",
        "description": "<p>I will argue that the core values of our movement are that everybody, no matter what background, can use the software for every purpose without discrimination. That everybody is allowed to study how software works. That you are always allowed to share your software with others, either to help other human beings or to make money. And that no individual, organisation or government should be forced to change their behaviour because of the software, but according to our principles, adapt and thereby improve the software for themselves and others.<\/p>\n\n<p>Furthermore, the talk understands itself as a plea for more respect and diversity in Free Software communities. It will be argued that while sticking to those values we should treat others decently who might have other believes, or another or no opinions at all about a topic we ourselves care about. That we should not try to put an emphasis on our other believes while working together on Free Software/Open Source Software, but instead work together with other groups or movements to bring our other topics forward.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "421",
            "value": "Matthias Kirschner"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9367.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9355",
        "start": "12:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "open_infrastructure",
        "title": "Why open infrastructure matters",
        "subtitle": [],
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>A lot of open source developers choose to deploy their software on infrastructure based on proprietary software. Behind this apparent paradox is the need to adapt to changing environments, adopt new technologies fast, and use increasing amounts of computing power. Open infrastructure (computing, networking and storage infrastructure based on open source software) has a lot to offer, but it's easy to overlook if you don't take the time to take a step back and analyze the situation rationally. In this talk, Thierry Carrez, VP of Engineering at the OSF, explains all the reasons why open infrastructure matters, and why it makes sense for you to adopt it today.<\/p>",
        "description": "<p>Outline of this talk:<\/p>\n\n<ul>\n<li>Infrastructure (what do we mean by infrastructure, and why it matters in the general evolution of computing)<\/li>\n<li>Open (key benefits of using open source software in general, and openly-developed community-led projects in particular)<\/li>\n<li>Capabilities, Compliance and Cost (extra benefits of using open source software for providing infrastructure)<\/li>\n<li>Interoperability (benefits of using the same open source projects across providers)<\/li>\n<li>Future-proof (open source allows to invest in adaptive communities rather than static products)<\/li>\n<li>Enabling innovation everywhere (infrastructure should not be only provided by a couple of Internet giants like Amazon and Google)<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "427",
            "value": "Thierry Carrez"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9355.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9097",
        "start": "13:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "gpl_and_business",
        "title": "Why the GPL is great for business",
        "subtitle": "Debunking the current business licensing discussion",
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>In the past few years we saw a lot of discussions around free software licenses and why they are bad for companies. This talk debunks this claim and shows how free software licenses are actually great for startups if done right.<\/p>",
        "description": "<p>In the last few years we saw a lot of discussion in the open source and free software startup space around licenses. Several companies stepped forward and claimed that it’s not possible to build a working company on top of a free software product. Some changed the license of their product to proprietary license like the Commons Clause or the Business Source License. They claim that this is needed to ‘save’ free software. This talk describes why this is fundamentally wrong. It’s possible to build a working startup and company on top of a free software product. This talk discusses how companies like Red Hat, SUSE and Nextcloud manages to have a 100% free software product including a big contributor community but is still able to pay developers and grow.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6495",
            "value": "Frank Karlitschek"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9097.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9641",
        "start": "14:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "united_nations",
        "title": "United Nations Technology and Innovation Labs",
        "subtitle": "Open Source isn't just eating the world, it's changing it",
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Amanda is the chair of the United Nations Technology and Innovation Labs' Open source and IP Advisory Board and will give an overview of the work being done by the labs and take the audience through a couple of case studies using data and blockchain for good in an open way.<\/p>",
        "description": "<p>Amanda will explain the goals and workings of the UNTIL Open Source Advisory Board and the opportunities for further community engagement with the labs, allowing a wider open community to be built supporting the labs through contributions and mentoring and the potential opportunities for Fellowship placings within the labs.\nShe will also look at the first projects working in the labs, with the Advisory and the open data and blockchain models that they have applied to these, using case studies.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6847",
            "value": "Amanda Brock"
          }
        },
        "links":
        [
          {
            "_href": "https://opensource.com/article/19/11/united-nations-goes-open-source",
            "value": "OpenSource.com Blog on the Advisory's work"
          },
          {
            "_href": "https://until.un.org/news/open-source-codes-and-challenge-sdgs-until-interview-amanda-brock",
            "value": "UN interview with Amanda"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9641.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9645",
        "start": "15:00",
        "duration": "00:50",
        "room": "Janson",
        "slug": "smartphones",
        "title": "Regaining control of your smartphone with postmarketOS and Maemo Leste",
        "subtitle": "Status of Linux on the smartphone",
        "track": "Freedom",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Linux mobile software (and GNU/Linux distributions) are not widely available on smartphones yet. This talk covers why it is desirable to have GNU/Linux (not: Android or Android-based) on the smartphone, what current state of various software attempts at Linux on the smartphone is, the progress they've been making, and will also dive into the available old and new hardware (including the PinePhone and Librem 5) to run the software &amp; distributions on.<\/p>",
        "description": "<p>Smartphones running regular (F)OSS Linux distributions are not common. We intend to provide an overview of the current Linux FOSS mobile stacks, distributions that package/provide the mobile stacks and to discuss the hardware that one can use to run this software on. We will provide additional details for the postmarketOS distribution and for Maemo Leste (Debian based FOSS mobile software). We also hope to go into some detail about the upcoming PinePhone (https://www.pine64.org/pinephone/)<\/p>\n\n<p>postmarketOS is a distribution based on alpine, with a focus on minimalism, security and mobile software. postmarketOS supports many old and new smartphones with varying degrees of support, and also packages/ships with various mobile software suites like Plasma Mobile, Maemo/Hildon, Phosh and more.<\/p>\n\n<p>Maemo Leste is based on Maemo Fremantle (from the Nokia N900 days), but completely open source. It's a repository on top of Debian/Devuan that pulls in the entire Maemo/Hildon user interface and suite of applications. Building on top of a proven set of interfaces, Maemo Leste also aims to be mostly compatible with Maemo the way many people might remember it, with a modern twist.<\/p>\n\n<p>Pine64 (known for ARM laptops and SBC (Single Board Computers) has decided to get into the mobile business with the Pine Tab and the Pine Phone device. Aiming to deliver developer devices in 2020Q1 and enthusiastic end-user devices in 2020Q2, they've energized software developers writing mobile interfaces for Linux and have been producing a mobile phone at remarkable pace. We will show the Pine64 device and discuss the current state of Linux support on the device.<\/p>\n\n<p>We plan to give live demos during the presentation, but will have pre-recorded videos as fallback.<\/p>",
        "persons":
        [
          {
            "_id": "5564",
            "value": "Merlijn B. W. Wajer"
          },
          {
            "_id": "6797",
            "value": "Bart Ribbers"
          }
        ],
        "links":
        [
          {
            "_href": "https://postmarketos.org/",
            "value": "postmarketOS"
          },
          {
            "_href": "https://maemo-leste.github.io",
            "value": "Maemo Leste blog/homepage"
          },
          {
            "_href": "https://www.openfest.org/2019/en/full-schedule/#lecture-471",
            "value": "Maemo Leste talk at Openfest 2019"
          },
          {
            "_href": "https://www.pine64.org/pinephone/",
            "value": "Pine64 pinephone page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9645.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9024",
        "start": "17:55",
        "duration": "00:20",
        "room": "Janson",
        "slug": "closing_fosdem",
        "title": "Closing FOSDEM 2020",
        "subtitle": [],
        "track": "Keynotes",
        "type": "keynote",
        "language": [],
        "abstract": "<p>Some closing words.  Don't miss it!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6",
            "value": "FOSDEM Staff"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9024.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.1.105 (La Fontaine)",
    "event":
    [
      {
        "_id": "9230",
        "start": "09:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "seccomp",
        "title": "SECCOMP your PostgreSQL",
        "subtitle": [],
        "track": "Databases",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>SECCOMP (\"SECure COMPuting with filters\") is a Linux kernel syscall filtering mechanism which allows reduction of the kernel attack surface by preventing (or at least audit logging) normally unused syscalls. Recent security best-practices recommend, and certain highly security-conscious organizations are beginning to require, that SECCOMP be used to the extent possible. The major web browsers, container runtime engines, and systemd are all examples of software that already support SECCOMP.<\/p>\n\n<p>This talk covers SECCOMP applied to PostgreSQL via 2 different methods -- namely top-down using systemd, and at the session level using a PostgreSQL extension called pgseccomp. The two methods will be explained and compared. We will also discuss how and why the two methods might be used in conjunction. Finally, a process to determine the list of expected/legitimate PostgreSQL kernel syscalls is described.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5557",
            "value": "Joe Conway"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9230.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9123",
        "start": "10:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "dqlite",
        "title": "dqlite: High-availability SQLite",
        "subtitle": "An embeddable, distributed and fault tolerant SQL engine",
        "track": "Databases",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>SQLite has proven extremely successful at providing applications with a powerful, portable and embeddable SQL engine that can handle most of their data storage needs.<\/p>\n\n<p>Unfortunately, SQLite is neither replicating nor fault tolerant. These two features are however very important for the rising Edge/IoT market: dqlite delivers both of them.<\/p>\n\n<p>dqlite is a C library which exposes a SQLite database over the network and replicates it using the Raft algorithm, with built-in automatic failover.<\/p>\n\n<p>It allows to build and operate a fault-tolerant cluster of nodes each running an instance of the user application.<\/p>\n\n<p>dqlite was created to support clustering in the LXD container management project, where it has been used for over a year. In this talk we will look at its design, implementation and various use cases.<\/p>",
        "description": "<p>Distributed systems are ubiquitous these days: we need to commoditize the underlying technologies and algorithms, making them easy to consume. The dqlite project offers application developers the opportunity to build on top of a storage engine which is as easy and convenient as a plain SQLite database, but also meets higher durability and fault tolerance requirements.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5249",
            "value": "Free Ekanayaka"
          }
        },
        "links":
        [
          {
            "_href": "https://dqlite.io",
            "value": "dqlite web site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9123.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9014",
        "start": "11:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "mysql8",
        "title": "MySQL Goes to 8!",
        "subtitle": [],
        "track": "Databases",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>The latest and greatest version of MySQL is MySQL 8.<\/p>\n\n<p>Currently the most used version of MySQL is MySQL 5.7. This talk will highlight what is new in MySQL 8.0 - a huge step forward for our users. MySQL 8.0 delivers significant improvements on all fronts, such as dramatically improved SQL, GIS, and JSON support. The talk will also cover the MySQL Document Store (MySQL = NoSQL + SQL) and MySQL InnoDB Cluster (HA out of the box) as well as MySQL Shell which ensures power, freedom, and flexibility for the Developer.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6369",
            "value": "Geir Høydalsvik"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9014.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9174",
        "start": "12:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "swim",
        "title": "SWIM - Protocol to Build a Cluster",
        "subtitle": "SWIM gossip protocol, its implementation, and improvements",
        "track": "Databases",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>SWIM - is a relatively new protocol to discover and monitor cluster nodes, to disseminate events and data between them. The protocol is extremely lightweight, decentralised, and its speed and load per node do not depend on cluster size.<\/p>\n\n<p>The protocol solves several tasks at once. First - build and keep up to date topology of a cluster without explicit configuration. The task is quite intricate because:<\/p>\n\n<ul>\n<li>new just started nodes know nothing about others, and they should somehow discover them;<\/li>\n<li>already working nodes can fail, and it should be detected so as to change a master, or evict an unrecoverable node from the cluster, or restart it.<\/li>\n<\/ul>\n\n\n<p>According to the protocol, cluster nodes broadcast packets and send p2p ping requests. Broadcast helps to discover new nodes, p2p pings help to detect failure of a known node.<\/p>\n\n<p>A second task - events dissemination in a cluster. Event is a node failure; UUID change; IP address update; new node appearance - anything that affects cluster state. Sometimes users define their own event types. When a node learns about an event, it needs to disseminate the event to other nodes. SWIM protocol describes an algorithm how to detect and disseminate events, and gives the following guarantees:<\/p>\n\n<ul>\n<li>it takes a constant time to learn about an event on at least one node in the cluster;<\/li>\n<li>it takes logarithmic from cluster size time to disseminate that event to each node of the cluster.<\/li>\n<\/ul>\n\n\n<p>In the talk I tell about how SWIM works, how and with which essential improvements it was implemented, how to use SWIM, and what are the practical performance results.<\/p>\n\n<p>Implementation is a part of Tarantool DBMS. Tarantool is the biggest Russian Open-Source DBMS. Tarantool currently goes toward better scalability, improvements in horizontal scaling, in cluster-wide calculations, and better cluster management. In scope of that roadmap SWIM protocol implementation was recently released.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6545",
            "value": "Vladislav Shpilevoy"
          }
        },
        "links":
        [
          {
            "_href": "https://www.tarantool.io/en/doc/2.2/reference/reference_lua/swim/",
            "value": "Documentation"
          },
          {
            "_href": "https://github.com/tarantool/tarantool/tree/master/src/lib/swim",
            "value": "Code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9174.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9223",
        "start": "13:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "speculative_execution",
        "title": "Improving protections against speculative execution side channel",
        "subtitle": [],
        "track": "Miscellaneous",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Speculative execution side channel methods pose new challenges to not only system administrators, users and security experts but also to developers. Developers can use different techniques to harden their code and reduce the feasibility of a possible malicious actor using these methods to leak secrets. But what is a secret? How can someone leak any of my data using these methods? This presentation introduces some architectural concepts that these methods use. It will also present how these methods work and how malicious actors might try to infer data from other users and codes. We will introduce some of the techniques that developers can use for mitigation, together with details about specific challenges that developers of different programming languages might face when implementing these mitigation techniques. Finally, we will present some of the mitigations that we are introducing in software to help ensure that these techniques can not be exploited in production environments.<\/p>",
        "description": "<p>No security or computer architecture background is required. Basic to intermediate programming skills are recommended.<\/p>\n\n<p>Attendees will come away with a better understanding of what speculative execution side channel issues are, how they work, and what they really mean for developers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7412",
            "value": "David Stewart"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9223.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9114",
        "start": "14:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "sabre",
        "title": "SaBRe: Load-time selective binary rewriting",
        "subtitle": [],
        "track": "Miscellaneous",
        "type": "maintrack",
        "language": [],
        "abstract": "<h2>Abstract<\/h2>\n\n<p>Binary rewriting is a technique that consists in disassembling a program to modify its instructions, with\nmany applications, e.g. monitoring, debugging, reverse engineering and reliability. However, existing solutions suffer from well-known\nshortcomings in terms of soundness, performance and usability.<\/p>\n\n<p>We present <em>SaBRe<\/em>, a novel load-time framework for selective binary rewriting. SaBRe rewrites specific constructs of\ninterest — mainly system calls and function prologues — when the program is loaded into memory. This enables users to intercept those constructs at runtime\nvia a modular architecture allowing custom plugins to be linked with SaBRe using a simple and flexible\nAPI. We also discuss the theoretical underpinnings of disassembling and rewriting, including conditions for\ncoverage, accuracy, and correctness; and how they affect SaBRe.<\/p>\n\n<p>We developed two backends for SaBRe — one for x86_64 and one for RISC-V — which were in turn used to\nimplement two open-source plugins: a fast system call tracer and a fault injector. Our evaluation\nshows that SaBRe imposes little performance overhead, between 0.2% and 4.3% on average.\nIn addition to explaining the architecture of SaBRe and demonstrating its performance,\nwe also show on a concrete example how easy creating a new plugin for SaBRe is.<\/p>\n\n<p>SaBRe is a free open-source software released under the GPLv3 license\nand originally developed as part of the Software Reliabilty Group at Imperial College London.<\/p>",
        "description": "<h2>Introduction<\/h2>\n\n<p>The goal of binary rewriting is to add, delete and replace\ninstructions in binary code. There are two main types of binary\nrewriting techniques: static and dynamic.\nIn static binary rewriting, the binary file is statically rewritten on disk, while\nin dynamic binary rewriting it is rewritten in memory, as the\nprogram executes.<\/p>\n\n<p>Static binary rewriting has the advantage\nthat the rewriting process does not incur any overhead during\nexecution, as it is performed before the program starts running.\nHowever, static binary rewriting is hard to get right: creating a\nvalid modified executable on disk is challenging, and correctly\nidentifying all the code in the program is error-prone in the\npresence of variable-length instructions and indirect jumps.<\/p>\n\n<p>By contrast, dynamic binary rewriting modifies the code in\nmemory, during program execution. This is typically accomplished by translating one basic block at a time and caching the\nresults, with branch instructions modified to point to already\ntranslated code. Since translation is done at runtime, when the\ninstructions are issued and the targets of indirect branches are\nalready resolved, dynamic binary rewriting does not encounter\nthe challenges discussed above for static binary rewriting.\nHowever, the translation is heavyweight and incurs a large\nruntime overhead.<\/p>\n\n<p>In this presentation, we introduce SaBRe, a system that implements\na novel design point for binary rewriting. Unlike prior techniques, SaBRe operates at load-time, after the program is\nloaded into memory, but before it starts execution. Like static\nbinary rewriting techniques, SaBRe rewrites the code in-place,\nbut the translation is done in memory, as for dynamic binary\nrewriting. To achieve a high level of both performance and reliability,\nSaBRe relies by default on trampolines, which are extremely efficient\nand can be used more than 99.99% of the time, and only falls back\non illegal instructions triggering a signal handler for pathological\ncases.<\/p>\n\n<p>The main limitation of SaBRe is that it is designed\nto rewrite only certain types of constructs, namely system\ncalls (including vDSO), function prologues and some architecture-\nspecific instructions (e.g. RDTSC in x86). However, as we illustrate\nlater on, this is enough to support a variety of tasks, with\nmuch lower overhead than with dynamic binary rewriting and\nwithout incurring the precision limitations of static binary\nrewriting.<\/p>\n\n<p>We implemented two binary rewriters based on this design:\none for x86 64 and one for RISC-V code. Both rewriters\nfeature a flexible API, which we used to implement three\ndifferent plugins: a fast system call tracer, a multi-version\nexecution system (not open-sourced yet) and a fault injector.\nIn summary, our main contributions are:\n1. A new design point for selective binary rewriting which\ntranslates code in memory in-place at load time, before\nthe program starts execution.\n2. An implementation of this approach for two architectures, one for x86 64 and the other for RISC-V.\n3. A comprehensive evaluation using two open-source plugins: a fast <code>strace<\/code>-like\nsystem call tracer and a fault injector.\n4. An extremely simple API that can be leveraged by users to\nimplement and integrate their own plugins.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6493",
            "value": "Paul-Antoine Arras"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/srg-imperial/SaBRe",
            "value": "SaBRe source repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9114.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9603",
        "start": "15:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "virtual_linux_desktop",
        "title": "The year of the virtual Linux desktop",
        "subtitle": [],
        "track": "Miscellaneous",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>We made the Linux desktop work in VR. Join me to hear about the history and future of xrdesktop and the FOSS XR landscape.<\/p>",
        "description": "<p>With tracked controllers, heads and hands, AR and VR introduced the requirement for a new set of user interactions. In this talk you will learn about existing implementations and how the classical UX model with keyboard and mouse translates to these new concepts. I will highlight the technical aspect of these requirements and how they were solved in xrdesktop. Featuring 3D window management and synthesis for traditional input, xrdesktop is a software stack that integrates VR in the GNOME and KDE desktop environments. You will also get an overview of the history and status of Open Source in AR and VR.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6842",
            "value": "Lubosz Sarnecki"
          }
        },
        "links":
        [
          {
            "_href": "http://col.la/xrdesktop",
            "value": "Moving the Linux desktop to another reality"
          },
          {
            "_href": "https://gitlab.freedesktop.org/xrdesktop",
            "value": "xrdesktop on Freedesktop"
          },
          {
            "_href": "https://guadec.ubicast.tv/videos/moving-gnome-to-another-reality/",
            "value": "GUADEC: Moving GNOME to Another Reality"
          },
          {
            "_href": "https://www.youtube.com/watch?v=siYvcs13b9M",
            "value": "xrdesktop Dev Podcast"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9603.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9236",
        "start": "16:00",
        "duration": "00:50",
        "room": "K.1.105 (La Fontaine)",
        "slug": "matrix",
        "title": "Making & Breaking Matrix's E2E encryption",
        "subtitle": "In which we exercise the threat model for Matrix's E2E encrypted decentralised communication",
        "track": "Miscellaneous",
        "type": "maintrack",
        "language": [],
        "abstract": "<p>Matrix is an open protocol and open network for decentralised real-time communication; shifting control over communication from the big proprietary silos back to the general population of the Internet. In 2016 we added E2E Encryption based on the Double Ratchet, and since then have been working away on getting the encryption so polished that we can transparently turn it on by default everywhere.  In this talk, we'll show how we have finally done this, what the blockers were, and then try to smash the encryption to pieces to illustrate the potential attacks and how we mitigate them.<\/p>",
        "description": "<p><a href=\"https://matrix.org\">Matrix<\/a> is an ambitious project to build a open decentralised real-time communication network; providing an <a href=\"https://matrix.org/docs/spec\">open standard protocol<\/a> and <a href=\"https://matrix.org/docs/projects/try-matrix-now/\">open source reference implementations<\/a>, letting anyone and everyone spin up a Matrix server and retake control of their real-time communication. Matrix is looked after by the non-profit <a href=\"https://matrix.org/foundation\">Matrix.org Foundation<\/a>, and as of Oct 2019 we have over 11.5M addressable users and around 40K servers on the public network.<\/p>\n\n<p>Over the course of 2019 we spent a huge amount of time finalising Matrix's end-to-end encryption so we could finally turn it on by default without compromising any of the behaviour users had grown accustomed to in non-encrypted rooms.  Specifically, the main remaining blockers were:\n * Ability to search in E2E encrypted rooms (now solved by <a href=\"https://github.com/matrix-org/seshat\">Seshat<\/a>: a Rust-based full-text-search engine embedded into Matrix clients)\n * Ability to get compatibility with non-E2E clients, bots and bridges (now solved by <a href=\"https://github.com/matrix-org/pantalaimon\">pantalaimon<\/a>: a daemon which offloads E2E encryption)\n * Reworking the whole encryption UI to expose cross-signing to radically simplify key verification (including QR-code scanning for simplicity)\n * Ability to receive notifications in E2E encrypted rooms.<\/p>\n\n<p>However, we have finally got there, and this talk will demonstrate how the final E2EE implementation works; the final problems we had to solve; the threat model we have implemented; and how we're doing on rolling it out across the whole network.  More interestingly, we will then demonstrate a variety of attacks against the encryption (e.g. shoulder-surfing QR codes during device verification; MITMing TLS; acting as a malicious server implementation; global passive adversary) to demonstrate how well we handle them.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2951",
            "value": "Matthew Hodgson"
          }
        },
        "links":
        [
          {
            "_href": "https://matrix.org",
            "value": "Matrix.org"
          },
          {
            "_href": "https://matrix.org/foundation",
            "value": "The Matrix.org Foundation"
          },
          {
            "_href": "https://matrix.org/docs/spec",
            "value": "The Matrix Specification"
          },
          {
            "_href": "https://matrix.org/docs/projects/try-matrix-now/",
            "value": "Try Matrix Now"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9236.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.2215 (Ferrer)",
    "event":
    [
      {
        "_id": "9747",
        "start": "10:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "standards_organizations_and_open_source",
        "title": "Open Source - Killing standards organizations or saving them",
        "subtitle": "Open source and standards join forces for mutual benefit",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Open source communities move quickly, value running code, and docs are best effort at best. Standards move slowly, value precise specs, and negotiate compromises for broad alignment. Given these differences, why would open source communities fraternize with standards orgs? Standards orgs such as IETF and MEF realize they need to change to remain relevant. By embracing open source, standards orgs benefit from the speed and collaborative spirit of open source and get timely feedback on the clarity and correctness of standards as they evolve in parallel with running code. Open source communities gain users, address additional use cases, and gain the stability of standards to ease integration efforts and avoid forks. This session explores this evolution in standards orgs, highlights areas of mutual interest, and shares ideas on the benefit of closer collaboration.<\/p>",
        "description": "<p>By collaborating with standards organizations and supporting existing and evolving standards, the open source community gains users, address a larger set of use cases, and benefit from the stability of standards that can help avoid harmful forking and ease integration efforts. Standards orgs benefit from the speed and collaborative spirit characteristics of open source, and they gain timely and critical feedback on the clarity and correctness of their standards as they evolve iteratively and in parallel with the open source code. The end result is open source code that is more consumable by industry, and standards that are more consumable by the open source community.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3782",
            "value": "Charles Eckel"
          }
        },
        "links":
        [
          {
            "_href": "https://ietf.org/how/runningcode/hackathons//",
            "value": "IETF Hackathon site"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9747.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9456",
        "start": "10:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "emissions_api",
        "title": "emissions API",
        "subtitle": "a service to easily access air quality data from remote sensing",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The European Space Agency’s Sentinel-5P satellite is built to monitor air quality data (carbon hydroxide, sulfur monoxide, ozone, …). All data gathered are publicly available …if you know what to do with those data sets, great, but if not:<\/p>\n\n<p>Emissions API’s mission is to provide easy access to this data without the need of being an expert in satellite data analysis and without having to process terabytes of data.<\/p>\n\n<p>This way, we hope to empower others to easily build apps that use this data – e.g. visually showing emissions of countries over time.<\/p>",
        "description": "<p>Achievements of climate goals are so far only verifiable for a very small group of people with specialized know-how. As a result, public discussion remains abstract and elusive for many people. Easy access to emissions data provides a more general audience with the opportunity to form a fact-based opinion. For example, one could evaluate the effectiveness of environmental regulations – such as diesel driving bans in inner cities or new sulfur limits in shipping–by comparing actual measurements from before and after on a map.<\/p>\n\n<p>Emissions API is a solution that provides simple access to emissions data of climate-relevant gases. For this purpose, data of the European Space Agency’s Sentinel-5P earth observation satellite will be prepared in such a way that it allows programmers easy access without the need to have a scientific background in the field.<\/p>\n\n<p>The project strives to create an application interface which lowers the barrier to use the data for visualization and/or analysis.\nTackling the problem<\/p>\n\n<p>The project’s core is an API, which can be used to query the processed data. For this purpose, we develop a cloud service which queries the freely accessible data of Sentinel-5P, aggregates it, stores it in a cache and makes it available.\nTarget audience<\/p>\n\n<p>This project targets developers who want to build their own services based on the satellite data of the Copernicus program, but who do not want to work with huge amounts of scientific data directly. We will provide examples and libraries to quickly get you started without being an expert in satellite data analysis.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6740",
            "value": "Timo Nogueira Brockmeyer"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/emissions-api",
            "value": "github project page"
          },
          {
            "_href": "https://emissions-api.org/",
            "value": "website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9456.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9224",
        "start": "10:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "git_issue_management",
        "title": "git-issue",
        "subtitle": "Git-based decentralized issue management with GitHub/GitLab integration",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Git-issue is a minimalist decentralized issue management system based on Git,\noffering (optional) biderectional integration with GitHub and GitLab issue management.\nIt has the following advantages over other systems.<\/p>\n\n<ul>\n<li><strong>No backend, no dependencies:<\/strong>\nYou can install and use <em>git issue<\/em> with a single shell script.\nThere's no need for a server or a database back-end, and the corresponding\nproblems and requirements for their administration.<\/li>\n<li><strong>Decentralized asynchronous management:<\/strong>\nAnyone can add, comment, and edit issues without requiring online access\nto a centralized server.\nThere's no need for online connectivity; you can pull and push issues\nwhen you're online.<\/li>\n<li><strong>Transparent text file format:<\/strong>\nIssues are stored as simple text files, which you can view, edit, share, and\nbackup with any tool you like.\nThere's no risk of losing access to your issues because a server has\nfailed.<\/li>\n<li><strong>Git-based:<\/strong>\nIssues are changed and shared through Git.\nThis provides <em>git issue<\/em> with a robust, efficient, portable,\nand widely available infrastructure.\nIt allows you to reuse your Git credentials and infrastructure, allows\nthe efficient merging of work, and also provides a solid audit trail\nregarding any changes.\nYou can even use Git and command-line tools directly to make sophisticated\nchanges to your issue database.<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3691",
            "value": "Diomidis Spinellis"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/dspinellis/git-issue",
            "value": "Git-issue on GitHub"
          },
          {
            "_href": "https://dspinellis.github.io/manview/?src=https://raw.githubusercontent.com/dspinellis/git-issue/master/git-issue.1",
            "value": "Manual page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9224.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10046",
        "start": "11:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "heptapod_mercurial",
        "title": "The Heptapod project",
        "subtitle": "Bringing Mercurial to GitLab",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Heptapod is a friendly fork of GitLab CE that supports the Mercurial DVCS.\nToday, Bitbucket starts dropping the support for Mercurial. Heptapod can provide nice new homes for projects that have to migrate out of Bitbucket.\nWe are looking for contributors - lots of different skills can be useful.<\/p>",
        "description": "<p>Mercurial is a free software distributed version control system (DVCS) written primarily in Python, with an intuitive command line interface and strong, safe history rewriting features.<\/p>\n\n<p>Mercurial is in active development and in use at several large organisations, which\nappreciate especially its extensibility and its ability to handle very large repositories.<\/p>\n\n<p>However, Mercurial has been somewhat lacking public exposure in the past few years for not being a first class citizen in the prominent integrated hosting and collaboration solutions.\nThis culminated recently with Bitbucket announcing last summer its plan to drop support for Mercurial, in particular planning to stop accepting new repositories by February 1st, 2020 (that's the first day of this FOSDEM edition!).<\/p>\n\n<p>In this talk, we will present the Heptapod project, which brings Mercurial support to GitLab Community Edition, the well-known open-source integrated platform for source collaboration and dev-ops. Lately, GitLab CE has been selected by some major free software projects, such as Debian and Gnome, to name only a few.<\/p>\n\n<p>Several free and open-source projects have successfully migrated from Bitbucket to Heptapod. We are willing to help more of them doing so, either by hosting them directly if possible (contact us) or by giving them a hand in the transition.<\/p>\n\n<p>Heptapod is a community-driven effort, whose development involves many programming languages: Ruby, Go, Python, Javascript and potentially Rust, but one does not need to be a expert in all of these to start contributing.<\/p>\n\n<p>We are calling interested people to join us on our Heptapod instance (of course), there's a bit of low hanging fruit to grab there.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7066",
            "value": "Georges Racinet"
          }
        },
        "links":
        [
          {
            "_href": "https://heptapod.net",
            "value": "Project page"
          },
          {
            "_href": "https://dev.heptapod.net",
            "value": "Main development instance"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10046.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9520",
        "start": "11:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "puavo_linux_desktops_finland",
        "title": "puavo.org",
        "subtitle": "Linux desktops in Finnish schools",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>A Finnish company Opinsys has provided and maintained\nmany thousands of Linux desktops in Finnish schools for\nabout fifteen years now.  This is a short introduction\nto the technology (called Puavo) they have developed\nfor this purpose.<\/p>",
        "description": "<p>Puavo can be used to manage Linux desktops suitable\nfor school environments.  It is a combination of web\nsoftware (Puavo Web) and a specially configured system\n(Puavo OS) using Debian GNU/Linux operating system as\nits base.  Puavo Web is built for managing user accounts\nand devices.  Puavo OS is designed for large-scale\ndeployment in primary and secondary schools.  The source\ncode for both is free software under GPLv2+ license.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6779",
            "value": "Juha Erkkilä"
          }
        },
        "links":
        [
          {
            "_href": "http://www.opinsys.fi",
            "value": "Opinsys"
          },
          {
            "_href": "http://puavo.org",
            "value": "puavo.org"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9520.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10052",
        "start": "11:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "semester_ly",
        "title": "Open Source for students, by students",
        "subtitle": "Teaching university students how to contribute to open source projects by providing a product to their peers",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Five years ago, Semester.ly was created for students, by students. As a one stop shop for students to find classes that fit their schedule, Semester.ly has course reviews, textbook prices, and the classes your Facebook friends are taking. As a student start-up, it quickly expanded to 8+ schools and accumulated 100,000 users. In 2016, Semester.ly went open source and many of its core members graduated. Over the past three years, university administrators and students have worked together to maintain Semester.ly’s success and grow it as an educational tool within universities. Semester.ly’s serves two purposes now: make course registration easier and teach students how to contribute to open source projects.<\/p>",
        "description": "<p>Every semester, students at universities across the country scramble to plan their course schedules for the upcoming academic term. Post-it notes, Excel spreadsheets, emails, and group chats all make up a stressful period in an already stressed out student’s life. The problem is simple: university backed course scheduling infrastructure is outdated. Universities have been around for hundreds of years and their internal software for decades, yet their students are a part of a technology revolution that expects things to be fast and social&lt;sup>1&lt;/sup>.<\/p>\n\n<p>A few months after tangling with course registration woes, students are engrossed in another stressful time period in which they attempt to acquire jobs. Employers look for experienced qualified candidates. Students go to school to become these candidates but most of the time, they just get a piece of paper that is losing value in the public mind&lt;sup>2&lt;/sup>. Universities try their best to prepare their students for the workforce through rigorous classwork and career resources but today’s workforce is ultra competitive and a college education isn’t enough&lt;sup>3&lt;/sup>.<\/p>\n\n<p>Here lie two seemingly unrelated problems for universities. University course registration systems are falling behind and universities aren’t fitting student’s needs in preparing them for post-graduation employment. Semester.ly solves both problems.<\/p>\n\n<p>Semester.ly was founded by an initial development team of Noah Presler, Felix Zhu, and Rohan Das during the summer of 2014. Back then, the goal of Semester.ly was to improve course registration. Before the founding team graduated, Semester.ly went open source in Spring 2016 with the hope that other students would carry on the torch. However, it was hard to find dedicated developers and funding without a business plan that involved making money later. These are problems that many open source organizations face but being based at a university also meant that team members would inevitably graduate every few years. There was a need for consistent members, incentives for developers, and funding for the server.<\/p>\n\n<p>Three organizational structures were created to solve these problems. The first was a student organization. This seemed like the obvious first choice since it's how the original team started but student developers didn’t have any incentive and would stop working once school work picked up. The second structure was a course to obtain credit for working on open source projects. After conversations with the Chair of the Computer Science Department at Johns Hopkins University, a course called Software for Resilient Communities was created focusing on four open source projects to benefit local and global communities&lt;sup>4&lt;/sup>. Since this was a course, students would take the first half of the semester to learn the technology stack, make an impact, and then never contribute again because they couldn’t repeat the class. This did succeed in getting lots of students exposed to open source projects but eventually the professor running the course left to run his own company and the course wasn’t offered again. The third and final organizational structure that Semester.ly maintains today is as a paid on-campus job. After all of these years, Semester.ly has become a strong presence on campus and school administrators have taken notice. To support our mission, Johns Hopkins Information Technology provides hosting, hourly pay for student developers, and consistent leadership for students. This organizational structure has been in place for about a year now and we’ve made great progress onboarding new student developers and creating new features.<\/p>\n\n<p>With this partnership, Semester.ly is more integrated with the university and several other partnerships have arisen. For example, Semester.ly now shows what tutoring services are available through the university and we’re developing a way to register for these tutoring services on Semester.ly next semester. Going forward, Semester.ly will continue to make course registration easier as well as provide whatever other services students see fit. Semester.ly proves that it's possible for open source projects to thrive on college campuses as a service and educational tool.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5740",
            "value": "Kristin Yim"
          }
        },
        "links":
        [
          {
            "_href": "http://semester.ly",
            "value": "Semester.ly homepage"
          },
          {
            "_href": "http://github.com/noahpresler/semesterly",
            "value": "Original Repository"
          },
          {
            "_href": "https://github.com/jhuopensource/semesterly",
            "value": "Johns Hopkins University Open Source Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10052.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10048",
        "start": "12:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "adult_education",
        "title": "Open Adult Education: a curriculum to bridge the digital skills gap with free and open source technologies",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The OPEN-AE project is developing an open, and modular curriculum directed to train e-facilitators and trainers working with people who are in need of upskilling and reskilling in free and open-culture. The OPEN AE curriculum is meant to be modular and adaptable to the immediate training needs of the efacilitators. The training aims to introduce the trainers to the values of free and open-culture and empower them with the values behind this culture so it can be transmitted to low-skilled adults. the training will also have modules supporting a transition to free and open source software and culture.  Open-AE is not merely about teaching free and open softwares, but aims to have the trainers be active participants in the culture, knowing how to license these openly how to collaborate and develop as a collective.<\/p>",
        "description": "<p>The OPEN-AE project is developing an open, and modular curriculum directed to train e-facilitators and trainers working with people who are in need of upskilling and reskilling in free and open-culture. The OPEN AE curriculum is meant to be modular and adaptable to the immediate training needs of the efacilitators. The training aims to introduce the trainers to the values of free and open-culture and empower them with the values behind this culture so it can be transmitted to low-skilled adults. the training will also have modules supporting a transition to free and open source software and culture.  Open-AE is not merely about teaching free and open software but aims to have the trainers be active participants in the culture, knowing how to license these openly how to collaborate and develop as a collective.<\/p>\n\n<p>ALL DIGITAL is a network that wants to ensure every European, or rather every person can be empowered by the digital transformation, in short, we work in the field of digital inclusion. Our organisation started slightly over ten years ago as a grassroots movement among digital competency centres, and this scaled to the European level. Today 43% lack basic digital skills with half of them having skills at all. It is important to ensure<\/p>\n\n<p>At the moment ALL DIGITAL is coordinating the OPEN-AE project which aims to introduce free and open-source technologies to those who do not have enough digital skills or are in need upskilling. The project consortium involves partners working in the sector of digital inclusion running digital competency centres around Europe and one European network, ALL DIGITAL. The project aims to bridge the digital skills gap with free and open source technologies by developing a training curriculum directed to e-facilitators working in the non-formal sector. This curriculum will be open and modular allowing trainers to immediately adapt it to their training needs.<\/p>\n\n<p>Open-AE aims to not merely be an one-off project but wants to start a movement in the digital inclusion sector to ensure the digital skills gap is not bridge merely with proprietary software, but empower users so they can be empowered users with access to the relevant software and they know how to participate in the open culture after the training ends. Many in the digital inclusion sector are intimidated by free and open source software, believing they need a higher level than basic skills to use the software effectively. Breaking down the image of free and open source software and making it more approachable is essential to ensure lower skills users can not only access and use digital technologies but are empowered by them.<\/p>\n\n<p>The Open-AE consortium would like to present their work to FOSDEM to be engaged in a dialogue with developers and the open source community in activities directed to bridge the digital skills gap, to know what work developers are doing, but also engage in the open community in a direct capacity. Two partners based in Brussels ALL DIGITAL a European network, and Maks, Medie en Actie in Kureghem, will present the work. The presentation will go over the need to work in the field of digital inclusion.<\/p>\n\n<p>The presentation will go over the challenges in the digital inclusion with approaching free and open source technologies, the process of how the curriculum was developed, the curriculum itself, and how to scale this movement and carry it further.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7021",
            "value": "Pia Groenewolt"
          }
        },
        "links":
        [
          {
            "_href": "https://open-ae.eu/",
            "value": "project website"
          },
          {
            "_href": "https://all-digital.org/projects/open-ae/",
            "value": "ALL DIGITAL project card"
          },
          {
            "_href": "http://www.unite-it.eu/profiles/blogs/how-to-open-ae",
            "value": "blog on workshop"
          },
          {
            "_href": "http://www.unite-it.eu/profiles/blogs/how-to-open-ae",
            "value": "Tool for the open ae curriculum"
          },
          {
            "_href": "https://www.ynternet.org/page/ressources/richard-stallman-2019-tour-conferences",
            "value": "Richard Stallman at a open ae/ ynternet workshop last year"
          },
          {
            "_href": "http://www.unite-it.eu/profiles/blogs/how-to-open-ae",
            "value": "workshop with efacilitators on how to open ae"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10048.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9706",
        "start": "12:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "wyliodrin_studio",
        "title": "Prototyping the Internet of Things with Wyliodrin STUDIO",
        "subtitle": "An open source platform for building IoT prototypes",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>In 2014, teaching a Raspberry Pi programming course was a real challenge, mostly due to the lack of development devices. This is how we came up with the idea of building Wyliodrin STUDIO.<\/p>\n\n<p>Wyliodrin STUDIO is an easy to use IDE for the Internet of Things that enables remote control over embedded devices. While it is a good prototyping tool, the platform also targets students and educators who want to get started in the IoT field. It is designed to help both technical and non-technical people to get started with programming devices such as the Raspberry Pi.<\/p>\n\n<p>In this talk we aim to present Wyliodrin STUDIO, how it works and how we and other universities used it to teach IoT technologies in classes such as computer science, power engineering and film directing.<\/p>",
        "description": "<p>Wyliodrin STUDIO is an open source, web-based IDE designed for fast prototyping of Internet of Things applications.<\/p>\n\n<p>We have build this platform because we needed an affordable way of programming embedded devices such as the Raspberry Pi. Since 2014, when the first platform version was released, we have improved the solution so now it can be used to remotely program, control and monitor devices. For the moment, the platform is compatible with devices such as the Raspberry Pi and BeagleBone Black and supports Python, Node.js and visual, block-based programming languages.<\/p>\n\n<p>Since 2014 the platform has been used by companies such as Intel and Cisco and in institutions such as UCLA, USC, Ulm University and Toronto Public Library.<\/p>\n\n<p>The purpose of our presentation is not only to make an overview of Wyliodrin STUDIO's characteristics, but also introduce the audience to our experience in teaching IoT courses and how the platform helped us.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6910",
            "value": "Alexandru Radovici"
          }
        },
        "links":
        [
          {
            "_href": "https://wyliodrin.studio",
            "value": "Wyliodrin STUDIO website"
          },
          {
            "_href": "https://www.github.com/wyliodrinstudio",
            "value": "Wyliodrin STUDIO source code"
          },
          {
            "_href": "https://www.npmjs.com/package/wstudio-web",
            "value": "Wyliodrin STUDIO offline web version"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9706.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9810",
        "start": "12:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "duckdb",
        "title": "DuckDB",
        "subtitle": "An Embeddable Analytical Database",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>We present DuckDB, our new, Open Source embedded analytical data management system.<\/p>",
        "description": "<p>Data management systems have evolved into large monolithic database servers running as stand-alone processes. This is partly a result of the need to serve requests from many clients simultaneously and partly due to data integrity requirements. While powerful, stand-alone systems require considerable effort to set up properly and data access is constricted by their client protocols. There exists a completely separate use case for data management systems, those that are embedded into other processes where the database system is a linked library that runs completely within a ``host'' process. The most well-known representative of this group is SQLite, the most widely deployed SQL database engine with more than a trillion databases in active use. SQLite strongly focuses on transactional (OLTP) workloads, and contains a row-major execution engine operating on a B-Tree storage format. As a consequence, SQLite's performance on analytical (OLAP) workloads is very poor.<\/p>\n\n<p>There is a clear need for embeddable analytical data management. This needs stems from two main sources: Interactive data analysis and edge computing. Interactive data analysis is performed using tools such as R or Python. The basic data management operators available in these environments through extensions (dplyr, Pandas, etc.) closely resemble stacked relational operators, much like in SQL queries, but lack full-query optimization and transactional storage. Embedded analytical data management is also desirable for edge computing scenarios. For example, connected power meters currently forward data to a central location for analysis. This is problematic due to bandwidth limitations especially on radio interfaces, and also raises privacy concerns. An embeddable analytical database is very well-equipped to support this use case, with data analyzed on the edge node. The two use cases of interactive analysis and edge computing appear orthogonal. But surprisingly, the different use cases yield similar requirements.<\/p>\n\n<p>In this talk, we present our new system, DuckDB. DuckDB is a new purpose-built embeddable relational database management system created at the Database Architectures group of the CWI. DuckDB is available as Open-Source software under the permissive MIT license. To the best of our knowledge, there currently exists no purpose-built embeddable analytical database despite the clear need outlined above. DuckDB is no research prototype but built to be widely used, with millions of test queries run on each commit to ensure correct operation and completeness of the SQL interface.<\/p>\n\n<p>DuckDB is built from the ground up with analytical query processing in mind. As storage, DuckDB uses a single-file format with tables partitioned into columnar segments. Data is loaded into memory using a traditional buffer manager, however, the blocks that are loaded are significantly larger than that of a traditional OLTP system to allow for efficient random seeks of blocks. Queries are processed using a vectorized query processing engine to allow for high performance batch processing and SIMD optimizations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6953",
            "value": "Hannes Mühleisen"
          }
        },
        "links":
        [
          {
            "_href": "http://duckdb.org",
            "value": "DuckDB Website"
          },
          {
            "_href": "https://github.com/cwida/duckdb",
            "value": "GitHub repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9810.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9366",
        "start": "13:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "apache_datasketches",
        "title": "Apache DataSketches",
        "subtitle": "A Production Quality Sketching Library for the Analysis of Big Data",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>In​ the analysis of b​ig data there are often problem queries that don’t scale because they require huge compute resources to generate exact results, or don’t parallelize well. Examples include c​ount-distinct, ​quantiles, most frequent items, joins, matrix computations, and graph analysis. Algorithms that can produce accuracy guaranteed approximate answers for these problem queries are a required toolkit for modern analysis systems that need to process massive amounts of data​ quickly. For interactive queries there may not be other viable alternatives, and in the case of real­-time streams, these specialized algorithms, called stochastic, s​treaming, sublinear algorithms,​ or 's​ketches',​ are the only known solution. This technology has helped Yahoo successfully reduce data processing times from days to hours or minutes on a number of its internal platforms and has enabled subsecond queries on real-time platforms that would have been infeasible without sketches. This talk provides a short introduction to sketching and to Apache DataSketches, an open source library of these algorithms designed for large production analysis systems.<\/p>",
        "description": "<p>Fast:\nSketches are fast. The sketch algorithms in this library process data in a single pass and are suitable for both real-time and batch. Sketches enable streaming computation of set expression cardinalities, quantiles, frequency estimation and more. This allows simplification of system's architecture and fast queries of heretofore difficult computational tasks.<\/p>\n\n<p>Big Data Platforms:\nThis library has been specifically designed for big data platforms. Included are adaptors for Hadoop Pig, Hive, Spark, Druid, and Postgresql, which also can be used as examples for other systems, and many other capabilities typically required in big data analysis systems. For example, a Memory package for managing large off-heap memory data structures.  Our sketch library is implemented in Java, C++ and Python and provides binary compatibility across languages and platforms.  Some of our sketches provide off-Java-heap capability which dramatically improves performance in large systems.   Our APIs provide a rich set of options to enable fine tuning performance parameters that are particularly important for large systems.<\/p>\n\n<p>Analysis:\nBuilt-in Theta Sketch set operators (Union, Intersection, Difference) produce sketches as a result (and not just a number) enabling full set expressions of cardinality, such as ((A ∪ B) ∩ (C ∪ D)) \\ (E ∪ F). This capability along with predictable and superior accuracy (compared with Include/Exclude approaches) enable unprecedented analysis capabilities for fast queries.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3098",
            "value": "Claude Warren"
          }
        },
        "links":
        [
          {
            "_href": "http://datasketches.apache.org",
            "value": "Project Website"
          },
          {
            "_href": "https://docs.google.com/presentation/d/1HP9uhWKCcRMZC96ZL1J0Jwup-cmvqIB3W7aKrvbC27M/edit?usp=sharing",
            "value": "Draft Presentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9366.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9720",
        "start": "13:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "deoldify_images",
        "title": "DeOldify",
        "subtitle": "Colorizing images and videos with AI",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>DeOldify is a Deep Learning project for colorizing and restoring old images and videos.<\/p>\n\n<p>In this presentation, you will learn what's behind DeOldify, how it achieves good results and if they are historically accurate.\nYou will also learn how to run the model yourself on your computer or Colab to colorize pictures/videos that you have.<\/p>",
        "description": "<p>DeOldify is a Deep Learning project for colorizing and restoring old images and videos.<\/p>\n\n<p>In this presentation, you will learn what's behind DeOldify, how it achieves good results and if they are historically accurate.\nYou will also learn how to run the model yourself on your computer or Colab to colorize pictures/videos that you have.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6916",
            "value": "Alexandre Vicenzi"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9720.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9851",
        "start": "13:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "pictor_radio_telescope",
        "title": "PICTOR: A free-to-use open source radio telescope",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>PICTOR, located in Athens, Greece, consists of a 1.5-meter parabolic antenna that allows anyone to make continuous and spectral (i.e. hydrogen line) drift-scan observations of the radio sky in the 1300~1700 MHz regime for free. The goal of this effort is to introduce students, educators, astronomers and others to the majesty of the radio sky, promoting radio astronomy education, without the need of building a large and expensive radio telescope.<\/p>\n\n<p>PICTOR is a fully open source (software &amp; hardware) project: https://github.com/0xCoto/PICTOR<\/p>",
        "description": "<p>PICTOR is a free-to-use open source and open hardware radio telescope that aims to promote radio astronomy on a budget. It consists of a 1.5 meter parabolic dish antenna, a 1420 MHz-optimized feedhorn, a two stage low noise amplifier (LNA) with a built-in high-pass filter, and an RTL-SDR. Future upgrades may also use higher-bandwidth SDRs, such as the LimeSDR Mini.<\/p>\n\n<p>This radio telescope allows users to measure hydrogen line emissions from our galaxy. Under certain conditions, hydrogen atoms can emit photons with a wavelength of 21 cm, which corresponds to a frequency of 1420.405 MHz. Because our galaxy is so rich in terms of neutral hydrogen, a radio telescope like PICTOR is capable of detecting such faint radio emissions. When the telescope is pointing to the galactic plane (the Milky Way band), the intensity around 1420 MHz gets significantly stronger. Radio astronomers are able to use information like the Doppler shift such emissions have undergone, in order to determine neutral hydrogen concentration, map the spiral geometry of our galaxy, and even provide evidence for the existence of dark matter by plotting the rotation curve of the Milky Way!<\/p>\n\n<p>In order to observe with PICTOR, a user can just visit www.pictortelescope.com, click \"Observe\", fill in their observation parameters (frequency, observing duration etc.) and submit their observation, and as soon as the observation is finished, the user will receive an email with their observation data and the parameters they entered.<\/p>\n\n<p>Since the initial launch, PICTOR has gotten lots of updates and improvements, particularly in the software backend, providing more data to the users, using advanced techniques to increase the signal-to-noise ratio by calibrating spectra and mitigating radio frequency interference (RFI) (if present), and more.<\/p>\n\n<p>There is also a PDF for users who are unfamiliar with radio astronomy and radio telescopes to get started: https://www.pictortelescope.com/Observing<em>the<\/em>radio<em>sky<\/em>with_PICTOR.pdf<\/p>\n\n<p>PICTOR is a fully open source (software &amp; hardware) project, and everything can be found on the GitHub repository: https://www.github.com/0xCoto/PICTOR<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6974",
            "value": "Apostolos Spanakis-Misirlis"
          }
        },
        "links":
        [
          {
            "_href": "https://www.pictortelescope.com/",
            "value": "Website"
          },
          {
            "_href": "https://www.pictortelescope.com/observe",
            "value": "PICTOR Telescope Control"
          },
          {
            "_href": "https://www.pictortelescope.com/Observing_the_radio_sky_with_PICTOR.pdf",
            "value": "PDF Guide"
          },
          {
            "_href": "https://www.github.com/0xCoto/PICTOR",
            "value": "Official GitHub Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9851.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9055",
        "start": "14:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "dataverse",
        "title": "Advancing science with Dataverse",
        "subtitle": "Publication, discovery, citation, and exploration of research data.",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Dataverse is open source research data repository software installed by 48 institutions around the world and translated into ten languages. It facilitates data sharing, allowing researchers to replicate and build upon each other's work and receive academic credit in the form of citations for publishing data. Data deposited into Dataverse installations is made more discoverable through harvesting of metadata via standard protocols, publication to registries such as DataCite, and indexing into scholarly search engines such as Google Dataset Search. Data exploration is enabled by a variety tools contributed by the international Dataverse community that make use of Dataverse APIs to get data in and out. These APIs also enable a variety of integrations with scholarly publishing systems such as electronic lab notebooks, journal systems, reproducibility platforms, and more.<\/p>",
        "description": "<p>In this talk a core developer for Dataverse will introduce the audience to the world of scholarly publishing, making the case for data publication and how it contributes to the advancement of science. An emphasis will be made on how Dataverse goes beyond simply being open source by being friendly to contributions from newcomers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6423",
            "value": "Philip Durbin"
          }
        },
        "links":
        [
          {
            "_href": "https://dataverse.org",
            "value": "Dataverse project website"
          },
          {
            "_href": "https://github.com/IQSS/dataverse",
            "value": "Dataverse source code (core)"
          },
          {
            "_href": "http://guides.dataverse.org",
            "value": "Dataverse documentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9055.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9611",
        "start": "14:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "radicle_code_collaboration",
        "title": "Towards decentralized alternatives for code collaboration",
        "subtitle": "Building Radicle, a peer-to-peer network for code collaboration",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>This talk will walk the audience through Radicle, a peer-to-peer network for code collaboration. It will touch on the design approach (outlined in the description) of the Radicle stack and outline the project's next steps and challenges for the coming year as we launch our network. It's narrative will also reflect the potential of distributed technology for free and open source sustainability and resilience. Radicle (http://radicle.xyz/) is a free and open source project supported by Monadic (https://monadic.xyz/).<\/p>",
        "description": "<p>Radicle is a peer-to-peer network for code collaboration. It's a decentralized collaboration environment that’s designed to be:<\/p>\n\n<ul>\n<li><strong>Offline first<\/strong> : all data, including issues, comments and other social artifacts is yours &amp; lives on your machine.<\/li>\n<li><strong>Peer-to-peer<\/strong> : with no central server or intermediary in control.<\/li>\n<li><strong>Cryptographically secure<\/strong> : user data that is tamper-proof &amp; unforgeable, using public key cryptography.<\/li>\n<li><strong>Programmable<\/strong> : developers can program the way in which they collaborate.<\/li>\n<li><strong>Interoperable &amp; open<\/strong> : reflecting the values of the open source community.<\/li>\n<\/ul>\n\n\n<p>Radicle integrates with distributed version control systems like git and includes a high-level language with reprogrammable semantics, P2P networking for sharing application state, and flexible command line tools. Inspired by P2P protocols like <a href=\"https://www.scuttlebutt.nz/\">Secure Scuttlebutt<\/a>, radicle connects distributed version control with peer-to-peer networking to make collaboration a primitive – starting with git and building up an entirely peer-to-peer developer experience that encourages experimentation around how we write software together. In other words, radicle lets developers program the process of writing code, shaping their workflow around a specific project or context.<\/p>\n\n<p>Like many P2P systems, radicle uses an offline-first model. Issues, comments, and other social artifacts are stored locally as a log of events and synced automatically with your collaborators. While git repositories are already portable, social artifacts are not - radicle aims to change this. Radicle also allows you to define entirely new message types: projects, feature requests, releases, etc., each with their own event streams, metadata, and access control policies. All of this information is completely portable and self-amending in situ.<\/p>\n\n<p>Making any kind of semantic modification to a decentralized data structure is typically difficult to coordinate and prone to forks, but radicle’s programmable evaluator makes this process straightforward, safe, and immediate. Additionally, built-in aggregate signatures allow for the definition of custom security models to read or modify each chain, even to revise an access control policy.<\/p>\n\n<p>Finally, radicle comes with sensible defaults, ensuring you can be productive right away, while also giving programmers a flexible system for rolling their own software collaboration workflow. Inspired in many ways by <a href=\"https://www.gnu.org/software/emacs/\">Emacs<\/a>, radicle is designed as an extensible system, where developers can share their programs with one another and extend their revision control environment however they like.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6801",
            "value": "Abbey Titcomb"
          }
        },
        "links":
        [
          {
            "_href": "http://radicle.xyz/",
            "value": "Our main website"
          },
          {
            "_href": "https://monadic.xyz/",
            "value": "Our team"
          },
          {
            "_href": "http://oscoin.io/",
            "value": "Our associated research project"
          },
          {
            "_href": "https://www.google.com/search?q=radilce+github&oq=radilce+github&aqs=chrome..69i57j0.1629j1j4&sourceid=chrome&ie=UTF-8",
            "value": "Our GitHub"
          },
          {
            "_href": "https://github.com/radicle-dev/radicle-whitepaper",
            "value": "Our whitepaper"
          },
          {
            "_href": "https://twitter.com/abbey_titcomb",
            "value": "My twitter profile"
          },
          {
            "_href": "https://www.zeroknowledge.fm/71",
            "value": "An associated podcast with one of the lead contributors"
          },
          {
            "_href": "https://github.com/cloudhead",
            "value": "GitHub profile of co-founder"
          },
          {
            "_href": "https://www.youtube.com/watch?v=Q9CCPDkodj0",
            "value": "A talk by a co-founder on FOSS sustainability"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9611.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10010",
        "start": "14:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "fpga_packet_processing",
        "title": "Getting started with FPGA's for Packet Processing",
        "subtitle": "Intel FPGA opportunities",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The FPGA is an emerging technology that can increase the performance of packet processing due to need of increased protocol complexity.\nThere are many models of system where FPGA is suitable more or less depending on use-case.<\/p>\n\n<p>The presentation will introduce the system models presenting how to use FPGA inside larger systems.\nThe models include inline, lookaside and fast-path packet processing capabilities requiring different approaches from system level making accelerated system more usable and easier to integrate with existing components.<\/p>\n\n<p>In this talk we cover the challenges related to integration of the FPGA system with SW components like DPDK/kernel drivers and orchestration.\nThe examples of real FPGA deployments will be presented on base of Intel Programmable Acceleration Card family.<\/p>",
        "description": "<p>The talk describes a  new usage for FPGA technology used for packet processing. It presents opportunities, problems going to be solve and challenges related to use a complex programmable systems for mass deployment.<\/p>\n\n<p>It covers typical use-cases and some basic rules defining how to use FPGA system efficienly and integrate it with existing software stack and existing orchestration systems like Openstack or kubernetes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7052",
            "value": "Miroslaw Walukiewicz"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10010.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9879",
        "start": "15:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "pycirkuit",
        "title": "Quality diagrams with PyCirkuit",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>I'd like to present PyCirkuit, a little python application acting as a front-end to circuit-macros and dpic language, allowing the creation of high quality graphics and circuit diagrams to be included into LaTeX and other documents.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6366",
            "value": "Orestes Mas"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9879.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9981",
        "start": "15:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "buildroot_license_compliance",
        "title": "License compliance for embedded Linux devices with Buildroot",
        "subtitle": "What your buildsystem can do to relieve your pain in fulfilling legal obligations",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Producing a Linux-based electronic device requires to put together lots of open source software packages, which is a complex task.<\/p>\n\n<p>Complying to the licensing obligations for each of them is also complex, especially if you are not a lawyer. Not complying is immoral, illegal and risky.<\/p>\n\n<p>Discover how your build system can help you!<\/p>",
        "description": "<p>With live demos, Luca will introduce you to:<\/p>\n\n<ul>\n<li>how Buildroot builds all the needed software components in a simple way;<\/li>\n<li>which are the obligations for the most common licenses;<\/li>\n<li>what Buildroot can (and what it cannot) do to help you in being compliant.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "3341",
            "value": "Luca Ceresoli"
          }
        },
        "links":
        [
          {
            "_href": "https://buildroot.org/",
            "value": "Buildroot homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9981.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9084",
        "start": "15:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "ota_support_program",
        "title": "Open Source Support Program by OTA",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The Open Technology Assembly (OTA), formerly known as Belgian Unix Users Group, is a non-profit organisation  which main goal was to promote and organise meetings around Unix and Open Source in general (mainly more than a decade ago).\nOver the years the Internet took over so that the interest in our meetings declined and finally we stopped organise meetings altogether. However, as a non-profit organisation we would like to do something useful such as supporting and funding new open source related projects.<\/p>",
        "description": "<p>The Open Technology Assembly (OTA) will open an Open Source Support program to apply for funding. It would be nice that the chosen Open Source projects owners submit a (lightning) talk for next year's FOSDEM, however, it is not obliged.\nWe will also organise an independent jury to go over the submitted projects and make a list of the projects which will get funding. Before FOSDEM starts we will have web pages explaining most of the details.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "8",
            "value": "Gratien D'haese"
          }
        },
        "links":
        [
          {
            "_href": "https://www.ota.be/",
            "value": "Open Technology Assembly"
          },
          {
            "_href": "https://github.com/ota-be/proposals",
            "value": "Proposals"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9084.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9370",
        "start": "16:00",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "ngi_zero",
        "title": "NGI Zero: A treasure trove of tech awesome",
        "subtitle": "Sampling through the Next Generation Internet initiative",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>The <a href=\"https://ngi.eu\">Next Generation Internet<\/a> initiative is the first concerted effort in Europe to put significant public funding to hands-on work to really fix the internet. The long term <a href=\"https://ngi.eu\">vision<\/a> of the initiative is to make the internet what we need and expected it to be in the first place: <strong>Resilient<\/strong>. <strong>Trustworthy<\/strong>. <strong>Sustainable<\/strong>. The concrete mission of the Next Generation Internet initiative is to \"re-imagine and re-engineer the Internet for the third millennium and beyond\". With new projects starting all the time, the density of awesome open source, open hardware, new science and new standards in-the-making is already intense: about 200 projects are currently on their way. These range from encrypted synchronisation for calendars and address books to symbolical protocol verification, from an open hardware RISC-V SoC to removing binary seeds from operating systems, from ethical search to the Fediverse etc.<\/p>\n\n<p>NGI Zero offers funding to independent researchers and FOSS developers working on free and open projects in the area of privacy and trust enhancing technologies and on search, discovery and discoverability. It also offers an elaborate 'pipeline' of supporting activities that live up to high standards (sometimes called 'walk the talk') in terms of security, privacy, accessibility, open source licensing, standardisation, packaging, etc. The talk will provide an overview of the awesome R&amp;D that is now in the pipeline, how these projects are supported, and everything you need to know about the various opportunities to 'come and work for the internet'.<\/p>",
        "description": "<p><a href=\"https://nlnet.nl/discovery\">NGI Zero Discovery<\/a> and <a href=\"https://nlnet.nl/PET\">NGI Zero PET<\/a> are a significant effort and ambitious effort by a large group of organisations led by <a href=\"https://nlnet.nl/foundation\">NLnet foundation<\/a> (that was instrumental in <a href=\"https://nlnet.nl/foundation/history\">pioneering the early internet in Europe<\/a>):<\/p>\n\n<ul>\n<li><a href=\"https://accessibility.nl/english\">Accessibility Foundation<\/a> - Center of expertise on accessibility of internet and other digital media for all people, including the elderly and people with disabilities<\/li>\n<li><a href=\"https://apc.org\">Association for Progressive Communications<\/a> - A global network and organisation that strives towards easy and affordable access to a free and open internet to improve the lives of people and create a more just world<\/li>\n<li><a href=\"https://techcultivation.org/\">Center for the Cultivation of Technology<\/a> - A charitable non-profit host organization for international Free Software projects<\/li>\n<li><a href=\"https://commonscaretakers.com\">Commons Caretakers<\/a> - A not-for-profit service provider for the development of Commons<\/li>\n<li><a href=\"https://www.netsec.ethz.ch/\">Network Security Group<\/a> of <a href=\"https://www.netsec.ethz.ch/\">Eidgenössische Technische Hochschule Zürich<\/a> - Academic research institute focused on building secure and robust network systems<\/li>\n<li><a href=\"https://fsfe.org\">Free Software Foundation Europe<\/a> - Association charity that aims to empower users to control technology.<\/li>\n<li><a href=\"http://www.ifross.org/\">ifrOSS<\/a> - Provides not-for-profit legal services and studies in the context of free and open source software<\/li>\n<li><a href=\"https://nixos.org/nixos/foundation.html\">NixOS Foundation<\/a> - Foundation supporting development and use of purely functional configuration management tools, in particular NixOS and related projects<\/li>\n<li><a href=\"https://nlnet.nl\">NLnet Foundation (NL)<\/a> - Grantmaking public benefit organisation founded by pioneers of the early European internet<\/li>\n<li><a href=\"https://ps.zoethical.com/\">Petites Singularités<\/a> - Non profit organisation working with free sofware and focusing on collective practices<\/li>\n<li><a href=\"https://radicallyopensecurity.com\">Radically Open Security<\/a> - Not-for-profit open source security company<\/li>\n<li><a href=\"http://securesoftware.nl\">TIMIT<\/a> - Experts in secure software<\/li>\n<li><a href=\"http://translatehouse.org/\">Translate House<\/a> - Develops and implements open source localization solutions<\/li>\n<\/ul>\n\n\n<p>The budget for the effort is kindly provided by the European Commission.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4953",
            "value": "Michiel Leenaars"
          }
        },
        "links":
        [
          {
            "_href": "https://ngi.eu/vision",
            "value": "Next Generation Internet vision"
          },
          {
            "_href": "https://nlnet.nl",
            "value": "NLnet Foundation"
          },
          {
            "_href": "https://nlnet.nl/discovery",
            "value": "NGI Zero Discovery"
          },
          {
            "_href": "https://nlnet.nl/PET",
            "value": "NGI Zero PET"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9370.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9985",
        "start": "16:20",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "european_software_funded_research",
        "title": "European Software Engineering funded research",
        "subtitle": "What has happened under Horizon 2020 and what we already now about the future.",
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>This lightning talk will explain the latest funding results of the European Framework Programme for Research (Horizon 2020) concerning software engineering.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7038",
            "value": "Luis C. Busquets Pérez"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9985.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10742",
        "start": "16:40",
        "duration": "00:15",
        "room": "H.2215 (Ferrer)",
        "slug": "fosdem_infrastructure",
        "title": "FOSDEM infrastructure review",
        "subtitle": [],
        "track": "Lightning Talks",
        "type": "lightningtalk",
        "language": [],
        "abstract": "<p>Informational and fun.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "497",
            "value": "Richard Hartmann"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10742.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.1301 (Cornil)",
    "event":
    [
      {
        "_id": "10701",
        "start": "09:00",
        "duration": "00:10",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_devroom_welcome",
        "title": "Kotlin DevRoom Welcoming Remarks",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcoming participants to the first edition of the Kotlin DevRoom @ FOSDEM<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6477",
            "value": "Nicola Corti"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10701.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10615",
        "start": "09:15",
        "duration": "00:40",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_useful_coroutine_patterns_for_android",
        "title": "Useful coroutine patterns for Android applications",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kotlin Coroutines are a great match for implementing common features in Android applications. In this presentation, we will go through a number of patterns that solves the pattern we often encounter when implementing traditional asynchronous features.<\/p>",
        "description": "<p>Coroutines can help us build robust solution for asynchronous work in Android applications, but it can also be difficult to learn what pattern should be used in different scenarios. When should you use launch instead of async, or when should you use a Channel instead of Flow, or maybe both? What use is a conflated channel and why is the catch() operator important? All this and some more will be covered in this talk.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6856",
            "value": "Erik Hellman"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10615.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10453",
        "start": "10:00",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_migrating_fosdem_companion",
        "title": "Migrating FOSDEM Companion to Kotlin",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>FOSDEM Companion is currently the most used mobile application at FOSDEM. It has been around since 2014 and is updated every year. In 2020, it's finally made the big leap to Kotlin!<\/p>",
        "description": "<p>The app has been entirely rewritten using the Kotlin programming language. This talk will cover the conversion process, and how the new code makes use of language features and APIs that are not available in Java to become more than a simple Java conversion.<\/p>\n\n<p>For example, we'll talk about:<\/p>\n\n<ul>\n<li>How Data classes and Parcelize remove a lot of boilerplate code in the model classes<\/li>\n<li>How immutability and null safety have been enforced in the code with minimal effort<\/li>\n<li>How KTX makes Android framework and Jetpack APIs more Kotlin-friendly<\/li>\n<li>Coroutines integration in the app.<\/li>\n<\/ul>\n\n\n<p>The talk will be illustrated by many code examples.<\/p>\n\n<p><em>Intended audiences:<\/em> Android developers with medium experience looking to improve their Kotlin codebases. Java developers curious about Kotlin.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2591",
            "value": "Christophe Beyls"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/cbeyls/fosdem-companion-android",
            "value": "FOSDEM Companion Github repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10453.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9960",
        "start": "10:30",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_idiomatic_microservices",
        "title": "Idiomatic Kotlin Microservices",
        "subtitle": "A live coding session on how to go pure Kotlin with microservices",
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Although Kotlin is, from a language perspective, 100% interoperable with Java, due to the slight paradigm shift (nullability) there might be some pain when using Java frameworks, e.g.: the need of <code>private var lateinit<\/code> when using JUnit, having to use compiler plugins to open up Spring annotated beans or a generated zero-arg constructor for Hibernate.\nThis talk goes through a full fledged alternative to the common Java stack when writing microservices, using: Ktor (Web framework), Kodein (DI container), Exposed (SQL library), Spek (test framework), Gradle Kotlin DSL, ...<\/p>",
        "description": "<p>This live coding session aims to share my experiences on how to combine (and how not to combine!) several open source libraries into a maintainable, scalable, sustainable, and all the other xxx-ables you can think of... based on several years of experience using Kotlin in production in different companies. Using libraries written from scratch for Kotlin enables us to fully make use of this beautiful language. Its functional nature, extension function types, null type safety, delegated properties; its preference for immutability and simply the feeling of writing proper, idiomatic Kotlin. The demo itself will cover a basic CRUD web service, following a TDD approach resulting in a production ready artifact.<\/p>\n\n<p>The target audience are primarily developers/architects and requires basic knowledge of the language (intermediate level) and preferably some experience with the existing Java ecosystem.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7020",
            "value": "Christoph Pickl"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=FVbisleDzh8",
            "value": "presentation: ultimate kotlin workshop 2"
          },
          {
            "_href": "https://www.youtube.com/watch?v=di2CfsOk3fI",
            "value": "presentation: intro to kotlin"
          },
          {
            "_href": "https://www.meetup.com/kotlin-amsterdam/",
            "value": "usergroup manager: kotlin amsterdam"
          },
          {
            "_href": "https://www.meetup.com/Kotlin-Vienna/",
            "value": "usergroup founder: kotlin vienna"
          },
          {
            "_href": "https://github.com/christophpickl/kotlin101slides/blob/master/bin/Kotlin101-2018_06_13-At_ERSTE.pdf",
            "value": "slides: kotlin 101 presentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9960.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10078",
        "start": "11:00",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_automate_your_workflows",
        "title": "Automate your workflows with Kotlin",
        "subtitle": "Forget everything about bash and perl!",
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>From git housekeeping to releasing. From keeping a sane backlog to\nhandling internationalization and monitoring status, the life of a\ndeveloper involves more than meets the eye.<\/p>\n\n<p>This talk will be a feedback about how we use Kotlin extensively to:<\/p>\n\n<ul>\n<li><p>automate the dev workflows with command-line apps on dev\nmachines.<\/p><\/li>\n<li><p>achieve CI independence with kotlin runners on CI machines.<\/p><\/li>\n<li><p>run Kotlin on the server using the gradle appengine plugin.<\/p><\/li>\n<li><p>ditch bash and perl and use kscript instead.<\/p><\/li>\n<\/ul>\n\n\n<p>That's a lot to cover and the goal of this talk is not to dig into\neach technology but more to inspire and show the range of possibles\nopened by Kotlin.<\/p>",
        "description": "<p>From git housekeeping to releasing. From keeping a sane backlog to\nhandling internationalization and monitoring status, the life of a\ndeveloper involves more than meets the eye.<\/p>\n\n<p>This talk will be a feedback about how we use Kotlin extensively to:<\/p>\n\n<ul>\n<li><p>automate the dev workflows with command-line apps on dev\nmachines.<\/p><\/li>\n<li><p>achieve CI independence with kotlin runners on CI machines.<\/p><\/li>\n<li><p>run Kotlin on the server using the gradle appengine plugin.<\/p><\/li>\n<li><p>ditch bash and perl and use kscript instead.<\/p><\/li>\n<\/ul>\n\n\n<p>That's a lot to cover and the goal of this talk is not to dig into\neach technology but more to inspire and show the range of possibles\nopened by Kotlin.<\/p>",
        "persons":
        [
          {
            "_id": "7079",
            "value": "Martin Bonnin"
          },
          {
            "_id": "7365",
            "value": "Michel Gauzins"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10078.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10622",
        "start": "11:30",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_experimenting_with_the_compiler",
        "title": "Experimenting with the Kotlin Compiler",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A lot of us will agree that Kotlin is an awesome language - but have you ever thought about experimenting with the Kotlin Compiler? This talk explores how to set up your development environment, add, remove or change language features, get feedback from the community and get your suggestions merged.<\/p>\n\n<p>You will get to know how to set up IntelliJ for working on different parts of the compiler in the Kotlin repo and learn how the compiler is structured and the different compilation phases. After looking at the structure, you will get know how to modify existing language features such and how to add a language keyword to Kotlin. In the end, we will look at different ways of bringing your changes to the Kotlin programming language!<\/p>\n\n<p>You will leave this talk with a solid grasp of Kotlin Compiler mechanisms and how to change things up a bit. You don't need to know anything about compilers or Computer Science theory!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7332",
            "value": "Jossi Wolf"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10622.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9970",
        "start": "12:00",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_communication_break_down_coroutines",
        "title": "Communication Break Down | Coroutines",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Coroutines are great, I think we all agree on that. But as the async, and possibly parallel, programming becomes easier the risk of sharing mutable variables between coroutines arises. When the boundaries are abstracted away we should rely on safe ways to communicate between our coroutines.\nIn this session I will go through safe and unsafe ways of communication between different coroutines, with the main focus on the safe ones and what differentiates them.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7027",
            "value": "Bob Dahlberg"
          }
        },
        "links":
        [
          {
            "_href": "https://speakerdeck.com/bobdahlberg/channels-n-stuff",
            "value": "A presentation held at Kotlin Everywhere which I'll build this one from"
          },
          {
            "_href": "https://speakerdeck.com/bobdahlberg",
            "value": "Some of my previous presentations"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9970.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10478",
        "start": "12:30",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_how_can_change_developer_exp_graphics_api",
        "title": "How Kotlin can change developer experience with modern graphics APIs",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Creating modern games in Kotlin forces you to use non-object oriented graphic languages and getting your hand dirty with native resource managemente. With wrappers around OpenGL and Vulkan, we make powerful graphics familiar to jvm devs and type-safe.<\/p>",
        "description": "<p>Vulkan and OpenGL are the cross-platform standard for creating modern games and graphics. However, their respectively stateless and state-based systems have no relation to an object-oriented language like Kotlin and you have to be careful to handle native resources interacting with the API.<\/p>\n\n<p>Wrappers that we have built at Kotlin Graphics allow for them to become object oriented. This talk will teach the attendees how to use our wrappers VKK and GLN for Vulkan and OpenGL respectively in order to create performant, modern graphics.<\/p>\n\n<p>Graphic power meets Kotlin expressiveness<\/p>\n\n<p>VKK and GLN bring features such as type safety through inline classes and enums, DSL constructs, extension functions, typealias, less verbosity, pure jvm allocation strategy and an easy to pick up system. Because of the type-safety guarantee, we can directly call the native methods without performing potentially expensive checks.<\/p>\n\n<p>This allows users of Kotlin to create performant, modern games like those you could build on C or C++.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7271",
            "value": "Giuseppe Barbieri"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/kotlin-graphics/vkk",
            "value": "VK², Kotlin Wrapper for Vulkan: code expressiveness and safety meet graphic power"
          },
          {
            "_href": "https://github.com/kotlin-graphics/gln/",
            "value": "OpenGL Next: functional programming and DSL"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10478.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10345",
        "start": "13:00",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_improve_your_android_app_with_coroutines",
        "title": "Improve your Android app with coroutines",
        "subtitle": "Application level integration of kotlinx coroutines",
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Koltinx Coroutines library implementation for higl level programmation.<\/p>\n\n<p>Presentation of application development with Jetbrains kotlinx library.<\/p>",
        "description": "<p>Demonstration of kotlinx Coroutines framework use for application development.<\/p>\n\n<p>Coroutines helped a lot to improve VLC app performances on Android.\nThis talk is a feedback on this conversion and a collection of good practices.<\/p>\n\n<p>We will see how it helped make the app more performant and maintainable.\nEspecially the benefit of structured concurrency and how it greatly helps solving most asynchronism problems.\nUse your components lifecycle to scope asynchronous jobs.\nGet rid of callback APIs with Flow API.\nAnd some more examples of how to dismiss the GUI frameworks limitations with coroutines<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7207",
            "value": "Geoffrey Métais"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10345.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10703",
        "start": "13:30",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_confessions_of_a_multiplatformer",
        "title": "Confessions of a Serial K–otlin Multiplatform–er",
        "subtitle": "__just don’t 𝚎𝚡𝚙𝚎𝚌𝚝 too much__",
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<h3>What is <em>Multiplatform<\/em>?<\/h3>\n\n<ol>\n<li><p> <strong>HELL<\/strong><\/p>\n\n<ul>\n<li><p>harder to develop, no documentation<\/p><\/li>\n<li><p>just a trend, failed in the past<\/p><\/li>\n<li><p>not suitable for performant apps that feel “native”<br/>\n <\/p><\/li>\n<\/ul>\n<\/li>\n<li><p> <strong>HEAVEN<\/strong><\/p>\n\n<ul>\n<li><p>simpler to develop, removes platform barriers<\/p><\/li>\n<li><p>write half the code, ship in half the time<\/p><\/li>\n<li><p>only need to hire “generalists” instead of “specialists”<br/>\n <\/p><\/li>\n<\/ul>\n<\/li>\n<li><p> <strong>OTHER<\/strong>  ✔︎<\/p>\n\n<ul>\n<li>elaborate in 25 minutes or less:<br/>\n<em>________________________________<\/em><br/>\n <br/>\n <\/li>\n<\/ul>\n<\/li>\n<\/ol>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7361",
            "value": "Eugenio Marletti"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10703.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10674",
        "start": "14:00",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_mp_into_the_multi_verse",
        "title": "Kotlin MP: Into the Multi-Verse",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kotlin Multiplatform is the new kid on the cross-platform block. The approach although is very different from what you have seen in the past. The new approach utilizes Kotlin Native to compile Kotlin language to native binaries for specific target platform which can run without a virtual machine. Thus enabling simplified code sharing across multiple platforms.\nIn this talk, you will be introduced to Kotlin/Native and demonstrate how to build a Kotlin Multiplatform app that runs on both iOS and Android using shared Kotlin code.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7033",
            "value": "Nishant Srivastava"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10674.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10492",
        "start": "14:30",
        "duration": "00:25",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_multiplatform_library_development",
        "title": "Multiplatform Kotlin Library Development",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Multiplatform Kotlin facilitates code-sharing by making platform-agnostic portions of the standard library available in common code that is written once but can run on any target. As Multiplatform development really starts to take off over the next year, there must also be a robust ecosystem of third party libraries available to application developers.<\/p>\n\n<p>I’ll talk through what it looks like to create such a library, with lessons from my experiences building one of the early libraries in the mobile Multiplatform space. We'll talk about how to find shared abstractions around different platform APIs, how to handle the fast-paced evolution of this environment, and what this all felt like as a first-time library developer. When we're done, you’ll be ready to leverage the growing ecosystem as well as make your own contributions.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7275",
            "value": "Russell Wolf"
          }
        },
        "links":
        [
          {
            "_href": "https://www.droidcon.com/media-detail?video=362742087",
            "value": "Previous version of this talk, given at Droidcon NYC 2019"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10492.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10623",
        "start": "15:00",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_bridging_the_physical_world",
        "title": "Bridge the physical world: Kotlin/Native on Raspberry Pi",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With Kotlin/Native, we can now compile Kotlin code to run on various platforms, including Raspberry Pi. This cross-platform ability has drawn the attention of many developers. Through the process of building a hand game robot which can play rock paper scissors with human beings, this talk aims to show you the possibility of using Kotlin to control GPIO pins on a Raspberry Pi and other experiments such as performing machine learning operations in Kotlin using TensorFlow backend, thanks to the interoperability with C libraries.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7333",
            "value": "Qian Jin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10623.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10446",
        "start": "15:40",
        "duration": "00:35",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_dissecting_the_inline_keyword",
        "title": "Dissecting the inline keyword in Kotlin",
        "subtitle": "A deep-dive into the internal working of the inline keyword",
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kotlin has a keyword called <code>inline<\/code>. While being mostly auto-suggested by the IDE, this little optimization forms the backbone for features like coroutines and APIs for sequences and collections and a lot more!<\/p>",
        "description": "<p>Java 8 introduced the concept of lambdas, while this was done at the language level, using bytecode instructions introduced in Java 7. Kotlin, tries to make this lambda functionality available for application targeting even Java 6! How does it do it? What optimizations does it do to make this compatibility happen?<\/p>\n\n<p>How does this feature form the backbone for features like coroutines and APIs for collections and sequences.<\/p>\n\n<p>How it doesn't stop there and introduces the concept of Inline classes, which enable Kotlin to have unsigned integers.<\/p>\n\n<p>How all of this is done, by just adding one keyword support in Kotlin!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7136",
            "value": "Suraj Shah"
          }
        },
        "links":
        [
          {
            "_href": "https://blog.quiph.com/dissecting-the-inline-keyword-in-kotlin-51735600d7",
            "value": "Draft link of medium article"
          },
          {
            "_href": "https://gist.github.com/shahsurajk/aa0ba330664e806924b58cd624053236",
            "value": "Link to the presentation given by me at a local meetup"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10446.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9438",
        "start": "16:20",
        "duration": "00:40",
        "room": "H.1301 (Cornil)",
        "slug": "kotlin_designing_a_dsl",
        "title": "Designing a DSL with Kotlin",
        "subtitle": [],
        "track": "Kotlin",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kotlin is one of those “new” JVM languages that are currently rocking the boat. Although it’s made a great impact on Android, it’s equally good on the server side. As Domain-Specific Languages are constrained by the language they run on, Kotlin frees developers from Java fluent builders to propose something better.<\/p>\n\n<p>Using the Vaadin web framework as an example, I’ll demo how one could design its own DSL with Kotlin.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5584",
            "value": "Nicolas Frankel"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=fS3NAbvJD7Y",
            "value": "Video"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9438.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.1302 (Depage)",
    "event":
    [
      {
        "_id": "9463",
        "start": "09:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "webmidi",
        "title": "WebMIDI",
        "subtitle": "The garlic bread of the music industry",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The connection between Web and MIDI seems as likely as the joining of Garlic with Bread! Yet, we now have the power to create music from the web browser! Either by generating MIDI files for later manipulation, or as live instruments, WebMIDI provides us with the power to build some amazing online music applications.<\/p>",
        "description": "<p>In this short form talk, Steven will cover the internal details of the MIDI protocol, and its related file format, to show how music is represented by computers. This details both the recording and playback of music within the browser, and external application. It comes complete with live demos, synthesized sounds, and occasional music jokes!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "392",
            "value": "Steven Goodwin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/MarquisdeGeek/WebMIDI",
            "value": "WebMIDI examples"
          },
          {
            "_href": "http://marquisdegeek.com/music_symphony1",
            "value": "A symphony written with it"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9463.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10194",
        "start": "09:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "building_decentralized_social_vr",
        "title": "Building Decentralized Social Virtual Reality using WebXR on your browser",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn how to build auditable privacy aware social vre experinces right inside your webpage in javascript using WebXR API. That will be corss platform, instant and run in every device with a browser. Adapting to the MIxed Reality capability of your user.\nThis session will give you a short primer on WebXR API's and hands-on on building a small social VR experience using open source tools and javascript in your browser.<\/p>",
        "description": "<p>Virtual Reality (VR) is undoubtedly one of the most sought after technology of the present times. Everybody is trying to make their presence felt in the sphere. And one of the prime use cases of VR is shared spaces.\nIt opens up possibility of having shared earning space, meeting space and even training space in real-time and in an interactive way.\nHowever often these kind of experiences are mired with privacy concerns, who is hosting the space, the data retained and who is observing the behaviors. On top the data retention implications.<\/p>\n\n<p>What if we could build Virtual Reality experiences right on the browser using JavaScript and all the shared room logic too in an open auditable way. And what if we could host it in decentralized way. Where it would be resistant to takedowns and have ability for users to host their own rooms.<\/p>\n\n<p>Interested in social VR, know about the possibilities it open, want to get your hands wet but don't want to invest learning another tool? Don't want to commit to the steep learning curve or buy expensive machines up front? Or are you afraid of the walled garden of SDK's? In this talk we rip open the veiled wall of proprietary VR with Web Virtual Reality designed to run in browser in any device including your phone. Learn how to build auditable privacy aware social VR experiences right inside your webpage in JavaScript using WebXR API. Adapting to the Mixed Reality capability of your user.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2403",
            "value": "Rabimba Karanjai"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10194.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9411",
        "start": "10:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "pwas_on_steroids",
        "title": "PWAs on steroids",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>PWAs bring the best of both mobile and native apps to user. PWAs equipped with service workers provide features like offline availability, push notifications etc. Now with modern webAPIs, PWAs are beyond the browsers; in Hardware. Consider turning bulb on/off with your PWA, sounds cool? Lets learn how to, in this talk!<\/p>",
        "description": "<p>PWAs have been limited to offline availability and push notifications for long time, I want to explain to developers there is much more to PWAs, I want to show how to interact with more device specific features with modern webAPIs like web Bluetooth, speech synthesis, speech recognition, webShare etc. With this talk I want to give attendees a compelling reason to develop PWA instead of a mobile app for there next thing. I plan to have a quick introduction to serviceworkers and then majorly explaining webAPIs, usage and implementation with demos.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4032",
            "value": "Trishul Goel"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/playlist?list=PLI08QU9qtPEIwA1zukgHW8D7hdB7dh7Pz",
            "value": "Previous talks"
          },
          {
            "_href": "https://slides.com/trishulgoel/fullstack-london#/",
            "value": "Slides"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9411.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9475",
        "start": "10:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "machine_learning_on_the_web",
        "title": "Machine Learning on the Web",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Have you ever wondered how you can make machine learning applications on the web, without learning Python or R? Well, brace yourself to explore the power of JavaScript and get to know how you can use it to build a machine learning web app.<\/p>",
        "description": "<p>Machine Learning is a new trending topic that everyone wants to be a part of. But it is a hard field to master. What if I tell you that you don’t need to know another language, only JavaScript is enough?\nIn my talk Machine Learning for Web Developers, I will present the views of a web developer. How a WebDev can get started, without learning any new languages.\nThe talk will cover a basic understanding of the following topics:\n- Classification\n- Regression\n- Error Functions\n- Optimizers\nFurther on, we'll not only discuss it's uses for you, but also we'll deploy them on an application with working code snippets and understand how you can deploy it all! We'll make use of Open Source ML Libraries like TensorFlow.js and Brain.js!\nIn the end the attendees will also get to know the advantages and drawbacks of running Machine learning applications on the browser. Finally we will then look for the use-cases where it is advisable to run machine learning models on browsers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6747",
            "value": "Harshil Agrawal"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9475.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9519",
        "start": "11:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "xr_adds_try_before_buy",
        "title": "XR adds: “Try before you buy”",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>One day people will wake up and realize that Augmented Reality is here.\nAdvertisers are keen on AR because it can create higher levels of engagement than traditional ads. The power of gamification and the power of people experimenting with AR technology helps them to make better decisions as consumers.\nYou can find an ad in your news feed, open the camera, and preview a product in the \"Real\" world.<\/p>",
        "description": "<p>One day people will wake up and realize that AR is here. There are many questions around this sometimes-overhyped sector. And the biggest of them is how it will make money?\nThere are several answers to that, and we will take a look at the most popular ones.<\/p>\n\n<p>Advertisers are keeping the eye on AR because it can create higher levels of engagement than traditional advertisements.<\/p>\n\n<p>People are very interested in things like shopping and ads, things that help to make a better decision.\nOn the other side, brands want their customers to spend more time thinking about their products and personalizing them to their needs.<\/p>\n\n<p>And XR (Extended Reality) can enable that!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6778",
            "value": "Anastasiia Miroshnichenko"
          }
        },
        "links":
        [
          {
            "_href": "https://aframe.io/docs/0.9.0/introduction/",
            "value": "A-Frame documentation"
          },
          {
            "_href": "https://sparkar.facebook.com/ar-studio/learn/documentation/before-you-start",
            "value": "Spark AR Studio"
          },
          {
            "_href": "https://developer.apple.com/augmented-reality/reality-composer/",
            "value": "Reality Composer"
          },
          {
            "_href": "https://www.8thwall.com/docs/web/",
            "value": "The 8th Wall Web"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9519.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10074",
        "start": "11:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "reactjs_redux_apollo",
        "title": "ReactJs, Redux & Apollo - state management in SUSI.AI",
        "subtitle": "The event mainly talks about patterns of state management with React using Redux & Apollo and their comparision",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The talk will be mainly around the state managements techniques and patterns used in ReactJs and throw light on the coding patterns for Redux and Apollo.\nI will be discussing about the the common patterns of the same and talk about the advantages and disadvantages of both. Lastly and most importantly, will\ntalk about an Open Source Voice Assistant - SUSi.AI implemented using ReactJs and Redux and the app architecture.<\/p>",
        "description": "<p>Minutes of the event<\/p>\n\n<p>00:00 - 00:01 - Basic introduction of myself and what I do.\n00:01 - 00: 04 - It will start with the brief introduction of ReactJs and the need of state management (both local and global).\n00:04 - 00:06 - Tell about the solutions in the market like Redux, MobX, Apollo.\n00:06 - 00:15 - Discuss about the commonly used coding patterns using them with examples and the best practices for them.\n00:15 - 00:20 - Talk about how we are making SUSI.AI - An Open Source Voice Assistant for the web and how is the app architectured to build an immersive and real time experience.<\/p>\n\n<p>Last 5 mins for the Q&amp;A session.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7022",
            "value": "Akshat Garg"
          }
        },
        "links":
        [
          {
            "_href": "https://susi.ai/",
            "value": "Link to SUSI.AI Webapp"
          },
          {
            "_href": "https://github.com/fossasia/susi.ai",
            "value": "Link to SUSI.AI repo"
          },
          {
            "_href": "https://www.linkedin.com/in/akshatnitd/",
            "value": "LinkedIn profile"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10074.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9395",
        "start": "12:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "improve_react_app",
        "title": "Improve React App using design patterns",
        "subtitle": "Don't reinvent the wheel",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Design patterns in layman's term are solutions to a recurring set of problems. Every problem has multiple solutions, design patterns are essentially a collection of the best solution for commonly occurring problems. These are not code snippets but the structure of the solution rather than the solution itself. Developers should learn design patterns so that they don’t have to come up with new solutions to every problem for which optimal tested solutions already exist(Standing on the shoulder of giants). Participants will also learn a common vocabulary to talk about solution patterns (Ex: “You can use a higher order component to solve X”). Once you understand design patterns you can identify them when you are going through a codebase and understand it from a higher perspective easily thus saving your time. Developers will be equipped with an array of patterns from which she can choose reusable solutions and avoid alternatives that can limit reusability. Developers will learn to write solutions in a mannerism that would be easily understandable by other developers(very important in large teams).<\/p>",
        "description": "<p>Design patterns in layman's term are solutions to a recurring set of problems. Every problem has multiple solutions, design patterns are essentially a collection of the best solution for commonly occurring problems. These are not code snippets but the structure of the solution rather than the solution itself. Developers should learn design patterns so that they don’t have to come up with new solutions to every problem for which optimal tested solutions already exist(Standing on the shoulder of giants). Participants will also learn a common vocabulary to talk about solution patterns (Ex: “You can use a higher order component to solve X”). Once you understand design patterns you can identify them when you are going through a codebase and understand it from a higher perspective easily thus saving your time. Developers will be equipped with an array of patterns from which she can choose reusable solutions and avoid alternatives that can limit reusability. Developers will learn to write solutions in a mannerism that would be easily understandable by other developers(very important in large teams).<\/p>\n\n<p>Writing components is hard, whereas writing reusable components is even harder.  As languages have become more powerful and have aspects of multiple programming paradigms(FP, OOP) it has opened up a new domain for us to explore in terms of design patterns.<\/p>\n\n<p>Participants will learn patterns that are commonly used in ReactJS. We will demonstrate a handful of design patterns which we have across, old and new while working on the Red Hat OpenShift(Container platform designed to improve developer productivity.) user interface. They will learn to identify problems that can be easily solved with design patterns. We will also show implementations and share the thought process that goes into deciding the design pattern so they can learn how to implement and judge whether it’s the best one.<\/p>\n\n<p>We expect participants to be familiar with Javascript and ReactJS. If they would like to follow along then a laptop would be useful. This talk would be helpful to anyone who is new to React or even to a seasoned developer who is not aware of these patterns.<\/p>\n\n<p>One short description of a design pattern and its use case:\nWe can consider the problem of composing a collection of components which all need to share a common state.\nBad Solution: Pass the state information to all the components through props manually.\nGood Solution: Create a parent component holding the state. Use components that require common state information as children of the parent component. And inside the parent component using React.Children.map function to pass the state information to all the children through cloning.\nThe good solution is known as “Compound Component” one of the many patterns we are going to talk about.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6696",
            "value": "Ankush Behl"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/openshift/console/",
            "value": "OpenShift Console"
          },
          {
            "_href": "https://meet.google.com/linkredirect?authuser=1&dest=https%3A%2F%2Fgithub.com%2Ffbeline%2Fdesign-patterns-JS",
            "value": "Design Patterns JS"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9395.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9334",
        "start": "12:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "lets_get_func_y",
        "title": "Let's Get Func-y",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>a.k.a. a web app is just multiple functions stacked on top of each other, wearing a trenchcoat.\nLet's get back to basics, for a minute. No frameworks, no libraries; just pure and plain ol' JavaScript.\nIn a nutshell, this talk is going to explain all the delightful ways to write functional code with Javascript and how it can be applied to your application to optimize performance.\nWe're going to focus on keywords like 'immutability' and 'state'.\nIf we're feeling adventurous, we'll even throw in a closure or two.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6609",
            "value": "Jemima Abu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9334.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10109",
        "start": "13:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "are_pwas_ready_to_take_over_the_world",
        "title": "Are PWAs ready to take over the world?",
        "subtitle": "Implementing main progressive web app features in practice",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk offers a walk-through of the main PWA features and a comparison how they behave across different platforms (Linux, Android, iOS), on various web browsers (Firefox, Chrome, Safari). Practical code examples will come from Sojourner - a FOSDEM conference companion app. We will also discuss some UX/UI challenges and their potential solutions specific for PWAs.<\/p>",
        "description": "<p>During this talk we will discuss the following aspects of PWA and illustrate them with practical code examples.<\/p>\n\n<p>Performance and network reliability:\n- Service Worker strategies\n- Offline-First operation<\/p>\n\n<p>Persistent Storage:\n- availability, limitations, access request\n- no login required<\/p>\n\n<p>Installation:\n- In-browser via Add to Home Screen (A2HS)\n- From app-store<\/p>\n\n<p>Design:\n- choosing the right design system\n- handling colors, icons and screen mode gracefully<\/p>\n\n<p>At the end we will summarize the state of PWAs in 2020 and for which types of applications they work best.<\/p>\n\n<p>Examples used to illustrate this talk will come from Sojourner FOSDEM conference companion app, written using Vue.js framework.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1724",
            "value": "Jarek Lipski"
          }
        },
        "links":
        [
          {
            "_href": "https://fosdem.sojourner.rocks",
            "value": "Sojourner FOSDEM conference companion app"
          },
          {
            "_href": "https://github.com/loomchild/sojourner-web",
            "value": "Sojourner source code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10109.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10089",
        "start": "13:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "beyond_angular_react_vue",
        "title": "2nd Generation JavaScript Frameworks & Libraries: Beyond Angular, React, and Vue!",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An overview of an interesting new development over the past years -- many vendors, large and small, have been making their JavaScript-based technology stacks available on GitHub. What does that mean and how to evaluate this development? Find out in this session, which includes small code demos and tips and tricks.<\/p>",
        "description": "<p>Did you know that over the past few years, large enterprises have been developing and open sourcing their JavaScript technology stacks? On GitHub, you'll find solutions by ING, Uber, PayPal, the Financial Times, Oracle, Microsoft, and many others. Some of these are software vendors, while others are in a variety of other industries. Each of them start from open source frameworks and libraries and all of them are interested in contributions.<\/p>\n\n<p>The session, with several live coding scenarios, focuses on something that's been going on below the surface, mostly unseen: large enterprises are using open source solutions in the JavaScript ecosystem (e.g., React, Vue, Knockout, Angular), developing their own internal tech stacks, and then pushing these stacks out to GitHub.<\/p>\n\n<p>Let's explore the advantages of these and see what can be done and how practical these developments are.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1025",
            "value": "Geertjan Wielenga"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10089.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10582",
        "start": "14:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "pushing_the_limits_of_the_web",
        "title": "Pushing the limits of the Web with WebAssembly",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Web is omnipresent nowadays and meets most of the needs of our applications.<\/p>\n\n<p>For almost 10 years, leading browsers have been working hard to push the boundaries and performance of our connected apps.<\/p>\n\n<p>This is also the main reason why WebAssembly, the new binary standard initially implemented by Safari, Chrome, Firefox and Edge, appeared. It allows the execution, in the browser, of your favourite programming languages ​​at almost native speed.<\/p>",
        "description": "<p>During this session, we browse the current means implemented by browsers to optimise the execution of JavaScript code. We will outline the limitations of current solutions, the benefits provided by the WebAssembly and review its performance.<\/p>\n\n<p>Enjoy the future of the Web, now!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7320",
            "value": "Jon Lopez Garcia"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10582.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10050",
        "start": "14:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "state_of_node_js_core",
        "title": "State of Node.js Core",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Node.js is now over a decade old. With Node.js 12 just entering into long-term support, and Node.js 13 being released, let us take a look at the new features, breaking changes, and what is next.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7064",
            "value": "Bethany Griggs"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10050.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9361",
        "start": "15:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "serverless_com_framework",
        "title": "Serverless.com framework",
        "subtitle": "Doing serverless in the open source way",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Who told that everything about serverless computing should be proprietary?\nDo you want deploy your functions and infrastructure in the open source way?\nDo you want to have modular, JS-based tool for it?\nCome and learn about Serverless.com - open source multicloud tool which support Kubeless, AWS Lambdas, Azure functions and many more!<\/p>",
        "description": "<p>2- minutes talk covering topics:\n- what is the serverless computing?\n- why is it important to have an open-source deployment tool?\n- how serverless framework working\n- advantages, weak moments and lesson learned<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5443",
            "value": "Kirill Kolyaskin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9361.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10085",
        "start": "15:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "new_features_vue",
        "title": "New features of Vue 3.0",
        "subtitle": [],
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Vue 3.0 is scheduled to be released in Q1 2020. With lots of new features in Vuejs 3.0 we look at biggest features and how they can be used in your code base to improve your programming experience.<\/p>",
        "description": "<p>Title: New features in Vue Js 3.0<\/p>\n\n<p>Description:\nVue 3.0 is scheduled to be released in Q1 2020. It has been 6 years since the first version 0.6 of Vue Js was released. Since then the community has grown and it is now in the top 3 most popular JavaScript frameworks to use. Currently Vuejs 2.6 is released which has a lot of plugins that can expand the programming and functionality features. Some of these programming features have been incorporated in vue 3.0 code base.<\/p>\n\n<p>The talk will explain the following new features and demo how they are used.<\/p>\n\n<ul>\n<li>Composition API<\/li>\n<li>Slots<\/li>\n<li>Optimized Slots Generations<\/li>\n<li>Proxy based observations<\/li>\n<li>Fragments<\/li>\n<li>Suspense components<\/li>\n<li>Multiple v-models<\/li>\n<li>New custom directives API<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7081",
            "value": "Martin Naughton"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/vuejs/roadmap",
            "value": "Vue js Roadmap"
          },
          {
            "_href": "https://github.com/vuejs/vue-next",
            "value": "Vue js 3.0 alpha code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10085.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9162",
        "start": "16:00",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "javascript_smartglasses",
        "title": "How to create Javascript-powered Smartglasses",
        "subtitle": "(no soldering knowledge required)",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>After having worked at an AR-focused company with the Vuzix, a Google Glass-like product, Ruben had a lot of fun with the hardware and really wanted to have one at home to play around with. Unfortunately, they are too expensive to get one just for hobby purposes.<\/p>\n\n<p>This session will cover what was required to build his own wearable, the pitfalls, the compromises, and the sheer joy of saying \"Screw it, I'll build it myself!\".<\/p>",
        "description": "<p>With the use of a Raspberry Pi, Vufine and a lot of Javascript, I've managed to cobble a hobby project together where I essentially have my own Javascript-powered smartglasses. The main reason why I built it is because I want to prototype ideas on what you could with the platform, but I think it's an interesting example to showcase how you can use Javascript and all out of the box. While the focus of the talk is how the stack works and everything is connected to each other, I also want to highlight what you can get out of hobby projects.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6359",
            "value": "Ruben van der Leun"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9162.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10117",
        "start": "16:30",
        "duration": "00:25",
        "room": "H.1302 (Depage)",
        "slug": "web_of_twins",
        "title": "Web of Twins",
        "subtitle": "From IoT to Immersive worlds and beyond...",
        "track": "JavaScript",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Overview of Web of thing concept, Mozilla WebThings IoT platform demonstrated using A-Frame 3D framework for building virtual reality experiences.<\/p>",
        "description": "<p>The Web of Things connects real-world objects to the World Wide Web,\nMozilla proposed an open source implementation of Web of things concept.\nto connect and control smart home devices with Privacy by design.<\/p>\n\n<p>Once the WebThing platform is in place WoT can be used for many other purposes,<\/p>\n\n<p>As a demonstration, devices can be also \"mirrored\" in a virtual world\nand interacted differently using XR devices.<\/p>\n\n<p>Using A-Frame framework it's very easy to create models\nand keep the the Digital Twins updated in real time on the Web.<\/p>\n\n<p>Each components of this \"Web of Twins\" experiment will be detailed\nfrom sensors or actuators to rich 3D user interfaces and more.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1773",
            "value": "Philippe Coval"
          }
        },
        "links":
        [
          {
            "_href": "https://www.w3.org/community/web-thing-protocol/",
            "value": "w3c webthing protocol community group"
          },
          {
            "_href": "https://iot.mozilla.org/",
            "value": "Mozilla webthings gateway"
          },
          {
            "_href": "https://aframe.io/",
            "value": "A-frame : A web framework for building virtual reality experiences"
          },
          {
            "_href": "https://github.com/rzr/twins",
            "value": "example: Robot Arm Twin"
          },
          {
            "_href": "https://github.com/rzr/aframe-smart-home",
            "value": "example: House model (GLTF)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10117.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.1308 (Rolin)",
    "event":
    [
      {
        "_id": "9359",
        "start": "09:00",
        "duration": "00:30",
        "room": "H.1308 (Rolin)",
        "slug": "sts_in_ceph_object_storage",
        "title": "STS in Ceph Object Storage",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ceph is an open source, highly scalable, software defined storage that provides object, file and block interfaces under a unified system. Ceph Object Storage Gateway (RGW) provides a RESTful object storage interface to the Ceph Storage cluster. It provides an interface that is compatible with a large subset of AWS S3 APIs.<\/p>\n\n<p>In this talk we discuss the implementation of a subset of the APIs of AWS Secure Token Service (STS). AWS STS is a web service which enables identity federation and cross-account access by providing temporary security credentials.<\/p>\n\n<p>Ceph Object Storage Gateway now supports some APIs of AWS STS particularly related to web identity federation and cross-account access. The advantages of these temporary credentials are that they automatically expire after a certain duration, provide limited access (via IAM policies) to resources, are provided to the user upon request, and obviate the need for users/ applications to save permanent security credentials thereby removing a potential security loophole.<\/p>\n\n<p>As an example consider a web application that has users and needs access to RGW S3 buckets to read/ write large files. The application can delegate identity management to a trusted third party identity provider(IDP). It can get temporary credentials from STS after authenticating with the IDP and access the required RGW S3 buckets.<\/p>",
        "description": "<p>Outline of the talk:<\/p>\n\n<ol>\n<li>Introduction to Ceph and Ceph Object Storage Gateway<\/li>\n<li>Current authentication mechanisms in Ceph Object Storage Gateway<\/li>\n<li>AWS Secure Token Service<\/li>\n<li>STS APIs implemented in Ceph Object Storage<\/li>\n<li>Advantages of using STS<\/li>\n<li>Example<\/li>\n<li>Future Work<\/li>\n<\/ol>",
        "persons":
        {
          "person":
          {
            "_id": "6638",
            "value": "Pritha Srivastava"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9359.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10127",
        "start": "09:35",
        "duration": "00:30",
        "room": "H.1308 (Rolin)",
        "slug": "nfs_ganesha",
        "title": "NFS Ganesha",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NFS-Ganesha is an extensible user-space NFS server that supports NFS v3, v4, v4.1, v4.2, pNFS, and 9P protocol. It has an easily pluggable architecture called FSAL (File System Abstraction Layer), which enables seamless integration with many filesystem backends (GlusterFS, Ceph, etc.). There will be a discussion on the components along with an architectural explanation of NFS Ganesha with a detailed look at how a request flows through the various layers of NFS Ganesha and see some critical aspects in using NFS Ganesha. Along with the discussion on \"your first contribution to NFS Ganesha\" the audience will be engaged in a collaborative session and with a live demo, take a detailed look at the Clustered HA implementation using pacemaker/corosync with a specific example of a distributed storage, GlusterFS.<\/p>\n\n<p>Finally, there will be an open dialogue about the inclusion of Transport Layer Security into NFS Ganesha. One major drawback seen with NFS is the lack of transmitting encrypted data packets to and from NFS Server and Client. This lack is widely frowned upon, and it seems like there is enough communication gap within the community about its development, which I hope to shorten and revive the chatter to begin progress in this course.<\/p>",
        "description": "<p>The intentions behind this talk:<\/p>\n\n<p>-> Introduce architectural explanation of NFS Ganesha\n-> A short code walk-through to explore crucial features of NFS Ganesha\n-> Live demo of Clustered High Availability implementation using pacemaker/corosync\n-> Talk about the implementation of Transport Layer Security(TLS) into NFS Ganesha<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6719",
            "value": "Arjun Sharma"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10127.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9508",
        "start": "10:10",
        "duration": "00:20",
        "room": "H.1308 (Rolin)",
        "slug": "evolution_of_path_based_geo_replication_in_gluster",
        "title": "Evolution of path based Geo-replication in Gluster",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As data is becoming more and more important in the world, we can't afford to lose it even if there is a natural calamity. We will see how Geo-Replication came in to solve this problem for us and how it evolved over the days.\nThrough this session, the users will learn how easy it is to set up Georep for Gluster to use it for their storage and back up their data with minimal understanding of storage and linux. Having a basic Gluster knowledge will make it even more easy<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6768",
            "value": "Hari Gowtham"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9508.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9594",
        "start": "10:35",
        "duration": "00:15",
        "room": "H.1308 (Rolin)",
        "slug": "run_zfs_in_userspace",
        "title": "Run ZFS in userspace",
        "subtitle": "How we used ZFS in userspace for storage engine cStor",
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While running in user space ZFS utilizes a user space binary called ztest.\nIn cStor, we followed a similar approach to create a binary called ‘zrepl’ that is part of cStor. It has been built using the libraries similar to what is used for ztest and contains transactional, pooled storage layers.\ncStor uses ZFS behind the scenes by running it in the user space. This talk we will discuss in detail how we used ZFS in userspace for storage engine cStor and highlight a few challenges that our team faced while building this data engine.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6836",
            "value": "Harshita Sharma"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9594.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9282",
        "start": "10:55",
        "duration": "00:35",
        "room": "H.1308 (Rolin)",
        "slug": "whats_new_in_samba_",
        "title": "What's new in Samba ?",
        "subtitle": "Latest news from the Samba project",
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presentation will give an overview of all the changes happening in the Samba project code, from the fileserver virtual filesystem (VFS) rewrite, the new features in the SMB3 code, the quest to remove the old SMB1 protocol and much more. Improvements in Samba scalability, clustering and the Active Directory code will be discussed.<\/p>\n\n<p>The intended audience is anyone who uses the Samba code, creates products with Samba or is interested in the SMB protocol.<\/p>",
        "description": "<p>The presentation will give an overview of all the changes happening in the Samba project code, from the fileserver virtual filesystem (VFS) rewrite, the new features in the SMB3 code, the quest to remove the old SMB1 protocol and much more. Improvements in Samba scalability, clustering and the Active Directory code will be discussed. I'll also cover the changes to Samba development and tooling, and how we are modernizing the code base to stay relevant in the Cloud-connected world of software defined storage.<\/p>\n\n<p>This can be either a 30 minute talk (20 mins + 5 questions) or 60 minute talk (45+10 for questions).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5796",
            "value": "Jeremy Allison"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9282.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9896",
        "start": "11:35",
        "duration": "00:40",
        "room": "H.1308 (Rolin)",
        "slug": "sds_ceph_async_directory_ops",
        "title": "Asynchronous Directory Operations in CephFS",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Metadata-heavy workloads are often the bane of networked and clustered filesystems. Directory operations (create and unlink, in particular) usually involve making a synchronous request to a server on the network, which can be very slow.<\/p>\n\n<p>CephFS however has a novel mechanism for delegating the ability for clients to do certain operations locally. While that mechanism has mostly been used to delegate capabilities on normal files in the past, it's possible to extend this to cover certain types of directory operations as well.<\/p>\n\n<p>The talk will describe work that is being done to bring asynchronous directory operations to CephFS. It will cover the design and tradeoffs necessary to allow for asynchronous directory operations, discuss the server and client-side infrastructure being added to support it, and what performance gains we expect to gain from this.<\/p>",
        "description": "<p>This is preliminary and may change between now and the conference, but this is what I'm planning to cover:<\/p>\n\n<ul>\n<li>overview of problem (why metadata operations are so slow on network filesystems) and proposed solution<\/li>\n<li>what about error handling?<\/li>\n<li>CephFS caps<\/li>\n<li>DIR<em>UNLINK and DIR<\/em>CREATE caps<\/li>\n<li>directory completeness and dentry revalidation<\/li>\n<li>asynchronous unlink<\/li>\n<li>Inode number delegation<\/li>\n<li>asynchronous creates<\/li>\n<li>benchmarks<\/li>\n<\/ul>",
        "persons":
        [
          {
            "_id": "5316",
            "value": "Patrick Donnelly"
          },
          {
            "_id": "5664",
            "value": "Jeff Layton"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9896.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9653",
        "start": "12:15",
        "duration": "00:35",
        "room": "H.1308 (Rolin)",
        "slug": "rook_cloud_native_storage_for_kubernetes",
        "title": "Rook Cloud Native Storage for Kubernetes",
        "subtitle": "Overview and what is new about Rook",
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>What is Rook and the architecture of Rook + the storage run in Kubernetes.\nWe'll also take a look at new features added to Rook.<\/p>",
        "description": "<p>The talk will give an overview of what Rook can do and what is new since last years talk about Rook Ceph storage.\nThe overview will be about what Rook is and the architecture.\nThe second part is going to show newly added features to Rook.<\/p>\n\n<p>Agenda:\n* What is Rook\n* Architecture of Rook\n* New features\n  * Ceph\n  * New Storage Backend: Yugabyte\n  * EdgeFS\n  * Upcoming<\/p>\n\n<p>Target audience are people interested in Rook, Ceph and Kubernetes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5590",
            "value": "Alexander Trost"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9653.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9212",
        "start": "13:00",
        "duration": "00:45",
        "room": "H.1308 (Rolin)",
        "slug": "building_blocks_for_containerized_ceph",
        "title": "Building Blocks for Containerized Ceph",
        "subtitle": "How Raw Block PersistentVolumes Changed the Way We Look at Storage in Kubernetes",
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Originally, Kubernetes PersistentVolumes (PVs) could only present storage to containers as filesystems. Now, raw block PersistentVolumes (PVs) allow applications to consume storage in a new way. In particular, Rook-Ceph now makes use of them to provide the backing store for its clustered storage in a more Kubernetes-like fashion and with improved security. Now we can rethink the notion of how we structure our storage clusters, moving the focus away from static nodes and basing them on more dynamic, resilient storage devices.<\/p>",
        "description": "<p>Originally, Kubernetes PersistentVolumes (PVs) could only present storage to containers as filesystems. However, some applications prefer to use block storage, usually for reasons of performance, and have no need for a full filesystem. Several such applications have had to go as far as directly accessing local system directories to get the functionality they need in Kubernetes.<\/p>\n\n<p>Raw block PVs are a relatively new feature that went beta in Kubernetes 1.13. They allow Kubernetes to present storage to containers as block devices, removing the need for provisioners to format filesystems on top of them. This not only allows for greater performance to the applications that expect it, it also helps improve security by reducing the level of permissions such an application's containers require to run.<\/p>\n\n<p>Rook-Ceph is the Ceph operator for the Rook project. It provides resilient storage by running the various Ceph components as containers and managing them via Kubernetes. Originally, it would bind-mount system directories to manipulate the storage devices it consumed. It now leverages raw block PVs to store its data, expanding the types of storage it can consume. In particular, cloud environments are now a space where its storage Pods can migrate in response to node failures and have the storage devices move with their Pods.<\/p>\n\n<p>For the uninitiated, this presentation will start with an overview of how storage is modeled and presented in Kubernetes. It will then describe how that storage was originally consumed by Rook-Ceph, what we changed about it, and the consequences (both good and bad) of those changes.<\/p>",
        "persons":
        [
          {
            "_id": "4519",
            "value": "Jose Rivera"
          },
          {
            "_id": "6430",
            "value": "Rohan Gupta"
          }
        ],
        "links":
        [
          {
            "_href": "https://github.com/rook/rook/",
            "value": "Rook GitHub"
          },
          {
            "_href": "https://github.com/rook/rook/blob/master/design/storage-class-device-set.md",
            "value": "Rook StorageClassDeviceSets Design"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9212.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9543",
        "start": "13:50",
        "duration": "00:35",
        "room": "H.1308 (Rolin)",
        "slug": "sds_ceph_stretch_clusters",
        "title": "Explicitly Supporting Stretch Clusters in Ceph",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ceph is an open source distributed object store, network block device, and file system designed for reliability, performance, and scalability. While Ceph is designed for use in a single data center, users have deployed “stretch” clusters across multiple data centers for many years, and deploying Ceph to back Red Hat’s OpenShift Container Storage product required us to support that workload explicitly and well — in particular, in the face of netsplits.\nThis requires improvements to our “monitor” leader elections and to the “OSD” peering process to keep data available without breaking our data integrity guarantees. This talk presents the whole cycle of that work from an algorithm and programmer perspective: the dangers we identified, the changes we needed, the architecture changes to support faster test iteration and coding, and the results.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6810",
            "value": "Gregory Farnum"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9543.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9300",
        "start": "14:30",
        "duration": "00:45",
        "room": "H.1308 (Rolin)",
        "slug": "sds_gluster_thin_arbiter",
        "title": "A 'Thin Arbiter' for glusterfs replication",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Maintaining consistency in replication is a challenging problem involving locking of nodes, quorum checks and reconciliation of state, all of which impact performance of the I/O path if not done right. In a distributed system, a minimum of 3 nodes storing metadata is an imperative to achieve consensus and prevent the dreaded split-brain state. Gluster has had solutions like the trusted 3-way replication or the ' 2 replica + 1 arbiter' configuration to achieve this.<\/p>\n\n<p>The latest in the series is a 'Thin Arbiter (TA)' which is more minimalist the existing '1 arbiter', targeted at container platforms and cloud deployments. A TA node can be deployed outside a gluster cluster and can be shared with multiple gluster volumes. It requires zilch storage space and does not affect I/O path latencies in the happy case. This talk describes the design, working and deployment of TA and the potential gotchas one needs to be aware of while choosing this solution.<\/p>\n\n<p>The intended audience is sysadmins/dev-ops personnel who might want to try out the thin-arbiter volume and troubleshoot any operational issues that may arise.<\/p>",
        "description": "<p>The Thin Arbiter (TA) is different from normal arbitration logic in the sense that  even if only one file is bad in one of the copies of the replica, it marks that entire replica unavailable (despite it having other files in it that  are healthy), until it is healed and syncs up to the other good copy.  While this might seem like a very bad idea for a highly available system,  it works very well to prevent split-brains due to intermittent network disconnects rather than a whole node going off-line indefinitely. In talking about this feature, my talk will cover:<\/p>\n\n<ul>\n<li>Introduction to how synchronous replication in gluster works.<\/li>\n<li>The role of quorum in preventing split-brains.<\/li>\n<li>Briefly describe the working of replica 3 and arbiter volumes.<\/li>\n<li>The basic idea behind thin-arbiter based replication.<\/li>\n<li>Explain the state machine behind the thin-arbiter transaction model.<\/li>\n<li>Describe how it can be installed and used.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6611",
            "value": "Ravishankar N."
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9300.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9423",
        "start": "15:20",
        "duration": "00:25",
        "room": "H.1308 (Rolin)",
        "slug": "management_of_storage_on_openshift",
        "title": "Management of Storage on OpenShift",
        "subtitle": "Managing storage was never so easy",
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will walk-through how users can deploy storage on OpenShift and manage it all from the browser. With just a few clicks and almost zero questions asked, we will demonstrate how anyone can deploy &amp; manage storage like never before. From beginners to experts, this session has fun bits for every storage enthusiast.<\/p>",
        "description": "<p>Goal is to enable every participant to set up their own storage cluster and manage it from the comforts of their browser.\nNo hefty configurations, just a few clicks to get going.<\/p>\n\n<p><em>Key Takeaways<\/em>\n- Operator Lifecycle Manager Overview\n- Storage Operators Overview\n- Container Storage in OpenShift\n- Rook, Ceph\n- Management Console for Storage<\/p>",
        "persons":
        [
          {
            "_id": "6696",
            "value": "Ankush Behl"
          },
          {
            "_id": "6720",
            "value": "Umanga Chapagain"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9423.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10000",
        "start": "15:50",
        "duration": "00:30",
        "room": "H.1308 (Rolin)",
        "slug": "the_history_of_error_correction_and_detection_and_how_it_led_to_cephs_erasure_coding_techniques",
        "title": "The history of error correction and detection and how it led to Ceph’s Erasure Coding Techniques",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>70 years of academic innovation in the development of error correction codes have led to the advanced erasure coding techniques that we use in Ceph. Learn more about how these came about, the different types, how they work, and how we use them in distributed storage today.<\/p>",
        "description": "<p>Erasure Coding is the latest in a long line of error detection and correction approaches over the last 70 years which have all had an impact on the way we approach storing and recovering data in sensible and efficient ways. I’ll give an overview of the main approaches over the years, including the parity bit, the hamming codes, RAID, reed-solomon, and how they have impacted media storage, distributed storage, and their usage in other unexpected ways. I’ll then provide an overview of erasure coding across distributed storage and specifically Ceph.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7042",
            "value": "Danny Abukalam"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10000.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10123",
        "start": "16:25",
        "duration": "00:35",
        "room": "H.1308 (Rolin)",
        "slug": "ephemeral_pinning_a_dynamic_metadata_management_strategy_for_cephfs",
        "title": "Ephemeral Pinning: A Dynamic Metadata Management Strategy for CephFS",
        "subtitle": [],
        "track": "Software Defined Storage",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Having a separate cluster of Metadata Servers (MDS) is a well known design strategy among distributed file-system architectures.  One challenge faced by this approach is how to distribute metadata among the MDSs. Unlike data storage and it's associated I/O throughput, which can be scaled linearly with the number of storage devices, file-system metadata is a fairly complex entity to scale due to it's hierarchical nature. In hindsight, a pure hashing based metadata distribution strategy seems like a perfect fit. But, this is not exactly the case. What are the pitfalls then? Too many inter-MDS hops (due to POSIX traversal semantics), loss of hierarchical locality degrades file-system performance, and as a result, this is not beneficial for a workload whose directory hierarchy tree grows in depth rather than breadth. CephFS's metadata balancer takes a different approach by partitioning metadata sub-trees across MDSs thereby preserving good locality benefits. Although efficient, this involves a lot of back and forth migrations of sub-trees and the locality benefits are sometimes trumped by sub-optimal distributions.<\/p>\n\n<p>In this talk, we present a new metadata distribution strategy employed in CephFS - Ephemeral Pinning. This strategy combines the benefits of hashing and naive sub-tree partitioning by intelligently pinning sub-trees to MDSs so as to obtain a balanced distribution as the workload metadata grows by depth and breadth. A consistent hashing based load balancer helps in maintaining an optimal distribution during addition or failure of MDSs.<\/p>",
        "description": "<p>This talk will cover the following key ideas:<\/p>\n\n<ul>\n<li>How metadata is handled in distributed file systems.<\/li>\n<li>Why it is so important to have an optimal distribution of metadata among Metadata Servers.<\/li>\n<li>The drawbacks and advantages of commonly used and popular metadata distribution strategies.<\/li>\n<li>Ephemeral Pinning - The new metadata distribution strategy employed by CephFS. We will explain the design and implementation of the distribution strategy and delineate it's strong suits.<\/li>\n<\/ul>\n\n\n<p>This talk would be beneficial for every distributed file-system project that handles file metadata separately. They would get an overview on existing metadata distribution strategies - it's pitfall's and benefits and the reason why we at CephFS came up with this approach. The benefit's of using consistent hashing for distributing metadata are also discussed.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6822",
            "value": "Sidharth Anupkrishnan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10123.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.1309 (Van Rijn)",
    "event":
    [
      {
        "_id": "9534",
        "start": "10:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_virt_landscape",
        "title": "Landscape of new challenges in modern virtualization platforms",
        "subtitle": "Tackling new issues in virtualization: security, performance, use cases and more",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Because virtualization is everywhere, new challenges in the IT world are revealing that this crucial component has to be improved on a regular basis. This requires a lot of coordination between Open Source projects as well as intense research and development efforts.<\/p>\n\n<p>NVMe storage performance revealing hidden bottlenecks, Intel CPU flaws changing the security landscape regarding isolation, increasing complexity of stacks requiring more and more components working together, hardware specialization, new protocols, new use cases on top (k8s): these are a few of the challenges that a virtualization platform must answer in 2020.<\/p>\n\n<p>We'll first see a landscape of these new challenges, then the possible approaches to solve them, and finally a concrete example of what the XCP-ng project is doing to integrate all these changes in a fully Open Source fashion, inside a turnkey Xen distro.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2730",
            "value": "Olivier Lambert"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9534.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10333",
        "start": "10:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_pubic_clouds_and_vulnerable_cpus",
        "title": "Public clouds and vulnerable CPUs: are we secure?",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A whole bunch of CPU vulnerabilities were revealed in the past few years:\nMeltdown and Spectre, SSB, L1TF and MDS -- and there's little hope that we've\nseen them all. Every time there is a new vulnerability released, big cloud\nprovides on day 1 claim that their hosts were updated and that their users\nare secure. Is this so or do we also need to do something inside our Linux\nguests to mitigate these vulnerabilities? And, do we have the required tools\nto actually do the mitigations? Are all of them enabled by default or not? And,\nif not, why? In the talk I'll try to answer these questions.<\/p>",
        "description": "<p>The talk will cover recently discovered CPU vulnerabilities starting with\nMeltdown and Spectre. I will go through them and try to highlight 'public\ncloud specifics': what has/can to be done in the infrastructure of the\ncloud and what has/can be done inside Linux guests depending on the desired\nlevel of security and usage patterns.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4893",
            "value": "Vitaly Kuznetsov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10333.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9289",
        "start": "11:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_virtio_fs",
        "title": "virtio-fs",
        "subtitle": "A shared file system for virtual machines",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk covers the new virtio-fs shared file system that allows a host directory tree to be shared with guests.  Sharing files with the guest is required by several use cases including container VMs, File-System-as-a-Service, and traditional virtualization.  virtio-fs goes further than previous attempts by taking advantage of the co-location of the guest and host using DAX to share the host page cache.  This presentation explains how to use virtio-fs, a bit about how it works internally, and the current status.<\/p>",
        "description": "<p>virtio-fs is a new shared file system giving access to a directory that both the host and guests can access.  Traditionally shared file systems have been used to make data available to the guest during installation, boot a guest from a directory tree on the host, or to develop code on the host and test it in-place without copying files into the guest.  New use cases including container VMs and File-System-as-a-Service have introduced new requirements that virtio-fs is designed to meet.<\/p>\n\n<p>Previous attempts at shared file systems have included virtio-9p or simply used network file systems.  virtio-fs is unique because it is possible to access files directly from the host page cache.  This eliminates data copies and communication, resulting in lower memory footprint and higher performance for many workloads.<\/p>\n\n<p>This presentation explains how to use virtio-fs and covers its architecture.  It includes performance benchmarks showing how various features perform and a comparison with virtio-9p.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2816",
            "value": "Stefan Hajnoczi"
          }
        },
        "links":
        [
          {
            "_href": "https://virtio-fs.gitlab.io/",
            "value": "virtio-fs website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9289.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10484",
        "start": "11:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_io_uring_in_qemu",
        "title": "io_uring in QEMU: high-performance disk I/O for Linux",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>io<em>uring is a new kernel asynchronous I/O processing mechanism proposed as a much faster alternative for conventional Linux AIO. Patches were merged in Linux 5.1 and gave a promised performance boost. We decided to integrate it into QEMU to make virtualized storage devices work more efficiently. Let's take a look at how io<\/em>uring works in QEMU.<\/p>\n\n<p>You will get a brief overview of the new kernel feature, how we used it in QEMU, combined its capabilities to speed up storage in VMs and what performance we achieved. Should io_uring be the new default AIO engine in QEMU? Come and find out!<\/p>",
        "description": "<p>io<em>uring is a new kernel asynchronous I/O processing mechanism proposed as a much faster alternative for conventional Linux AIO. Patches were merged in Linux 5.1 and gave a promised performance boost. We decided to integrate it into QEMU to make virtualized storage devices work more efficiently. io<\/em>uring enhances the existing Linux AIO API, and provides QEMU a flexible interface, allowing you to use the desired set of features: submission polling, completion polling, fd and memory buffer registration. By explaining these features we will come to examples of how and when you need to use them to get the most out of io_uring. Expect many benchmarks with different QEMU I/O engines and userspace storage solutions (SPDK).<\/p>\n\n<p>You will get a brief overview of the new kernel feature, how we used it in QEMU, combined its capabilities to speed up storage in VMs and what performance we achieved. Should io_uring be the new default AIO engine in QEMU? Come and find out!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7272",
            "value": "Julia Suvorova"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10484.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10463",
        "start": "12:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_lightweight_virt_at_the_edge",
        "title": "Lightweight virtualization in the Cloud and at the Edge",
        "subtitle": "hypervisors gone rogue",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Running applications in the Cloud has changed the way users develop and ship\ntheir code. Quite recently, the community has given rise to microservices-based\napproaches, towards solutions that follow the paradigm of Platform-, Software-,\nand Function-as-a-Service (PaaS, SaaS, and FaaS respectively).<\/p>\n\n<p>To accommodate user demands, while maintaining security and isolation, Cloud\nvendors have adopted a hybrid approach where user workloads are being executed\nin lightweight sandboxed environments, where micro-hypervisors provide the\nisolation and container-based images facilitate application deployment. As a\nresult, lighter virtualization stacks remains a key aspect to maximize\nperformance in a multi-tenant but isolated environment.<\/p>\n\n<p>To this end, we started experimenting with various Virtual Machine Monitors\n(VMMs) that could provide the ideal trade-off between performance, flexibility\nand application portability. In this talk, we present the design of a minimal\nVMM, based on KVM, residing entirely in the Linux Kernel and showcase the\nmerits and shortcomings (minimal footprint, security concerns), for each\nuse-case (Cloud FaaS, edge multi-tenancy). Additionally, we present our\nexperience from porting Firecracker to a low-power device (RPi4) demonstrating\nthe merits of lightweight hypervisor stacks for flexible application execution\nat the edge.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "5495",
            "value": "Anastassios Nanos"
          },
          {
            "_id": "7347",
            "value": "Babis Chalios"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10463.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10195",
        "start": "12:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_lxd_for_mixed_workloads",
        "title": "LXD for mixed system containers and VM workloads",
        "subtitle": "Introducing LXD's new virtual machine feature",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LXD is most known as a system container manager, offering a simple user experience and images for most Linux distributions.\nIt also offers a simple REST API, network and storage management, project views and easy clustering to dozen of hosts.<\/p>\n\n<p>Over the past few months, LXD has now grown the ability to run virtual machines alongside containers, using the exact same REST API and configuration.\nThis presentation will cover that new feature, why it was done, where it's at now and where we're going with it, as well as provide a quick demo of setting up a small LXD cluster and running both containers and virtual machines on it.<\/p>",
        "description": "<p>LXD is an open source system container manager, developed by the team behind LXC, written in Go and that's been around for over 5 years now.\nIt's widely used both on servers, running the backend of services such as Travis-CI and on everyday devices like Chromebooks.\nContainers are created from images with prebuilt images available for most Linux distributions.<\/p>\n\n<p>Multiple hosts can easily be clustered together to form one large virtual host, exposing the exact same API as a single host would.\nStorage pools and networks can also be created and managed through LXD and resources can be segmented into projects.<\/p>\n\n<p>With the addition of virtual machine support (through qemu), it is now possible to manage a mixed deployment of virtual machines and containers, sharing the same configuration, storage and networks. With the use of our built-in agent, the exact same operations that are normally possible against a container also become possible against virtual machines, including executing commands, transferring files, ...<\/p>\n\n<p>Existing API clients for LXD can also now drive both containers and virtual machines without any API changes required.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3310",
            "value": "Stéphane Graber"
          }
        },
        "links":
        [
          {
            "_href": "https://linuxcontainers.org/lxd",
            "value": "Main website"
          },
          {
            "_href": "https://github.com/lxc/lxd",
            "value": "Github"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10195.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9566",
        "start": "13:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_ovirt_4k",
        "title": "oVirt 4k - teaching an old dog new tricks",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Teaching oVirt to work with 4k storage.<\/p>",
        "description": "<p>How can we have compression and deduplication using VDO, the new Linux\ncompression layer? How can we use the latest and greatest disks drives?\nWe need to support disks with 4k block size.<\/p>\n\n<p>oVirt is your best friend when you need to manage your virtualized data\ncenter, but when it was created 10 years ago, support for 4k storage was\nnot considered. Can you teach an old dog new tricks? Sure you can!<\/p>\n\n<p>In this talk we will share what we learned implementing 4k storage\nsupport in oVirt. We will present the challenges teaching old and\nstubborn code base to work with disks using 4k storage, and how we\naddressed them; introducing storage format v5, moving from sectors to\nbytes, detection of block size on file storage, improving testing in\nstorage area, adding new 4k APis to sanlock and improving qemu block\nsize detection.<\/p>\n\n<p>Audience:\noVirt administrator interested in utilizing the latest and greatest\nfeatures and hardware. Developers looking for new ways to deal with old\ncode.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6667",
            "value": "Nir Soffer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9566.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10350",
        "start": "13:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_edge_clouds_with_opennebula",
        "title": "Edge Clouds with OpenNebula",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Edge computing is currently getting a lot of traction thanks to the growing availability of rented computing resources around the world. The idea is based on moving the core computational logic and storage to distant locations that are closer to the entities they interact with (e.g. users or sensors). The benefits come from improving network latencies, increasing user experience with the provided service, and lowering the transfers to the central locations. Edge clouds bring the flexibility and proven workflows of cloud computing to the edge.<\/p>\n\n<p>OpenNebula is an open source framework to build private and hybrid clouds based on KVM, LXD, and/or VMware vCenter. While the main domain is the corporate private on-premises cloud, it comes with simple and extensible tooling (\"oneprovision\") for automated deployment of edge clouds. When provided with a deployment descriptor, it allocates the physical hosts on the public bare-metal cloud provider, configures all necessary services (e.g. install libvirt/KVM or LXD), and enables them for use in OpenNebula. The process is as simple as running a command-line tool and the cloud administrator gets a fully usable configured edge cluster in a few  minutes.<\/p>\n\n<p>As part of a usability validation exercise, we successfully deployed public gaming servers from scratch to running services on 17 different locations worldwide in just 25 minutes: https://opennebula.org/opennebula-a-lightning-fast-video-gaming-edge-use-case-2 .<\/p>\n\n<p>This talk introduces the OpenNebula \"edge\" concept and shows the current state, capabilities, and limitations of edge cloud deployment tooling. It explores the difficulties of running the IaaS-in-IaaS cloud and demonstrates with practical examples the use of tooling and management of edge deployments.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7051",
            "value": "Vlastimil Holer"
          }
        },
        "links":
        [
          {
            "_href": "https://opennebula.org/opennebula-a-lightning-fast-video-gaming-edge-use-case-2",
            "value": "A Lightning-fast Video Gaming Edge Cloud Use Case"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10350.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9419",
        "start": "14:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_baremetal_at_the_edge",
        "title": "Baremetal at the Edge",
        "subtitle": "Managing bare metal machines where PXE would fail",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Deploying bare metal machines at the edge of the cloud may not play well with conventional PXE protocol suite. In this presentation we will explain how the emerging virtual media boot technology could significantly improve scalability, reliability and security of the Cloud.<\/p>",
        "description": "<p>In this talk, the latest advancements in bare metal provisioning service (ironic) will be explained and PXE-less machine deployment will be demonstrated showcasing two scenarios - bare metal management within the OpenStack cloud and a stand-alone ironic use-case (e.g. within a container orchestration system).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4259",
            "value": "Ilya Etingof"
          }
        },
        "links":
        [
          {
            "_href": "https://wiki.openstack.org/wiki/Ironic",
            "value": "ironic"
          },
          {
            "_href": "https://en.wikipedia.org/wiki/Redfish_(specification)",
            "value": "Redfish spec"
          },
          {
            "_href": "https://en.wikipedia.org/wiki/Virtual_disk_and_virtual_drive",
            "value": "Virtual media devices"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9419.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9948",
        "start": "14:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_vm_journey_from_vmware_to_k8s",
        "title": "A VM journey from VMware to Kubernetes",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kubernetes became primary platform for managing containerized applications.\nIn connection with KubeVirt, it can manage both containers and virtual machines in a single cluster to enable mixed workloads and so give second breath to existing legacy workloads based on virtual machines which might not be feasible to containerize for either technical or business reasons.<\/p>\n\n<p>Consolidation of so far distinct clusters for VMs and containers is the next logical step.\nCome to see an end to end conversion of a VMware virtual machine into Kubernetes.<\/p>",
        "description": "<p>Conversion of a virtual machine from VMware to Kubernetes will be presented.<\/p>\n\n<p>An attendee will learn:\n- briefly about KubeVirt (virtualization add-on for Kubernetes)\n- how to convert an existing VM to Kubernetes\n- implementation aspects (deep-dive)\n- about ongoing development and how to participate<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6053",
            "value": "Marek Libra"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9948.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9430",
        "start": "15:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_back_to_the_future",
        "title": "Back to the future",
        "subtitle": "Incremental backup in oVirt",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Do you need to go back in time to restore data from important VMs? oVirt\ndoes not provide a time machine yet, but you can build one using oVirt\nbackup APIs.<\/p>\n\n<p>Building on changed blocks tracking in qemu, and upcoming libvirt backup\nAPI, oVirt will provide API to perform incremental backups. You will be\nable to back up VMs more efficiently, downloading only changed blocks.\nIncremental backup will be simpler and more reliable, not requiring\ncreating and deleting snapshots. Uploading will support on-the-fly\nconversion from raw to qcow2 when restoring disks.<\/p>\n\n<p>In this talk we will travel into the future, introducing the oVirt\nincremental backup API for starting and ending backups, and the\novirt-imageio API for downloading changed blocks. Finally, we will travel\nback to the past, and show how to restore raw guest data into new disks.<\/p>\n\n<p>Audience:\nBackup vendors and virtualization developers, interested in utilizing\nincremental backup API. Also, oVirt administrators and users interested in\npeeking into the future of oVirt.<\/p>\n\n<p>Session summary:\nPeek into the future of oVirt backup API.<\/p>",
        "description": "<p>Do you need to go back in time to restore data from important VMs? oVirt\ndoes not provide a time machine yet, but you can build one using oVirt\nbackup APIs.<\/p>\n\n<p>Building on changed blocks tracking in qemu, and upcoming libvirt backup\nAPI, oVirt will provide API to perform incremental backups. You will be\nable to back up VMs more efficiently, downloading only changed blocks.\nIncremental backup will be simpler and more reliable, not requiring\ncreating and deleting snapshots. Uploading will support on-the-fly\nconversion from raw to qcow2 when restoring disks.<\/p>\n\n<p>In this talk we will travel into the future, introducing the oVirt\nincremental backup API for starting and ending backups, and the\novirt-imageio API for downloading changed blocks. Finally, we will travel\nback to the past, and show how to restore raw guest data into new disks.<\/p>\n\n<p>Audience:\nBackup vendors and virtualization developers, interested in utilizing\nincremental backup API. Also, oVirt administrators and users interested in\npeeking into the future of oVirt.<\/p>\n\n<p>Session summary:\nPeek into the future of oVirt backup API.<\/p>",
        "persons":
        [
          {
            "_id": "6534",
            "value": "Eyal Shenitzky"
          },
          {
            "_id": "6667",
            "value": "Nir Soffer"
          }
        ],
        "links":
        [
          {
            "_href": "https://ovirt.org/develop/release-management/features/storage/incremental-backup.html",
            "value": "oVirt feature page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9430.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9567",
        "start": "15:30",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_running_vms_out_of_thin_air",
        "title": "Running virtual machines out of thin air",
        "subtitle": [],
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How to run virtual machines in oVirt without copying their disks.<\/p>",
        "description": "<p>Have you ever wanted to run your virtual machine in oVirt without copying its hugh disks?\nTired of checking the slow transfer progress? We did, and we have a good plan to avoid the wait!<\/p>\n\n<p>In this talk we show how oVirt can start virtual machine without copying the disks,\nusing external disk via NBD or other protocols supported by qemu.\nOnce the virtual machine is running, copy the disks in the background to oVirt storage.\nThis minimizes downtime to seconds instead of minutes, and can be used in many scenarios\nsuch as importing virtual machines from other systems (even from foreign systems via virt-v2v),\npreviewing backups before restore, and provisioning a virtual machines.<\/p>\n\n<p>Audience:\nVirtualization administrators or developers interested in oVirt architecture and would like a peek into future development.<\/p>",
        "persons":
        [
          {
            "_id": "6667",
            "value": "Nir Soffer"
          },
          {
            "_id": "6718",
            "value": "Daniel Erez"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9567.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9802",
        "start": "16:00",
        "duration": "00:30",
        "room": "H.1309 (Van Rijn)",
        "slug": "vai_reaching_epyc",
        "title": "Reaching \"EPYC\" Virtualization Performance",
        "subtitle": "Case Study: Tuning VMs for Best Performance on AMD EPYC 7002 Series Based Servers",
        "track": "Virtualization and IaaS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Virtualization brings many advantages, but what about the overhead it introduces? What about performance? This talk will show how great virtualization performance can be achieved, if proper tuning is applied to all the components of the system: hypervisor, host and guests, for both Xen and KVM. As a case study, we will describe how we tuned our OS in order to be able to reach, inside VMs, close to baremetal performance, on a server powered by a CPU from the AMD EPYC 7002 (codename \"Rome\") series. We will, of course, show the benchmarks proving that (run on KVM), even when memory encryption is used.<\/p>",
        "description": "<p>Virtualization is great because it decouples the software from the hardware on top of which it runs, and this brings benefits in terms of flexibility, security, reliability and cost savings. But what about the overhead that this, unavoidably, introduces?<\/p>\n\n<p>Well, often enough, a virtualized system is really able to fulfill its goals with an acceptable quality of service, efficient exploitation of HW resources, satisfactory user experience, etc., only if all the components are configured properly. This is not entirely new, as baremetal systems need tuning too, but in a virtualized environment one has to take care of tuning both the the host and the guests. And beware that the interactions between all the different components may not always be straightforward, especially on a large server with complex CPU architecture, such anything based on the AMD EPYC 7002 (codename \"Rome\") series of processors.<\/p>\n\n<p>This talk will go over some of the typical virtualization “tuning tricks” (for both Xen and KVM). Then, as a case study, we will illustrate how we managed to reach, inside Virtual Machines, a performance level that almost matches the one of the host, on a server powered by a CPU from the AMD EPYC 7002 series. In fact, we will show the results of running CPU and memory intensive benchmarks (on KVM) with and without the suggested tuning. Last (but not least :-D), we will show the impact that the Secure Encrypted Virtualization (SEV) technology has on performance.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3513",
            "value": "Dario Faggioli"
          }
        },
        "links":
        [
          {
            "_href": "https://documentation.suse.com/sbp/all/single-html/SBP-AMD-EPYC-2-SLES15SP1/index.html",
            "value": "Optimizing Linux for AMD EPYC™ 7002 Series Processors with SUSE Linux Enterprise 15 SP1"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9802.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.2213",
    "event":
    [
      {
        "_id": "10431",
        "start": "09:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "introduction_to_devroom_and_open_source_design",
        "title": "Introduction to the devroom and the Open Source Design collective",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A brief introduction to the Open Source Design collective.<\/p>",
        "description": "<p>Every year we take some time to introduce the Open Source Design collective, what we do, where to find us and how to get involved.<\/p>",
        "persons":
        [
          {
            "_id": "2363",
            "value": "Bernard Tyers"
          },
          {
            "_id": "5778",
            "value": "Amit Nambiar"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10431.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10062",
        "start": "10:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "open_source_design_africa",
        "title": "Open Source design - Africa",
        "subtitle": "Open Source Design movement in Africa",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Source Community Africa (O.S.C.A) is a movement that promotes and drive the open source culture within and across Africa. We aim to bridge the diversity gap of the open source culture through advocacy because of potential and great energy coming from the continent. This presentation will help put the African ecosystem closer to the existing platforms which will bring more diversity that includes representing the black/African community showcasing how mentorship and training are doing centred around opensource.<\/p>",
        "description": "<p>This presentation will cover the challenges and limitations of design contributions from Africa. What OSCA is doing to bridge the gab. As a designer who has been in the space of contributing to open source and has faced the challenges of how to convince a maintainer why design is as important as code, there has always been this problem which I have personally experienced as one who loves opensource, I got to understand the processes because I was patient enough to learn about the structure to influence it, but not every designer have that mindset to leave their comfort zone. So what I have been able to do as a designer is to influence the open source community Africa to take this challenge as a project as I believe it is something that designers should learn as a process of collaboration.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6824",
            "value": "Peace Ojemeh"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10062.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10621",
        "start": "10:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "what_are_we_talking_about_when_we_say_open_design",
        "title": "What are we talking about when we say \"open design\"?",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>As designers working with Libre/Open Source software, we have a strong opinion on how tools shape practice. And as designers, in general, we care deeply about our methods, workflows, principles and licenses. For some time now we've been debating the issue of terminology: how we describe our practice to others and how free/libre software terms and ideas can be integrated into design methods.<\/p>\n\n<p>In this talk, we want to propose an exercise in labeling. Building up from conversations we had with other designers moving in the sphere of Libre Software and Libre Culture, we want to:\n- present terms and try to define their scope in the hopes of improving the ways in which open design can be explained to others\n- distinguish between possible stances inside the sphere of open design, such as using libre tools vs. proprietary toolchains, designing for free software vs. designing with free software\n- explore how we understand other designers/studios/communities' ideas and practices\n- better understand how we can present our views and work vis-à-vis other design approaches -- especially to \"traditional\" and proprietary-oriented audiences<\/p>\n\n<p>This talk is a follow-up to \"Open Design, Libre Graphics: Why terminology matters\", that we presented at Libre Graphics Meeting 2019. This was the starting point of a discussion we feel the need to bring to the table, along with other designers that share the love for F/LOSS.<\/p>",
        "description": "<p>As designers working with Libre/Open Source software, we have a strong opinion on how tools shape practice. And as designers, in general, we care deeply about our methods, workflows, principles and licenses. For some time now we've been debating the issue of terminology: how we describe our practice to others and how free/libre software terms and ideas can be integrated into design methods.<\/p>\n\n<p>In this talk, we want to propose an exercise in labeling. Building up from conversations we had with other designers moving in the sphere of Libre Software and Libre Culture, we want to:\n- present terms and try to define their scope in the hopes of improving the ways in which open design can be explained to others\n- distinguish between possible stances inside the sphere of open design, such as using libre tools vs. proprietary toolchains, designing for free software vs. designing with free software\n- explore how we understand other designers/studios/communities' ideas and practices\n- better understand how we can present our views and work vis-à-vis other design approaches -- especially to \"traditional\" and proprietary-oriented audiences<\/p>\n\n<p>This talk is a follow-up to \"Open Design, Libre Graphics: Why terminology matters\", that we presented at Libre Graphics Meeting 2019. This was the starting point of a discussion we feel the need to bring to the table, along with other designers that share the love for F/LOSS.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2590",
            "value": "Manufactura Independente"
          }
        },
        "links":
        [
          {
            "_href": "http://manufacturaindependente.org/",
            "value": "Manufactira Independente"
          },
          {
            "_href": "https://libregraphicsmeeting.org/2019/schedule-fri-31-05/",
            "value": "Why terminology matters (talk, LGM 2019)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10621.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10620",
        "start": "11:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "some_excerpts_from_theory_of_design_in_architecture",
        "title": "Some Excerpts from the Theory of Design in Architecture",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk discusses some theories from architectural discourse which attempt to solve problems which required critical and creative thinking. It is interesting to see the overflows and overlaps of theories between design(architecture) and construction(engineering) to solving similar underlying problems. The lengthy history of the field throws up some interesting references and may expose some ideas which might be applicable in new age design+engineering problems.<\/p>",
        "description": "<p>An architect as a professional in today's day and age represents someone involved in the construction industry tasked with a responsibility for conceptualizing physical spaces and bringing them into reality. Etymologically the word finds its origins in ancient Greek with the word being comprised of 'arkhi' and 'tekton' which loosely translate to 'master' and 'builder' correspondingly.<\/p>\n\n<p>Historically architectural design and construction was carried out by artisans such as stone masons and carpenters, who were coordinated by a \"master builder\". There was no clear distinction between architect and engineer. This has created a body of theoretical knowledge which spans across different industry.<\/p>\n\n<p>This created a field of study spanning the spectrum of creative thinking and logical thinking. The talk sheds light on some interesting examples of how 'architects' have dealt with problems in such a space.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5778",
            "value": "Amit Nambiar"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10620.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9258",
        "start": "11:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "ui_ux_trips_and_tricks_for_developers",
        "title": "UI/UX Tips & Tricks for developers",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>I will present some general UI/UX tips &amp; tricks that will help you design better. Everyone should know the basic principles and patterns of design, and once you understand them you will naturally integrate them in your work.<\/p>",
        "description": "<p>UI/UX is a craft. The more you practice it, the better you are at it. Some people argue that you need to have 'good taste' in order to be a designer, to be the 'artsy type'. While this might be true for Graphic Design, Branding and Visual Arts in general, when it comes to Interface, Interaction and Product Design, the focus is more on practicality and 'common sense'.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2779",
            "value": "Ecaterina Moraru"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9258.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10475",
        "start": "12:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "accessibility_in_musescore",
        "title": "Accessibility in MuseScore",
        "subtitle": "Our experience with Qt and QML",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MuseScore is the world's most popular sheet music program. It is used by millions of musicians around the world, including many who are blind, partially sighted, or who struggle to use a traditional mouse-based interface. In this presentation, we share our experience in making a popular open source program accessible to keyboard and screen reader control.<\/p>",
        "description": "<p>A screen reader is a \"robot voice\" that describes what happens on the screen, which enables people who are blind to use a computer. Screen readers cannot \"see pixels\", so it is up to the programmer to tell the screen reader what is going on. We give tips on how to do this in Qt’s traditional C++ framework as well as it’s JavaScript-based QML language.<\/p>\n\n<p>Screen readers know how to deal with buttons, menus and text, but they have no idea what a treble clef is! As a music notation program, many parts of MuseScore's interface are custom widgets that do not have a counterpart in traditional UI design. This poses additional challenges when it comes to implementing accessibility. We share the thinking behind our design decisions in MuseScore, and how these may be applied to other programs.<\/p>\n\n<p>Keyboard navigation is a key aspect of accessibility, not only for people who are blind, but also for people who are motor-impaired, or ordinary users who find it quicker to use the keyboard than the mouse. There is more to keyboard navigation than shortcuts and getting around with the Tab key! We talk about how we have introduced groupings and hierarchy into MuseScore’s design to improve the experience for keyboard users.<\/p>\n\n<p>Our accessibility work is undertaken in partnership with <a href=\"https://www.ukaaf.org/\">UKAAF<\/a> and <a href=\"https://www.rnib.org.uk/\">RNIB<\/a>, two leading accessibility organisations based in the UK.<\/p>\n\n<p>MuseScore is written in C++ / Qt, with some Javascript / QML. It is available for Windows, macOS and Linux under GPL version 2.<\/p>",
        "persons":
        [
          {
            "_id": "4184",
            "value": "Peter Jonas"
          },
          {
            "_id": "7276",
            "value": "Marc Sabatella"
          }
        ],
        "links":
        [
          {
            "_href": "https://musescore.org/",
            "value": "MuseScore"
          },
          {
            "_href": "https://doc.qt.io/qt-5/accessible.html",
            "value": "Accessibility in Qt"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10475.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10476",
        "start": "12:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "git_workflow_for_design_in_os_projects",
        "title": "Gitflow Design",
        "subtitle": "A git workflow for design in open-source projects",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Gitflow design as mentioned in the description is a git workflow for designers and design work. It's meant to be open, platform-agnostic and help minimise dependencies on proprietary software and help to increase collaboration.<\/p>\n\n<p>By using git, we get to take advantage of a lot of useful features available such as controlled access, review process, feedback system, version control files, preview changes in context with side-by-side diffs, detailed history of changes and more, something developers had for years, but that designers never really took advantage o<\/p>",
        "description": "<p>Gitflow Design exists as a way to mitigate issues commonly found in design workflows of open-source software projects where the work created never comes into git. Which means such work is not being tracked and doesn't have an auditable history. Files also might not be stored in a common place accessible to everyone, so its always a hit and miss on how to gain access to them, and sometimes due to these being created with proprietary software they can sit behind a closed gateway and as contributors come and go from the project their access can be lost.<\/p>\n\n<p>By using git we make things easier and open for anyone wanting to collaborate and hopefully streamlining the work process by connecting the development and design repositories together. For this to work a success we need to adopt a design workflow that focuses on open-source ideals, so that no one is restricted by proprietary software and gatekeepers. We introduce such workflow bellow which we have been testing, It's called Gitflow Design.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7266",
            "value": "Diogo Sergio"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/Ride-The-Lightning/RTL-Design",
            "value": "Gitflow Design (In Action)"
          },
          {
            "_href": "https://www.diogosergio.com/wp-content/uploads/2019/11/GitflowDesign.v01.pdf",
            "value": "Presentation Slides (Link)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10476.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9954",
        "start": "13:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "uxbox_open_source_online_prototyping_platform",
        "title": "UXBOX, the time for an open source online prototyping platform has arrived",
        "subtitle": "Vision and short demo",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Hello World UXBOX! This will be our first public announcement of the coming of UXBOX, the open source prototyping online platform based on SVG. We will share our vision and the 2020 product roadmap, explaining the resources that are committed to them. We will perform a quick demo and hope to start a productive conversation with the Open Source Design Community.<\/p>",
        "description": "<p>After 2 years of painstakingly slow development, Kaleidos (UXBOX sponsor, also Taiga creator) has finally decided to devote full-time resources and relevant investment to once and for all create a modern open source UX/UI prototyping online platform. With open standards (SVG) as a core feature and value, we hope to contribute a much needed platform to the Open Source Design community, which we consider to be instrumental to make UXBOX the best online prototyping tool out there, period.\nThis short talk would share both the vision of the product, its current state and the 2020 roadmap. Moreover, we will want to nurture a healthy and welcoming community around the development and usage of UXBOX and we will give some hints on how we plan to do this so we can already take great feedback from FOSDEM attendees.\nUXBOX is being developed by open source enthusiasts coming from the tech and UX/UI trenches that have already built 20+ products for startups and launched Taiga in the past. Kaleidos, its umbrella company, has raised seed money and is devoting funds to make sure there is an amazing multidisciplinary team focused on UXBOX, also able to engage with a newly born community of users and contributors.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7009",
            "value": "Pablo Ruiz-Múzquiz"
          }
        },
        "links":
        [
          {
            "_href": "http://uxbox.io",
            "value": "UXBOX landing"
          },
          {
            "_href": "https://github.com/uxbox",
            "value": "UXBOX repos"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9954.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10490",
        "start": "13:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "using_biometric_gadgets_for_express_tests_in_ux_ui_research",
        "title": "Using biometric gadgets for express-tests in the UX/UI research",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Estimating the user’s physical and mental state with a set of special measuring devices can be helpful in detecting bottlenecks of the human-computer interaction. Until recent years, evaluating cognitive and physical load by biometrical parameters (heart rate, galvanic skin response, brain waves, gaze direction, etc.) was too expensive to be widely adopted for FLOSS. However contemporary consumer-grade gadgets targeted at fitness and entertainment are much more affordable and precise enough to be used in the UX/UI comparison. Still, their different primary goal often complicates their usage for the  research.  The talk will highlight which devices are the most suitable ones for the research purposes in the open-source world (the ones having open-source and GNU/Linux frameworks to access biometric data).  Gadgets covered with the talk are fitness-trackers, EEG headsets, and eye-trackers. Patterns of getting data, problems with cyphering and licensing will be discussed, as well as brief biometry usage scenarios and examples of the UI express-testing.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6726",
            "value": "Dmitriy Kostiuk"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10490.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10530",
        "start": "14:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "beyond_the_pile_of_knobs",
        "title": "Beyond the Pile of Knobs: Usability and Design for Privacy, Security, Safety & Consent",
        "subtitle": "Privacy and security shouldn't be a privilege or inaccessibly complex. We will share what we've learned working with projects that center security and privacy to support vulnerable populations.",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Simply Secure will share examples of how we can design, centering the needs of the most vulnerable. We will present the problems, e.g. why the UX patterns that make consenting or refusing consent so difficult in practice and why open source security tools are often associated with bulky user interfaces and inaccessible jargon, and share findings from our 5 years of working with projects in the Internet Freedom, Digital Rights, Media Justice, Translation, Training, Civic Tech and Development communities.<\/p>",
        "description": "<p>Security and privacy are usually handed off to development teams as technical challenges, with the design and user experience as an after thought — meaning that as designers, we are building off of limited examples and a small research field. With security risks posing a real threat on the internet, design and usability are critical to building safer more trustworthy technology because users will work around poorly design experiences.<\/p>\n\n<p>In this talk, we will share examples of how we can design, centering the needs of the most vulnerable. We will present the problems, e.g. why the UX patterns that make consenting or refusing consent so difficult in practice and why open source security tools are often associated with bulky user interfaces and inaccessible jargon, and share findings from our 5 years of working with projects in the Internet Freedom, Digital Rights, Media Justice, Translation, Training, Civic Tech and Development communities.<\/p>\n\n<p>Simply Secure is a nonprofit that supports practitioners by putting people at the center of trustworthy technology. Launched in 2014, our work focuses on building technology that enhances and protects human dignity by centering the needs of vulnerable populations. We use a human-centered approach because we believe that the user experience of a device, program, or application plays a critical role in building trustworthy technology. At a minimum, responsible user experience (UX) offers timely, comprehensible, and actionable information to users — it gives them genuine agency in interacting with the system. Fundamentally our goal is to support practitioners in developing the skills needed to work on the wicked problems presented by technology today.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7288",
            "value": "Georgia Bullen"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10530.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10603",
        "start": "14:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "over_asciidoctor_and_generating_publishing_a_book",
        "title": "Jumpstarting your business with Odoo",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I will describe the process of discovering the wonders of Odoo when I got the project to write a book about it. My writing tools are Vim, Git, Asciidoctor-pdf and Inkscape. I will describe both the technical as the organisational challenges during the writing process.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6179",
            "value": "Jeroen Baten"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10603.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10346",
        "start": "15:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "file_sharing_and_storage_for_human_rights_organizations",
        "title": "File sharing & storage for human rights organizations",
        "subtitle": "A design research case study",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Least Authority is presenting a design research project that looks at open source file storage and sharing solutions for human rights organizations. We will present the project, the first phase of our research process, and outlook on next steps that involve adapting our open source tools.<\/p>",
        "description": "<p>Least Authority's mission is to build and strengthen ethical and usable technology solutions that advance digital security and support privacy as a fundamental human right. We support open source projects, such as Tahoe-LAFS, Gridsync, Magic Folders and Magic Wormhole. This session presents a design research project, where we investigate file storing/file sharing needs of human rights organisations. As an outcome of this research, we are exploring how we can adapt our open source tools to best meet use cases and usability requirements of human rights organisations. This presentation will focus on the research process and the development of findings with the purpose of making open source tools available to meet human rights organizations’ needs. The project is funded by the Open Technology Fund.<\/p>",
        "persons":
        [
          {
            "_id": "7201",
            "value": "Allon Bar"
          },
          {
            "_id": "7422",
            "value": "Abigail Garner"
          }
        ],
        "links":
        [
          {
            "_href": "https://leastauthority.com/open-source/",
            "value": "Overview of some of the open source tools used by Least Authority"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10346.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9955",
        "start": "15:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "design_contributions_to_oss",
        "title": "Design contributions to OSS: Learnings from the Open Design project at Ushahidi",
        "subtitle": "Structuring in-person and remote workshops for open source design contributions.",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Ushahidi builds OSS humanitarian tools, remotely for some of the most marginalized people across the globe. To tackle these systemic problems with how to ‘open source’ a design effort and bring the community along with the ‘on-staff’ Ushahidi designers, we’ve been piloting a series of design events on our OSS crisis communication tool TenFour with our partners Designit and Adobe. Together, we’re looking to solve the problems with how open source design can work by engaging through meaningful technology that makes a difference in the world.<\/p>\n\n<p>We’re here to take you through that journey and what we’ve learnt about design contributions to OSS.<\/p>",
        "description": "<p>In this session, we'll briefly cover the history of the project and the main problems we attempted to solve and we'll present the learning and adaptions to our workshop framework and methodology that aims to engage design teams and individuals that are not yet 'on-board' with OSS as an ethos or movement.<\/p>\n\n<p>Looking into some the abstract deeper motivations for design professionals to contribute but also some practical tips on structuring issues, labelling and maintaining design (and extended functions like research, UX and product management) you'll leave with a set of tools and methods you can apply to your OSS to engage with designers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7016",
            "value": "Eriol Fox"
          }
        },
        "links":
        [
          {
            "_href": "http://opendesign.ushahidi.com/",
            "value": "Open Design website"
          },
          {
            "_href": "https://www.tenfour.org/",
            "value": "TenFour OSS"
          },
          {
            "_href": "https://ushahidi.com/",
            "value": "Ushahidi"
          },
          {
            "_href": "https://github.com/ushahidi/opendesign",
            "value": "Open Design repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9955.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10512",
        "start": "16:00",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "designing_to_change_it_all",
        "title": "Designing to change it all",
        "subtitle": "Designing processes and designing some products on the way...",
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>At the ‘SamenBeter’ project we firmly believe a good product is a product that improves how people work. So we start with designing the change we want before we even start thinking about a product. How that looks in practice? Come and see, but be prepared for a fast ride!<\/p>",
        "description": "<p>Is it possible to design a radical change in the healthcare system? Why is the first product we build for that an authorization standard? Why are we talking about the ‘personality of a system’? How come the people designing it ended up in community centres, playing a game about privacy with the visitors? What is that ‘developer journey’ we are talking about? why are we making such a big fuss about a license nobody seems to read?<\/p>\n\n<p>The ‘SamenBeter’ project has a moderate goal: to change healthcare, all of it. And because we are fuelled with design thinking, we are making deliberate design choices about everything. About what we want to change in healthcare, about the process of getting there, about the role of technology, about the values the technology should adhere, about the way we should develop the technology, about the way the technology will be adapted and about how the community should be developed.<\/p>\n\n<p>In this talk I will showcase the SamenBeter project as example of how design is about much more then user interfaces. It is about designing processes, user interactions and designing the adaptation of the product itself. And last but not least: why did we take the effort to design everything and not just a product? Yes, it is too much to fit in one talk, so fasten your seatbelts!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3348",
            "value": "Winfried Tilanus"
          }
        },
        "links":
        [
          {
            "_href": "https://www.samenbeter.org/",
            "value": "Project website (Dutch)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10512.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10432",
        "start": "16:30",
        "duration": "00:20",
        "room": "H.2213",
        "slug": "pitch_your_project",
        "title": "Pitch your project",
        "subtitle": [],
        "track": "Open Source Design",
        "type": "devroom",
        "language": [],
        "abstract": "<p>If you contribute to a free / open source project in need of design contributions, come and pitch it to the designers in the room.<\/p>",
        "description": "<p>In this session, FOSS projects as given time to present and ask for contributions to the designers in the room. Each project is given 3 minutes to present. In those 3 minutes, they should briefly introduce the project, explain what design help they need, and provide contact details so designers can reach them after FOSDEM.<\/p>\n\n<p>The Open Source Design collective will use the information to submit a \"job\" for each project to the Open Source Design \"jobs board\" (https://opensourcedesign.net/jobs/), so that the request for design help reaches not just the designers in the room, but also the wider design community.<\/p>",
        "persons":
        [
          {
            "_id": "2363",
            "value": "Bernard Tyers"
          },
          {
            "_id": "5778",
            "value": "Amit Nambiar"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10432.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "H.2214",
    "event":
    [
      {
        "_id": "10743",
        "start": "10:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_fibonacci_spirals_and_21_ways_to_contribute_to_postgres_beyond_code",
        "title": "Fibonacci Spirals and 21 Ways to Contribute to Postgres—Beyond Code",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Postgres is growing like gangbusters: in popularity, in adoption, and in the size of the ecosystem. And over 400 developers contribute code to Postgres today: their expertise, design chops, and skill are big factors in the increasing popularity of Postgres. But what if you’re not a developer? Are there things you can do to help grow the usage and popularity of Postgres? And are these non-code ways to contribute to Postgres important? Valued? Will they make a real difference?<\/p>\n\n<p>If you love Postgres and want to help drive Fibonacci growth of the Postgres community, this talk is for you. I’ll walk through 21 different (and important) ways to contribute to Postgres—along with tips and resources for getting started.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7390",
            "value": "Claire Giordano"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2927-fibonacci-spirals-and-21-ways-to-contribute-to-postgresbeyond-code/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10743.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10744",
        "start": "11:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_find_your_slow_queries_and_fix_them",
        "title": "Find your slow queries, and fix them!",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Where, oh where, is all that time going? What in the world is that database thing doing?! This talk will help you understand what's happening (and why) and how to analyze poor query performance. We'll also go over steps and strategies to take to improve them and get the performance (and scalability!) you need.<\/p>\n\n<p>It all starts with figuring out what queries are slow, we'll do that by going into the various PostgreSQL configuration options for logging queries and a few helpful modules for getting even more information about ongoing queries. Next we'll go over EXPLAIN and EXPLAIN ANALYZE output for select queries, what the EXPLAIN output means in terms of how the query is being executed. Lastly (this is the good part- you have to stay til the end to get it!) we'll go over ways to improve the queries, including index creation, rewriting the query to allow PG to use a different plan, and how to tune parameters for specific queries.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6259",
            "value": "Stephen Frost"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2838-find-your-slow-queries-and-fix-them/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10744.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10745",
        "start": "12:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_a_deep_dive_into_postgresql_indexing",
        "title": "A Deep Dive into PostgreSQL Indexing",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Indexes are a basic feature of relational databases, and PostgreSQL offers a rich collection of options to developers and designers. To take advantage of these fully, users need to understand the basic concept of indexes, to be able to compare the different index types and how they apply to different application scenarios. Only then can you make an informed decision about your database index strategy and design. One thing is for sure: not all indexes are appropriate for all circumstances, and using a ‘wrong’ index can have the opposite effect that you intend and problems might only surface once in production. Armed with more advanced knowledge, you can avoid this worst-case scenario! We’ll take a look at how to use pg<em>stat<\/em>statment to find opportunities for adding indexes to your database. We’ll take a look at when to add an index, and when adding an index is unlikely to result in a good solution. So should you add an index to every column? Come and discover why this strategy is rarely recommended as we take a deep dive into PostgreSQL indexing.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6448",
            "value": "Ibrar Ahmed"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2863-a-deep-dive-into-postgresql-indexing/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10745.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10746",
        "start": "13:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_postgresql_on_k8s_at_zalando_two_years_in_production",
        "title": "PostgreSQL on K8S at Zalando: Two years in production",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Many DBAs avoid any kind of cloud offering and prefer to run their databases on dedicated hardware. At the same time companies demand to run Postgres at scale, efficiently, automated and well integrated into the infrastructure landscape. The arrival of Kubernetes provided good building blocks and an API to interact with and with it solve many problems at the infrastructure level.<\/p>\n\n<p>The database team at Zalando started running highly-available PostgreSQL clusters on Kubernetes more than two years ago. In this talk I am going to share how we automate all routine operations, providing developers with easy-to-use tools to create, manage and monitor their databases, avoiding commercial solutions lock-in and saving costs, show open-source tools we have built to deploy and manage PostgreSQL cluster on Kubernetes by writing short manifests describing a few essential properties of the result.<\/p>\n\n<p>Operating a few hundred PostgreSQL clusters in a containerized environment has also generated observations and learnings which we want to share: infrastructure problems (AWS), how engineers use our Postgres setup and what happens when the load becomes critical.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4155",
            "value": "Alexander Kukushkin"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2957-postgresql-on-k8s-at-zalando-two-years-in-production/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10746.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10747",
        "start": "14:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_an_ultimate_guide_to_upgrading_your_postgresql_installation",
        "title": "An ultimate guide to upgrading your PostgreSQL installation",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Even an experienced PostgreSQL DBA can not always say that upgrading between major versions of Postgres is an easy task, especially if there are some special requirements, such as downtime limitations or if something goes wrong. For less experienced DBAs anything more complex than dump/restore can be frustrating.<\/p>\n\n<p>In this talk I will describe why we need a special procedure to upgrade between major versions, how that can be achieved and what sort of problems can occur. I will review all possible ways to upgrade your cluster from classical pg_upgrade to old-school slony or modern methods like logical replication. For all approaches, I will give a brief explanation how it works (limited by the scope of this talk of course), examples how to perform upgrade and some advice on potentially problematic steps. Besides I will touch upon such topics as integration of upgrade tools and procedures with other software — connection brokers, operating system package managers, automation tools, etc. This talk would not be complete if I do not cover cases when something goes wrong and how to deal with such cases.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4651",
            "value": "Ilya Kosmodemiansky"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2955-an-ultimate-guide-to-upgrading-your-postgresql-installation/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10747.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10748",
        "start": "15:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_the_state_of_full_text_search_in_postgresql_12",
        "title": "The State of (Full) Text Search in PostgreSQL 12",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How to navigate the rich but confusing field of (Full) Text Search in PostgreSQL. A short introduction will explain the concepts involved, followed by a discussion of functions, operators, indexes and collation support in Postgres in relevance to searching for text. Examples of usage will be provided, along with some stats demonstrating the differences.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4095",
            "value": "Jimmy Angelakos"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2890-the-state-of-full-text-search-in-postgresql-12/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10748.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10749",
        "start": "16:00",
        "duration": "00:50",
        "room": "H.2214",
        "slug": "postgresql_rtfm",
        "title": "RTFM",
        "subtitle": [],
        "track": "PostgreSQL",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Reading the manual before starting a new work is always a good practice.<\/p>\n\n<p>However some situations like pressure for delivery or lack of attention may lead to wrong assumptions that cause unpredictable results or even disasters.<\/p>\n\n<p>The talk, in a semi serious way, will walk the audience through some of corner cases caused by the lack of the good practice of RTFM.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5052",
            "value": "Federico Campoli"
          }
        },
        "links":
        [
          {
            "_href": "https://www.postgresql.eu/events/fosdem2020/schedule/session/2849-rtfm/",
            "value": "Schedule"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10749.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "H.3242",
    "event":
    {
      "_id": "10785",
      "start": "15:30",
      "duration": "01:30",
      "room": "H.3242",
      "slug": "bof_ngi_meetup",
      "title": "NGI Meetup",
      "subtitle": "Meetup for Next Generation Internet",
      "track": "BOFs (Track B - in H.3242)",
      "type": "bof",
      "language": [],
      "abstract": "<p>The Next Generation Internet initiative is one of the most substantial efforts in recent years to move the state of technology forward. It consists currently of over 200 projects, ranging from open hardware, middleware, web services, ActivityPub and cryptography to more fair search technology and decentralised internet tools. More projects are being added through open calls regularly. There are over twenty different talks related to this programme at FOSDEM 2020! This Birds of a Feather is for anyone interested in or involved with the Next Generation Internet initiative.<\/p>",
      "description": [],
      "persons":
      {
        "person":
        {
          "_id": "4953",
          "value": "Michiel Leenaars"
        }
      },
      "links":
      [
        {
          "_href": "https://nlnet.nl/discovery",
          "value": "NGI Zero Discovery"
        },
        {
          "_href": "https://nlnet.nl/PET",
          "value": "NGI Zero PET"
        },
        {
          "_href": "https://ngi.eu",
          "value": "NGI Overview website"
        },
        {
          "_href": "https://submission.fosdem.org/feedback/10785.php",
          "value": "Submit feedback"
        }
      ]
    }
  },
  {
    "_name": "H.3244"
  },
  {
    "_name": "J.1.106",
    "event":
    {
      "_id": "10533",
      "start": "11:00",
      "duration": "01:00",
      "room": "J.1.106",
      "slug": "bof_weblate",
      "title": "Weblate meetup",
      "subtitle": "Weblate users meetup",
      "track": "BOFs (Track A - in J.1.106)",
      "type": "bof",
      "language": [],
      "abstract": "<p>Weblate future, features, bugs, collaboration between users and other related topics.<\/p>",
      "description": [],
      "persons":
      {
        "person":
        {
          "_id": "3120",
          "value": "Michal Čihař"
        }
      },
      "links":
      [
        {
          "_href": "https://weblate.org/",
          "value": "Weblate"
        },
        {
          "_href": "https://submission.fosdem.org/feedback/10533.php",
          "value": "Submit feedback"
        }
      ]
    }
  },
  {
    "_name": "AW1.120",
    "event":
    [
      {
        "_id": "10697",
        "start": "09:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_free_software_radio_devroom_introduction",
        "title": "Free Software Radio Devroom Introduction and Hackfest Review",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Greetings and plans for the day and future<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1510",
            "value": "Philip Balister"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10697.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10598",
        "start": "09:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_modernizing_distribution_of_sdr_tools",
        "title": "Modernizing Distribution of SDR Tools and Libraries with Conan",
        "subtitle": "What does cmake have to do with SNR?",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There are so many great open source libraries and tools that people have written that make up the software defined radio ecosystem, but we have unfortunately created a high bar for consumption of this software, and an even higher bar for using modern versions. In this presentation we look at how we can use modern C/C++ package management with Conan to simplify the lives of our users who want to use the latest versions without living in dependency hell.<\/p>",
        "description": "<p>Users of SDR software have spent far too much time staring at cmake builds and wondering what how to get the missing build time dependency.  The package feeds from major distributions contain a lot of the popular software, but they tend to lag development significantly and lock users into specific versions.  If you want to run the latest code you are back to compiling it.  It does not have to be this way.  Using Conan these applications and their dependencies can be managed in a modern way where users can pull binary packages when available and easily rebuild packages when needed all in a sandboxed environment.<\/p>\n\n<p>This talk cover the following points:\n* What is Modern C++ Package Management\n* How this can simplify consumption from a SDR user perspective (I just want to play with my hardware...)\n* Demo of using this workflow with some packaged SDR applications\n* Example of how this packaging works for a library\n* What we can do better as developers to simplify this task<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6110",
            "value": "Brennan Ashton"
          }
        },
        "links":
        [
          {
            "_href": "http://conan.io",
            "value": "Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10598.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10551",
        "start": "10:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "block_header_parsing_tool",
        "title": "Block Header Parsing Tool",
        "subtitle": "Implement a block parsing library",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GNU Radio's value comes from many things, but one of them is a vast library of blocks, both in-tree and out-of-tree. Right now, it is hard to use these blocks in a different context than GNU Radio itself or interface with blocks automatically or programmatically.<\/p>",
        "description": "<p>A python-based tool that can interact with GNU Radio block headers written in C++, to automatically parse them and extract information about them such as which getters/setters they have, their I/O signatures, factory signatures, etc. GRModtool can be extended with the parsing tool as one of its utilities. The parsed information can be further used for creating YAML files for the GRC.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6546",
            "value": "Arpit Gupta"
          }
        },
        "links":
        [
          {
            "_href": "https://headerparser.wordpress.com",
            "value": "Weekly Blog"
          },
          {
            "_href": "https://github.com/aru31/gnuradio/projects/1",
            "value": "Github Project"
          },
          {
            "_href": "https://github.com/gnuradio/gnuradio/pull/2750",
            "value": "Major Pull Request"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10551.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10758",
        "start": "10:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_how_to_evolve_the_gnu_radio_scheduler",
        "title": "How to evolve the GNU Radio scheduler",
        "subtitle": "Embracing and breaking legacy",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GNU Radio is the widest used software radio stack for research and development on PC-style hardware, having enabled hundreds of high-rate applications. I'll discuss where its limits are, where we need to stick to GNU Radio's recipe for SDR success, and where to disruptively address its architectural shortcomings<\/p>",
        "description": "<p>Today's GNU Radio hits hard limits when it comes to a few things that\nare absolutely crucial for modern communication stacks: It doesn't make any\nguarantees on latency, and its architecture doesn't allow for tight integration\nwith hardware accelerators. And whilst most communications are packet-based,\npacketed data is a second-class citizen in the kingdom of sample streams that is\nGNU Radio.<\/p>\n\n<p>In this talk, we'll discuss why that is the case, and what can be remedied\nwithin the current framework, and what not. We'll try to assess what usage\nparadigms are worth keeping for the future of GNU Radio, and what needs to\nchange.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4473",
            "value": "Marcus Müller"
          }
        },
        "links":
        [
          {
            "_href": "https://gnuradio.org",
            "value": "Project Homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10758.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10197",
        "start": "11:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "a_rose_by_any_other_name",
        "title": "A Rose by Any Other Name Would Run Just as Long",
        "subtitle": "Understanding Computational and Hardware Complexity in Software Defined Radio Framework",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Abstract: Radio based communication systems and imagers operate under real-time constraints. Off-loading computes to an FPGA seems like a solution to speeding-up your application but comes with many pitfalls.  Specifically, software-oriented implementations fail to achieve the required interface bandwidths or computational throughput required to see a speed-up.  In this talk, we will discuss the organization of common compute motif's in software-defined-radio and their complexity in time and resources for FPGAs.<\/p>",
        "description": "<p>Rough goals of talk:\n1) Communicate why FPGA acceleration would be attractive\n2) Discuss common pitfalls\n2a) A behaviorally oriented accelerator\n2b) Starving the beast, failing to provide the required data bandwidths\n2c) Processor oriented runtime, creates execution overheads\n3) Thinking about accelerators, what do they look like\n3a) FFT\n3b) Correlators\n3c) Matrix-Vector Multiply\n4) Building an off-load model<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7128",
            "value": "John Brunhaver"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10197.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10103",
        "start": "11:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "gr_satellites_latests_developments",
        "title": "gr-satellites latests developments",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>gr-satellites is a GNU Radio out-of-tree module with the goal of decoding every Amateur satellite. Currently it supports more than 80 different satellites. After GNU Radio 3.8 was released last summer, gr-satellites is seeing a lot of development and important changes. A refactored version, which will be released as gr-satellites 3.0 is on the works. This version brings more modularity to avoid code duplication, more flexibility in the input and output that the user can employ, and the idea to improve its integrability with other tools. Satellites are defined using a YAML file and the GNU Radio flowgraph is constructed on the fly by a Python script by connecting so called \"component\" blocks. Advanced users can also use the components directly in their own flowgraphs. This talk gives an overview of the gr-satellites 3.0 development progress.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7088",
            "value": "Daniel Estévez"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/daniestevez/gr-satellites",
            "value": "gr-satellites Github"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10103.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10125",
        "start": "12:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "r2cloud_decode_satellite_signals_on_raspberry_pi",
        "title": "r2cloud - Decode satellite signals on Raspberry PI",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<ol>\n<li>Java for digital signal processing\n\n<ul>\n<li>why java?<\/li>\n<li>how to do digital signal processing in Java. Some examples<\/li>\n<li>decoding LRPT (with images), BPSK (with real data)<\/li>\n<\/ul>\n<\/li>\n<li> Working base station network\n\n<ul>\n<li>how it differs from satnogs<\/li>\n<li>testing, code coverage. Enterprise approach for building communication software<\/li>\n<\/ul>\n<\/li>\n<li> Plans. Q&amp;A<\/li>\n<\/ol>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7102",
            "value": "Andrey Rodionov"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/dernasherbrezon/r2cloud",
            "value": "r2cloud"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10125.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9307",
        "start": "12:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_platform_independent_cpu_fpga_co_design",
        "title": "Platform independent CPU/FPGA co-design: the OscImp-Digital framework",
        "subtitle": "G. Goavec-Merou, P.-Y. Bourgeois, J.-M. Friedt",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Combining the flexibility of FPGA hardware configuration with the high abstraction level of an operating system running on a general purpose central processing unit (CPU) requires mastering a broad range of knowledge, from low level hardware configuration to kernel drivers to libraries and userspace application. While some vendor specific frameworks tackle the challenge, we focus on a vendor independent solution applicable to current FPGA Systen on Chip providers: the OscImp Digital framework provides a comprehensive set of FPGA IP, associated Linux driver, library and userspace examples based on GNU Radio running on the embedded CPU. We demonstrate its use on the Redpitaya platform processing baseband signals as well as the Zynq, most significantly associated with the AD9363 radiofrequency frontend on the PlutoSDR board. In both cases, the FPGA is not only used to stream I/Q coefficients but pre-process the datastream in order to reduce bandwidth and efficiently feed the CPU: we demonstrate embedded FM broadcast radio reception as well as GPS decoding on the PlutoSDR custom bitstream. The framework is available at https://github.com/oscimp/oscimpDigital<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1813",
            "value": "Jean-Michel Friedt"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/oscimp/oscimpDigital",
            "value": "github repository of the project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9307.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9788",
        "start": "13:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_striving_for_performance_portability",
        "title": "Striving for Performance Portability of Software Radio Software in the Era of Heterogeneous SoCs",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Future heterogeneous DSSoCs will be extraordinarily complex in terms of processors, memory hierarchies, and interconnection networks. To manage this complexity, architects, system software designers, and application developers need design and programming technologies to be flexible, accurate, efficient, and productive. Recently, our team has started to explore the mapping of GnuRadio to various heterogeneous SoCs in order to understand how programming technologies can support this goal of making this SDR framework performance portable. Using our software stack, we are porting several SDR applications to GPUs from NVIDIA, AMD, and ARM, and to NVIDIA Xavier SoCs, Qualcomm Snapdragon, and Xilinx Zynq devices. Our current approach uses a directive-based programming model and a new intelligent runtime scheduler to port and execute the workflows. We are evaluating several open programming models to enable performance portability; initially, they include directive-based compilers, OpenCL, and SYCL. All of these approaches will generate tasks that are then queued and scheduled by our open-source intelligent runtime scheduler, which is a critical component of our approach. Initial performance results appear promising; however, more automation will further broad deployment. Also, we have developed a host of tools to examine and profile SDR workflows and modules. Specifically, these analysis tools enable automated characterization of the behavioral and computational features of GNU Radio blocks and workflows. The static tools in GR-tools help developers to create ontologies and queries to classify GR modules based on custom scenarios. The dynamic toolset provides automated profiling capabilities of GR workflows and presents detailed statistics on how components in a given software defined radio application perform. GR-tools also produces a graph-based representation of the analyzed data and provides powerful visualization options to filter and display the information obtained from the static and dynamic tools. Our software is available as open-source software and will be made available to the community.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6848",
            "value": "Jeffrey Vetter"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9788.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10566",
        "start": "13:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_cooperative_perception_in_future_cars_using_gnu_radio",
        "title": "Cooperative Perception in Future Cars using GNU Radio",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Title: Cooperative Perception in Future Cars using GNU Radio<\/p>\n\n<p>Speaker: Augusto Vega, IBM Research (NY, USA)<\/p>\n\n<p>Abstract:\nThe phenomenon of self-driving (autonomous) vehicles is a symbol of the grand re-emergence of artificial intelligence and robotics as a promising technology. The most general model of future vehicular transportation is that of artificially intelligent, connected, autonomous vehicles (CAVs) [1].<\/p>\n\n<p>In this talk, we present a representative open-source application for CAVs operating as a collaborative swarm and communicating via GNU Radio. The application, called ERA [2], incorporates local sensing, creation of occupancy grid maps, vehicle-to-vehicle (V2V) communication of grid maps between neighboring vehicles using GNU Radio-based dedicated short-range communication (DSRC), and map fusion to create a joint higher-accuracy grid map [3]. Specifically, each vehicle in ERA uses its onboard sensors to generate local occupancy grid maps, which it communicates to other nearby vehicles using DSRC. When a vehicle receives occupancy maps from nearby cars, it merges the received ones with the locally-generated occupancy maps, expanding the scope and increasing the accuracy of this vehicle's perception. The DSRC transceiver adopted in ERA is an open-source GNU Radio implementation of the IEEE 802.11p standard by Bastian Bloessl [4]; while perception and map creation is implemented using ROS (Robot Operating System) [5]. We created an appropriate software interface between GNU Radio and ROS which enables proper execution and interaction of both frameworks.<\/p>\n\n<p>In addition to presenting a deep dive into ERA's code, we will also show performance analysis results of ERA (including its GNU Radio components) and discuss potential acceleration opportunities for performance and efficiency improvement -- including optimizations of Viterbi decoding and complex exponential through hardware acceleration. We believe that ERA can help to fill the gap between the fast-growing CAV R&amp;D domain and GNU Radio, specifically when it comes to the wireless communication aspect of future vehicles.<\/p>\n\n<p>[1] A. Vega, A. Buyuktosunoglu, P. Bose, “Towards \"Smarter\" Vehicles Through Cloud-Backed Swarm Cognition,” Intelligent Vehicles Symposium 2018: 1079-1086.<\/p>\n\n<p>[2] ERA. URL: https://github.com/IBM/era<\/p>\n\n<p>[3] E. Sisbot, A. Vega, A. Paidimarri, J. Wellman, A. Buyuktosunoglu, P. Bose, D. Trilla, “Multi-Vehicle Map Fusion using GNU Radio,” Proceedings of The GNU Radio Conference 2019, 4(1).<\/p>\n\n<p>[4] B. Bloessl, “IEEE 802.11 a/g/p transceiver for GNU radio,” URL: https://github.com/bastibl/gr-ieee802-11<\/p>\n\n<p>[5] ROS. URL: https://www.ros.org<\/p>\n\n<p>Desired slot time: 30 mins<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7179",
            "value": "Augusto Vega"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/IBM/era",
            "value": "ERA"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10566.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10583",
        "start": "14:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_srslte_project_update",
        "title": "srsLTE project update",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1833",
            "value": "Andre Puschmann"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10583.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10162",
        "start": "14:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_hannel_equalization_using_gnu_radio",
        "title": "Channel Equalization using GNU Radio",
        "subtitle": "compensating for impairments in the wireless channel, and extensions to existing GNU Radio functionality",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We examine the use of equalizers in wireless communication systems, how these are implemented in GNU Radio, and how the existing GR equalizer functionality can be extended with a new OOT using training-based adaptation.  The theory of multipath channels, ISI, and how to overcome with adaptive equalization will be reviewed and shown with interactive flowgraphs.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7100",
            "value": "Josh Morman"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10162.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10567",
        "start": "15:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_task_scheduling_of_software_defined_radio_kernels",
        "title": "Task Scheduling of Software-Defined Radio Kernels in Heterogeneous Chips: Opportunities and Challenges",
        "subtitle": [],
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Title: Task Scheduling of Software-Defined Radio Kernels in Heterogeneous Chips: Opportunities and Challenges<\/p>\n\n<p>Speaker: Augusto Vega, IBM Research (NY, USA)<\/p>\n\n<p>Abstract:\nThe proliferation of 'heterogeneous' chip multiprocessors in recent years has reached unprecedented levels, especially in the context of IoT and distributed edge computing (e.g. connected and autonomous vehicles). By combining the right set of hardware resources (cores, accelerators, chip interconnects and memory technology) along with an adequate software stack (operating system and programming interface), heterogeneous chips have become an effective high-performance and low-power computing alternative.<\/p>\n\n<p>However, heterogeneous architectures come with new challenges. Fundamentally, the complexity derived from the design's heterogeneous nature challenges the effective scheduling of tasks (processes), a scenario that becomes even more critical when real-time execution deadlines must be met. This is particularly important in the context of GNU Radio, given that its underlying scheduler is completely unaware of chip heterogeneity today. Early stage prototyping and evaluation of GNU Radio scheduling policies in heterogeneous platforms becomes a valuable asset in the design process of a future GNU Radio scheduler.<\/p>\n\n<p>In this talk, we present a new open-source simulator for fast prototyping of task scheduling policies, called STOMP (Scheduling Techniques Optimization in heterogeneous Multi-Processors) [1]. It is written in Python and implemented as a queue-based discrete-event simulator with a convenient interface that allows users and researchers to \"plug in\" new scheduling policies in a simple manner. We also present a systematic approach to task scheduling in heterogeneous platforms through the evaluation of a set of progressively more \"intelligent\" scheduling policies using STOMP. We rely on synthetic kernels representative of a GNU Radio application [2], including functions like Viterbi decoding and fast Fourier transform (FFT) that have to be scheduled across general-purpose cores, GPUs or hardware accelerators to meet the application's real-time deadlines. We will show results indicating that relatively simple scheduling policies can satisfy real-time requirements when they are properly designed to take advantage of the heterogeneous nature of the underlying chip multiprocessor.<\/p>\n\n<p>[1] STOMP. URL: https://github.com/IBM/stomp\n[2] ERA. URL: https://github.com/IBM/era<\/p>\n\n<p>Desired slot time: 30 mins<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7179",
            "value": "Augusto Vega"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/IBM/stomp",
            "value": "STOMP"
          },
          {
            "_href": "https://github.com/IBM/era",
            "value": "ERA"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10567.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10496",
        "start": "15:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_iot_device_fingerprinting_and_localization",
        "title": "SDR4IoT - Using SDR for IoT Device Fingerprinting and Localization",
        "subtitle": "A project part of the FED4FIRE+ Open Calls",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will present the result of our experimentation done at i.Lab Wireless Testbed in Ghent, in the context of <a href=\"https://www.fed4fire.eu/\">FED4Fire+ H2020 project<\/a>. Our project aims to collect raw radio frequency (RF) signals of widely used radio protocols for Internet of Things (IoT) devices in the 2.4GHz ISM bandwidth, such as Bluetooth Low Energy and LoRa, using software-defined radio (SDR).\nThis will allow us collecting a large, reliable and reproducible dataset of RF fingerprint. This dataset will be further used to develop deep learning algorithms for IoT device fingerprinting and localization. Our use case is the authentication of autonomous vehicles or robots in a building according to their localization, without any over-the-air key exchange algorithm.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6682",
            "value": "Alexis DUQUE"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10496.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9337",
        "start": "16:00",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_openwifi",
        "title": "openwifi",
        "subtitle": "Opensource \"Wi-Fi chip design\" and Linux driver",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An open source \"Wi-Fi chip design\"(Will be AGPLv3) will be presented and a live demo will be shown in the room! The design is based on SDR (Software Defined Radio) and offers full-stack 802.11a/g/n capabilities on FPGA and ARM Linux (Xilinx Zynq SoC + AD9361 RF front-end).It conforms with Linux mac80211 framework and behaves just like COTS Wi-Fi chip under Linux. The main components of the design are: RF front-end control; PHY; low-MAC; interfacing (DMA, register) with ARM; mac80211 compliant Linux driver; high-MAC (mac80211 framework); Linux user space tools (ifconfig, iwconfig, dedicated tools via netlink).​ Since it is a SDR based \"white box\" design instead of commercial “black box” chip, you can do Wi-Fi research and customization without any reverse engineering efforts.<\/p>\n\n<p>Why does it fit FOSDEM?<\/p>\n\n<p>It will be the 1st open source project for full-stack Wi-Fi SDR implementation. Lots of people, especially wireless network/security researchers, SDR researchers and hackers, will be interested in. We are eager to show the demo in the room and hear feedback from people/community. Potential contributors are also very welcomed, and we will be glad to offer help.<\/p>",
        "description": "<p>Overall architecture: Please find attachment.<\/p>\n\n<p>Features:<\/p>\n\n<ul>\n<li>802.11a/g; 802.11n MCS 0~7; 20MHz<\/li>\n<li>Mode: Ad-hoc; Station; AP<\/li>\n<li>DCF (CSMA/CA) low MAC layer in FPGA<\/li>\n<li>Configurable channel access priority parameters:<\/li>\n<li>duration of RTS/CTS, CTS-to-self<\/li>\n<li>SIFS/DIFS/xIFS/slot-time/CW/etc<\/li>\n<li>Time slicing based on MAC address<\/li>\n<li>Easy to change bandwidth and frequency:<\/li>\n<li>2MHz for 802.11ah in sub-GHz<\/li>\n<li>10MHz for 802.11p/vehicle in 5.9GHz<\/li>\n<li>On roadmap: 802.11ax<\/li>\n<\/ul>\n\n\n<p>Supported SDR platforms:<\/p>\n\n<ul>\n<li>zc706 (Xilinx) + fmcomms2 (Analog Devices)<\/li>\n<li>On roadmap: ADRV9361-Z7035/ADRV9364-Z7020 + ADRV1CRR-BOB (Analog Devices)<\/li>\n<li>On roadmap: zcu102 (Xilinx) + fmcomms2/ADRV9371 (Analog Devices)<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6450",
            "value": "Xianjun Jiao"
          }
        },
        "links":
        [
          {
            "_href": "https://europe.wirelessinnovation.org/2019-showcase-demonstrations",
            "value": "demo in WinnComm"
          },
          {
            "_href": "https://www.orca-project.eu/orca-presence-at-the-eucnc-2019/",
            "value": "demo in EuCnC"
          },
          {
            "_href": "https://github.com/open-sdr/openwifi",
            "value": "will be open source here"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9337.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9308",
        "start": "16:30",
        "duration": "00:30",
        "room": "AW1.120",
        "slug": "fsr_software_defined_radio_based_scientific_instrumentation",
        "title": "Software Defined Radio based scientific instrumentation",
        "subtitle": "using SDR frontends and oscilloscopes for fast measurements",
        "track": "Free Software Radio",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Software Defined Radio is best known for receiving and processing radiofrequency signals transmitted over the ether. However, many scientific experiments benefit from the flexibility, stability and reconfigurability of digital signal processing even when handling radiofrequency signals. In this presentation, we address two demonstrations of this concept. First, readily available SDR hardware is used to replace general purpose laboratory instruments (spectrum analyzer, lock in amplifier)\nfor characterizing radiofrequency processing acoustic transducers (filters, resonators). The benefit of SDR lies in communication bandwidth: while general purpose\ninstrument communication protocols (GPIB, VXI11 over Ethernet) require hundreds of milliseconds or seconds to transfer data, SDR platforms stream at high bandwidth I/Q coefficients collected on the fly on a ZeroMQ socket by the (GNU/Octave) processing software. We demonstrate a 10000 fold bandwidth gain when converting a general purpose instrument experiment to a SDR approach. Another approach is to address high bandwidth radiofrequency oscilloscopes as radiofrequency source for time of flight measurement. The gr-oscilloscope GNU Radio source demonstrates how to communicate between GNU Radio and laboratory grade equipment, here oscilloscopes, for processing discontinuous data streams using GNU Radio.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1813",
            "value": "Jean-Michel Friedt"
          }
        },
        "links":
        [
          {
            "_href": "http://jmfriedt.free.fr/gr_oscilloscope.pdf",
            "value": "article [in French]"
          },
          {
            "_href": "https://github.com/jmfriedt/gr-oscilloscope38",
            "value": "github repository (GNU Radio 3.8)"
          },
          {
            "_href": "https://www.rtl-sdr.com/gr-oscilloscope-using-an-oscilloscope-as-a-software-defined-radio/",
            "value": "rtl-sdr.com report"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9308.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "AW1.121",
    "event":
    [
      {
        "_id": "10595",
        "start": "09:00",
        "duration": "00:05",
        "room": "AW1.121",
        "slug": "welcome_bsd_devroom",
        "title": "Welcome to the BSD devroom",
        "subtitle": [],
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the BSD devroom<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2366",
            "value": "Rodrigo Osorio"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10595.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9699",
        "start": "09:10",
        "duration": "00:45",
        "room": "AW1.121",
        "slug": "orchestrating_jails",
        "title": "Orchestrating jails with nomad and pot",
        "subtitle": "A container-based cloud computing platform for FreeBSD",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Docker and Kubernetes are changing the way to deploy services and applications in the Linux world.\nWhat about FreeBSD?\n2 years ago we presented pot, another jail abstraction framework. In time, the pot framework has developed to provide features containers-alike.\nThe plugin interface provided by nomad (a container orchestrator), allowed us to develop a driver for pot, enabling nomad to orchestrate pot jails.\nIn this talk, we'd like to present this FreeBSD-based ambitious alternative to Docker-Kubernetes<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5023",
            "value": "Luca Pizzamiglio"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9699.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9090",
        "start": "10:00",
        "duration": "01:00",
        "room": "AW1.121",
        "slug": "opensmtpd_in_the_cloud",
        "title": "OpenSMTPD over the clouds",
        "subtitle": "the story of an HA setup",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>OpenSMTPD has gained filters support in its latest version and it is a now an smtp server that can compete with other better known mail servers and can be used to handle both incoming and outgoing mail flows in a secure way.\nIts simple configuration and its \"secure by design\" approach makes it one of the best candidates for a mail server software.<\/p>",
        "description": "<p>Now that OpenSMTPD has gained filter support it can be used as a mail server with all features of other email servers.\nThis is the story of how OpenSMTPD can be setup in an high availability environment and how other OpenBSD tools can be used to achieve the goal.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5424",
            "value": "Giovanni Bechis"
          }
        },
        "links":
        [
          {
            "_href": "https://opensmtpd.org/",
            "value": "OpenSMTPD home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9090.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10082",
        "start": "11:05",
        "duration": "00:30",
        "room": "AW1.121",
        "slug": "netbsd_not_just_for_toasters",
        "title": "NetBSD - Not Just For Toasters",
        "subtitle": [],
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NetBSD may seem like an exotic choice for an operating system. But it is actually a decent desktop OS for developers and a rock-solid server OS, in the cloud as well as on old hardware. Come for the freedom from systemd, stay for the great packages, modern features and enthusiastic community!<\/p>",
        "description": "<p>In this talk, I will give reasons why adopting NetBSD makes sense, show some cool hardware that you can run NetBSD on, and talk about new features in the upcoming NetBSD 9 release.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "848",
            "value": "Benny Siegert"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10082.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10139",
        "start": "11:40",
        "duration": "00:40",
        "room": "AW1.121",
        "slug": "freebsd_around_the_world",
        "title": "FreeBSD Around the World!",
        "subtitle": [],
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The FreeBSD Foundation has been supporting the FreeBSD Project and community for 20 years! In this talk, I'm going to share a little history of FreeBSD and the Foundation, how the Project works, and why you should get involved. I'll continue to share how the Foundation has been advocating for FreeBSD around the world, and what you can do to help bring on new users and contributors. Finally, I'll cover significant projects we are supporting to keep FreeBSD relevant, stable, and secure.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5127",
            "value": "Deb Goodkin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10139.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9106",
        "start": "12:25",
        "duration": "00:40",
        "room": "AW1.121",
        "slug": "freebsd_llvm_support",
        "title": "FreeBSD and LLVM support",
        "subtitle": "What is LLVM all about and how it integrates FreeBSD system",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We will explain what is LLVM project all about and how central it is under the FreeBSD operating system, as it serves to basically build it ; first we ll go through its major components and what is supported..<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6487",
            "value": "David Carlier"
          }
        },
        "links":
        [
          {
            "_href": "http://www.llvm.org",
            "value": "Main website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9106.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9383",
        "start": "13:10",
        "duration": "01:00",
        "room": "AW1.121",
        "slug": "fuzzing_bsd_kernel",
        "title": "Break your BSD kernel",
        "subtitle": "Fuzzing BSD kernel",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Fuzzing is an efficient technique to find bugs and vulnerabilities in the software.\nTodays BSD based operating systems allows using such techniques to test the kernel code easily.\nThis talk is designated to be a starting point for everyone who would like to start his journey with fuzzing his BSD kernel as well provide all necessary information needed.<\/p>",
        "description": "<p>The kernel is a central part of most of the modern operating systems. This place where hardware meets software controls main subsystems like Networking Stack (and other communication stacks), File Systems, Security and many other.\nDue to this fact security of overall system relay on the safety of the kernel.\nOne of the well-proven techniques to test software security is fuzzing.\nFor the last couple of years, researchers found a long list of vulnerabilities in many popular Open Source projects thanks to the efficiency of this technique.\nKernel fuzzing was always more complicated than userspace programs. Nevertheless, that is constantly improving and today's entry barrier is much lower than it used to be, thanks to the improvement made in recent years.\nFor the last couple of years, NetBSD became strong with new security features in the BSD world, as Sanitizers or Fuzzers.\nDue to the work of the community, it grew to an attractive target for people interested in operating systems and security.\nFuzzing can be also a very beneficial technique for kernel and drivers developers who want to improve or test the security of their code.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6684",
            "value": "Maciej Grochowski"
          }
        },
        "links":
        [
          {
            "_href": "https://2019.eurobsdcon.org/slides/Fuzzing%20Filesystems%20on%20NetBSD%20via%20AFL+KCOV%20-%20Maciej%20Grochowski.pdf",
            "value": "EuroBSD presentation about AFL+KCOV"
          },
          {
            "_href": "https://blog.netbsd.org/tnf/entry/write_your_own_fuzzer_for",
            "value": "https://blog.netbsd.org/tnf/entry/write_your_own_fuzzer_for"
          },
          {
            "_href": "https://blog.netbsd.org/tnf/entry/fuzzing_netbsd_filesystems_via_afl",
            "value": "https://blog.netbsd.org/tnf/entry/fuzzing_netbsd_filesystems_via_afl"
          },
          {
            "_href": "https://www.meetbsd.com/wp-content/uploads/MeetBSD_2018_Kamil_Rytarowski-MKSANITIZER.pdf",
            "value": "https://www.meetbsd.com/wp-content/uploads/MeetBSD_2018_Kamil_Rytarowski-MKSANITIZER.pdf"
          },
          {
            "_href": "http://netbsd.org/~kamil/eurobsdcon2019_fuzzing/presentation.html#slide1",
            "value": "http://netbsd.org/~kamil/eurobsdcon2019_fuzzing/presentation.html#slide1"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9383.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10087",
        "start": "14:15",
        "duration": "00:15",
        "room": "AW1.121",
        "slug": "kde_on_freebsd",
        "title": "KDE on FreeBSD",
        "subtitle": [],
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The state of KDE (the Plasma desktop and applications) on FreeBSD, what works, what needs better support lower in the stack. How do we get rid of HAL?<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7084",
            "value": "Adriaan de Groot"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10087.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10095",
        "start": "14:35",
        "duration": "00:45",
        "room": "AW1.121",
        "slug": "netbsd_audio",
        "title": "NetBSD audio - a userland perspective",
        "subtitle": "Discussing the usage of NetBSD's audio API in third party software",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NetBSD has a rather interesting and unique native audio API, distinct from OSS, inherited from an early version of the Solaris API with extensions and improvements made over the years.<\/p>\n\n<p>In this talk, Nia describes the advantages of using NetBSD's native audio API in comparison to other alternatives, and discusses her improvements to third-party software to encourage usage and adoption of the API.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7086",
            "value": "Nia Alarie"
          }
        },
        "links":
        [
          {
            "_href": "https://netbsd.org/gallery/presentations/nia/netbsd-audio/",
            "value": "Original pkgsrcCon presentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10095.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9717",
        "start": "15:25",
        "duration": "00:30",
        "room": "AW1.121",
        "slug": "porting_wayland",
        "title": "X11 and Wayland: A tale of two implementations",
        "subtitle": "Implementing the hikari window manager/compositor",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I will outline my journey implementing my X11 window manager\n<code>hikari<\/code> and the corresponding Wayland compositor shortly after. <code>hikari<\/code> is a\nstacking window manager/compositor with some tiling capabilities. It is still\nmore or less work in progress and currently targets FreeBSD only but will be\nported to Linux and other operating systems supporting Wayland once it has\nreached some degree of stability and feature completeness.<\/p>",
        "description": "<p>This talk covers:<\/p>\n\n<ul>\n<li>a brief explanation regarding differences between X and Wayland<\/li>\n<li>some of <code>hikari<\/code>'s design goals and motivation<\/li>\n<li>choice of programming language<\/li>\n<li>an overview of libraries that were used<\/li>\n<li>tools for ensuring code quality and robustness<\/li>\n<li>obstacles<\/li>\n<li>resources that helped me to implement the whole thing<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6917",
            "value": "raichoo"
          }
        },
        "links":
        [
          {
            "_href": "https://hub.darcs.net/raichoo/hikari",
            "value": "Hikari - Window Manager"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9717.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9815",
        "start": "16:00",
        "duration": "01:00",
        "room": "AW1.121",
        "slug": "freebsd_prometheus",
        "title": "Graphing FreeBSD disk utilization with Prometheus",
        "subtitle": "Writing a Prometheus gstat_exporter",
        "track": "BSD",
        "type": "devroom",
        "language": [],
        "abstract": "<p>All in a days work: How to write a Prometheus gstat_exporter and integrate it in a Grafana Dashboard<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6956",
            "value": "Thomas Steen Rasmussen"
          }
        },
        "links":
        [
          {
            "_href": "https://blog.tyk.nu/blog/all-in-a-days-work-prometheus-gstat_exporter-and-grafana-dashboard/",
            "value": "Blog post"
          },
          {
            "_href": "https://github.com/tykling/gstat_exporter",
            "value": "Github repo"
          },
          {
            "_href": "https://grafana.com/grafana/dashboards/11223",
            "value": "Grafana dashboard"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9815.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "AW1.125",
    "event":
    [
      {
        "_id": "9921",
        "start": "09:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "racket_poetry",
        "title": "Making poetry with Racket",
        "subtitle": "Come and see how to make Poems that are also Code!",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Racket allows us to create languages on the fly. It's extremely practical for making DSLs (domain specific languages), but can it also be used to make art?\nThat's what we'll see in this talk, making (executable) poetry with Racket!<\/p>",
        "description": "<p>I've always been fascinated by languages, may it be programming languages, \"natural\" , or constructed ones.\nThe way streams of words convey meaning, information, requests, but also emotions, thoughts, feelings, stories, mood...\nHumans have been using languages for thousands of years. It's one of our most important creation and the one we use the most.\nFor a long time, we only had two sorts of language: natural and constructed. But since the invention of computing, and the concept of \"software\", we now have third sort: programming languages.\nWe've been writing programming languages for a century now, but, can we consider programming languages to be languages human could also talk with?\nCan we consider making art with them? Poetry?\nLet's try out using the wonderful language forge that is Racket, and see if we can learn something on the way, and have fun!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5616",
            "value": "Jérôme Martin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9921.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9678",
        "start": "09:50",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "mgmtconfigmore",
        "title": "A small, FRP DSL for distributed systems",
        "subtitle": "Mgmt Config: More about our language",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Mgmt is a next gen config management tool that takes a fresh look at existing automation problems.\nThe tool has two main parts: the engine, and the language.\nThis presentation will have a large number of demos of the language.\nThe language is a minimalistic, functional, reactive DSL.\nIt was designed to both constrain the user with safe types, and no core looping constructs, but also to empower the user to build powerful real-time distributed systems.\nThis year we will expand on last years talk by showing more of the core language features like classes, functions, closures and more!\nFinally we'll talk about some of the future designs we're planning and make it easy for new users to get involved and help shape the project.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2026",
            "value": "James Shubin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/purpleidea/mgmt/",
            "value": "project homepage"
          },
          {
            "_href": "https://twitter.com/mgmtconfig",
            "value": "twitter homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9678.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9147",
        "start": "10:10",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "xllang",
        "title": "XL, an extensible programming language",
        "subtitle": "A language that grows with Moore's law instead of being killed by it",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>XL is an extensible programming language, designed to grow with Moore's law instead of being killed by it.\nExtensible means that programmers can add features and notations much like they would add functions or classes in existing languages.\nThe mechanisms are based on meta-programming, and are a bit similar to the macros that gave Lisp its longevity, but with interesting twists.\nAs a proof of this extensibility, basic arithmetic (addition, multiplication, etc) or control statements (if-then-else, loops, etc) are implemented by libraries in XL, yet offer similar performance and usability as built-in features in C++.\nAnother validation of the extensibility is Tao3D, an XL-based interactive graphic language that will be used to give the presentation.<\/p>",
        "description": "<p>XL is an extensible programming language, designed to grow with Moore's law instead of being killed by it. Every 5 year or so, a major paradigm arrives, that makes earlier languages obsolete. Past examples include object-oriented programming, distributed programming or application extension languages. The inability of classical programming languages to integrate such changes also leads to a number of niche languages implementing minority paradigms, ranging from Prolog to make to yaml.<\/p>\n\n<p>Extensible in XL means that programmers can add features and notations much like they would add functions or classes in existing languages. XL is quite minimalist, since all this is done using a single operator written \"is\".\nThis operator can be used to define variable (<code>X is 0<\/code>), functions (<code>is_even X is X mod 2 = 0<\/code>), multi-operator expressions (<code>X in Y..Z is X &gt;= Y and X &lt; Z<\/code>), or programming constructs. Loops are defined in XL as follows:<\/p>\n\n<pre><code>loop Body is\n    Body\n    loop Body\n<\/code><\/pre>\n\n<p>This extensibility mechanisms is therefore based on meta-programming, and are in that way similar to the macros that gave Lisp its longevity. Lisp was first to normalize object-oriented programming with CLOS. But XL has interesting twists.\nFor starters, there is a strong focus on making notations match concepts. For example, XL will let you write (<code>1 + 2 * 3<\/code>) or program if statements that look normal. This is actually important.<\/p>\n\n<p>This talk will give three proofs of this extensibility:<\/p>\n\n<ul>\n<li>The standard library of XL provides things that have to be put in the compiler in other languages, like basic arithmetic (addition, multiplication, etc), basic control statements (if-then-else, while loops, etc), the module system, and so on. The compiler is actually in the library (or rather, it will be, one day).<\/li>\n<li>The Tao3D language turned XL into a functional reactive 3D document description language. That would have been a stretch for C, and maybe even for Lisp, for reasons that will be discussed.<\/li>\n<li>ELIoT, later renamed ELFE, and now integrated in trunk XL, turned XL into a distributed language, where you write one program and it executes on several machines, dispatching code around and exchanging data transparently.<\/li>\n<\/ul>\n\n\n<p>Tao3D will actually be used to give the presentation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5672",
            "value": "Christophe de Dinechin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/c3d/xl",
            "value": "Main web site for the language"
          },
          {
            "_href": "http://tao3d.sourceforge.net",
            "value": "Web site for XL-derived Tao3D language"
          },
          {
            "_href": "http://https://github.com/c3d/elfe",
            "value": "ELFE, an XL-derived language featuring distributed programming"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9147.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10224",
        "start": "10:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "forth_new_synthesis",
        "title": "Forth - The New Synthesis",
        "subtitle": "Growing Forth with preForth and seedForth",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The \"new synthesis\" of Forth is an ongoing effort in spirit of the Forth Modification Laboratory workshops. Its aim is to identify the essentials of Forth and to combine them in a new way to build systems that can scale-down as Forth always did\nand can scale-up to large applications and development projects.<\/p>\n\n<p>The new synthesis is guided by the two principles biological analogy and disaggregation.<\/p>\n\n<p>We scrutinize many aspects of traditional and modern Forth implementations trying to separate techniques that are normally deeply intertwined. After isolating the techniques we thrive to combine them in new ways.<\/p>\n\n<p>The talk describes two mile stones of the ongoing project:<\/p>\n\n<ul>\n<li><p>preForth (&lt; 500 LOCs) a minimalistic non-interactive Forth kernel that can bootstrap itself and can be used as an easy-to-port basis for a full Forth implementation or implementing other programming languages. It is an open ended language that inherits functionality from the target platform's development tools.<\/p><\/li>\n<li><p>seedForth (&lt;500 LOCs) a minimal stack based extensible programming system accepting tokenized source code. seedForth can be extended in various ways: as stand alone applications, as fully interactive systems, as umbilical target system for embedded system's programming<\/p><\/li>\n<\/ul>\n\n\n<p>We try to use Forth wherever possible in order to minimize semantic and formalism mismatches. Everything should be readily available - no hidden secrets.<\/p>\n\n<p>Of course many of the subjects we are looking at have been used by others in the Forth community and outside - we are dwarfs standing on the shoulders of giants - however we believe our new synthesis to be original.<\/p>",
        "description": "<p>Our findings in the new synthesis so far can be summarized:<\/p>\n\n<ul>\n<li><p>high level inner interpreter (EuroForth 2016, [1]) We showed that a traditional Forth indirect threaded code virtual machine can implemented in high level Forth bringing threaded code manipulation tricks to any Forth implementations.<\/p><\/li>\n<li><p>stacks for structured data (Forth Tagung (convention) 2017, german. [2]) Stores and handles structured items (strings, queues, lists, stacks) on stack and return stack. No memory required.\nShows how terminal input and number output can work without random accessible memory.<\/p><\/li>\n<li><p>handler based outer interpreter (EuroForth 2017, [3]) This demonstrates a very simple modular architecture for the Forth text interpreter separating interpretation and compilation\nactions for parsed tokens by handlers that possible consume and process a token text or pass it on unprocessed.<\/p><\/li>\n<li><p>preForth, simpleForth, Forth (Forth Tagung (convention) 2018, german, [4]) Presents preForth, a minimalistic non-interactive Forth kernel that can bootstrap itself, simpleForth, still non-interactive, which adds memory and control structures and \\textsf{Forth} a simple interactive Forth bootstrapped from preForth/simpleForth. See below for details.<\/p><\/li>\n<li><p>String Descriptors (EuroForth 2018, [5]) We revise different Forth string manipulation facilities and present string descriptors, an intermediate string representation balancing utility and ease of implementation.<\/p><\/li>\n<li><p>Regex (part of string descriptors paper, EuroForth 2018, [5]) Presents a simple implementation of regular expressions extended for Forth's demand to detect space separated tokens and intended to be used in the token detection part of handler based outer interpreters.<\/p><\/li>\n<li><p>seedForth  a minimal stack based extensible programming system accepting tokenized source code. seedForth can be extended in various ways (EuroForth 2018 [6]).<\/p><\/li>\n<\/ul>\n\n\n<p>This talk will go into the details of preForth and seedForth and will how the source code tokenizing works as well as how to extend seedForth to become a modern interactive yet minimal programming environment (&lt;1000 LOCs).<\/p>\n\n<p>References<\/p>\n\n<p>[1] Implementing the Forth Inner Interpreter in High Level Forth,\\newline Ulrich Hoffmann, EuroForth Conference 2016, Reichenau, 2016\n[2] Stack of Stacks,\\newline Ulrich Hoffmann, Forth Tagung 2017, Karlkar, 2017\n[3] A Recognizer Influenced Handler Based Outer Interpreter Structure,\\newline EuroForth 2017, Bad Vöslau, 2017\n[4] Bootstrapping Forth,\\newline Forth Tagung 2018, Linux Hotel,\\newline Essen, 2018\n[5] A descriptor based approach to Forth strings,\\newline Andrew Read and Ulrich Hoffmann, EuroForth conference, Edinburgh, 2018\n[6] String descriptors on GitHub\\newline \\url{https://github.com/Anding/descriptor-based-strings}\n[7] preForth and seedForth on GitHub\\newline \\url{https://github.com/uho/preForth}<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7149",
            "value": "Ulrich Hoffmann"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/uho/preforth",
            "value": "preForth home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10224.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9439",
        "start": "10:50",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "pharominimalreflectivelang",
        "title": "A minimal pur object-oriented reflective language",
        "subtitle": "A minimal pur object-oriented reflective language",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Pharo is a minimalist reflective dynamically typed object-oriented language. Pharo is inspired from Smalltalk: Its full syntax fits on a postcard.\nIts model is simple: everything is an object instance of a class, methods are all public virtual, attributes are first class objects and are protected. There is single inheritance and\ntraits. And nothing else! (see <a href=\"http://mooc.pharo.org\">http://mooc.pharo.org<\/a>). Still Pharo is a real language that is started to be used in industry <a href=\"http://pharo.org/success\">http://pharo.org/success<\/a> and <a href=\"http://consortium.pharo.org\">http://consortium.pharo.org<\/a>. The entire Pharo stack is MIT.\nPharo reflective core is bootstrapped from source code.  Experiences shows that we can have down to 11k (adding 2 smallint) and that a simple web app can be\ntrim down to 500 kb.<\/p>",
        "description": "<p>In this talk I will present Pharo in a nutshell: Syntax, model, but also user stories.\nI will show the vision of the project and where we want to go. I will present some key architectural choices.\nI will show some powerful features such as stack on the fly reification and their application: contextual breakpoint, on the fly program transformation.<\/p>\n\n<p>Bio: I'm one of the core developer of Pharo, head of the consortium and helping consortium engineers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6732",
            "value": "Stephane Ducasse"
          }
        },
        "links":
        [
          {
            "_href": "http://pharo.org",
            "value": "http://pharo.org"
          },
          {
            "_href": "http://stephane.ducasse.free.fr",
            "value": "http://stephane.ducasse.free.fr"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9439.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9443",
        "start": "11:10",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "pharominimalrefllangkernels",
        "title": "Bootstrapping minimal reflective language kernels",
        "subtitle": "Bootstrapping minimal reflective language kernels",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, we present a series of tools to bootstrapping smaller crafted kernel languages.\nSmaller kernels allow us to run applications in resources limited environments (IoT).\nAlso, it allows us to modify and study language modifications and extensions easing the evolution of new and existing languages.\nThese experiments are performed in a fully debuggable simulated environment, allowing us to overcome common mistakes and problems.\nThis is not only an experimental environment as it allows us to generate production-ready language kernels.<\/p>\n\n<p>We use Pharo to generate language kernels that are intended to run on top of the Pharo VM.\nThese tools are also used to bootstrap bigger systems as Pharo itself.<\/p>",
        "description": "<p>The current explosion of embedded systems (i.e., IoT, Edge Computing) implies the need for generating tailored and customized software for them. Different approaches have been taken for building, deploying, updating and debugging these systems, although there is still no standard way to do this.\nThe goal of this talk is to present the tools and techniques necessary for building, debugging, and deploying custom small language kernels.<\/p>\n\n<p>Kernel languages are generated from a combination of language definition and the description of the elements and processes to generate the runtime.\nKernel languages must be consistent internally and in relation with the environment where they run (e.g. the VM, the OS)\nLanguages that are bootstrapped from their source code are not new.\nHowever, correctly defining a working consistent language kernel is a complex manual task without support from tools to debug or test before the generation of the language and its deployment.\nThis complexity limits the study of new languages, the creation of prototypes and the evolution of existing ones.<\/p>\n\n<p>We present a set of tools to overcome the different difficulties that bootstrapping a reflective language kernel presents. Allowing us to simulate the kernel, debug it, validate it and generate it.\nMoreover, our proposed approach offers tools to detect many common mistakes and causes of error.<\/p>\n\n<p>We center our solution in reflective object-oriented languages that run on top of a VM.\nOur tool uses Pharo and generates languages to run on top of its VM.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6734",
            "value": "Pablo Tesone"
          }
        },
        "links":
        [
          {
            "_href": "http://pharo.org/",
            "value": "Used Pharo"
          },
          {
            "_href": "https://github.com/carolahp/pharo/tree/candle",
            "value": "Bootstrapping Tool"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9443.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10710",
        "start": "11:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "gnuguixpackagemanager",
        "title": "Universal package & service discovery with Guix",
        "subtitle": "Α universal functional package manager and operating system which respects the freedom of computer users.",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GNU Guix is a universal functional package manager and operating system which\nrespects the freedom of computer users. It focuses on bootstrappability and\nreproducibility to give the users strong guarantees on the integrity of the full\nsoftware stack they are running. It supports atomic upgrades and roll-backs\nwhich make for an effectively unbreakable system.<\/p>",
        "description": "<p>I'll present how I intend to leverage the Guile programming language to boost\nsearchability of packages and services via intuitive user interfaces and semantics.<\/p>\n\n<p>Guix, like many other package managers, suffers from usability\nissues when it comes to the explorability of the content (that is,\npackages and services), facing the exorbitant amount of software there\nis out there.  Users should be able to discover the programs they need\nfor a specific task, without having to know them in advance.  It should\nbe easy to specify build options for the packages, e.g. \"build without\nsound\" or \"add IPFS support.\"  They should not have to waste time\nwriting their own hacks and scripts when ready-to-use services already\nexist and are just waiting to be discovered.<\/p>\n\n<p>So how do we fix the issue of improving this discoverability, with ease\nof use?<\/p>\n\n<p>In the context of the Next Generation Internet initiative, I've started\nworking on enhancing search, discovery and reusability of packages and\nservices.<\/p>\n\n<p>\"A universal software navigator on steroids -- for everyone.\"<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7370",
            "value": "Pierre Neidhardt"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10710.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9959",
        "start": "11:50",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "gnumes",
        "title": "GNU Mes",
        "subtitle": "Scheme-only bootstrap and beyond",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Last year GNU Mes brought the Reduced Binary Seed bootstrap to GNU Guix: gcc, glibc and binutils were removed and the size of the bootstrap binaries went down from 250MB to 130MB.  This year we introduce the Scheme-only bootstrap: Awk, Bash, Core Utilities, Grep, Gzip, Make, Sed, Tar are replaced by Gash and Gash Core Utils, halving the size of the Guix bootstrap seed again, to 60MB.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4111",
            "value": "Jan Nieuwenhuizen (janneke)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9959.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9993",
        "start": "12:10",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "lispeverywhere",
        "title": "Lisp everywhere!",
        "subtitle": "Gurudom is around the corner",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Minimalism matters in computing. Minimalism allows for smaller systems\nthat take less resources and consume less energy. More importantly,\nfree and open source minimalism allows for secure systems that are\neasy to understand. Minimalism is also educational and brings back the\nfun of the early days of computing where people learn to understand\nsystems from the ground up. As a co-organizer of this devroom I will\ntalk about my journey through many programming languages and ending up\nwith Scheme (a minimal Lisp). Lisp is the second oldest language in\nuse today and growing. I'll show you that once you master Lisp you can\nuse it everywhere from software deployment, the shell, the editor and\ndebugging and for programming systems and in the browser. As a matter\nof fact, Lisp is everywhere!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3219",
            "value": "Pjotr Prins"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9993.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9987",
        "start": "12:40",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "guile2020",
        "title": "Celebrating Guile 2020",
        "subtitle": "Lessons Learns in the Last Lap to Guile 3",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Guile maintainer Andy Wingo shares his thoughts on the last lap of the race to Guile 3.  We'll go over ways that Guile got faster, more capable, and more minimal at the same time.<\/p>",
        "description": "<p>New languages are often lovely and minimal but don't have a wide user community.  To the extent that an old language has a community, it also has a legacy burden of supporting that community's old code.  How should these be balanced?  Is there a balance?<\/p>\n\n<p>In this talk, Andy Wingo takes the opportunity of the Guile 3 release to reflect on change and continuity: how can a language stay minimal over time, and how is Guile working towards this goal?  We cover cases in which things have gone well, not so well, as well as ongoing challenges and opportunities.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "446",
            "value": "Andy Wingo"
          }
        },
        "links":
        [
          {
            "_href": "http://gnu.org/s/guile",
            "value": "Guile home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9987.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10269",
        "start": "13:10",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "gexpressionsguile",
        "title": "Introduction to G-Expressions",
        "subtitle": "Introduction to G-Expressions",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will present an overview of G-Expressions and how the GNU Guix project uses them.<\/p>",
        "description": "<p>The GNU Guix project invented G-Expressions to make it easier to stage S-Expressions for later manipulation or evaluation.  They are similar to S-Expressions (hence the name) but provide useful code staging features beyond what can be easily accomplished with just \"quasiquote\" and \"unquote\".  A high-level object (such as a Guix package) can be included in a G-Expression; the transitive dependencies of that high-level object will then be automatically carried along with the G-Expression.  When the G-Expression is converted to an S-Expression and stored on disk for later manipulation or evaluation, the high-level object will be automatically \"lowered\" to an appropriate representation (such as the package's output path) via a \"compiler\".  Compared to direct manipulation of S-Expressions, G-Expressions provide a simpler and more intuitive way to stage code that refers to such high-level objects.<\/p>\n\n<p>The Guix project uses G-Expressions to accomplish a wide variety of tasks, including:<\/p>\n\n<ul>\n<li>Executing the \"liberation\" procedure to convert Mozilla Firefox's source code into GNU IceCat's source code<\/li>\n<li>Building Docker containers from scratch<\/li>\n<li>Executing activation actions during system boot<\/li>\n<li>...and more!<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7161",
            "value": "Christopher Marusich"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10269.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10415",
        "start": "13:40",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "rakulang",
        "title": "Let me tell you about Raku",
        "subtitle": "On why syntax is not so important, with an introduction to the emerging language Raku",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Most languages steadily incorporate new programming concepts in new releases, and new languages have these concepts already baked in. These concepts are related to how functions work and are considered and invoked, different data structures and working with things like Unicode. There's a language, Raku, that incorporates most of the new concepts that have appeared in this century. This talk is an introduction to the language by way of the concepts it uses.<\/p>",
        "description": "<p>Known as Perl 6 until October 14th this year, and released in Christmas 2015, Raku (https://raku.org) was designed as \"The language for the next 100 years\", and as such, it was created with the intention of incorporating most modern programming concepts. With the same motto as its (kind-of) predecessor, Perl, \"There are many ways to do it\", Raku is a multi-paradigm language that is functional, asynchronous, object-oriented, and with new interesting features like grammars.\nIn this talk I'll take a look at a dozen of features of modern languages; I'll exemplify every feature with examples from different languages, trying to get through the different concepts of Raku by way of how they are implemented in other languages.\nFinally, we'll see a few examples of Raku, showing how its rich feature set makes it ideal for learning new programming concepts, as well as putting them to good use to solve your own problems.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1263",
            "value": "Juan Julián Merelo"
          }
        },
        "links":
        [
          {
            "_href": "http://raku.org",
            "value": "Raku main page"
          },
          {
            "_href": "http://docs.raku.org",
            "value": "Raku documentation"
          },
          {
            "_href": "http://rakuadventcalendar.wordpress.com",
            "value": "Raku Advent Calendar"
          },
          {
            "_href": "http://github.com/JJ",
            "value": "GitHub profile of JJ Merelo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10415.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9683",
        "start": "14:00",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "minimalistictypedlua",
        "title": "Minimalistic typed Lua is here",
        "subtitle": "Minimalistic typed Lua is here",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I will present a typed dialect of Lua with a minimalistic implementation. I will discuss the design choices that went into the design, implementation and development approach. We will also discuss whether Lua's minimalism is retained and ponder on the nature of the resulting dialect. This is a sequel for last year talk in which I discussed the challenges on typing dynamic languages and Lua in particular, presenting the results achieved since then.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2352",
            "value": "Hisham Muhammad"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/hishamhm/tl",
            "value": "Github repository for the typed Lua dialect"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9683.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9735",
        "start": "14:30",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "raptorjit_lua",
        "title": "RaptorJIT: a fast, dynamic systems programming language",
        "subtitle": "Forking LuaJIT to target heavy-duty server applications",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>RaptorJIT is a Lua implementation suitable for high-performance low-level system programming. With the project scope reduced to the systems programming domain we want RaptorJIT fit one use case and excel at it, and we’re not afraid of radical change.<\/p>\n\n<p>This talk will be about our efforts to reduce the project’s complexity to improve maintain-ablility and pave the way for new features. A story about porting the LuaJIT interpreter from assembly to C, ruthless trade-offs, and ambitious performance targets in an expressive language.<\/p>\n\n<p>Topics include: predictable performance in JIT compilers, always-on profilers, memory safety in low-level programming<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6923",
            "value": "Max Rottenkolber"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/raptorjit/raptorjit/",
            "value": "RaptorJIT project page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9735.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10553",
        "start": "14:50",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "crystal_lang",
        "title": "The best of both worlds?",
        "subtitle": "Static and dynamic typing in the Crystal programming language",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Long has raged the war between static and dynamic typing proponents. Dynamic typing promises speedy development, less verbose code, and happier developers. Static typing promises to find bugs earlier, help you fix them when they're found, and ease refactoring. Crystal is a statically typed language, but with several novel features aimed in a different direction: the perfect compromise between the two. In this talk I will cover the history and basics of Crystal, and explore the type system which makes Crystal unique.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6470",
            "value": "Steph Hobbs"
          }
        },
        "links":
        [
          {
            "_href": "https://crystal-lang.org/",
            "value": "Crystal"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10553.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10220",
        "start": "15:20",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "nimoneverything",
        "title": "C and JS as intermediary languages",
        "subtitle": "Running Nim on everything from microcontrollers to web-sites",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Nim is an interesting new language whose design is focused around the concept of a small core and great extensibility through a powerful macro system and multiple compilation targets. In this talk I want to showcase how Nim compiles to both C/C++ and JavaScript, and what this means for how easy interoperability and targeting many different platforms can be. Showcasing how the same language can be used for programming anything from the tiniest resource scarce microcontrollers to web-sites or web-technology based desktop applications (like Electron) to normal desktop applications and server applications.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5879",
            "value": "Peter Munch-Ellingsen"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10220.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10238",
        "start": "15:50",
        "duration": "00:30",
        "room": "AW1.125",
        "slug": "nimmovesemantics",
        "title": "Move semantics in Nim",
        "subtitle": "Deterministic Memory Management",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk explains Nim's move semantics and their connection to reference counting, how Nim's model differs from C++ and why move semantics can offer superior performance. Nim with deterministic memory management never has been easier.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7150",
            "value": "Andreas Rumpf (Araq)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10238.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10144",
        "start": "16:20",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "nimultralowoverheadruntime",
        "title": "Designing an ultra low-overhead multithreading runtime for Nim",
        "subtitle": "Exposing fine-grained parallelism for 32+ cores hardware via message passing",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While multithreading abstractions are consolidating over a couple of basic primitives around the notion of tasks and futures, under the hood implementations are vastly differing.\nThe abstraction \"details\" are significant in the current era as developers now have to find parallelism opportunities for 16+ cores on consumer CPUs.<\/p>\n\n<p>We go over the design space of task-parallel and data-parallel multithreading runtime library and present an unique, scalable approach\nbased on message passing.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7108",
            "value": "Mamy Ratsimbazafy"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/mratsim/weave",
            "value": "PoC + Production implementation"
          },
          {
            "_href": "https://github.com/nim-lang/RFCs/issues/160",
            "value": "Design space + RFC in the Nim community"
          },
          {
            "_href": "https://github.com/numforge/laser/blob/master/research/runtime_threads_tasks_allocation_NUMA.md",
            "value": "Research"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10144.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10182",
        "start": "16:40",
        "duration": "00:20",
        "room": "AW1.125",
        "slug": "asyncawaitnim",
        "title": "Async await in Nim",
        "subtitle": "A demonstration of the flexibility metaprogramming can bring to a language",
        "track": "Minimalistic, Experimental and Emerging Languages",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The most basic API for async IO that is high level uses callbacks, but working with those becomes convoluted very quickly. A great solution is <a href=\"https://en.wikipedia.org/wiki/Async/await\">async await<\/a>, but implementing it in a language is a complex endeavour. That is unless your language is flexible enough with strong enough metaprogramming support to make it possible to implement it without modifications to the compiler. Nim is one such language and its async await implementation is entirely implemented inside the standard library. In this talk I will describe how async await in Nim works, both at the syntax level and the event loop level.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7124",
            "value": "Dominik Picheta"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10182.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "AW1.126",
    "event":
    [
      {
        "_id": "9624",
        "start": "09:00",
        "duration": "00:15",
        "room": "AW1.126",
        "slug": "geo_istsos3",
        "title": "istsos3: Data Analysis and statistical tools and unit conversions",
        "subtitle": "GSoC 2017, 18 at OSGeo(istSOS)",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Project Name: Data Analysis and statistical tool suite (GSoC 2017)\nThe primary goal of my project was to create OAT(Data analysis and statistics) extension in RESTFul Web API and OAT extension having data analysis and statistical tools for istSOS which is being used to automate the creation of statisticate documents using OAT library (FREEWAT) and harvesting the data from an istSOS server.<\/p>\n\n<p>Project Name:  istSOS - Support of unit of conversion in istsos3 (GSoC 2018)\nThe aim of my project primarily is to add plugins conversion of the unit of measure in istSOS3. The user can convert a unit in another specified unit. For Unit of measure conversion in istSOS3 we added postgresql-unit and pint libraries which has a powerful feature of unit conversion along with many specified functions like unit conversion function instantly and all types of operations support to istsos3.<\/p>",
        "description": "<p>Project Name: istSOS (OSGeo) - Data Analysis and statistical tool suite (GSoC 2017)<\/p>\n\n<p>This section comprises of following parts:\n1. OAT installation\n2. Implemented OAT methods<\/p>\n\n<p>OAT is a Python package that is integrated in the FREEWAT environment through an interface exposing its features to modelers and non-programmer users. OAT library implements two main classes: the Sensor class that is designated to handle time­series data and metadata and the Method class which is designated to represent a processing method. The library applies the behavioral visitor pattern which allows the separation of an algorithm from the object on which it operates: thanks to this design pattern it is possible to add a new processing capability by simply extending the Method class without the need to modify the Sensor class. From a dependency point of view, OAT takes advantage of the PANDAS (McKinney, 2010), NUMPY and SCIPY (Van der Walt et. al. 2011) packages.<\/p>\n\n<p>Project Name:  istSOS (OSGeo) - Support of unit of conversion in istsos3 (GSoC 2018)\nThe aim of my project primarily is to add plugins conversion of the unit of measure in istSOS3. The user can convert unit in another specified unit. For Unit of measure conversion in istSOS3 we added postgresql-unit and pint libraries which has a powerful feature of unit conversion along with many specified functions like unit conversion function instantly and all types operations supports to istsos3 data like add, subtraction, multiplication, and division with magnitude and units.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6850",
            "value": "Rahul Chauhan"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/presentation/d/1OPtv-kMufxSSBMQzD5CQ9BuUpN6fLEKujHbEMbSFLgA/edit?usp=sharing",
            "value": "Slides"
          },
          {
            "_href": "https://www.linkedin.com/in/rahulworld/",
            "value": "LinkedIn"
          },
          {
            "_href": "https://github.com/rahulworld",
            "value": "Github"
          },
          {
            "_href": "https://drive.google.com/open?id=1_9QRftvsKa6iS9GLjn3jEv6vrNiDu-TC",
            "value": "Resume"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9624.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10503",
        "start": "09:20",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "introduction_to_spatiotemporal_asset_catalogs_stac",
        "title": "Introduction to SpatioTemporal Asset Catalogs (STAC)",
        "subtitle": "Introducing the new cloud-native cataloging specification for geospatial data: STAC",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The talk introduces STAC, the SpatioTemporal Asset Catalog specification. It aims to enable a cloud-native geospatial future by providing a common layer of metadata for better search and discovery. It is an emerging open standard to catalog and expose geospatial data from different sources either in a static or dynamic way.<\/p>\n\n<p>We’ll cover the core set of metadata fields for STAC Catalogs, Collections, and Items first, along with available extensions for describing different types of data (EO, SAR, Point Cloud, etc.). With the basics of STAC in hand, the talk will go through the Open Source ecosystem for working with STAC metadata: validators, graphical user interfaces and client command line tools and libraries for search, access, and exploitation.<\/p>",
        "description": "<p>The SpatioTemporal Asset Catalog (STAC) specification is an emerging standard to catalog and expose geospatial data from different sources. It aims to enable a cloud-native geospatial future by providing a common layer of metadata for better search and discovery.<\/p>\n\n<p>This talk gives a detailed overview of STAC and the way it allows for static and dynamic implementations at the same time. The simple concept of static catalogs living alongside the data on cloud file storage (e.g., AWS S3, GCS) by adding small JSON files is highlighted before talking through the dynamic searchable APIs built on top of the new OGC API – Features standard.<\/p>\n\n<p>The talk will cover the core set of metadata fields for STAC Catalogs, Collections, and Items, along with available extensions for describing different types of data (EO, SAR, Point Cloud, etc.). With the basics of STAC in hand, the talk will go through the Open Source ecosystem for working with STAC metadata: validators, graphical user interfaces and client command line tools and libraries for search, access, exploitation and API generation.<\/p>\n\n<p>The specification is an open standard developed on GitHub by a wide range of organizations with a strong focus on extensibility to support various domains. It encourages interested parties to extend the specification for their needs for a future of interoperable discovery and work with geospatial data. An ecosystem of Open Source tooling is evolving around the specification.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7281",
            "value": "Matthias Mohr"
          }
        },
        "links":
        [
          {
            "_href": "http://www.stacspec.org",
            "value": "STAC homepage"
          },
          {
            "_href": "https://github.com/radiantearth/stac-spec",
            "value": "STAC GitHub repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10503.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10504",
        "start": "09:40",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "introduction_to_openeo",
        "title": "Introduction to openEO",
        "subtitle": "openEO develops an open API to connect R, Python, JavaScript and other clients to big Earth observation cloud back-ends in a simple and unified way",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>openEO is a new API specification for Earth Observation data cubes that supports data extraction, processing and viewing.<\/p>\n\n<p>Both the standard and its implementations are Open Source projects, which itself rely on Open Source libraries under the hood, such as GRASS GIS, GDAL, Geotrellis, Rasdaman, or provide a standardized interface to proprietary systems such as Google Earth Engine. Client implementations are available for JavaScript, R, Python, QGIS and web browsers.<\/p>\n\n<p>This talk will show an overview of the main capabilities, and available client and backend implementations.<\/p>",
        "description": "<p>Earth Observation data are becoming too large to be downloaded locally for analysis. Also, the way they are organised (as tiles, or granules: files containing the imagery for a small part of the Earth and a single observation date) makes it unnecessary complicated to analyse them. The solution to this is to store these data in the cloud, on compute back-ends, process them there, and browse the results or download resulting figures or numbers. Unfortunately, data and APIs are too often proprietary solutions and lock-in to a service provider happens easily so an interoperable standard across service providers is much needed.<\/p>\n\n<p>The aim of openEO is to develop an open API to connect R, Python, JavaScript and other clients to big Earth observation cloud back-ends in a simple and unified way. With such an API, each client can work with every service provider, and it becomes possible to compare them in terms of capacity, cost, and results (validation, reproducibility).<\/p>\n\n<p>The specification is centered around Earth Observation data cubes that supports data extraction, processing and viewing. It specifies a set of common processes to be used so that switching between service providers is less of a problem. Both the standard and its implementations are Open Source projects. Under the hood, the client and backend implementations rely on Open Source libraries, such as GRASS GIS, GDAL, Geotrellis, Rasdaman, but also provide a standardized interface to proprietary systems such as Google Earth Engine.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7281",
            "value": "Matthias Mohr"
          }
        },
        "links":
        [
          {
            "_href": "http://www.openeo.org",
            "value": "openEO homepage"
          },
          {
            "_href": "https://github.com/Open-EO",
            "value": "openEO GitHub organization"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10504.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10564",
        "start": "10:05",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "geoserver",
        "title": "GeoServer Basics",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GeoServer Basics\nWelcome to GeoServer, a popular web service for publishing your geospatial data using industry standards for vector, raster and mapping.<\/p>\n\n<p>Are you just getting started with GeoServer, or considering it for the first time?<\/p>\n\n<p>This presentation is here to help, introducing the basics of:\nUsage: Concepts used to connect to your data and publish as a spatial service.\nContext: What role GeoServer plays in your organization and what value the application provides.\nCommunity: How the project is managed, and a discussion of the upcoming activities.<\/p>\n\n<p>Attend this presentation to get a running start on using GeoServer in your organization.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7290",
            "value": "Jody Garnett"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/geoserver/geoserver",
            "value": "GeoServer Repo"
          },
          {
            "_href": "http://geoserver.org",
            "value": "GeoServer Website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10564.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10761",
        "start": "10:25",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "geonetwork_basics",
        "title": "GeoNetwork Basics",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GeoNetwork Basics\nWelcome to GeoNetwork, a leading web service for keeping track of the spatial information used by your organization.<\/p>\n\n<p>Jody is an experienced open source community member, digging into what this technology offers, and how it is used. This presentation shares these findings with you, and touches on what makes GeoNetwork succeed:<\/p>\n\n<p>We look at what GeoNetwork is for, the business challenge it is faced with, and the amazing technical approach taken by the technology.\nFor context we look at the core layer publishing workflow to see what is required\nWe peek under the hood at how the editor works, and discover the central super-power of GeoNetwork\nLook at examples of how GeoNetwork has been extended by organizations to see what is possible with this technology<\/p>\n\n<p>Attend this presentation for an informative tour of the GeoNetwork ecosystem.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7290",
            "value": "Jody Garnett"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/geonetwork/core-geonetwork",
            "value": "GeoNetwork repository"
          },
          {
            "_href": "https://acthttp://geonetwork-opensource.orgnia.mundialis.de/",
            "value": "GeoNetwork Website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10761.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10518",
        "start": "10:50",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "getting_inspired_by_open_software_for_a_web_site_g3nfyi",
        "title": "Getting inspired by open software for a web site: g3n.fyi",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>So you are here at FOSDEM in Brussels. Also sightseeing? Geocaching? Tried to optimize your way along the sights or to find many caches without making it a hike? Then you've got the traveling salesman problem! Famous in computer science because finding the optimum is extremely difficult and finding good approximations can be done easily.<\/p>\n\n<p>Last year we had a talk about 3geonames.org where the Hilbert curve was mentioned to be used in name generation. When researching about this space curve it turned out that such space filling curves give good approximations for the traveling salesman problem. This has already been evaluated scientifically. Route finding using thees curves is extremely simple. Other algorithms need much more computational effort. Using a space filling curve to find a route proposal and improving it with 2-Opt optimization algorithm gives the quality of 2-Opt at high speed. Even so fast that it keeps track with interactive changes of the waypoints on a moving map display.<\/p>\n\n<p>This mechanism gives short routes for your sightseeing or geocaching planning and can also be used professionally if you have to visit several locations on a single tour as in package delivery, meals on wheels, or elderly care.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3595",
            "value": "Thomas Bremer"
          }
        },
        "links":
        [
          {
            "_href": "http://www.3gn.fyi",
            "value": "http://www.3gn.fyi"
          },
          {
            "_href": "http://www.3gn.eu",
            "value": "http://www.3gn.eu"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10518.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10378",
        "start": "11:15",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "arabesque_a_geographic_flow_visualization_application",
        "title": "Arabesque: a geographic flow visualization application",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p><em>Arabesque<\/em> is a FLOSS web application dedicated to flow mapping and analysis. Using web technologies, it provides tools to the user to load O/D data. The user can easily modify filters parameters or add new ones. A default symbology is proposed but the user can define is own.<\/p>\n\n<p><em>Arabesque<\/em> aims to provides a fast, lightweight framework to visualize and explore flow data with a special attention on graphics and symbology in order to produce beautiful and just flow maps.<\/p>\n\n<p>This presentation will be a short presentation of the project and a quick demo of the application. It is the extension of the presentation made at FOSS4G 2019: release, code publication, updates and a live demo.<\/p>",
        "description": "<p>Geographic flow visualization (gFlowiz) is an interdisciplinary project dedicated to flows and networks in the geoweb.\nIt is led by a team of French researchers and engineers in Geography, Cartography and Computer Science from both IFSTTAR and CNRS.<\/p>\n\n<p>A state of the art on current issues of flows and movement analysis on the geoweb has been produced through the compilation of around 70 applications in a thematic dashboard, and a 200 respondants survey on flow map usages and needs has been realized.<\/p>\n\n<p>The results of this were combined to create the specifications of the <em>Arabesque<\/em> application.\n<em>Arabesque<\/em> is a FLOSS web application dedicated to flow mapping and analysis. Using web technologies, it provides tools to the user to load Origin/Destination data in robust and well documented formats (CSV or geojson). <em>Arabesque<\/em> will display the most significant data at launch but the user can easily modify filters parameters or add new ones on nodes and/or links. A default symbology is proposed but color scales, size, transparency and shape of objects can be modified as well.<\/p>\n\n<p><em>Arabesque<\/em> aims to provides a fast, lightweight framework to visualize and explore flow data.\nA special attention has been provided on graphics and use of correct symbology in order to produce\nbeautiful and just flow maps.<\/p>\n\n<p>This presentation will be a short presentation of the <a href=\"https://geoflowiz.hypotheses.org/\">Gflowiz project<\/a> and a quick demo of the <a href=\"https://arabesque.ifsttar.fr\"><em>Arabesque<\/em> application<\/a>.<\/p>\n\n<h3>Speaker bio<\/h3>\n\n<ul>\n<li>Nicolas Roelandt works at the <a href=\"https://www.ifsttar.fr/en/the-institute/ifsttar/who-are-we/\">IFSTTAR research institute<\/a> as a GIS engineer. He is an OSGeo charter member and an OSGeoLive PSC member.<\/li>\n<li>Françoise Bahoken is researcher in geography at the <a href=\"https://www.ifsttar.fr/en/the-institute/ifsttar/who-are-we/\">IFSTTAR research institute<\/a>. Her subject is flow and movements geographical patterns through cartography<\/li>\n<li>Laurent Jégou is a cartographer and geographer at the <a href=\"https://www.univ-tlse2.fr\">Toulouse-Jean Jaurès University<\/a><\/li>\n<li>Marion Maisonobe is a geographer at the <a href=\"http://www.parisgeo.cnrs.fr/spip.php?article8513&amp;lang=es\">CNRS research institute<\/a>. She studies scientific networks and their geography.<\/li>\n<li>Etienne Côme is researcher at the <a href=\"https://www.ifsttar.fr/en/the-institute/ifsttar/who-are-we/\">IFSTTAR research institute<\/a>.  His research interests include probabilistic graphical models, data-science and visualisation and their use to solve transportation problems.<\/li>\n<li>Grégoire Le Campion works at the [CNRS research institute] (http://http://www.passages.cnrs.fr/) as a data science/statistical engineer.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7109",
            "value": "Nicolas Roelandt"
          }
        },
        "links":
        [
          {
            "_href": "https://geoflowiz.hypotheses.org/",
            "value": "Gflowiz project blog (French)"
          },
          {
            "_href": "http://arabesque.ifsttar.fr/",
            "value": "Arabesque application"
          },
          {
            "_href": "https://github.com/gflowiz/arabesque",
            "value": "Arabesque source code"
          },
          {
            "_href": "https://media.ccc.de/v/bucharest-205-gflowiz-an-open-science-framework-to-analyze-and-geovisualize-networks-and-flow-datasets",
            "value": "FOSS4G 2019 : \"gFlowiz, an open science framework to analyze and geovisualize networks and flow datasets\""
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10378.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10511",
        "start": "11:40",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "boostgeometry_r_tree_speeding_up_geographical_computation",
        "title": "Boost.Geometry R-tree - speeding up geographical computation.",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4314",
            "value": "Adam Wulkiewicz"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10511.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9262",
        "start": "12:05",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "testing_navit_using_device_farms",
        "title": "Testing Navit using Device Farms",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4699",
            "value": "Patrick Höhn"
          }
        },
        "links":
        [
          {
            "_href": "http://www.navit-project.org",
            "value": "Project Website"
          },
          {
            "_href": "http://github.com/navit-gps/navit",
            "value": "Github Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9262.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10495",
        "start": "12:30",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "reverse_geocoding_is_not_easy",
        "title": "Reverse Geocoding is not easy",
        "subtitle": "IGN 10/10 makes you feel like a geocoder",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Having seen a dozen of different OpenStreetMap-based geocoders, I did not expect to find myself writing another one. But here I am, tasked with making a reverse geocoder better than the industry-standard Nominatim. Turns out it is a fun and not so straightforward task. Let’s see what can go wrong.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3485",
            "value": "Ilya Zverev"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/gojuno/jrg/",
            "value": "GitHub repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10495.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10380",
        "start": "12:55",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "working_with_spatial_trajectories_in_boost_geometry",
        "title": "Working with spatial trajectories in Boost Geometry",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4288",
            "value": "Vissarion Fysikopoulos"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10380.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9197",
        "start": "13:20",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "mobilitydb_",
        "title": "MobilityDB",
        "subtitle": "Managing mobility data in PostGIS",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>MobilityDB is an open source moving object database system (https://github.com/ULB-CoDE-WIT/MobilityDB). Its core function is to efficiently store and query mobility tracks, such as vehicle GPS trajectories. It is engineered up from PostgreSQL and PostGIS, providing spatiotemporal data management via SQL. It integrates with the postgreSQL eco-system allowing for complex architectures such as mobility stream processing and cloud deployments.<\/p>\n\n<p>The presentation will explain the architecture of MobilityDB, its database types, indexes, and operations. An end to end example will be demonstrated, starting with data preparation, loading, transformation, querying, until visualization. This presentation will be of special interest to the PostgreSQL community, and to professionals in the transportation domain.<\/p>\n\n<p>This presentation will build on our talks in PGConf.ru 2019, and FOSS4G Belgium 2019.<\/p>",
        "description": "<p>MobilityDB is an open source PostgreSQL extension that adds support for temporal and spatio-temporal objects to the PostgreSQL and PostGIS. MobilityDB implements the Moving Features specification from the Open Geospatial Consortium (OGC).<\/p>\n\n<p>Features:\n- Time types: Period, PeriodSet, and TimestampSet which, in addition of the the TimestampTz type provided by PostgreSQL, are used to represent time spans.\n- Temporal types: tbool, tint, tfloat, and ttext which are based on the bool, int, float, and text types provided by PostgreSQL and are used to represent basic types that evolve on time.\n- Spatio-temporal types: tgeompoint and tgeogpoint which are based on the geometry and geography types provided by PostGIS (restricted to 2D or 3D points) and are used to represent points that evolve on time.\n- Range types: intrange and floatrange which are used to represent ranges of int and float values.<\/p>\n\n<p>All these types have associated an extensive set of functions and operators. GiST and SP-GIST index support for these types are also provided.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6560",
            "value": "Mahmoud  Sakr"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/ULB-CoDE-WIT/MobilityDB",
            "value": "https://github.com/ULB-CoDE-WIT/MobilityDB"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9197.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10392",
        "start": "13:45",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "geo_spatial_queries_on_multi_petabyte_weather_data_archives",
        "title": "Geo-spatial queries on multi-petabyte weather data archives",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Geo-spatial queries on multi-petabyte weather data archives\nJohn Hanley, Nicolau Manubens, Tiago Quintino, James Hawkes, Emanuele Danovaro<\/p>\n\n<p>Weather forecasts produced by ECMWF and environment services by the Copernicus programme act as a vital input for many downstream simulations and applications. A variety of products, such as ECMWF reanalyses and archived forecasts, are additionally available to users via the MARS archive and the Copernicus data portal. Transferring, storing and locally modifying large volumes of such data prior to integration currently presents a significant challenge to users. The key aim for ECMWF effort in H2020 Lexis project is to provide tools for data query and pre-processing close to data archives, facilitating fast and seamless application integration by enabling precise and efficient data delivery to the end-user.<\/p>\n\n<p>ECMWF aims to implement a set of services to efficiently select, retrieve and pre-process meteorological multi-dimensional data by allowing multi-dimensional queries including spatio-temporal and domain-specific constraints. Those services are exploited by Lexis partners to design complex workflows to mitigate the effect of natural hazards and investigate the water-food-energy nexus.<\/p>\n\n<p>This talk will give a general overview of Lexis project and its main aims and objectives. It will present the pilot applications exploiting ECMWF data as the main driver of complex workflows on HPC and cloud computing resources. In particular, it will focus on how ECMWF's data services will provide geospatial queries on multi-dimensional peta-scale datasets and how this will improve overall workflow performance and enable access to new data for the pilot users.<\/p>\n\n<p>This work is supported by the Lexis project and has been partly funded by the European Commission's ICT activity of the H2020 Programme under grant agreement number: 825532.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7230",
            "value": "Emanuele Danovaro"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10392.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10509",
        "start": "14:10",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "actinia_geoprocessing_in_the_cloud",
        "title": "actinia: geoprocessing in the cloud",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With a rapidly increasing wealth of Earth Observation (EO) and geodata, the demand for scalable geoprocessing solutions is growing as well. Following the paradigm of bringing the algorithms to the data, we developed the cloud based geoprocessing platform actinia (<a href=\"https://actinia.mundialis.de\">https://actinia.mundialis.de<\/a> and <a href=\"https://github.com/mundialis/actinia_core\">https://github.com/mundialis/actinia_core<\/a>). This free and open source solution is able to ingest and analyse large volumes of data in parallel. actinia provides a HTTP REST API around GRASS GIS functionality, extended by ESA SNAP and user scripts written in Python. Core functionality includes the processing of raster and vector data as well as time series of satellite images. The backend is connected to the full Landsat and Copernicus Sentinel archives. actinia is an OSGeo Community Project since 2019 and a backend of the <a href=\"https://openeo.org\">openEO.org<\/a> API (EU H2020 project).<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2686",
            "value": "Markus Neteler"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/mundialis/actinia_core/",
            "value": "actinia GitHub repository"
          },
          {
            "_href": "https://actinia.mundialis.de/",
            "value": "actinia server and docs"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10509.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9778",
        "start": "14:35",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "robosatpink_deep_learning_computer_vision_patterns_extraction_at_scale",
        "title": "RoboSat.pink: Deep Learning Computer Vision patterns extraction at scale",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>RoboSat.pink, a Deep Learning Computer Vision framework for GeoSpatial Imagery,\nallow you to perform at scale:<\/p>\n\n<ul>\n<li>DataSet Quality Analysis<\/li>\n<li>Change Detection highlight<\/li>\n<li>Features extraction<\/li>\n<\/ul>\n\n\n<p>This presentation will focus on the latests enhancements of RoboSat.pink,\nand mainly on:<\/p>\n\n<ul>\n<li>How we increase again pattern recognition accuracy, even with unconsistents labels<\/li>\n<li>How we speed up the whole process, and allow to scale even on large areas<\/li>\n<li>New hot features<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5089",
            "value": "Olivier Courtin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/datapink/robosat.pink",
            "value": "RoboSat.pink GitHub page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9778.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9287",
        "start": "15:00",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "apache_spark_on_planet_scale",
        "title": "Apache Spark on planet scale",
        "subtitle": "Using Apache Spark to process OpenStreetMap data",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Apache Spark is an open-source distributed general-purpose cluster-computing framework with implicit data parallelism. OpenStreetMap is a huge database of features, found on Earth surface. Working with that database is hard, so Spark is a natural solution to solve OSM size-caused processing issues. I'm going to show how to load OSM data to Spark, run processing algorithms like extract/merge or render and how using Spark improves development process and cuts processing times greatly.<\/p>",
        "description": "<p>Will show, how to use Spark OSM DataSource to load data to the Spark DataFrame and how to use Spark for OSM data merge/extract, simple analysis, rendering etc. Talk will also mention multithreaded OSM PBF parser, that can be used independently of Spark or other processing library.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4888",
            "value": "Denis Chaplygin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9287.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9096",
        "start": "15:25",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "creating_gpx_tracks_from_cycle_routes_in_openstreetmaps",
        "title": "Creating GPX tracks from cycle routes in OpenStreetMaps",
        "subtitle": "Using the OverpassAPI to download and process cycle routes from OpenStreetMaps",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Across Europe, there are many regional, national and international cycle routes; they provide safe ways for families and friends to travel and explore by bike. They can however, be hard to follow: overgrown vegetation can hide directions, signs are subject to vandalism and sometimes it is just easy to miss a turn.<\/p>\n\n<p>Having freely available GPX tracks for cycle routes means people can better plan their journey and avoid wrong turns when following the route. OpenStreetMaps is the best source of information for cycle routes and these relations can easily be downloaded using the OverpassAPI.<\/p>\n\n<p>In this talk I will present an Open Source tool to download GPX tracks of cycle routes, and a website for people to download the generated GPX files. I will discuss some of the nuances of how cycle routes are stored as relations and what processing needs to be performed in order to create a continuous route. In addition, I will speak about how the tool can be used to identify inconsistencies in OpenStreetMaps data.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6494",
            "value": "Henry Miskin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9096.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10237",
        "start": "15:50",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "geo_damn",
        "title": "Divide and map. Now.",
        "subtitle": "damn project",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There is a Tasking manager by the Humanitarian OpenStreetMap Team (HOT). We use it heavily during mapathons (mapping for developing countries). The Tasking Manager serves one primary purpose: take some great area to be mapped and split it to squares a human can map in a few minutes. With this divide and map approach, we can map a lot.<\/p>\n\n<p>There are some issues with the Tasking Manager, however. The main problem is performance -- it is slow and failing when loaded by requests.<\/p>\n\n<p>The next is the architecture of the Tasking Manager. It is wrong, in my opinion.<\/p>\n\n<p>The last but not least is that the Tasking Manager is not community-driven. The Tasking Manager is a product of HOT for which you can download the source code.<\/p>\n\n<p>In the talk, I want to introduce <strong>Divide and map. Now.<\/strong> -- damn project. It is an alternative to the Tasking Manager that tries to fix the issues noted above.<\/p>",
        "description": "<p>I am going to publish the full description between Dec 2019 and Jan 2020 as it is not ready yet. The damn project is not fully released yet, although parts of it are developed as opensource:\n- https://gitlab.com/qeef/damn<em>server\n- https://gitlab.com/qeef/damn<\/em>client\n- https://gitlab.com/qeef/damn<em>plugin\n- https://gitlab.com/qeef/damn<\/em>manager<\/p>\n\n<p>EDIT: The project is released:\n- https://www.openstreetmap.org/user/qeef/diary/391778\n- https://www.damn-project.org/<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6918",
            "value": "Jiri Vlasak"
          }
        },
        "links":
        [
          {
            "_href": "https://www.damn-project.org/",
            "value": "https://www.damn-project.org/"
          },
          {
            "_href": "https://www.openstreetmap.org/user/qeef/diary/391778",
            "value": "https://www.openstreetmap.org/user/qeef/diary/391778"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10237.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9347",
        "start": "16:15",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "integration_processes",
        "title": "Integration Processes",
        "subtitle": "Data flowing the easy way",
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>To run our software we need a flow of data going through it. Usually we write scripting pieces to make that workflow of data moving from one component to the next. Integration Processes are the \"glue\" between these software pieces. Automating the data flows, adding conditional steps, handling credentials on a secure way,... That's usually a tedious and repetitive task lots of developers do again and again. With Integration Processes frameworks we can make it simpler and reuse expertise from other developers. We could even build entire workflows without throwing a single line of code.<\/p>",
        "description": "<p>Apache Camel is an open source integration framework that empowers you to quickly and easily integrate various systems consuming or producing data. Based on Enterprise Integration Patterns to help you solve your integration problem by applying best practices out of the box. Camel is one of the the most active project in the Apache Foundation and is the base of many other FOSS projects.<\/p>\n\n<p>Syndesis is an open source project that helps non-developers create complex integrations easily on a graphic interface.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6503",
            "value": "María Arias de Reyna"
          }
        },
        "links":
        [
          {
            "_href": "https://syndesis.io/",
            "value": "Syndesis Project"
          },
          {
            "_href": "https://camel.apache.org/",
            "value": "Apache Camel Project"
          },
          {
            "_href": "https://www.enterpriseintegrationpatterns.com/",
            "value": "Enterprise Integration Patterns"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9347.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10762",
        "start": "16:40",
        "duration": "00:20",
        "room": "AW1.126",
        "slug": "geochallenge",
        "title": "The Wallonian GeoChallenge Invitation",
        "subtitle": [],
        "track": "Geospatial",
        "type": "devroom",
        "language": [],
        "abstract": "<p>During the first months of 2020, the Geoportail of Wallonia,  and some partners will organise a public event called « The GeoChallenge ».<\/p>\n\n<p>In a few words, the idea is to ask  participants to solve public services or citizens expectations by using Wallonia’s geographic information and ressources.<\/p>\n\n<p>More than a hackathon, the event will last a few weeks with the idea to create results that translate into concrete benefits.<\/p>\n\n<p>The first call for proposals will be launched in january and will last until the end of february.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7410",
            "value": "Emmanuel Jauquet"
          }
        },
        "links":
        [
          {
            "_href": "http://geoportail.wallonie.be/home.html",
            "value": "http://geoportail.wallonie.be/home.html"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10762.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.3.201",
    "event":
    [
      {
        "_id": "9401",
        "start": "09:00",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "dldsmwc",
        "title": "Do Linux Distributions Still Matter with Containers?",
        "subtitle": [],
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In the beginning there was compiling and static linking. My first programs when I was 10 years old worked like that. Then, we discovered dynamic linking. This was great because we could now patch one library and all of the programs would pick up the change on restart. But we created another problem - dependencies. Throughout the history of computing we have solved one problem and created another. Containers are no different. This talk will walk through why we invented Linux distros and why we should continue to appreciate them in a world full of container images...<\/p>",
        "description": "<p>In the beginning there was compiling and static linking. My first programs when I was 10 years old worked like that. Then, we discovered dynamic linking. This was great because we could now patch one library and all of the programs would pick up the change on restart. But we created another problem - dependencies. Throughout the history of computing we have solved one problem and created another. Containers are no different. This talk will walk through why we invented Linux distros and why we should continue to appreciate them in a world full of container images.<\/p>\n\n<p>The short answer is yes. Yes, they still matter because of several reasons:<\/p>\n\n<ol>\n<li><p>A linux distribution is a bunch of human beings that work together to create a dependency tree of software packages. This dependency tree is still convenient in container images<\/p><\/li>\n<li><p>There is a TON of knowledge embedded in systemd unit files on how to properly start/stop commonly used daemons<\/p><\/li>\n<li><p>Mapping CVEs to packages with meta data is still useful in a container<\/p><\/li>\n<li><p>Standardized C libraries like glibc are used by binaries, interpreters like Python, and even virtual machines managers like the JVM<\/p><\/li>\n<li><p>Critical libraries like libssl, openssl, and hardware accelerated bridges, are useful to everyone<\/p><\/li>\n<li><p>Linux distros are a connection point with gravity which builds community. Community is what solves problems<\/p><\/li>\n<li><p>Host and container image portability (glibc actually can take different code paths depending on what hardware is made available by the kernel. Also, glibc has a min/max kernel version that it supports well when compiled)<\/p><\/li>\n<\/ol>",
        "persons":
        {
          "person":
          {
            "_id": "5619",
            "value": "Scott Mccarty"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/presentation/d/175ZuAywtPyRsDaS7vHoCvq8W2jvgY0f53hmGcTFOc_E/edit#slide=id.g4f6592764e_6_0",
            "value": "Do Linux Distributions Still Matter with Containers?"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9401.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10480",
        "start": "10:00",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "wuoh",
        "title": "What's up on Haiku?",
        "subtitle": "R1/beta2, packaging, porting and contributing.",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>What are the new features in the upcoming R1/beta2? How did the packaging system work out? How to make your software easier to port to it, and how to contribute?<\/p>",
        "description": "<p>Haiku is a Free Software Operating System, inspired by the BeOS, which focuses on personal computing.<\/p>\n\n<p>It's been in the making for more than 18 years now. We'll see what's coming up for the R1/beta2 release.<\/p>\n\n<p>The packaging system has been integrated for some years now, as a different approach to software distribution. Did it live up to its promise? How well does it scale with the growing number of available packages?<\/p>\n\n<p>What are the specifics of Haiku that you should care about when writing portable software?<\/p>\n\n<p>How to contribute to various parts of the system?<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3587",
            "value": "François Revol (mmu_man)"
          }
        },
        "links":
        [
          {
            "_href": "https://www.haiku-os.org/",
            "value": "Haiku website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10480.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9278",
        "start": "10:30",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "hfaf",
        "title": "Homebrew: Features and Funding",
        "subtitle": [],
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A talk about the Homebrew package manager and how we've been working with our users to introduce new features to subsets of users, encouraging users to donate to the project and communicating both these to as many users as possible without being annoying.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3150",
            "value": "Mike McQuaid"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9278.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10112",
        "start": "11:00",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "ggaaattyp",
        "title": "GNU Guix as an alternative to the Yocto Project",
        "subtitle": [],
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk demonstrates how to use GNU Guix to build a root filesystem for an\nembedded device (Pine A64 LTS).  I will also try to answer the question:\ncould GNU Guix be a viable alternative to the Yocto project and what would be\nthe benefits of using GNU Guix?<\/p>",
        "description": "<p>Working as an embedded software engineer, I've been using Yocto and Buildroot\nprojects to create root filesystems for embedded devices. While Buildroot is\nonly suitable for small embedded systems, Yocto does scale well, but is a\nreally complex tool.<\/p>\n\n<p>Plus, both tools are difficult to handle for developers without a strong\nunderstanding of Linux system integration, and on the other hand, do not\nprovide APIs and introspection tools for integrators.<\/p>\n\n<p>In this talk, I want to explore the possibility of using GNU Guix as an\nalternative to the Yocto project to generate embedded root filesystems.<\/p>\n\n<p>With 7 years of existence, more than 10000 packages and 4 supported\narchitectures, GNU Guix can be used as a transactional package manager and an\nadvanced distribution of the GNU operating system running on the Linux kernel.<\/p>\n\n<p>What would be missing to cover all Yocto features? How could the embedded\ndeveloper benefit from GNU Guix features such as its high level Scheme API,\npackage substitution mechanism, strong reliability and reproducibility?<\/p>\n\n<p>To provide some real world application, I'll compare the process of adding\nsupport for a new board (Pine A64 LTS) on Yocto and GNU Guix. Then I'll\ncompare how to configure, build and flash a small root filesystem for\nthat same board, on the two tools.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6927",
            "value": "Mathieu Othacehe"
          }
        },
        "links":
        [
          {
            "_href": "https://guix.gnu.org/blog/2017/porting-guixsd-to-armv7/",
            "value": "blog post on porting GuixSD to ARM"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10112.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9075",
        "start": "11:30",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "sdnpof",
        "title": "Software distribution: new points of failure",
        "subtitle": "In a censored world",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There is a multitude of software or code ecosystems: Linux distribution packages, language-specific (e.g. Python or node.js) modules, third-party desktop themes, git repositories, and recently also Flatpak and Snap. Users thus obtain software and code mainly from the network. This talk explores what can go wrong in such code delivery mechanisms, and what actually went wrong when a new threat has materialized: networks in certain countries started to be unreliable \"thanks\" to the governments (classical example: https://isitblockedinrussia.com/?host=7-zip.org == true). And what technical steps can be done in order for the said ecosystems to survive when censorship and overblocking spreads over the globe even more.<\/p>",
        "description": "<p>The focus will be on how mirror networks and CDNs operate (and what's the difference and why it matters), illustrated by examples of Debian mirrors and NPM. Both availability and integrity concerns regarding code delivery will be discussed.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6456",
            "value": "Alexander E. Patrakov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9075.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9457",
        "start": "12:00",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "rhdlp",
        "title": "Reinventing Home Directories",
        "subtitle": "Let's bring the UNIX concept of Home Directories into the 21st century",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The concept of home directories on Linux/UNIX has little changed in the last 39 years. It's time to have a closer look, and bring them up to today's standards, regarding encryption, storage, authentication, user records, and more.<\/p>\n\n<p>In this talk we'll talk about \"systemd-homed\", a new component for systemd, that reworks how we do home directories on Linux, adds strong encryption that makes sense, supports automatic enumeration and hot-plugged home directories and more.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "945",
            "value": "Lennart Poettering"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/systemd/systemd",
            "value": "systemd GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9457.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9455",
        "start": "13:00",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "ussftbasd",
        "title": "Using systemd security features to build a more secure distro",
        "subtitle": [],
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Systemd provides a bunch of features which can be used to contain and secure services,\nmaking security and isolation primitives provided by the kernel accessible to system programs.\nThis allows service authors to write much simpler code, and often to avoid any integration\nwith the operating system for security purposes.\nUnfortunately, those features are still not widely used, possibly because developers\nwant to maintain compatibility with a wide range of systems.<\/p>\n\n<p>I'll talk about the features that are the most useful,\nhow they can be used in practice, and how this could be used\nto make a noticeable change in security at the distribution level.<\/p>",
        "description": "<p>The number of security features that systemd provides is long and growing:\nFirst, it performs setup like creating runtime directories and opening sockets, so the service doesn't need privileges.\nSecond, it makes it easy to run services as unprivileged users, removing a whole set of problems.\nThird, it uses kernel features like mount and network namespaces, capabilities, resource limits, to constrain services.\nFourth, it implements additional filters using BPF (per-service firewalls, devices controller).\nFifth, it does resource cleanup after the service is done, removing the need for privileges again.<\/p>\n\n<p>We could use this to vastly simplify services and to provide an additional level of security for system services.\nSome distributions are making use of this, but not nearly enough.\nFedora is probably at the forefront, but the common case is still to run as root will full access to everything the service doesn't need.\nDebian is now discussing a General Resolution to drop SysV Init compatibility and empower packagers to use all systemd features.\nFull support in the two biggest distro families would motivate upstreams to make systemd their \"baseline\" and build more secure services.\nNew features like \"dynamic users\" could be used to make Linux systems take more modern approaches to system security.<\/p>\n\n<p>I want the talk to serve as a prompt for a general discussion how we could modernize service packaging in distros,\nto avoid reimplementing security features in individual daemons, and how to stop the 90's mentality of running everything as root.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6739",
            "value": "Zbigniew Jędrzejewski-Szmek"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9455.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10387",
        "start": "14:00",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "ilbsclte",
        "title": "Introducing libeconf",
        "subtitle": "Bringing systemd-like configuration layering to everything else",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>systemD has a very distribution-friendly way of providing it's configuration, with distributions providing defaults in /usr and users being able to override things either selectively or entirely with their own files in /etc.\nThis is especially nice for distributions wishing to be in some way stateless, support a read-only root filesystem, or provide some kind of factory-reset.\nlibeconf is a newly written C library to ease the adoption of similar configuration layering in other programs across the Linux ecosystem.<\/p>",
        "description": "<p>This talk will give a brief introduction to libeconf, how to use it in your existing programs and demonstrate some examples that have already adopted libeconf (eg. PAM, util-linux, rebootmgr, etc).<\/p>\n\n<p>The session will also share some future plans and welcome suggestions for future contributions, especially for additional features, language bindings, etc.<\/p>\n\n<p>The target audience is primarily developers of 'low level' distribution plumbing (eg. core daemons &amp; services, package managers, etc) that are most likely to benefit from libeconf, but might be of interest to anyone developing any service for linux distributions.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4006",
            "value": "Richard Brown"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10387.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10372",
        "start": "14:30",
        "duration": "00:25",
        "room": "K.3.201",
        "slug": "guadc",
        "title": "GRUB upstream and distros cooperation",
        "subtitle": [],
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presentation will discuss current state of GRUB upstream development and cooperation with distributions.<\/p>",
        "description": "<p>The first half of presentation will be focusing on last year, current and future development efforts. The second half will discuss cooperation between GRUB upstream and distros. In general it will show current progress in the project and main pain points. One of the goals of the presentation is to solicit some help from the community. Maintainers are quite busy and they are not able to solve all issues themselves. So, help from others is greatly appreciated. At the end of presentation Q&amp;A session is planned.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5202",
            "value": "Daniel Kiper"
          }
        },
        "links":
        [
          {
            "_href": "https://www.gnu.org/software/grub/",
            "value": "GNU GRUB - GNU Project - Free Software Foundation (FSF)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10372.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10386",
        "start": "15:00",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "inmcofasmd",
        "title": "Integrating new major components on fast and slow moving distributions",
        "subtitle": "How latest GNOME desktop was integrated into latest SUSE / openSUSE releases",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Upgrading big components in Linux distributions is hard. But integrating them while minimizing regressions (for stable distributions) and not slowing down release pace (for rolling releases) requires a lot of process and tooling.<\/p>\n\n<p>Let's deep dive in those.<\/p>",
        "description": "<p>Over the previous months, openSUSE and SUSE teams have worked together on integrating latest GNOME release (3.34) in their various distributions, while minimizing duplicated work and sharing as much code as possible.<\/p>\n\n<p>We'll describe how it was done for the 3 differents flavors of distributions:\n- openSUSE Tumbleweed (rolling release)\n- SUSE Linux Enterprise 15 SP2 (Enterprise release)\n- openSUSE Leap 15.2 (stable release)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4992",
            "value": "Frederic Crozat"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10386.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9674",
        "start": "16:00",
        "duration": "00:55",
        "room": "K.3.201",
        "slug": "frpgfr",
        "title": "Fedora rawhide packages gating, for real!",
        "subtitle": "How we have implemented gating rawhide packages in Fedora",
        "track": "Distributions",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Rawhide, the, rolling, development version of Fedora has often been considered has too broken and too unstable. Sometime to the detriment of the development of stable releases as well.\nIn a near future, this should no longer be happening as now every change made to every package landing in Fedora rawhide can be gated based on test results.<\/p>\n\n<p>This talk will walk you through the processes and changes that Fedora landed to make of this idea a reality.<\/p>",
        "description": "<p>Rawhide is the development version of Fedora. It is the version from which stable Fedora releases branch from and thus every change made to it will trickle down to the next stable release. This also means that there are time in the development of Fedora where changes landing in rawhide can (and do!) have a detrimental effect on the next stable release.<\/p>\n\n<p>With the rawhide package gating initiative, Fedora has gained mechanisms to test and gate packages based on the results of these tests.<\/p>\n\n<p>In this talk we will go through the mechanisms built to allow this gating, how it works, how to debug if there are issues with it.\nWe will also gladly receive feedback from Fedora contributors who have interacted with it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2140",
            "value": "Pierre-Yves Chibon"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9674.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.3.401",
    "event":
    [
      {
        "_id": "9852",
        "start": "09:00",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_license_clearlydefined",
        "title": "Discover dependency license information with ClearlyDefined",
        "subtitle": "License discovery and record-keeping for crates",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Complying with license obligations can incur a lot of hurdles. This results in developers skipping compliance or failing to achieve correct compliance. To compound this, package authors sometimes fail to describe the license of their package clearly or omit license information of included files. ClearlyDefined is a community curated repository of discovered license information for Crates packages, among other types.<\/p>\n\n<p>This talk will cover: the importance of the license obligations of the dependencies of your Rust package, tool, or application. How to discover the license information of those packages. And demonstrate some Cargo compatible tooling that allows automated license recordkeeping and notice file generation as a part of your CI system.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6969",
            "value": "Jeff Mendoza"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.clearlydefined.io/",
            "value": "About ClearlyDefined"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9852.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10321",
        "start": "09:30",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_cargo_deny",
        "title": "cargo deny",
        "subtitle": "Fearlessly update your dependencies",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A talk about https://github.com/EmbarkStudios/cargo-deny, why we created it, and how it helps us manage our dependencies in the long term.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7195",
            "value": "Jake Shadle"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10321.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10170",
        "start": "10:00",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_packaging_gnu_guix",
        "title": "Packaging Rust programs in GNU Guix",
        "subtitle": "Build reproducibility and dependency management",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Rust is a language with a healthy ecosystem and a strong developer base. With built-in dependency management it's easy to build and install new programs even for those who have never used the language. But how is its adoption among Linux distros?\nCome with me as we figure out how best to package rust libraries and binaries in Linux distributions which demand total control over dependency management.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7096",
            "value": "Efraim Flashner"
          }
        },
        "links":
        [
          {
            "_href": "https://lists.gnu.org/archive/html/guix-devel/2019-10/msg00180.html",
            "value": "overhauling the cargo-build-system"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10170.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9098",
        "start": "10:30",
        "duration": "00:20",
        "room": "K.3.401",
        "slug": "rust_rustdoc",
        "title": "rustdoc: beyond documentation",
        "subtitle": "All the goodies packed in rustdoc, and more",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Rust compiler comes with a few tools, rustdoc is one of them. It is THE standard rust tool to generate documentation for your crates.<\/p>",
        "description": "<p>Rust compiler comes with a few tools, rustdoc is one of them. It is THE standard rust tool to generate documentation for your crates.<\/p>\n\n<p>You can write documentation using \"///\" or \"//!\" patterns (which are syntaxic sugar over <code>#[doc = \"...\"]<\/code>).<\/p>\n\n<p>It generates HTML which can used locally without a need for internet connection. The documentation search is running in JS directly in your browser. You have a source code viewer integrated. You can pick different themes (and even add one yourself). It works with javascript disabled. It provides settings to make your docs browsing more comfortable. You can generate docs with extra content (take a look at https://docs.rs/pwnies for a good example!).<\/p>\n\n<p>But not only it generates documentation, it also adds things for each type that you didn't know was available thanks to the \"Auto-traits implementation\" and \"Blanket implementation\" sections.<\/p>\n\n<p>In addition to generate documentation, it provides functionalities such as an integrated documentation's test runner (which themselves can be quite customized!). It also provides lints that can you deny (missing<em>docs, missing<\/em>doc_example).<\/p>\n\n<p>With just all this, rustdoc is already a quite complete tool. But more will come in the future:<\/p>\n\n<ul>\n<li>more interactive source code viewer<\/li>\n<li>automatic link generation based on the item name<\/li>\n<li>more output formats supported (json would be the first)<\/li>\n<li>cfgs (doctest and doc)<\/li>\n<li>doc aliases for search (for instance, \"*\" proposes pointer in the std lib)<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "4927",
            "value": "Guillaume Gomez"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9098.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9472",
        "start": "10:50",
        "duration": "00:45",
        "room": "K.3.401",
        "slug": "rust_muses",
        "title": "Rusty instruments",
        "subtitle": "Building Digital Musical Instruments with Rust and friends",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will introduce the Muses project, which applies programming language theory and practice, physical computing, networking, and musicial theory to design and implementation of Digital Musical Instruments. Rust is a key ingredient in the Muses project, providing a robust and performant foundation for cross platform, desktop, and embedded system development.<\/p>\n\n<p>The talk will give a brief introdution to Muses project as a whole and then focus on the use of Rust in developing a selection of very different components\nin the system and its benefits for these wildy varing use cases.<\/p>\n\n<p>Demos of the Digitial Musical Instruments with Rust at their heart will shown through out the talk.<\/p>",
        "description": "<p>Controller and gesture interaction with audio and/or visual media is today ubiquitous, requiring the development of intuitive software solutions for interaction design. Designing and building these interfaces often require extensive domain expertise in audio and visual media creation, e.g. the musician, but additionally in engineering and software development. In this talk we focus on custom controller-based interactive systems for sound and musical performance, with a focus on an intuitive and simple design process that is accessible to artists.<\/p>\n\n<p>A large part of the software developed for these systems is low-level system code, where direct access to hardware and understandable performance are hard requirements for these systems. Historically, these systems are written in C/C++ and in the case of embedded systems C is still the language of choice. With the emergence of the system programming language Rust an alternative for developing these systems is now with us with its support for high-level features such as traits, type inference, pattern matching, and of course it's affine based type system for pointers.<\/p>\n\n<p>This talk will introduce the Muses project, which applies programming language theory and practice, physical computing, networking, and musical theory to design and implementation of Digital Musical Instruments. Rust is a key ingredient in the Muses project, providing a robust and performant foundation for cross platform, desktop, and embedded system development.<\/p>\n\n<p>A high-level overview of the schedule is:<\/p>\n\n<ul>\n<li> Introduction to the Muses project<\/li>\n<li> 100 foot view of the Muses architecture<\/li>\n<li> Experience using Rust for audio and interface development<\/li>\n<li> Demonstration<\/li>\n<\/ul>\n\n\n<p>The demonstration will include the following physical components:<\/p>\n\n<ul>\n<li><p> Custom interface<\/p>\n\n<ul>\n<li>Hardware encoders + arcade buttons<\/li>\n<li>Sensel touch interface with custom interface<\/li>\n<li>STM32 based embedded hardware platform, all running Rust<\/li>\n<\/ul>\n<\/li>\n<li><p> Raspberry PI for Sound<\/p>\n\n<ul>\n<li>Pure Data for sound synthesis<\/li>\n<li>Rust based driver for communicating with custom hardware<\/li>\n<li>Rust based Open Sound Control (OSC) server for custom control messages<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n\n\n<p>The framework also includes an approach to automatically generating interfaces from a DSL for SVG interfaces, written largely in Haskell, but with a tessellation pipeline written in Rust. However, while this will be mentioned in passing it is not the intention of this talk to cover this aspect of the system in detail. (For  more information on this, see the provided link for the project website and associated papers, also linked from the site.)<\/p>\n\n<h2>Expected prior knowledge / intended audience<\/h2>\n\n<p>Knowledge of programming will be expected and prior use of C/C++, Rust, or other systems programming language would be useful.<\/p>\n\n<p>Audio topics will be introduced through out the talk and it is not expected that audience members have a musical background.<\/p>\n\n<h2>Speaker bio<\/h2>\n\n<p>Dr Benedict R. Gaster is an Associate Professor at University of West of England, he is the director of the Computer Science Research Centre, which within he also leads the Physical Computing group. He research focuses on the design embedded platforms for musical expression and more generally the IoT, he is the co-founder of Bristol LoRaWAN a low power wide area network for Bristol city, is the technical lead for city wide project on city pollution monitoring for communities, having developed UWE Sense a hardware platform for cheap sensing. Along with his PhD students and in collaboration with UWE's music tech department, is developing a new audio platform based on ARM micro-controllers using the Rust programming language to build faster and more robust sound!<\/p>\n\n<p>Previously Benedict work at Qualcomm and AMD where he was a co-designer on the programming language OpenCL, including the lead developer on AMD's OpenCL compiler. He has a PhD in computer science for his work on type systems for extensible records and variants. He has published extensively, has given numerous presentations, including ones at FOSDEM on Rust and LoRaWAN.<\/p>\n\n<h2>Links to some previous talks by the speaker<\/h2>\n\n<p>Below are are some examples of recent talks:<\/p>\n\n<ul>\n<li> <a href=\"https://bgaster.github.io/farm19/\">Fun with Interfaces (SVG Interfaces for Musical Expression).<\/a> FARM'19: 7th International Workshop on Functional Art, Music, Modeling and Design (FARM).<\/li>\n<li> <a href=\"https://archive.fosdem.org/2018/schedule/event/rustyarm_rust_on_embedded_platforms/\">Rustarm AKA A project looking at Rust for Embedded Systems.<\/a> FOSDEM’18.<\/li>\n<li> <a href=\"https://archive.fosdem.org/2017/schedule/event/lorawan/\">Outside the Block Syndicate: Translating Faust's Algebra of Blocks to the Arrows Framework<\/a>. International Faust Conference (IFC-18), 2018<\/li>\n<li> <a href=\"https://archive.fosdem.org/2017/schedule/event/lorawan/\">LoRaWAN for exploring the Internet of Things. Talk Hard: A technical, political, and cultural look at LoRaWAN for IoT.<\/a> FOSDEM’17.<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "3798",
            "value": "Benedict Gaster"
          }
        },
        "links":
        [
          {
            "_href": "https://muses-dmi.github.io/",
            "value": "Project's main website"
          },
          {
            "_href": "https://muses-dmi.github.io/papers/",
            "value": "Papers related to project"
          },
          {
            "_href": "https://muses-dmi.github.io/projects/](https://muses-dmi.github.io/projects/",
            "value": "Sub projects"
          },
          {
            "_href": "https://github.com/muses-dmi",
            "value": "Project's source code on Github"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9472.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10324",
        "start": "11:40",
        "duration": "00:45",
        "room": "K.3.401",
        "slug": "rust_optimizing_rav1e",
        "title": "Optimizing rav1e",
        "subtitle": "Effective profiling techniques and optimization strategies",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>rav1e is a fast AV1 encoder written in rust (and plenty of assembly), released monthly.<\/p>\n\n<p>Since the 0.1.0 release we try to make sure we provide an adequate speed or quality boost compared to the previous.<\/p>\n\n<p>This talk is about what tools are available in the rust ecosystem and what are the practices that worked best for us.<\/p>",
        "description": "<p>The presentation will touch the following topics:\n- Exploring a codebase and profiling it effectively, both for cpu usage and memory usage.\n- Which are the optimization strategies that worked for us better (critical path analysis vs peak consumer)\n- Benchmarking and tracing<\/p>\n\n<p>I'll provide examples on what tools worked well or not so well and what currently I consider the best and most promising tools for each tasks.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4860",
            "value": "Luca Barbato"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10324.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10258",
        "start": "12:30",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_techniques_sled",
        "title": "Rust techniques used in sled",
        "subtitle": "A correctness-critical and performant Rust codebase",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The sled high-performance embedded database has been under development for over 4 years. This talk will cover techniques that have been used to dramatically outperform existing databases while optimizing for long term developer happiness in a complex, correctness-critical Rust codebase.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7331",
            "value": "Tyler Neely"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10258.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9313",
        "start": "13:00",
        "duration": "00:45",
        "room": "K.3.401",
        "slug": "rust_redisjson",
        "title": "RedisJSON",
        "subtitle": "A document DB in Rust",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Over the last decade, Redis has become one of the most popular NoSQL DBs delivering on the promise of high throughput and low latency. What started as a pure C code base is gradually being augmented with Rust due to the trifecta of safety, concurrency, and speed. A primary example is thre RedisJSON module which turns Redis into a document DB.<\/p>\n\n<p>The talk outlines the principal architecture of the re-implementation of RedisJSON, the challenges encountered and the solutions for these. The focus is on the practical aspects rather than conveying theoretical knowledge. A comparison with other open source document DB concludes this presentation, concentrating on latency and throughput aspects.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5472",
            "value": "Christoph Zimmermann"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/RedisJSON/RedisJSON2",
            "value": "github repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9313.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10214",
        "start": "13:50",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_python_sharing_memories",
        "title": "Sharing memories of Python and Rust",
        "subtitle": "The story of a lifetime inside Mercurial",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Mercurial version control system now has an option for running Rust code to improve performance. In this talk we will explore the challenges of using Rust efficiently inside a performance-sensitive Python project with more than 10 years of backwards compatiblity.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7143",
            "value": "Raphaël Gomès"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10214.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9127",
        "start": "14:20",
        "duration": "00:45",
        "room": "K.3.401",
        "slug": "rust_webgpu",
        "title": "Building WebGPU with Rust",
        "subtitle": "The new foundation for graphics and compute",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>WebGPU is a new graphics and compute API designed from the ground up by a W3C community group. It's a successor to WebGL, which also has a chance to become a standard on native platforms. We are going to talk about the API itself as well as our Rust-based implementation \"wgpu\".<\/p>",
        "description": "<p>Expected prior knowledge / intended audience: basic familiarity with one of the graphics APIs is good but not required.\nWe'll explain in details how this is different from existing APIs.<\/p>\n\n<p>\"wgpu\" is the native implementation of this API in Rust, running on top of Vulkan, Metal, D3D12, D3D11, and potentially OpenGL.\nThis is a talk about the API architecture being designed as well as our implementation of it.\nWe want to share the experience of leveraging the power of Rust ecosystem and language in order to build this level of abstraction.\nWe'll show a few demos and spread excitement about the new API.<\/p>\n\n<p>The talk is related to the Fosdem 2018 talk about gfx-rs: the old talk mentioned WebGPU as one of the clients for the low-level abstraction.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5057",
            "value": "Dzmitry Malyshau"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/gfx-rs/wgpu",
            "value": "wgpu-native implementation"
          },
          {
            "_href": "https://github.com/gfx-rs/wgpu-rs",
            "value": "WebGPU Rust API"
          },
          {
            "_href": "https://github.com/gpuweb",
            "value": "WebGPU community group"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9127.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10425",
        "start": "15:10",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_wasm_progress_2019",
        "title": "Progress of Rust and WASM in 2019",
        "subtitle": "The year in review",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There was a huge progress in Rust tools for WebAssembly in the last year. Let's review some of the most noticeable changes. The talk is mostly about wasm-bindgen.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7250",
            "value": "Ilya Baryshnikov"
          }
        },
        "links":
        [
          {
            "_href": "https://youtu.be/C10gSyxO4i4",
            "value": "My talk on RustCon Asia"
          },
          {
            "_href": "https://github.com/ibaryshnikov",
            "value": "GH page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10425.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10054",
        "start": "15:40",
        "duration": "00:25",
        "room": "K.3.401",
        "slug": "rust_vm_introspection",
        "title": "Rustifying the Virtual Machine Introspection ecosystem",
        "subtitle": "Why Rust is the best language for introspection agents in the future",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>From stealth malware analysis to OS hardening through fuzzing, virtual machine\nintrospection is expanding the possibilities offered by our hypervisors,\nshifting our view of virtual machines, from opaques containers to fully\ntransparent and instrumentable systems.<\/p>\n\n<p>Today the VMI ecosystem is made of a multitude of applications, targeting one\nhypervisor or emulator, with their own semantic library. (Examples includes\nDrakvuf, PANDA, PyREBox, icebox, etc...). If we want to make the most out of VMI\nin the future, we need to build the libraries that will unify this ecosystem and\nlet the developers focus on what matters: building quality VMI apps.<\/p>\n\n<p>This is where libmicrovmi comes into play. It aims to solve this problem, by\nproviding a core, foundation library, written in Rust, to be cross-platform,\nhypervisor-agnostic and emulator-agnostic, on top of which higher-level\nlibraries and apps can rebase.<\/p>\n\n<p>Rust makes a lot of sense for VMI for 2 main reasons:<\/p>\n\n<ul>\n<li>Rust is safe: considering that we are processing untrusted input from virtual\nmachines, we cannot allow any crash or exploitation in the introspection\nagent. Also one of our use case is OS hardening, which needs an excellent\nlevel of trust<\/li>\n<li>Rust is fast: processing an event requires to pause the VCPU. The longer the\npause, the more delayed the guest execution will be, and when scaling to\nthousands of events per second this can dramatically influence how many breakpoints\nyou are willing to put, especially on production systems. Speed matters.<\/li>\n<\/ul>\n\n\n<p>Therefore Rust is the de facto choice for VMI apps in the future, and we are\nbuilding it today, by providing libmicrovmi, a new foundation for VMI.<\/p>\n\n<p>Libmicrovmi has drivers for:<\/p>\n\n<ul>\n<li>Xen<\/li>\n<li>KVM<\/li>\n<li>Hyper-V (in progress)<\/li>\n<\/ul>",
        "description": "<h1>What is VMI ?<\/h1>\n\n<p><em>Vrtual Machine Introspection<\/em> is a concept born in a 2003 research paper titled\n\"A Virtual Machine Introspection Based Architecture for Intrusion Detection\".\nThe idea resides in inspecting and understanding the real-time high-level state\nof a virtual machine, based on the hardware layer, for security purposes.<\/p>\n\n<p>Since then the technology has made its way, from research and academic\ndevelopments to being fully integrated and supported into mainstream\nhypervisors, like Xen.<\/p>\n\n<h1>What are the use-cases ?<\/h1>\n\n<p>The initial population who adopted VMI has been malware sandbox providers. Since\ncommon malware had a tendency to hide from debuggers, the level of stealth\nreached with this technology made it perfectly suited for this job, alongside\nthe full system view.<\/p>\n\n<p>Today VMI has grown to be applied in various domains:<\/p>\n\n<ul>\n<li>Debugging<\/li>\n<li>Malware Analysis<\/li>\n<li>Live Memory Analysis<\/li>\n<li>OS Hardening<\/li>\n<li>Fuzzing<\/li>\n<\/ul>\n\n\n<h1>What is the state of the technology today ?<\/h1>\n\n<p>As of today, Xen is the leading hypevisor, haivng VMI APIs since 2011. And since\n2017, both KVM and VirtualBox have patches available, and even reviewed on the\nmailing list for KVM.<\/p>\n\n<p>Regarding the libraries available, LibVMI stands out, as it provides a unified,\nhypervisor-agnostic, VMI API to applications, and a well-known malware analysis\nframework (Drakvuf) is based on it.<\/p>\n\n<p>However, most of VMI applications today do not share the same common set of core\nlibraries, which makes the ecosystem fragmented and hard to deal with, where a lot\nof efforts is spent solving the same problems everyone has, isolated by their\nown stacks.<\/p>\n\n<h1>Why Rust ?<\/h1>\n\n<p>This is where Rust comes into play. The language itself combines 3 important features:<\/p>\n\n<ul>\n<li>Safety: new VMI applications have a focus on OS hardening, rebasing your trust\non an introspection agent to avoid a kernel compromise is a huge deal,\nespecially when the agent has high-privileges.<\/li>\n<li>Speed: the amount of hardware events that can you can handle per second will\ndefine how much impact your agent has on the guest execution. This has to be\nkept as low as possible, otherwise the technology's adoption won't go further\nthan private malware analysis systems.<\/li>\n<li>Cross-platform: Rust's build system and standard library allow to effortlessly\nbuild a cross-plaform library, which is a requirements to bring developers\nusing KVM, Hyper-V or even VirtualBox to share the same library.<\/li>\n<\/ul>\n\n\n<p>Building this core library that will unify the ecosystem is the goal of libmicrovmi.<\/p>\n\n<h1>Related work<\/h1>\n\n<p>I have been building a hypervisor-level debugger, based on LibVMI. It can\nintrospect a Windows guest and debug a specific process, while providing a GDB\nstub to be plugged into your favorite GDB fronted (IDA, radare2, etc ....)<\/p>\n\n<h1>Expected knowledge<\/h1>\n\n<p>The audience will need a bit of familiarity with virtualization concepts, this\nwill be enough to understand the idea of introspection.<\/p>\n\n<p>They can be totally new to Rust, as I once was a few months ago.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5503",
            "value": "Mathieu Tarral"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/Wenzel/libmicrovmi",
            "value": "libmicrovmi Github repo"
          },
          {
            "_href": "https://twitter.com/mtarral/status/1141832159457677317",
            "value": "demo of Xen mem-dump"
          },
          {
            "_href": "https://twitter.com/seguridadyredes/status/1153701146306994176",
            "value": "demo of KVM mem-dump"
          },
          {
            "_href": "https://twitter.com/mtarral/status/1195866380329005058?s=20",
            "value": "Hyper-v driver update"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10054.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9911",
        "start": "16:10",
        "duration": "00:45",
        "room": "K.3.401",
        "slug": "rust_dbus_library",
        "title": "zbus: yet another D-Bus library",
        "subtitle": "The why, how & WTH of creating a pure D-Bus Rust crate",
        "track": "Rust",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, I will present zbus, a D-Bus crate written from scratch. D-Bus is an inter-process communication mechanism, available and used on almost all modern Linux desktops and many embedded systems. I will start with why I felt the need to take this huge undertaking on my shoulders, followed by the design goals, the challenges faced and how I overcame them during the development.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1469",
            "value": "Zeeshan Ali"
          }
        },
        "links":
        [
          {
            "_href": "https://gitlab.freedesktop.org/zeenix/zbus/",
            "value": "Git repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9911.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "K.4.201",
    "event":
    [
      {
        "_id": "10143",
        "start": "10:05",
        "duration": "00:25",
        "room": "K.4.201",
        "slug": "debugging_hawktrace",
        "title": "Low-end platform profiling with HawkTracer profiler",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HawkTracer is low-overhead instrumentation-based profiler built at Amazon Video for platforms with limited capabilities. It's written in C but can be used almost with any other language (we've successfully used it with JavaScript, LUA and Python). It's highly extensible (at compile time) and portable so it can be run on almost any embedded device. In this talk I'll introduce the architecture of the profiler, present it's advantages and limitations, show how can you instrument the code and demonstrate the profiler in action by running it with an example cross-language (C++ and Python) project.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6168",
            "value": "Marcin Kolny"
          }
        },
        "links":
        [
          {
            "_href": "http://hawktracer.org",
            "value": "Project's homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10143.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9322",
        "start": "10:35",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_gdb_pipelines",
        "title": "GDB pipelines -- convenience iteration over inferior data structures",
        "subtitle": "Bringing MDB's \"walkers\" to GDB",
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We introduce a GDB plugin for working with large data structures in the inferior.<\/p>\n\n<p>This plugin brings some of the flexibility of Unix pipelines to the GDB command prompt, providing the ability to <em>conveniently<\/em> run some action on every element in a data structure that matches certain criteria.<\/p>\n\n<p>One big aim of this plugin is to make it easy and convenient for a user to write their own sub-commands to iterate over the data structures used in their own program.<\/p>\n\n<p>This is intended for anyone who has found difficulty inspecting large data structures from inside GDB.<\/p>",
        "description": "<p>MDB -- the debugger on Solaris -- has a feature called \"walkers\" that is used to great effect when inspecting the contents of large data structures in the Solaris Kernel.<\/p>\n\n<p>We introduce a GDB plugin to provide the same type of functionality.<\/p>\n\n<p>Similar to Unix pipelines, one can now flexibly write a surprisingly powerful command by combining several \"walkers\".<\/p>\n\n<p>Some examples are:\n- Search an inferior data structure for nodes that are malformed.<\/p>\n\n<pre><code> gdb-pipe &lt;mywalker&gt; &lt;startnode&gt; | if ! &lt;some verification test&gt;\n<\/code><\/pre>\n\n<ul>\n<li><p>Put breakpoints on member functions of those nodes in a data structure matching some criteria.\n   gdb-pipe &lt;mywalker> &lt;startnode> | if &lt;interesting-check> | show break {}->function-member<\/p><\/li>\n<li><p>Put breakpoints on a given function when passed a node that matches some criteria.\n   gdb-pipe &lt;mywalker> &lt;startnode> | if &lt;interesting-check> | show break somefunc if &lt;arg> == {}<\/p><\/li>\n<\/ul>\n\n\n<p>This plugin has a strong aim to make it easy for users to write \"walkers\" over their own data structures, and already has \"walkers\" for the open source projects \"neovim\" and \"GCC\".<\/p>\n\n<p>We would like to discuss possible future directions for this plugin with regards to speed improvements to work on extremely large data structures, and how there could be a tie-in with pretty-printers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6632",
            "value": "Matthew Malcomson"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/hardenedapple/gdb-walkers",
            "value": "Plugin repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9322.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10515",
        "start": "11:10",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_gdb_tui",
        "title": "The GDB Text User Interface",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GDB has had a curses-based interface for many years.  Come see what new features are available and how it can improve your debugging experience.<\/p>",
        "description": "<p>This talk will cover GDB's text user interface (the \"TUI\").  In particular we'll discuss the benefits of the rewrite, the new features that are available, and how you can easily extend it yourself.  A fun demo will be included.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1585",
            "value": "Tom Tromey"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10515.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10404",
        "start": "11:45",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "debugging_memcheck_reloaded",
        "title": "Memcheck Reloaded",
        "subtitle": "dealing with compiler-generated branches on undefined values",
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Valgrind's Memcheck tool reports various kinds of errors. One of the most important are those where an if-condition or a memory address uses undefined data.  Detecting that reliably on optimized code is challenging, and recent compiler development has made the problem worse.<\/p>",
        "description": "<p>Two years ago, at FOSDEM 2018, I did a talk describing the techniques Memcheck uses to achieve a very low false positive rate.  But by 2018 both GCC and Clang were routinely emitting code with branches on uninitialised data. Surprisingly, there are situations where such code is correct.  Unfortunately Memcheck assumes that every conditional branch is important and so emits many complaints when this happens.<\/p>\n\n<p>The worst thing was, this problem couldn't be solved using the bag of tricks we'd accumulated over Memcheck's decade-plus lifetime.  Our options didn't look good.  But in early 2019 it became clear how to fix this: enhance Valgrind's trace generation machinery to analyse more than one basic block at a time, and use that to recover the source-level &amp;&amp;-expressions, which can then be instrumented precisely.  This talk tells the story.<\/p>\n\n<p>The implementation (appears to!) work.  If all goes well, it will ship in the upcoming 3.16 release.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "143",
            "value": "Julian Seward"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10404.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9730",
        "start": "12:30",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_strace_modern",
        "title": "Modern strace",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>strace is a diagnostic, debugging and instructional utility for Linux. It is used to monitor and tamper with interactions between processes and the Linux kernel, which include system calls, signal deliveries, and changes of process state. In this talk the maintainer of strace will describe new features implemented since FOSDEM 2018.<\/p>",
        "description": "<p>Several interesting features were implemented within strace project since FOSDEM 2018, including:<\/p>\n\n<ul>\n<li>seccomp-assisted system call filtering<\/li>\n<li>system call return status filtering<\/li>\n<li>PTRACE_GET_SYSCALL_INFO API support<\/li>\n<li>new options: -DD, -DDD, -X, -z, -Z<\/li>\n<\/ul>\n\n\n<p>In this talk the maintainer of strace will describe these new features and demonstrate what kinds of problems they help to solve.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3674",
            "value": "Dmitry Levin"
          }
        },
        "links":
        [
          {
            "_href": "https://strace.io/",
            "value": "strace homepage"
          },
          {
            "_href": "https://gitlab.com/strace/strace.git",
            "value": "source code @gitlab"
          },
          {
            "_href": "https://github.com/strace/strace.git",
            "value": "source code @github"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9730.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9721",
        "start": "13:05",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_strace_perfotmance",
        "title": "strace: fight for performance",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The talk gives an overview of various optimisations implemented in strace over the past several years. While most of them are quite trivial (like caching of frequently-used data or avoiding syscalls whenever possible), some of them are a bit more tricky (like usage of seccomp BPF programs for avoiding excessive ptrace stops) and/or target more specific use cases (like the infamous thread queueing patch[1], which was carried as a RHEL downstream patch for almost 10 years).<\/p>\n\n<p>[1] https://gitlab.com/strace/strace/commit/e0f0071b36215de8a592bf41ec007a794b550d45<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6919",
            "value": "Eugene Syromyatnikov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9721.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10456",
        "start": "13:40",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_strace_bpf",
        "title": "strace --seccomp-bpf: a look hunder the hood",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>strace is known to add significant overhead to any application it traces.\nEven when users are interested in a handful of syscalls, strace will by\ndefault intercept all syscalls made by the observed processes, involving\nseveral context switches per syscall.  Since strace v5.3, the\n<code>--seccomp-bpf<\/code> option allows reducing this overhead, by stopping observed\nprocesses only at syscalls of interest.  This option relies on seccomp-bpf\nand inherits a few of its limitations.<\/p>\n\n<p>In this talk, we will describe the default behavior of ptrace and strace,\nto understand the problem <code>--seccomp-bpf<\/code> addresses.  We will then detail\nthe inner workings of the new option, as seen from ptrace (seccomp-stops)\nand bpf (syscall matching algorithms).  Finally, we'll discuss limitations\nof the new option and avenues for improvement.<\/p>",
        "description": "<ul>\n<li>Problem addressed and ptrace default behavior<\/li>\n<li>seccomp-bpf, <code>SECCOMP_RET_TRACE<\/code>, and the new behavior<\/li>\n<li>cBPF syscall matching algorithms<\/li>\n<li>Main limitations: working together with <code>-p<\/code> and <code>-f<\/code><\/li>\n<li>Avenues for improvements<\/li>\n<\/ul>\n\n\n<p>Part of this talk is covered in the following blog post:\n<a href=\"https://pchaigno.github.io/strace/2019/10/02/introducing-strace-seccomp-bpf.html\">https://pchaigno.github.io/strace/2019/10/02/introducing-strace-seccomp-bpf.html<\/a>.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6037",
            "value": "Paul Chaignon"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10456.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10410",
        "start": "14:15",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "debugging_bpf",
        "title": "Tools and mechanisms to debug BPF programs",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>By allowing to safely load programs from user space and to execute them in the kernel, eBPF (extended Berkeley Packet Filter) has brought new possibilities to the Linux kernel, in particular in terms of tracing and network processing.<\/p>\n\n<p>But when a program fails to load, or when it does not return the expected values, what tools do we have to examine, inspect and debug eBPF objects? This talk focuses on the different tools and mechanisms available to help eBPF developers debug their programs, at the different stages of the workflow. From bpftool to test runs, let's find the best way to track bugs!<\/p>",
        "description": "<p>I am not sure how long the time slots for the debugging devroom are, so the\ncontent would be adapted according to the duration of the talk. The idea is to:<\/p>\n\n<ol>\n<li>Very briefly introduce the existing tools/mechanisms for debugging BPF\nprograms at each stage of the workflow<\/li>\n<li>Spend some time on a more in-depth introduction to bpftool, which can be\nused to perform a variety of operations on eBPF programs, maps, or BTF\nobjects<\/li>\n<li>Mention leads for future work<\/li>\n<\/ol>\n\n\n<p>In more details, this would look like:<\/p>\n\n<ol>\n<li>Different tools to debug<\/li>\n<\/ol>\n\n\n<p>1.1 Compilation time (make sure program is generated as intended)<\/p>\n\n<ul>\n<li>LLVM backend<\/li>\n<li>llvm-objdump<\/li>\n<li>eBPF assembly<\/li>\n<\/ul>\n\n\n<p>1.2 Load time / Verifier / JIT compile time (make sure program loads successfully)<\/p>\n\n<ul>\n<li>libbpf / ip / tc<\/li>\n<li>verifier logs, kernel logs, extack messages<\/li>\n<li>Documentation<\/li>\n<li>bpftool<\/li>\n<\/ul>\n\n\n<p>1.3 Runtime (make sure program return as expected)<\/p>\n\n<ul>\n<li>bpftool<\/li>\n<li>bpf<em>trace<\/em>printk() helper / perf events<\/li>\n<li>(user space BPF machines)<\/li>\n<li>BPF<em>PROG<\/em>TEST_RUN<\/li>\n<li>bpftool prog run<\/li>\n<li>perf annotations<\/li>\n<li>BTF debug information<\/li>\n<li>BPF trampolines: spy on BPF with BPF<\/li>\n<\/ul>\n\n\n<p>1.4 User space (develop programs that manipulate BPF objects)<\/p>\n\n<ul>\n<li>strace, valgrind support for bpf()<\/li>\n<li>probing kernel with bpftool<\/li>\n<li><p>using tools to generate BPF (bcc, bpftrace, libkefir, ...)<\/p><\/li>\n<li><p>bpftool introduction (with examples)<\/p><\/li>\n<li><p>listing objects<\/p><\/li>\n<li>loading programs, attaching programs, creating maps<\/li>\n<li>performing “test runs”<\/li>\n<li>probing kernel for existing features<\/li>\n<li><p>taking over the world<\/p><\/li>\n<li><p>In the future?<\/p><\/li>\n<li><p>checking a program loads: bpftool prog probe object_file.o<\/p><\/li>\n<li>debugger: break points, dump for registers/stack/context?\n(Complete the support (hooks exist) in GDB? Extend BPF<em>PROG<\/em>TEST_RUN\ninfrastructure?)<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "4933",
            "value": "Quentin Monnet"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10410.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10393",
        "start": "15:00",
        "duration": "00:15",
        "room": "K.4.201",
        "slug": "debugging_mini",
        "title": "Support for mini-debuginfo in LLDB",
        "subtitle": "Debugging without installing debug-symbols, or how to read the .gnu_debugdata section.",
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The \"official\" mini-debuginfo man-page describes the topic best:<\/p>\n\n<blockquote><p>Some systems ship pre-built executables and libraries that have a\nspecial <code>.gnu_debugdata<\/code> section. This feature is called MiniDebugInfo.\nThis section holds an LZMA-compressed object and is used to supply extra\nsymbols for backtraces.<\/p>\n\n<p>The intent of this section is to provide extra minimal debugging information\nfor use in simple backtraces. It is not intended to be a replacement for\nfull separate debugging information (see Separate Debug Files).<\/p><\/blockquote>\n\n<p>In this talk I'll explain what it took to interpret support for mini-debuginfo\nin LLDB, how we've tested it, and what to think about when implementing this\nsupport (e.g. merging <code>.symtab<\/code> and <code>.gnu_debugdata<\/code> sections).<\/p>",
        "description": "<p>If the <code>.symtab<\/code> section is stripped from the binary it might be that\nthere's a <code>.gnu_debugdata<\/code> section which contains a smaller <code>.symtab<\/code> in\norder to provide enough information to create a backtrace with function\nnames or to set and hit a breakpoint on a function name.<\/p>\n\n<p>My change looks for a <code>.gnu_debugdata<\/code> section in the ELF object file.\nThe <code>.gnu_debugdata<\/code> section contains a xz-compressed ELF file with a\n<code>.symtab<\/code> section inside. Symbols from that compressed <code>.symtab<\/code> section\nare merged with the main object file's <code>.dynsym<\/code> symbols (if any).\nIn addition we always load the <code>.dynsym<\/code> even if there's a <code>.symtab<\/code>\nsection.<\/p>\n\n<p>For example, the Fedora and RHEL operating systems strip their binaries\nbut keep a <code>.gnu_debugdata<\/code> section. While gdb already can read this\nsection, LLDB until my patch couldn't. To test this patch on a\nFedora or RHEL operating system, try to set a breakpoint on the \"help\"\nsymbol in the \"zip\" binary. Before this patch, only GDB can set this\nbreakpoint; now LLDB also can do so without installing extra debug\nsymbols:<\/p>\n\n<pre><code>lldb /usr/bin/zip -b -o \"b help\" -o \"r\" -o \"bt\" -- -h\n<\/code><\/pre>\n\n<p>The above line runs LLDB in batch mode and on the \"/usr/bin/zip -h\"\ntarget:<\/p>\n\n<pre><code>(lldb) target create \"/usr/bin/zip\"\nCurrent executable set to '/usr/bin/zip' (x86_64).\n(lldb) settings set -- target.run-args  \"-h\"\n<\/code><\/pre>\n\n<p>Before the program starts, we set a breakpoint on the \"help\" symbol:<\/p>\n\n<pre><code>(lldb) b help\nBreakpoint 1: where = zip`help, address = 0x00000000004093b0\n<\/code><\/pre>\n\n<p>Once the program is run and has hit the breakpoint we ask for a\nbacktrace:<\/p>\n\n<pre><code>(lldb) r\nProcess 10073 stopped\n* thread #1, name = 'zip', stop reason = breakpoint 1.1\n    frame #0: 0x00000000004093b0 zip`help\nzip`help:\n-&gt;  0x4093b0 &lt;+0&gt;:  pushq  %r12\n    0x4093b2 &lt;+2&gt;:  movq   0x2af5f(%rip), %rsi       ;  + 4056\n    0x4093b9 &lt;+9&gt;:  movl   $0x1, %edi\n    0x4093be &lt;+14&gt;: xorl   %eax, %eax\n\nProcess 10073 launched: '/usr/bin/zip' (x86_64)\n(lldb) bt\n* thread #1, name = 'zip', stop reason = breakpoint 1.1\n  * frame #0: 0x00000000004093b0 zip`help\n    frame #1: 0x0000000000403970 zip`main + 3248\n    frame #2: 0x00007ffff7d8bf33 libc.so.6`__libc_start_main + 243\n    frame #3: 0x0000000000408cee zip`_start + 46\n<\/code><\/pre>\n\n<p>In order to support the <code>.gnu_debugdata<\/code> section, one has to have LZMA\ndevelopment headers installed. The CMake section, that controls this\npart looks for the LZMA headers and enables <code>.gnu_debugdata<\/code> support by\ndefault if they are found; otherwise or if explicitly requested, the\nminidebuginfo support is disabled.<\/p>\n\n<p>GDB supports the \"mini debuginfo\" section <code>.gnu_debugdata<\/code> since v7.6\n(2013).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7234",
            "value": "Konrad Kleine"
          }
        },
        "links":
        [
          {
            "_href": "https://reviews.llvm.org/D66791",
            "value": "Patch to support mini-debuginfo in LLVM"
          },
          {
            "_href": "https://sourceware.org/gdb/current/onlinedocs/gdb/MiniDebugInfo.html#MiniDebugInfo",
            "value": "Main resource for mini-debuginfo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10393.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10308",
        "start": "15:20",
        "duration": "00:40",
        "room": "K.4.201",
        "slug": "debugging_debuginfod",
        "title": "The elfutils debuginfod server",
        "subtitle": [],
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Debugging data is a necessary evil. It is necessary for running debuggers in situ, some tracing tools, or for coredump analysis. It is evil because it is big - potentially many times the size of the binaries. Therefore, software distributions have conflicting needs to generate &amp; keep this data but not burden everyone with its storage.<\/p>\n\n<p>We will review some degrees of freedom for debugging data distribution, across compiled languages and OS distributions, identifying some of the best practices. We will identify the remaining shortcomings that necessitate exploring yet another way of making debuginfo data available needed.<\/p>\n\n<p>We will present the elfutils debuginfo-server prototype, where a web service offers a lightweight, build-id-indexed lookup of debuginfo-related data on demand. This service is designed to run on a nearby host, private or shared within teams, or even by OS distributions. Clients built into various debugging type tools will be demonstrated.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "160",
            "value": "Mark Wielaard"
          },
          {
            "_id": "3036",
            "value": "Frank Ch. Eigler"
          }
        ],
        "links":
        [
          {
            "_href": "https://gcc.gnu.org/wiki/cauldron2019#cauldron2019talks.The_elfutils_debuginfo_server",
            "value": "cauldron 2019 talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10308.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10354",
        "start": "16:05",
        "duration": "00:30",
        "room": "K.4.201",
        "slug": "debugging_kubernetes",
        "title": "Debugging apps running in Kubernetes",
        "subtitle": "An overview of the tooling available",
        "track": "Debugging Tools",
        "type": "devroom",
        "language": [],
        "abstract": "<p>New tools are coming out to make it possible to add breakpoints and debug running code in a Kubernetes Pod. This talk will present an overview of some of these tools. We'll cover tools that make it easy to update the code that's running in a Pod (Skaffold/Ksync/Telepresence). And we'll also cover how to connect your IDE to the code and set breakpoints.<\/p>",
        "description": "<ul>\n<li>A really brief, high level overview of k8s pods &amp; how to run an application there<\/li>\n<li>List out some the tools available that make debugging possible<\/li>\n<li>Overview of how each tool differs<\/li>\n<li>A demo of 2 different debugging tools<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6208",
            "value": "Jeff Knurek"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10354.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.4.401",
    "event":
    [
      {
        "_id": "9292",
        "start": "09:00",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "startup_gen",
        "title": "BSP generator for 3000+ ARM microcontrollers",
        "subtitle": [],
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For embedded developers using alternative programming languages, but also for anyone using third party driver frameworks such as libopencm3, one of the main pain points to start using a microcontroller is to make a Board Support Package.<\/p>\n\n<p>Things like linker script or startup code (crt0) not only require skills, but also information that are not always easily accessible.<\/p>\n\n<p>In this talk we will present a tool that generates linker script, startup code, and low level hardware binding for 3000+ ARM microcontrollers using information extracted from archives provided as part of the ARM Cortex Microcontroller Software Interface Standard (CMSIS).<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3897",
            "value": "Fabien Chouteau"
          }
        },
        "links":
        [
          {
            "_href": "http://www.keil.com/pack/doc/CMSIS/Pack/html/index.html",
            "value": "CMSIS packs"
          },
          {
            "_href": "https://github.com/AdaCore/startup-gen",
            "value": "Repository (private for now, will be public soon)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9292.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9681",
        "start": "09:30",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "fpga_hw_dbg",
        "title": "On-hardware debugging of IP cores with free tools",
        "subtitle": [],
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An approach to challenges of an on-FPGA debugging of IP cores based on\nfree software tools is demonstrated. Various aspects and related problems\nof an on-hardware debugging are presented along with the tools to\naddress them, such as OpenOCD, sigrok/PulseView, GHDL, etc.  Real-life\nworking configuration and missing bits of software are accompanied by\nthe live debug session demo running on Open-source Hardware.<\/p>",
        "description": "<p>Debugging of hardware blocks on an FPGA is always challenging and may\nbe frustrating, especially with no reliable tools at hands. Way too\noften the process turns into developing and debugging of the tools,\ninstead of a target design.<\/p>\n\n<p>Commercial solutions are available (SignalTap, ChipScope, Synopsys\nIdentify RTL Debugger, MicroSemi Smart Debug), at the same time there\nare a lot of well known problems associated with them: vendor lock,\nsingle target, closed source and not always flexible enough, license\nterms and costs.<\/p>\n\n<p>Owing to free software developers essential tools for\non-hardware debugging of IP cores are available today.  However there\nare problems associated with these tools too.  Among the most notable\nones are a weak integration between separate tools and small bits of\ncode and config files missing here and there. A working combination of\ntools along with explanations of how they may be used together to\ndebug IP cores is provided.  A presentation covers such free\nsoftware as GHDL, sigrok/PulseView, and OpenOCD.  Source code of free\nIP cores, all configuration and script files and presentation slides\nwill be available in a dedicated repository on github.<\/p>\n\n<p>A live demonstration of the PulseView connected to an in-FPGA\nlogic analyzer via JTAG interface and working in parallel with a gdb\ndebug session on a RISC-V soft-core CPU in the same FPGA with an\nopen and low-cost hardware will be presented.<\/p>\n\n<p>An outline of the open tasks and possible future development\ndirections concludes the presentation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6861",
            "value": "Anton Kuzmin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9681.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9858",
        "start": "10:00",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "oshw_ci",
        "title": "Continuous Integration for Open Hardware Projects",
        "subtitle": [],
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While it is standard to deploy every single code commit using CI systems and deploy new code automatically we are only at the beginning of automation for designing hardware. In this talk I will share the experience with continuous integration tools in FOSSASIA hardware projects, and specifically our Pocket Science Lab. I will outline opportunities and challenges for implementing CI processes for hardware.<\/p>",
        "description": "<p>While it is standard to deploy every single code commit using CI systems and deploy new code automatically we are only at the beginning of automation for designing hardware. In this talk I will share the experience with continuous integration tools in FOSSASIA hardware projects, and specifically our Pocket Science Lab. I will outline opportunities and challenges for implementing CI processes for hardware.<\/p>\n\n<p>With PSlab apart from the firmware we have connected CI processes to our hardware repository. This means each design change can be automatically build into a digital prototype. Electronics materials are largely standardized and with KiCad we are even able to create package lists and Gerber files automatically. Furthermore we deploy to Kitspace using a yaml file. Here any user can order all components and the board through a one-click process. Every version could easily be built here.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2541",
            "value": "Mario Behling"
          }
        },
        "links":
        [
          {
            "_href": "https://pslab.io",
            "value": "Pocket Science Lab"
          },
          {
            "_href": "https://fossasia.org",
            "value": "FOSSASIA"
          },
          {
            "_href": "https://github.com/fossasia/pslab-hardware",
            "value": "PSLab Hardware Repository"
          },
          {
            "_href": "https://kitspace.org/boards/github.com/fossasia/pslab-hardware/",
            "value": "PSLab at Kitspace"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9858.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10219",
        "start": "10:30",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "firmware_test",
        "title": "Open Source Firmware Testing at Facebook",
        "subtitle": "If you don't test your firmware, your firmware fails you",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We talked extensively about LinuxBoot, a Linux-based environment intended to be integrated into the firmware on the boot ROM. This time we want to talk about how do we test LinuxBoot before it goes to production. We will talk about ConTest, an open-source continuous and on-demand system testing framework that we designed to be modular, validating, and infrastructure-agnostic, and how it is helping us validate open source firmware on our datacenter platforms.<\/p>",
        "description": "<p>With LinuxBoot we became vendors of our own system firmware. In order to go to production we need a reliable quality assurance process, and firmware testing was a necessity. In this talk we are presenting ConTest (short for Continuous Testing), a modular framework aimed at automating system testing workflows, like firmware validation and provisioning. ConTest has several goals in mind: being open source and community-driven; validate as much as possible at compile time and at job submission time, to minimize unnecessary operations and run-time failures; being lightweight and infrastructure-agnostic, so it can run in Facebook’s datacenters as well as on a Raspberry Pi; being composable, thanks to an interface-and-plugins architecture; being user-oriented so that it’s not necessary to know the internals to use it effectively; and being metrics and events driven, so that users can gain valuable insights about their jobs, more than just success rate (e.g. micro-benchmarking and trend analysis).<\/p>\n\n<p>ConTest is aimed at anyone who need to automate system-level testing. Various plugins are provided out of the box, with examples on how to use them. The users can combine them like building blocks using a simple job description format based on JSON, and test scenarios of variable complexity. When default plugins are not enough, for example in order to talk to a custom service, users can develop new plugins, and plug them just like if they were part of the core framework. Open-sourcing your own plugins is always appreciated!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5790",
            "value": "Andrea Barberio"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/facebookincubator/contest",
            "value": "Continuous and on-demand system testing"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10219.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9167",
        "start": "11:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "freedomev",
        "title": "FreedomEV 2.0",
        "subtitle": "From Tesla Hacking to a free mobility stack",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Last year the FreedomEV project was launched as an addon to the existing software for the older Tesla Model S and Tesla Model X cars.<\/p>\n\n<p>FreedomEV envisions a future without mass surveillance, with full control over our own car.<\/p>\n\n<p>Today we launch FreedomEV 2.0.\nMore features, more supported cars and where we are now.<\/p>\n\n<p>Let us play with our car!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5425",
            "value": "Jasper Nuyens"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9167.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9421",
        "start": "12:00",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "paduak_toolchain",
        "title": "A free toolchain for 0.01 € - computers",
        "subtitle": "The free toolchain for the Padauk 8-bit microcontrollers",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Taiwanese company Padauk makes small 8-bit microcontrollers, the smallest of which are available at 0.01 € even in small quantities. Even the larger ones are just a few cents; a particularly interestign feature is the hardware multithreading support available in larger devices.\nUntil recently, the only available toolchain was Padauk's non-free toolchain based around their \"MINI-C\" IDE (which despite, the name, ist just a bit of C-like syntactic sugar coating for assembler, and in no way a C implementation).<\/p>\n\n<p>In 2019, an effort to provide a free alternative resulted in a full free toolchain. Documentation beyond that provided by Padauk was created by reverse-engineering. A free design for a programmer along with firmware was created. Assembler, simulator and a Small Device C Compiler (SDCC) backend were written.<\/p>",
        "description": "<p>The Padauk microcontrollers (µC) are small 8-bit Systems-on-a-Chip (SoC). Their program memory (PROM or Flash) is 0.5 KW to 4 KW with word sizes from 13 to 16 bit. Their data memory is 60 B to 256 B with 8-bit Bytes. The µC only have few peripherals; however, some of the larger devices are barrel processors with support for up to 8 hardware threads. This allows the emulation of even timing-critical peripherals in software. Padauk also supplies a programmer and a non-free \"MINI-C\" IDE. There is a lack of documentation when it comes to aspects not needed for users of MINI-C. In particular, there is no documentation of opcodes and very little information on the programming protocol.\nThere are 4 subarchitectures, which we name by the word size in the program memory pdk13, pdk14, pdk15 and pdk16. There is some variation in the form of optional instructions within the subarchitectures.<\/p>\n\n<p>In 2019, a full free toolchain for these µC was created.\nThe necessary documentation was reverse-engineered. A free programmer design and firmware was created. For the pdk13, pdk14 and pdk15, we wrote free assemblers and simulators. We also wrote an SDCC backend for these. SDCC is a free C compiler that emphasizes standard-compliance and generating efficient code for small devices; while not up to the level of GCC and LLVM it tends to hold up well against many non-free compilers targetting small devices (see e.g. the FOSDEM 2018 talk \"The free toolchain for the STM8\"). While stack handling on the Padauk µC is much better than on e.g. small Mirochip PIC devices, it is still not efficient (in particular, there is no stack-pointer-relative addressing mode). Thus SDCC does not place local variables on the stack by default, which makes functions non-reentrant and is not standard-compliant, but a common choice in such cases (see e.g. the mcs51 backend in SDCC or Keil for MCS-51). However, this approach does not work well for devices with hardware-multithreading (i.e. few pdk14 and all pdk16).<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2698",
            "value": "Philipp Klaus Krause"
          }
        },
        "links":
        [
          {
            "_href": "http://sdcc.sourceforge.net/",
            "value": "Small Device C Compiler, assembler, simulator"
          },
          {
            "_href": "https://github.com/free-pdk/",
            "value": "Programmer, documentation, sample code"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9421.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10452",
        "start": "12:30",
        "duration": "00:25",
        "room": "K.4.401",
        "slug": "coreboot_amd",
        "title": "Status of AMD platforms in coreboot",
        "subtitle": [],
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The presentation is about AMD's involvement in coreboot evolution and development. Gives a high-level overview of the engagement of the silicon vendor in the coreboot project history. The presentation may contain a little bit of technical aspects of firmware and BIOS. However, the intended audience is not only firmware and BIOS developers, but also free and libre hardware enthusiasts too. If anybody is interested in the future of famous platforms like Asus KGPE-D16, Lenovo G505S, PC Engines apu1/apu2, please attend the presentation.<\/p>",
        "description": "<p>The history of AMD cooperation in coreboot projects reaches 2007 where the\nfirst contribution appeared for the Geode LX processors. AMD's open-source\nsupport continued for many years until now (with some break). This presentation\nwill briefly introduce the history of AMD and coreboot, the evolution of the\ncode, processors, creation of CIMX and AGESA and so on. It will also show the\ngradual change in the AMD attitude to open-source and introduction of binary\nplatform initialization. Binary blobs, very disliked by the open-source\ncommunity started to cause problems and raised the needs for workarounds to\nsupport basic processor features. Soon after that AMD stopped supporting the\ncoreboot community. Moreover, recent coreboot releases started to enforce\ncertain requirements on the features supported by the silicon code base. Aging\nplatforms kept losing interest and many of them (including fully open ones) are\nbeing dropped from the main tree. Nowadays AMD released the newest AGESA with\nthe cooperation of hired coreboot developers, but only for Google and their\nChromebooks based on Ryzen processors. These are hard times for open firmware\non AMD platforms. If you are curious about what is the present status of AMD\nboards and hardware (for example famous Asus KGPE-D16, Lenovo G505S, PC Engines\napu1/apu2) in coreboot and what future awaits them, this presentation will give\nyou a good overview.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7269",
            "value": "Michał Żygowski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10452.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10650",
        "start": "13:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "olimex_oshw",
        "title": "Open Source Hardware for Industrial use",
        "subtitle": "OSHW model has benefits for SOC vendors, industrial manufacturers and end users",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Olimex is designing Open Source Hardware Linux computers since 2012.\nThey are adopted by hundreds of manufacturers all around the world and prove the Open Source business model is sustainable.\nThe lecture is about the advantages which OSHW bring to the industrial vendors and what drives their decision to use our boards.\nWe will explain the benefits for the SOC vendors to have OSHW designs with their ICs, the end user benefits and how OSHW helps us to excel our products and make them better and better.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1641",
            "value": "Tsvetan Usunov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10650.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10707",
        "start": "14:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "videobox",
        "title": "FOSDEM Video Box",
        "subtitle": "A bespoke HDMI capture device for conferences.",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A bespoke OSHW HDMI video capture solution is being developed for use at FOSDEM and other open source conferences. This talk will explain the what, why, how and hopefully when.<\/p>",
        "description": "<p>FOSDEM is unique in that it has 750+ talks on two days, with more than 28 parallel tracks. All are captured and streamed out live, and a sanitised version of each talk is re-encoded for separate viewing after the event. For each track, there are (at least) two capture boxes, one for the speakers' laptop (which also feeds the projector), and at least one for a camera. This means FOSDEM has close to 60 video capture boxes deployed.<\/p>\n\n<p>The FOSDEM video boxes are also used at several other conferences, and we are in active contact with several more, as each conference basically has the same problem to solve, albeit at a smaller scale than FOSDEM.<\/p>\n\n<p>Today, our capture boxes are an amalgamation of many different devices tied together, and while the whole is working surprisingly well, it is far from ideal. Some bits are non-free, some bits are hard or even impossible to control, and the result is bulky and, relatively speaking, expensive. Sourcing the exact same components again to expand the current array of boxes is nigh impossible, and the bulk of these boxes means that deployment is more of a hassle than it could be.<\/p>\n\n<p>To solve almost all of our issues, we are creating a bespoke HDMI capture solution by tying a HDMI-to-parallel-RGB decoder chip to the camera input of the venerable Allwinner A20 SoC. The Allwinner A20 was chosen due to its feature set, large community (linux-sunxi), its advanced upstream support and the availability of OSHW board designs. We were lucky to find a suitable board in the Olimex Lime2 (which is OSHW), which exposes all the necessary IO pins on pinheaders.<\/p>\n\n<p>Capturing 1280x720@50Hz, encoding it to h.264 for local storage and streaming over the network, while displaying the captured frames directly to HDMI or VGA (projector) and a status LCD, while also capturing (and passing through) audio is a challenge on this cheap, low power but open hardware. It forces us to make use of a wide array of SoC HW blocks, not all of which previously had driver support, and we are close to saturate the available memory and bus bandwidth.<\/p>\n\n<p>So while a good part of this talk is about describing the bigger problem we are trying to solve, this project very much is an issue of hardware enablement.<\/p>",
        "persons":
        [
          {
            "_id": "240",
            "value": "Mark Van den Borre"
          },
          {
            "_id": "577",
            "value": "Luc Verhaegen"
          },
          {
            "_id": "664",
            "value": "Gerry Demaret"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10707.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10732",
        "start": "15:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "oshw_custom",
        "title": "Using OSHW and OSS for building your custom hardware platform",
        "subtitle": "Lessons learned from building a custom hardware platform.",
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The lecture describes a journey (and bunch of bragging stories) of designing and implementing an extendable hardware platform utilizing OSHW and OSS.<\/p>",
        "description": "<p>We talk about:<\/p>\n\n<ul>\n<li>business requirements and how they affected the choice of hardware platform (Olimex Lime2)<\/li>\n<li>hardware bugs how they are related to tight deadlines<\/li>\n<li>what is actually needed to build a custom shield<\/li>\n<li>maintaining and administering the whole platform<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7384",
            "value": "Priit Laes"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10732.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10670",
        "start": "16:00",
        "duration": "00:55",
        "room": "K.4.401",
        "slug": "replicant",
        "title": "Extending the lifetime of smartphones with Replicant, a fully free Android distribution",
        "subtitle": [],
        "track": "Hardware Enablement",
        "type": "devroom",
        "language": [],
        "abstract": "<p>After a very quick introduction on Replicant and the smartphones ecosystem, we will look at what affects smartphones' and tablets' lifetime and how to increase it by making Replicant more sustainable.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7334",
            "value": "Denis Carikli (GNUtoo)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10670.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "K.4.601",
    "event":
    [
      {
        "_id": "9647",
        "start": "09:00",
        "duration": "00:50",
        "room": "K.4.601",
        "slug": "uk_sel4",
        "title": "seL4 Microkernel Status Update",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>I will give an overview of where seL4 stands today in terms of functionality, verification, ecosystem, deployment and community. The focus will be on what has happened in seL4 land over the past 12 months, which is a lot: seL4 Foundation, RISC-V support and introducing time protection.<\/p>",
        "description": "<p>The biggest news of the year is that we are in the process of setting up the seL4 Foundation, as an open, transparent and neutral organisation tasked with growing the seL4 ecosystem. It will bring together developers of the seL4 kernel, developers of seL4-based components and frameworks, and those deploying seL4-based systems. Its focus will be on coordinating, directing and standardising development of the seL4 ecosystem in order to reduce barriers to adoption, raising funds for accelerating development, and ensuring clarity of verification claims. I will report on the state of this.<\/p>\n\n<p>The other big development is that we are closing in on completing verified seL4 on the open RISC-V architecture. This includes the functional correctness proof (that guarantees that the kernel is free of implementation bugs), the binary correctness proof (which guarantees that the compiler did not introduce bugs) and the tranition to the new mixed-criticality scheduling model, which supports the safe co-location of critical real-time software with untrusted components, even if the latter can preempt the former.<\/p>\n\n<p>Finally, on the research side we have introduced the new concept of <em>time protection<\/em> (the temporal equivalent of the established memory protection) that allows us to systematically prevent information leakage through timing channels.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6203",
            "value": "Gernot Heiser"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9647.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9408",
        "start": "10:00",
        "duration": "00:35",
        "room": "K.4.601",
        "slug": "uk_m3",
        "title": "M³: Taking Microkernels to the Next Level",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Current microkernels have shown to provide advantages in terms of security, robustness, and flexibility of systems. However, in recent years, the hardware added new challenges that need to be addressed as well, demanding approaches that include the hardware into the picture. First, hardware is getting more and more heterogeneous and consists not only of general-purpose cores, but contains also various accelerators. Second, system designers need to integrate untrusted third-party components (e.g., accelerators or modems) to meet today's performance, energy, and development-time demands. And third, security vulnerabilities such as Meltdown, Spectre, and Fallout have shown that today's complex general-purpose cores should not be trusted anymore to properly enforce isolation boundaries between different software components.<\/p>\n\n<p>In my talk, I will present a new system architecture that takes existing microkernel ideas to the \"next level\" to address the mentioned challenges. We use a hardware/operating system co-design consisting of a small and simple hardware component, called <em>trusted communication unit<\/em> (TCU), that we add next to each processing element (core, accelerator, modem, etc.) and an operating system, called <em>M³<\/em>, that takes advantage of it. The TCU provides a uniform interface for all processing elements, simplifying the management and usage of heterogeneous processing elements, and enables secure communication between arbitrary processing elements. M³ is designed as a microkernel-based system and runs its components on different processing elements with TCU-based communication channels between them. To account for the security vulnerabilities in today's cores, M³ places components onto different and physically isolated processing elements by default, but allows sharing of processing elements as a fallback.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1159",
            "value": "Nils Asmussen"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9408.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10419",
        "start": "10:40",
        "duration": "00:15",
        "room": "K.4.601",
        "slug": "uk_helenos",
        "title": "HelenOS in the Year of the Pig",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This is going to be an all-encompassing update talk for HelenOS developments that happened in the Year of the Pig (since the last FOSDEM).<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "604",
            "value": "Jakub Jermář"
          }
        },
        "links":
        [
          {
            "_href": "http://www.helenos.org/",
            "value": "Helenos Project Website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10419.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9284",
        "start": "11:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_linux",
        "title": "Linux Kernel Library",
        "subtitle": "A Library Version of Linux Kernel",
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>LKL (Linux Kernel Library) is aiming to allow reusing the Linux kernel\ncode as extensively as possible with minimal effort and reduced\nmaintenance overhead.  It allows us to link the library with any\nprograms (which wish to call as a function call) containing Linux\nkernel code.  There are many use cases: reading/writing files without\ngeneral system calls, putting experimental protocol implementation\nwithout neither of host kernel update nor kernel module installation,\nusing customized kernel in container instance, building a unikernel\nbased on existing rumprun framework, or testing/fuzzing kernel\nimplementation in userspace execution, etc.<\/p>\n\n<p>In this talk, we are going to present<\/p>\n\n<ul>\n<li>why/how/when we started this project,<\/li>\n<li>share the outcomes using LKL<\/li>\n<li>fuzzing test with Linux filesystem<\/li>\n<li>out of tree network protocols on Android<\/li>\n<li>lkl.js<\/li>\n<li>macOS port<\/li>\n<li>docker integration<\/li>\n<li>future directions including upstreaming to Linux kernel<\/li>\n<\/ul>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6465",
            "value": "Hajime Tazaki"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9284.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10152",
        "start": "11:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_phantom",
        "title": "Phantom OS",
        "subtitle": "Orthogonal Persistence-based OS Intro and Design Concepts",
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Phantom OS is an Operating system based on the orthogonal persistence. Application does not feel OS shutdown and restart. Even abrupt restart. It is guaranteed that application will be restarted in consistent state.<\/p>",
        "description": "<ul>\n<li><p>As long as you have reference to any variable, it’s state is the same between OS reboots. You don’t have (though you can) save program state to files.<\/p><\/li>\n<li><p>Managed code. Native Phantom applications are running in a bytecode machine. (But it is worth to mention that Phantom has simple Posix compatibility subsystem too.)<\/p><\/li>\n<li><p>Global address space. Phantom OS is an application server. All applications can communicate directly, by sharing objects.<\/p><\/li>\n<li><p>Phantom OS persistence is achieved not by serializing data to files, but by running all applications in a persistent RAM. You can (and it will be true) think of Phantom memory subsystem as of a persistent paging engine<\/p><\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7110",
            "value": "Dmitry Zavalishin"
          }
        },
        "links":
        [
          {
            "_href": "https://phantomdox.readthedocs.io/en/latest/",
            "value": "Phantom OS programmer's guide"
          },
          {
            "_href": "https://github.com/dzavalishin/phantomuserland/",
            "value": "Phantom OS repository"
          },
          {
            "_href": "https://github.com/dzavalishin/phantomuserland/wiki/ScreenShots",
            "value": "Phantom OS screenshots"
          },
          {
            "_href": "http://innopolis.ru/en/",
            "value": "Innopolis University and town info"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10152.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9111",
        "start": "12:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_gneiss",
        "title": "Gneiss: A Nice Component Framework in SPARK",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Gneiss is an abstraction layer for component based environments that aims to\nprovide a foundation for formally provable components. It enables the creation\nof platform independent, asynchronous components in SPARK and provides\nfunction contracts that allow to prove the correct interaction with the\nunderlying platform.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6087",
            "value": "Johannes Kliemann"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/Componolit/gneiss",
            "value": "Gneiss on GitHub"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9111.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10020",
        "start": "12:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_android",
        "title": "A Component-based Environment for Android Apps",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With 2.5 billions of active users Android is the most widely deployed mobile operating system in the world. Its vast complexity paired with a monolithic architecture regularly result in severe security issues like the infamous Stagefright bug. In this presentation we talk about an ongoing research project which aims at running Android applications on top of the component-based Genode OS framework and secure them using formally verified components. We discuss how Android applications interact, how well this matches the semantics of Genode and what it takes to support unmodified Android apps.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5076",
            "value": "Alexander Senier"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10020.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10150",
        "start": "13:00",
        "duration": "00:50",
        "room": "K.4.601",
        "slug": "uk_sculpt",
        "title": "Demonstration of the Sculpt Operating System",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Sculpt OS is a novel general-purpose operating system designed from the ground up and implemented using the building blocks of the Genode OS framework. It started with the vision of a truly trustworthy OS that combines a completely new system structure with microkernels, capability-based security, sandboxed device drivers, and virtual machines. The talk is a live demonstration of the current incarnation of Sculpt.<\/p>",
        "description": "<p>The Genode OS framework is an operating-system technology created from scratch. Over the past decade, it steadily evolved from a fairly obscure research prototype to a practical day-to-day operating system.<\/p>\n\n<p>Being a component-based system designed after the principle of least privilege from the very beginning, it breaks with many concepts that we take for granted in traditional operating systems, e.g., the central role of files. Instead, Genode introduces a novel way of composing system scenarios out of building blocks where the building blocks are able to cooperate without ultimately trusting each other. Those building blocks include not only applications but also all classical OS functionalities including kernels, device drivers, file systems, and protocol stacks.<\/p>\n\n<p>In 2018 - after more than 10 years of developing Genode in a shadowy corner of the open-source community - the project created Sculpt OS, which is a Genode-based general-purpose OS for commodity PC hardware. Since it is not derived from any existing OS, Sculpt re-approaches established concepts like the installation, configuration, and spawning of programs from a new angle. This is reflected by its custom user interface.<\/p>\n\n<p>Besides presenting the motivation and the fundamental ideas behind Genode, the talk will introduce and demonstrate the current state of Sculpt OS, draw connections to related open-source projects, and give a glimpse on the project's future plans.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "607",
            "value": "Norman Feske"
          }
        },
        "links":
        [
          {
            "_href": "https://genode.org",
            "value": "Genode OS framework"
          },
          {
            "_href": "https://genode.org/download/sculpt",
            "value": "Sculpt OS"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10150.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10381",
        "start": "14:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_genode_armv8",
        "title": "A Brief Survey through Genode's ARMv8 Playground",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Genode project has evolved over the past decade into a versatile toolkit for general-purpose computing. Even though support for ARM embedded devices is an inherent part of it since the very beginning, the focus of the past years was more x86-Architecture centered. Sculpt, the desktop incarnation of Genode, being the prime example. Recently, Genode's ARMv8 port ignited extensive development efforts to support more sophisticated workloads on top of modern embedded and mobile devices.<\/p>\n\n<p>The talk provides an overview about the current ARMv8 Genode landscape, its ambitions and potential. It will live demonstrate recent achievements from device support up to hardware-assisted virtualization on top of the NXP i.MX8 SoC.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "769",
            "value": "Stefan Kalkowski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10381.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10344",
        "start": "14:30",
        "duration": "00:50",
        "room": "K.4.601",
        "slug": "uk_nova",
        "title": "NOVA Microhypervisor on ARMv8-A",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NOVA is a modern open-source microhypervisor that can host unmodified guest operating systems next to critical host applications. Although originally developed for the x86 virtualization extensions of Intel and AMD, the internals of the microhypervisor and its external API were designed with flexibility in mind, such that the code could also be ported to other architectures.<\/p>\n\n<p>In this talk we present the first ever version of NOVA on ARMv8-A.  We will show how the NOVA abstractions map onto the ARM architecture, how modern virtualization features such as GIC and SMMU are being used, discuss the ongoing evolution of the NOVA API and how the ARM port differs from the earlier x86 version.<\/p>\n\n<p>The talk will conclude with a short demo, an outlook into the NOVA roadmap and the formal verification efforts around the code base, as well as opportunities for collaboration with the NOVA community.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7210",
            "value": "Udo Steinberg"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10344.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10376",
        "start": "15:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_hipperos",
        "title": "The HIPPEROS RTOS",
        "subtitle": "A Song of Research and Development",
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HIPPEROS is an upcoming open source RTOS that was developed at ULB and by a former spin-off company of ULB.\nThe talk will be a presentation followed by an open discussion about the main architecture principles of the HIPPEROS kernel and OS, what platforms and architectures we support and our agenda regarding open source.<\/p>",
        "description": "<p>This multitasking RTOS is specifically designed to take advantage of multi-core platforms for critical, hard real-time applications that must be predictable. It targets high-end embedded platforms that exhibit heterogeneous parallelism. The HIPPEROS kernel is designed from scratch in order to support recent process models present in the real-time systems research literature.\nThe RTOS is based on a micro-kernel with an asymmetric master/slave architecture. It allows to natively support parallel processor architectures, by dedicating one core to the heavy operations of the kernel (scheduling, memory management, etc.) and the other cores can then execute user mode application and serve real-time tasks with very few interferences.<\/p>\n\n<p>The OS kernel was designed and implemented by a team made of people from the ULB PARTS laboratory (http://parts.ulb.ac.be/).\nThe goal was to create a spin-off company around the topic of Real-Time Operating Systems, including the creation of a new micro-kernel for high-end embedded systems with an innovative software architecture, backed-up by research (both theoretical and applied), designed, developed and maintained with \"good\" (and agile) software design methodology.\nWithin this business, a side objective was to maintain strong links with universities and the research world, by validating the OS design in an academic environment and continuous research activities.<\/p>\n\n<p>Currently, the company is under liquidation. The state of the project is frozen but we started an ongoing initiative aiming to open source the code base. This would allow external contributions and therefore continuing maintenance and development of new features.\nHIPPEROS could then become a test ground for academics and industrials that aim to try new ideas regarding the reliability and efficiency of their systems. With no such undertaking, the code base might just disappear, therefore cancelling out the 7-year team effort.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7208",
            "value": "Antonio Paolillo"
          }
        },
        "links":
        [
          {
            "_href": "https://antonio.paolillo.be",
            "value": "Speaker's web page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10376.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10215",
        "start": "16:00",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_unicraft",
        "title": "Unikraft: A Unikernel Toolkit",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Although unikernels - images containing specialized OS primitives and libraries targeting a specific application - have shown impressive performance potential (e.g., fast I/O of 40 Gbps, fast instantiation in the millisecond range, minimal memory footprints of only KBs and a minimal trusted compute base), creating them has proven to be a complicated and time-consuming process. This is mostly because operating system components have to be individually specialized and developed for each target application and target platform.<\/p>\n\n<p>In this talk we give an update on the Unikraft open source project. Unikraft is a toolkit for creating specialized unikernels and it aims to remove the need for time-consuming, expert work. In the past two years, the community has put a lot of effort into supporting OS functionality, drivers, and platforms, porting libraries, and providing tools to ease porting of existing applications. We will give an overview of all the exciting achievements and conclude with an outlook of recent project directions: binary compatibility (Linux ABI), support for a wide range of compiled and interpreted languages (e.g., web assembly, Go, Python, Ruby, etc.), enhanced safety features, and the ability to seamlessly produce images ready to run as extremely lean VMs, containers, or directly on bare metal. The aim is that Unikraft will represent a step forward towards wider adoption of unikernels beyond the research community.<\/p>",
        "description": "<p>We have spent quite a bit of our time over the last years developing unikernels – highly specialized kernels targeting specific applications. We have been originally interested in them for virtualized network functions because of their fantastic performance benefits: tiny memory footprints, boot times comparable to those of processes, and fast I/O performance, to name a few.<\/p>\n\n<p>Despite the fact that this work and work from several others is proof of their potential, unikernels have yet to see massive adoption. One of the main showstoppers is development time: for instance, developing Minipython, a MicroPython unikernel, took the better part of 3 months to put together and test. ClickOS, a unikernel for NFV, was the result of a couple of years of work. What’s particularly bad about this development model besides the considerable time spent is that each unikernel was basically a “throwaway”: every time we wanted to create a new unikernel targeting a different application and a different platform, we would start more or less from scratch. This comes from the fact that each application has different OS dependencies and benefit from different optimizations and specializations of these layers.<\/p>\n\n<p>Two years ago, we started Unikraft as an open source incubator project under the umbrella of the Xen Project and the Linux Foundation. Our goal is to build a common pool of decomposed OS functionalities, called libraries, where various Unikernel projects can share implementations and optimizations with others. The project provides Unikernel builders tools that help them to select needed libraries and configurations. Unikraft's build system quickly and automatically creates images tailored to the needs of their specific applications. The users can choose multiple target platforms (e.g., extremely lean VMs, containers, or directly as bare metal) without having to do additional work for each of them.<\/p>\n\n<p>We are going to present the efforts and achievements done by the community in the last two years. We will also give an outlook of recent project directions: binary compatibility (Linux ABI), support for a wide range of compiled and interpreted languages (e.g., web assembly, Go, Python, Ruby, etc.), and enhanced safety and protection features. With a bit of left time, we will show a live demo to the audience.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5391",
            "value": "Simon Kuenzer"
          }
        },
        "links":
        [
          {
            "_href": "http://www.unikraft.org",
            "value": "unikraft.org"
          },
          {
            "_href": "https://github.com/unikraft",
            "value": "Sources (GitHub)"
          },
          {
            "_href": "http://docs.unikraft.org",
            "value": "Documentation"
          },
          {
            "_href": "https://xenproject.org/developers/teams/unikraft/",
            "value": "Unikraft Team (The Xen Project)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10215.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10510",
        "start": "16:30",
        "duration": "00:25",
        "room": "K.4.601",
        "slug": "uk_vuos",
        "title": "VUOS: Give Your Processes a New VU",
        "subtitle": [],
        "track": "Microkernels and Component-based OS",
        "type": "devroom",
        "language": [],
        "abstract": "<p>VUOS is a different perspective on namespaces, anykernels and related concepts. The main idea behind VUOS is that it is possible to give processes their own \"view\" using partial virtual machines.<\/p>\n\n<p>A partial virtual machine intercepts the system call requests and operates like a filter: system calls can be forwarded to the kernel of the hosting system or processed by the partial virtual machine hypervisor.\nIn this way processes can see a mix of resources provided by the kernel (on which they have the same view of the other processes) and virtual resource. It is possible to mount filesystems, load networking stacks, change the structure of the file system tree, create virtual devices.<\/p>\n\n<p>The hypervisor is just a user process so while it gives new perspective for processes, it does not widen the attack surface of the kernel.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2639",
            "value": "Renzo Davoli"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/virtualsquare/vuos",
            "value": "VCS"
          },
          {
            "_href": "http://wiki.virtualsquare.org/",
            "value": "virtualsquare"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10510.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UA2.114 (Baudoux)",
    "event":
    [
      {
        "_id": "10757",
        "start": "09:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "how_firefox_upholds_its_values",
        "title": "How Firefox upholds its values and keeps up with change",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How the Firefox team changed how we thought about shipping features and replaced a process biased towards those who had the loudest voices and the luxury of time with a process that is more inclusive and allows us to reduce risk to Firefox users when we ship.<\/p>",
        "description": "<p>In this talk you'll learn how the Firefox team changed how we ship new features in the browser, and adopted industry best practices including gradual deployments and feature flags.<\/p>\n\n<p>Why?<\/p>\n\n<ul>\n<li>Listening to our most vocal users may bias us towards the needs of an unrepresentative group of users<\/li>\n<li>When you release a browser to millions of users on a heterogeneous set of platforms, you're testing in production<\/li>\n<li>Avoiding dot releases<\/li>\n<\/ul>\n\n\n<p>I'll talk about what we learned and how it's shaped how we release Firefox at Mozilla.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7405",
            "value": "Emma Humphries"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/presentation/d/1cqgXYP8T-Ymuou_87lWzH-i_UwYyktgvwsaC-hGPtQc/",
            "value": "Slides"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10757.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9037",
        "start": "10:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "make_it_accessible",
        "title": "Make it accessible",
        "subtitle": "Tips and tricks for create a good accessible frontend",
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk focuses on Web Accessibility, namely the practice of ensuring that people with disabilities—be it physical, situational or socio-economic—have access to and can interact with websites and applications.<\/p>",
        "description": "<p>This talk focuses on Web Accessibility, namely the practice of ensuring that people with disabilities—be it physical, situational or socio-economic—have access to and can interact with websites and applications.<\/p>\n\n<p>We will begin the talk sharing the concept of an interface, intended as a layer between two parties that do not speak the same language. We’ll continue talking about accessibility devices and myths that surround them. Then we will dive into how to refactor codebases for screen reader optimization, following accessibility guidelines that improve the user experience for all people. We will conclude by sharing some useful tools that help developers build accessible webpages.<\/p>\n\n<p>In the end we'll see some useful tools for helping developers to make accessible webpages<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3936",
            "value": "Gabriele Falasca"
          }
        },
        "links":
        [
          {
            "_href": "https://drive.google.com/file/d/1TQIACx4XjeqTdJYB30veuDK847wzAC8N/view?usp=sharing",
            "value": "Slides of the talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9037.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10665",
        "start": "10:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "you_cant_spell_accessibility_without_css",
        "title": "You Can't Spell Accessibility Without CSS",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, we'll discuss website accessibility in the context of CSS. Things like when to use an image and when to use a background image, how to ensure proper contrast between text and background colors, maintaining a hierarchical layout in your design, when to use an outline: 0 property (almost never), and a whole bunch of other things.<\/p>",
        "description": "<p>This talk is suited to beginner and intermedite front end developers.\nSpecific topics covered include:\n- maintaining the hierarchical structure of content,\n- creating non-obtrusive elements\n- ensuring contrast between background and text\n- using devtools to check accessibility<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6609",
            "value": "Jemima Abu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10665.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10766",
        "start": "11:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "is_the_web_rea11ly_for_all",
        "title": "Is the web rea11y for all?",
        "subtitle": "Firefox DevTools & A11y",
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The web is pretty much present in everyone's life nowdays. But is it really for all? How are we making it a smooth usage for those with disabilities, for those with reduce time and internet connection? Or even more further, for those that just use the web for the first time?\nLet's learn a bit how the devtools from Firefox can help us improve everyone's experience without much of a sacrifice on our end.<\/p>",
        "description": "<p>A11y and inclusion is getting more traction nowadays but people still think that they address only those with disabilities. As a person without any officially i did find myself in this situation and felt confused about how the web should be ( was about to loose money on ticket conferences because i was not seeing the categories). Some Developers are a bit defensive saying they don't have users for whom to build more a11y in or the time to add these features. Showing the devtools Firefox has for it - will show how fast you can check your page and how no costy is. Also not knowing all best practices won't be a blocker and firefox will give you suggestions. In a way i wanted to bring attention to A11y nd Inclusion in a more technical way.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4338",
            "value": "Ioana Chiorean"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10766.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10708",
        "start": "11:30",
        "duration": "00:40",
        "room": "UA2.114 (Baudoux)",
        "slug": "what_are_the_top_10_frustrations_for_web_developers_and_designers",
        "title": "What are the Top 10 Frustrations for Web Developers and Designers?",
        "subtitle": "Lessons from the 2019 MDN Developer Needs Assessment",
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The MDN Web Developer Needs Assessment is the first edition of an annual study providing a prioritized list of designer and developer needs.<\/p>",
        "description": "<p>As an industry working on the Web, as a platform and set of tools, we recognized a critical voice was missing when it came to making decisions about feature development — that of web designers and developers.<\/p>\n\n<p>The MDN Web Developer Needs Assessment is the first edition of an annual study providing a prioritized list of designer and developer needs.<\/p>\n\n<p>We put this report together with the help of more than 30 stakehold- ers from the MDN Product Advisory Board member organizations and the input of more than 28,000 developers and designers from 173 countries who took the twenty minutes necessary to complete the survey entirely. That’s more than 10,000 hours contributed by the community to help us understand their pain points, wants, and needs. With that involvement, we believe the MDN Web DNA is the largest web developer and designer focused research study ever conducted.<\/p>\n\n<p>Their input now, and in future versions, will influence how browser vendors prioritize feature development so we can address the needs of designers and developers, both on and off the Web. By producing the report annually, we can track needs and pain points over time so we can see the impact of our efforts.<\/p>\n\n<p>A critical aspect of the report is that it provides a voice for commu- nities of practitioners. We did not tailor it to current assessments and priorities of participating browser vendors. A single browser vendor does not own it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7364",
            "value": "Kadir Topal"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10708.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10741",
        "start": "12:15",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "discover_the_new_firefox_profiler",
        "title": "Discover the New Firefox Profiler",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Using a profiling tool help developers to get detailed information about the execution of their application and allow them to understand the behavior of it.<\/p>\n\n<p>The Firefox Profiler is a profiler that is built into Firefox. It has tighter integration with Firefox than external profilers. It can provide more information and insight into what the browser is doing. It can also show the memory usage and Firefox internal code execution.<\/p>\n\n<p>During the talk, I will be explaining, how to capture a good profile and how to analyze profile data. I will be sharing Firefox Profiler specific features like memory tooling, single tab/advanced view and how to use them. I will also be sharing the future of Firefox Profiler!<\/p>",
        "description": "<p>Web applications are more popular than ever and users expect more from a web application. Unfortunately, they are using applications more frequently from low powered devices, which strains your application’s performance. Managing application performance can be challenging as modern applications have many dependencies and their complexity can hide the issues.<\/p>\n\n<p>Using profiling tools to look for potential bottlenecks can significantly reduce the number of problems in your application. It helps you to get detailed information about the execution of your application and it allows you to understand the behavior of it.<\/p>\n\n<p>The Firefox Profiler is a profiler that is built into Firefox and is available at https://profiler.firefox.com/. It has tighter integration with Firefox than external profilers. It can provide more information and insight into what the browser is doing. Aside from understanding the execution of a web page, it can also show the memory usage and Firefox internal code execution.<\/p>\n\n<p>The intended audience is all web developers and people who want to contribute to Mozilla by helping us analyze the Firefox performance issues by capturing profiles and filing bugs.<\/p>\n\n<p>The talk will cover topics like:\n- Profiling basics\n- How profile capturing UI works.=\n- How to capture a profile without getting a lot of noise in the profile data\n- Profile data content\n- Firefox Profiler specific features like:\n- Single tab/advanced view\n- Memory profiling\n- Profiling network\n- Profile comparison view\n- Brand new features in Firefox Profiler<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7388",
            "value": "Nazım Can Altınova"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10741.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10779",
        "start": "12:45",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "web_compatibility_and_ml",
        "title": "Web compatibility and ML",
        "subtitle": "Improving webcompat issue triaging using ML",
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In 2019, Mozilla's Open Innovation and WebCompat team joined forces to improve the process of gathering web compatibility issues. One of the experiments was to introduce machine learning capabilities in the triaging process and automate some steps. This talk is about the early steps and how we got some hands on experience with machine learning, what we've achieved so far and potential next steps.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7421",
            "value": "Nemo"
          }
        },
        "links":
        [
          {
            "_href": "https://webcompat-ml.readthedocs.io/en/latest/",
            "value": "Documentation"
          },
          {
            "_href": "https://github.com/mozilla/webcompat-ml",
            "value": "Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10779.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10698",
        "start": "13:15",
        "duration": "00:40",
        "room": "UA2.114 (Baudoux)",
        "slug": "facilitating_distributed_deterministic_computation_with_wasi",
        "title": "Facilitating distributed deterministic computation with WASI",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>WebAssembly System Interface (WASI) is the new brilliant community effort at standardising the use of WebAssembly (Wasm) outside the browser environment. Initiated by Mozilla, now under the umbrella of Bytecode Alliance, WASI has the potential to revolutionise the way we think about the \"build once, run anywhere\" in a truly secure manner. But could WASI also lend itself to a task of running any code within a network of distributed, untrusted nodes such as BOINC or Golem Network, and ensuring that the results received are indeed correct? The short answer is yes, if determinism of computations could be enforced which opens many ways at verifying the results. Enforcing determinism is a rather difficult thing to achieve in other platforms such as JVM etc., now possible thanks to Wasm and WASI. This talk will delve deep into the inner workings of the WASI spec, and its goto implementation, the wasi-common library, and explore how and if determinism can be enforced at the WASI syscall level.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7359",
            "value": "Jakub Konka"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10698.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10752",
        "start": "14:00",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "loanwords_agriculture_and_webassembly",
        "title": "Loanwords, Agriculture & WebAssembly",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we take a whirlwind tour through untranslatable language jargon and native indigenous agricultural techniques to help us think about where the web ecosystem appears to be headed and how to switch the current course towards a more sustainable future.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7392",
            "value": "Andre Garzia"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10752.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10755",
        "start": "14:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "a_mozilla_iot_forcast_thats_sunny_and_clear",
        "title": "A Mozilla IoT Forecast thats Sunny and Clear -- No Clouds!",
        "subtitle": "WebThings by Mozilla",
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>WebThings (by Mozilla) is an open source smart home implementation to improve privacy, security, and interoperability.<\/p>",
        "description": "<p>Want to manage your own private smart home? Want your connected things to be interoperable across brands, securely accessible and controllable over the web? Come see how to run your entire smart home on the edge, in your own home, no clouds required! This talk demonstrates how to run the WebThings Gateway on a Raspberry Pi (or in a Docker container on your favorite platform) to manage IoT devices that you build or buy. You'll also learn how to build your own \"web things\", in minutes, using open source WebThings framework libraries.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7404",
            "value": "Kathy Giori"
          }
        },
        "links":
        [
          {
            "_href": "https://iot.mozilla.org",
            "value": "Mozilla IoT"
          },
          {
            "_href": "https://microblocks.fun",
            "value": "MicroBlocks"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10755.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10673",
        "start": "15:30",
        "duration": "00:25",
        "room": "UA2.114 (Baudoux)",
        "slug": "privacy_by_design",
        "title": "Privacy by Design",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Most of the websites leak out the user data, and most of the times (~90%) it is not known to the site admins. These leakage happen via tag managers, third party CDNs, embeds, fonts etc. In this talk I would like to discuss the opportunities for developers to avoid these while developing websites. This talk will help them to ensure their websites does exactly what they intend their website to do. The side-effect of this always is better performance 😎<\/p>",
        "description": "<p>Every other website on the internet uses third party trackers to improve their product and provide better user experience, which eventually leads to a compromise in user privacy. As developers, we are responsible for making our users feel safe and do whatever it takes to secure the privacy of our users.\nIn this talk we will discuss the data leaks which happen while using third party trackers and will walk through the measures we can take to avoid them and ensure the privacy of our users, right from the time of development.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4032",
            "value": "Trishul Goel"
          }
        },
        "links":
        [
          {
            "_href": "https://slides.com/trishulgoel/privacy-by-design",
            "value": "Slides"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10673.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10734",
        "start": "16:00",
        "duration": "00:30",
        "room": "UA2.114 (Baudoux)",
        "slug": "what_makes_people_come_and_what_makes_them_stay",
        "title": "What Makes People Come and What Makes Them Stay",
        "subtitle": [],
        "track": "Mozilla",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Over the years the tech industry has been trying to change its diversity and inclusion statistics but that seems to have been a hard nut to crack. This is a talk about what makes people come, but then also what makes people stay. Because diversity is inviting people to the dance, but inclusion is enabling them to join it. Let's figure out how you can make people come and want to stay in your organizations, and teams, and let's see one use-case where Mozilla did the same.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4085",
            "value": "Gloria Dwomoh"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10734.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UA2.220 (Guillissen)",
    "event":
    [
      {
        "_id": "10337",
        "start": "09:00",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_close_lid_encrypt",
        "title": "Close lid to encrypt",
        "subtitle": "Hard disk encryption in Linux suspend mode",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Today, hard disk encryption only protects user's data when their machine is shut down.\n\"Close lid to encrypt\" aims to enhance this protection also to suspend mode.<\/p>",
        "description": "<p>Hard disk encryption is a necessity for everyone, who fears the physical theft or seizure of their device. However, your data is still only protected while the machine is shut down. But most people rarely shutdown their devices anymore. Usually, you just close the lid of your notebook and you're on your way.<\/p>\n\n<p>\"Close lid to encrypt\" aims to improve the privacy of your data. When you close the lid of your notebook, it goes into sleep/suspend mode. All  processes are frozen and don't need to access your hard disk anymore. We use this opportunity to clean the keys of your encrypted devices and suspend them as well. Therefore, the data on your hard drive is protected.\nWhen resuming your computer, you must re-enter the password of your encrypted volumes. But then you're just where you've been working before.<\/p>\n\n<p>To make all this work, we rely on a small kernel patch, the cryptsetup project, initramfs and cgroups2. \"Close lid to encrypt\" right now focuses on Debian and it derivatives and we plan to bring all code upstream. This effort is funded by the German Prototypefund.<\/p>\n\n<p>In this 20 minute presentation, I will thoroughly explain the problem and our approach to solving it. Of course, I will also explain the limits of our approach.\nFurthermore, I will demonstrate our already working prototype and answer your question.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7204",
            "value": "Tim Dittler"
          }
        },
        "links":
        [
          {
            "_href": "https://prototypefund.de/project/close-lid-to-encrypt/",
            "value": "Project side from funder"
          },
          {
            "_href": "https://salsa.debian.org/mejo/cryptsetup-suspend",
            "value": "Our work space"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10337.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10433",
        "start": "09:10",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_id4me",
        "title": "Open and federated identities with ID4me",
        "subtitle": "An alternative to \"sign in with Facebook\"",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Online identities are the cornerstone on which data-based capitalism is built - so, Google, Facebook and other OTTs are trying to dominate them and close them into silos. The ID4me platform extends OpenID Connect to create an open and federated architecture that allows any number of providers to interoperate, and gives back control to users, and a role to community service providers.<\/p>",
        "description": "<p>In the last years, the Internet has been increasingly centralized into the hands of GAFAM and other over-the-top companies that built walled gardens in fields like messaging and social networks. More and more of these companies have user data monetization and targeted advertising as a core revenue stream; thus, tracking people across their Internet activities is necessary to their existence.<\/p>\n\n<p>This is why they have also built closed identity systems that supply single-sign-on and very easy sign up for new websites and services, at the expense of privacy and user control. As managing hundreds of separate accounts is inconvenient and insecure, and as alternatives such as password managers are not easy enough for the average Internet user, clicking on “sign in with Google” or “sign in with Facebook” has become a very common choice.<\/p>\n\n<p>We think that this is bad for the Internet in general, and thus we are creating a platform that allows anyone to provide identities, creating an open, public and federated single-sign-on and data management system. We are extending OpenID Connect just a bit, the bit that is necessary to break the silos and allow interoperability; and we are basing the system on the DNS, the widely available and already federated naming directory of the Internet.<\/p>\n\n<p>The talk will explain how the system works and encourage participation and contributions.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4611",
            "value": "Vittorio Bertola"
          }
        },
        "links":
        [
          {
            "_href": "https://id4me.org",
            "value": "ID4me project website"
          },
          {
            "_href": "https://gitlab.com/ID4me",
            "value": "ID4me codebase and docs"
          },
          {
            "_href": "https://www.ietf.org/archive/id/draft-bertola-dns-openid-pidi-architecture-01.txt",
            "value": "Internet draft describing the architecture"
          },
          {
            "_href": "id4me Technical Overview v1.4.pdf",
            "value": "ID4me technical overview document"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10433.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9824",
        "start": "09:20",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_identity_box",
        "title": "Identity Box",
        "subtitle": "Decentralized Web of the Future",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Society is becoming increasingly more aware of the importance of protecting digital information and it is becoming clear that the current centralized model has came to an end.\nThe future of the Internet is distributed. Unsupervised, unmoderated access, affordable storage, data-replication, and security and privacy built-in are the most important aspects of the Internet of the future.<\/p>\n\n<p>Unfortunately, a global, reliable, decentralized network cannot be built without actual physical nodes, as the opposite of thousands of nodes in centralized cloud data center. Only by building an open network of physical nodes we can pave our way as a society to the decentralized Internet of the future.<\/p>\n\n<p>Identity Box is a personal P2P networking device giving you access to a global network of distributed storage, digital identity, and distributed personal apps. It is a community effort of\nbuilding the next-generation, decentralized infrastructure that enables an open platform for privacy-preserving ecosystems.<\/p>",
        "description": "<p>Most of the data today belong to just a handful of companies. Personal documents, photographs, videos, things that we put online in general, contain lots of sensitive information. Information that we would rather prefer to stay private. Very often the same companies that provide more or less \"complimentary\" storage space for our disposal, also help us managing our whole digital existence. The combination of the data and the identity information is a powerful combination which empowers well-established business models where the user's data or the user itself become a product. Allowing sensitive data to be kept by well-known service providers makes it easier than ever for illegal institutions, but also the state, to gain insights into the data that they have no rights to access.<\/p>\n\n<p>Our sensitive personal data are kept by the state, healthcare organizations, financial institutions, and corporations. We do not have control over these data and our access to them is limited. Every institution storing the data has not only its own policies, but also uses proprietary technologies to access the data. These data silos make interoperability hard and give institutions almost complete freedom to use the data without consent of the user.<\/p>\n\n<p>Society is becoming increasingly more aware of the importance of protecting the digital content and it is becoming clear that the current centralized model has came to an end.\nThe future of the Internet is distributed. Unsupervised, unmoderated access, affordable, unlimited storage, security and privacy built-in are the most important aspects of the Internet of the future.<\/p>\n\n<p>Unfortunately, a global, reliable, decentralized network cannot be built without actual physical nodes, as the opposite of thousands of nodes in centralized cloud data centers. Users need to be re-introduced to the concept of decentralization and learn the advantages of technologies like self-sovereign identity, and content-addressable networks. Only by building an open network of physical nodes we pave our way as a society to the decentralized Internet of the future. Building the decentralized Internet of the future is therefore a community effort, where all participants become the actual owners of the distributed global infrastructure.<\/p>\n\n<p>To support this community movement, we propose Identity Box: a personal P2P networking device giving you access to the global network of distributed storage, digital identity, and distributed personal apps.<\/p>\n\n<p>Identity Box is a physical device, but at the same far more than just piece of hardware. Together with the included software and Identity App, Identity Box enables an ecosystem of rich, distributed personal applications. It supports IPFS, Self-Sovereign Identity, and end-to-end encrypted storage. And that's just the beginning.<\/p>\n\n<p>Join us in building the decentralized Internet of the future!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6319",
            "value": "Marcin Czenko"
          }
        },
        "links":
        [
          {
            "_href": "https://idbox.online",
            "value": "Identity Box home page."
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9824.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10042",
        "start": "09:30",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_decentralized_object_storage",
        "title": "Decentralized object storage",
        "subtitle": "An open source decentralized object storage",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A presentation of the architecture of Storj decentralized object storage.\nStorj is a company that has built a completely open source decentralized object storage written in Go.\nCurrently Storj is in the lat beta release before releasing the production version of the decentralized object storage network.<\/p>",
        "description": "<p>A presentation of the architecture of Storj decentralized object storage.\nStorj is a company that has built a completely open source decentralized object storage written in Go.\nCurrently Storj is in the lat beta release before releasing the production version of the decentralized object storage network.<\/p>\n\n<p>The network is formed by a big community of operators, named Storj Node Operators, who offer storage space and network bandwidth to the network.\nStorj incentives the Storj Node Operators for their contributed storage space and network bandwidth.<\/p>\n\n<p>The network is AWS S3 compatible and is pursuing to achieve the same or even better service layer agreements than AWS S3 at a cheaper price in terms of storage and bandwidth, all thanks to the great community of Storage Node Operators.\n23.-\nIn this event, I will expose the architecture of the network and the challenges that decentralized network storage presents in comparison with the ones that are not exposed to a centralized one.<\/p>\n\n<p>I will comment how the confidentially, durability, retrievability and upload/download speed is maintained.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7067",
            "value": "Ivan Fraixedes"
          }
        },
        "links":
        [
          {
            "_href": "https://storj.io",
            "value": "Home page"
          },
          {
            "_href": "https://github.com/storj",
            "value": "Github organization"
          },
          {
            "_href": "https://github.com/storj/storj",
            "value": "Github main repository"
          },
          {
            "_href": "https://storj.io/blog",
            "value": "Blog"
          },
          {
            "_href": "https://forum.storj.com",
            "value": "Community"
          },
          {
            "_href": "https://documentation.storj.io/",
            "value": "Documentation"
          },
          {
            "_href": "https://storj.io/storjv3.pdf",
            "value": "PDF Whitepaper"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10042.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10096",
        "start": "09:40",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_librecast",
        "title": "Librecast: Privacy and Decentralization with Multicast",
        "subtitle": "IPv6 Multicast and the Next Generation Internet",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Written in 2001, RFC 3170 states: \"IP Multicast will play a prominent role on the Internet in the coming years.  It is a requirement, not an option, if the Internet is going to scale.  Multicast allows application developers to add more functionality without significantly impacting the network.\"<\/p>\n\n<p>Nearly two decades later, multicast is still largely ignored and misunderstood.<\/p>\n\n<p>This talk explains why multicast is the missing piece in the decentralization puzzle, how multicast can help the Internet continue to scale, better protect our privacy, solve IOT problems and make polar bears happier at the same time.<\/p>",
        "description": "<p>There are many common misconceptions about multicast, including that it is only useful for streaming video and audio.  It does so much more than that.<\/p>\n\n<p>Multicast is really about group communication.  It is, by definition, the most efficient way to distribute data to groups of nodes.<\/p>\n\n<p>Multicast brings with it a very different way of thinking about distributed systems, and what is possible on the Internet.  From database replication to chatops, server federation, configuration management and monitoring.<\/p>\n\n<p>Even applications, such as chat, which are fundamentally multicast in nature are being built on top of unicast protocols.  There is a Better Way.<\/p>\n\n<p>Unicast networking leads to centralised and inefficient systems that are more open to attack and censorship.  This talk will show how multicast allows for more efficient, decentralized designs, leading to increased efficiency and much-reduced energy consumption.  This is better for our democracy, human rights and our planet.<\/p>\n\n<p>Multicast lets us do things that would be impossible with unicast.  Imagine sending software updates to a billion IoT nodes simultaeneously, using just one tiny virtual server.<\/p>\n\n<p>At a time when even the web is moving to UDP with HTTP/3 and WebRTC, it is time we took a serious look at what we're missing by not using multicast at the network layer to underpin our Internet protocols.<\/p>\n\n<p>We'll discuss how you can start using multicast in your project today, and how multicast design and thinking differs from unicast.  We'll cover some of the different types of IP multicast, the basics of multicast routing, how to build in TCP-like reliability and take a look forward to how improvements in multicast can make a better Internet for the future.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4805",
            "value": "Brett Sheffield"
          }
        },
        "links":
        [
          {
            "_href": "https://librecast.net/",
            "value": "Librecast Project"
          },
          {
            "_href": "https://blog.brettsheffield.com/multicast",
            "value": "Brett Sheffield"
          },
          {
            "_href": "https://github.com/librestack/iotupd",
            "value": "Multicast IoT Update Daemon"
          },
          {
            "_href": "https://github.com/librestack/libreum",
            "value": "Multicast Chat Demo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10096.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9892",
        "start": "09:50",
        "duration": "00:10",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_scion",
        "title": "SCION - future internet that you can use today",
        "subtitle": [],
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Do you know where your internet traffic flows? Does it go through China even if you don't want it to? SCION is a new internet architecture aimed at solving this problem. We will show how you can easily join the already existing worldwide network.<\/p>",
        "description": "<p>The current Internet was not designed with control and security considerations in mind: incidents such as the hijacking of all traffic for YouTube by a Pakistani ISP in February 2008, the Cloudflare DNS service hijacked by AnchNet in May 2018, or a large chunk of European mobile traffic being rerouted through China in June 2019 show that we cannot quite trust the current Internet. SCION is a proposed future Internet architecture aiming to offer high availability and security, even in the presence of actively malicious network operators and devices.<\/p>\n\n<p>Designing a new Internet from scratch gives us the opportunity to make it work a lot better: we are aiming to notably improve security, availability, and performance. At the same time, just replacing the Internet would not be feasible, and thus we also emphasise practical concerns, such as incremental deployment and backwards compatibility. Thanks to that, SCION is currently the only clean-slate Internet architecture with a world-wide research network and production deployments in several large institutions in Switzerland; and you can start using it today.<\/p>\n\n<p>In this lightning talk, we will briefly present the current state of SCION implementation, focusing on how it provides its most important features:<\/p>\n\n<ul>\n<li>path awareness and path control by end hosts<\/li>\n<li>geofencing and isolation from untrusted actors<\/li>\n<li>increased performance by active usage of multiple links<\/li>\n<\/ul>\n\n\n<p>We will point you to the resources presenting how easy it is today for the end user to join the network and start using the available services through the world-wide test deployment, SCIONLab, consisting of around 50 different points-of-presence around the globe, many of them connected via direct, BGP-free, links.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6396",
            "value": "Mateusz Kowalski"
          }
        },
        "links":
        [
          {
            "_href": "https://www.scionlab.org",
            "value": "SCIONLab global research network"
          },
          {
            "_href": "https://www.scion-architecture.net",
            "value": "SCION Internet Architecture"
          },
          {
            "_href": "https://github.com/scionproto/scion",
            "value": "SCION implementation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9892.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10340",
        "start": "10:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_rfc1984",
        "title": "RFC 1984",
        "subtitle": "Or why you should start worrying about encryption backdoors and mass data collection",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In 1996 Brian E. Carpenter of IAB and Fred Baker of IETF wrote a co-statement on cryptographic technology and the internet.  This RFC wasn't a request for a technical standard, it was a statement on their concerns about Governments trying to restrict or interfere with cryptography. They felt that there was a need to offer \"All Internet Users an adequate degree of privacy\"<\/p>\n\n<p>Since that time successive governments around the world have sought to build back doors into encrypted apps and services to access more citizen and visitor data.  As of July 2019, the AG of the United States William Barr stated: “Some argue that, to achieve at best a slight incremental improvement in security, it is worth imposing a massive cost on society in the form of degraded safety,” i.e For security Americans should accept weakened encryption.  The head of the FBI also claimed that weakened encryption wouldn't break it.  At the moment the US Government is actively trying to stop Facebook implementing end to end encryption across it's suite of apps.<\/p>\n\n<p>In Australia the metadata retention laws have been abused against journalists with 58 searches carried out by the AFP.  In 2015 ACT police carried out 115 metadata searches.  UK officials have a cavalier attitude to the EU SIS database which tracks undocumented migrants, missing people, stolen cars, or suspected criminals.<\/p>\n\n<p>The EU isn't immune to this either with France considering implementing Facial Recognition on its government services.<\/p>\n\n<p>IETF Session 105 mentioned privacy and concerns with the mass collection of data. While the IAB and IESG were worried about US export controls on cryptography there is an argument for RFC 1984 to be updated to include the unnecessary mass collection of data and to use it as a term for IT professionals, privacy advocates and the public to rally behind.<\/p>\n\n<p>In this talk let's recount a brief history of governments around the world wanting to weaken encryption as RFC 1984 warned us about.<\/p>\n\n<p>We live in a time where citizens put data into commercial, healthcare and Government systems to access services, some services are only accessible online. From CCTV to Facebook people have little understanding of why mass collection of data is dangerous. There is little scrutiny of who can access that data, from Scotland to the US.<\/p>\n\n<p>Open Surveillance is only a small part of the picture when profiling citizens.  It still counts as personal data, when combined with metadata and the actual data that people put into social media and services like ancestor DNA test kits.  Businesses who use CCTV have to put up signs to warn the public they are recording.  So called anonymized data still contains identifiers that can tie to individuals.<\/p>\n\n<p>Let's talk about Ovid and peacocks. Let's explore how to expand the RFC to cover recent developments in surveillance capitalism with governments accessing that data, but not securing it. We need to make it clear weakened encryption, the mass collection and careless retention of data isn't acceptable. RFC1984 became Best Practice in 2015, we need to do more to raise awareness and to implement it in our projects.<\/p>",
        "description": "<p>Why we need to implement RFC 1984:<\/p>\n\n<p>\"The Internet Architecture Board (IAB) and the Internet Engineering\n   Steering Group (IESG),[...] are concerned by the need for increased\n   protection of international commercial transactions on the Internet,\n   and by the need to offer all Internet users an adequate degree of\n   privacy.\n\"<\/p>\n\n<p>I'd like to start by briefly mentioning Ovid and the legend of Io.  Ovid was anti authoritarian during the time of Augustus as he'd been exiled by the Emperor.  He wrote The Metamorphoses; an epic poem about Greek myths with the theme of transformation.   The myth is often used as a metaphor for surveillance.  With Io suffering restriction of liberty and being abused by authority. Being turned into a cow was bad enough, to make things worse she was constantly watched by the agent of Hera another authority Argus (Argus Panoptes) the 100 eyed giant.  Argus is a great name for a security firm in fact there are quite a few firms that use an eye in the logo.<\/p>\n\n<p>Pop culture like Neil Gamien's American gods on Amazon  have also referenced this legend to show surveillance and how it can convey power to authority.  In the end a modern interpretation of the myth could argue that Hermes sending Argus to sleep to kill him is a good metaphor for opposing actors using exploits to subvert and disable surveillance to access information to Citizens data.   We focus more on Argus the agent of Surveillance rather than Io, who was violated, changed and then incarcerated with surveillance against her will.<\/p>\n\n<p>Argus Panoptes inspired the idea of the Panopticon. A  building design by English Philospher Jeremy Bentham as a prison that could be observed by a single guard.  Our Internet is in danger of being a virtual panopticon for future citizens.  The EFF already started thinking about this with panopticlick so that you can test who's tracking you through your browser. So who's watching us?<\/p>\n\n<p>Of course this explanation and the metaphor is from a Western Perspective.  Privacy doesn't mean the same thing to all countries and cultures.  Neither does the symbolism of the Peacock.<\/p>\n\n<p>Many IT professionals consider RFCs are more like guidelines, see RFC Clueless.org. Popular email services like Me.com, Outlook.com and even gmail.com have been listed on RFC ignorant, then it's successor RFC clueless .  Sadly the giants often ignore RFCs.   Which breaks the idea of interoperable standards and protocols and leaves us in danger of being at the  mercy of large hosting giants.<\/p>\n\n<p>There is a narrative that threads through the media since that time.  Privacy is dead, you need to give up that freedom to stay safe.  Politicians like the UK Prime Minister David Cameron in 2015 stated:<\/p>\n\n<p>.\"In our country, do we want to allow a means of communication between people which even in extremis, with a signed warrant from the home secretary personally, that we cannot read? “Up until now, governments have said: ‘No, we must not'.\" \"<\/p>\n\n<p>Malcolm Turnbull the Australian Prime Minister in 2017 stated that \" the laws of Australia take precedence over the laws of mathematics.\"<\/p>\n\n<p>With organizations like Palantir providing information to ICE to target illegal immigrants in the US; The UK Home Office deliberately destroying data in the the Windrush scandal;  It's clear that human rights, specifically the right to privacy is in danger.  Recently the EU confirmed that UK Border Force officials had illegally copies Shengen SIS data to third party Organizations based in the US.<\/p>\n\n<p>That's before I even start on repressive regimes where that data can and will be used to oppress citizens of that regime.<\/p>\n\n<p>The recent IETF Session 105 this month mentioned privacy and concerns with the mass collection of data. While the IAB and IESG were worried about US export controls on cryptography there is an argument for RFC1984 to be updated to include the unnecessary mass collection of data and to use it as a term for IT professionals, privacy advocates and the public to rally behind.<\/p>\n\n<p>I propose a brief history of governments around the world wanting to weaken encryption as RFC1984 warned us about:<\/p>\n\n<p> \" The IAB and IESG are therefore disturbed to note that various\n   governments have actual or proposed policies on access to\n   cryptographic technology that either:<\/p>\n\n<p>   (a) impose restrictions by implementing export controls; and/or<\/p>\n\n<p>   (b) restrict commercial and private users to weak and inadequate<\/p>\n\n<pre><code>   mechanisms such as short cryptographic keys; and/or\n<\/code><\/pre>\n\n<p>   (c) mandate that private decryption keys should be in the hands of<\/p>\n\n<pre><code>   the government or of some other third party; and/or\n<\/code><\/pre>\n\n<p>   (d) prohibit the use of cryptology entirely, or permit it only to<\/p>\n\n<pre><code>   specially authorized organizations.\"\n<\/code><\/pre>\n\n<p>RFC 1984 was explicitly named to reference an Orwellian Society that uses mass surveillance.  Let's expand that beyond encryption to the mass collection of data and ask how do we limit this?  How do we limit access to this data?  How do we stop the nightmare?<\/p>\n\n<p>Addendum: As time goes on with the current political climate, I expect more focus by the media and the IAB and the IETF on this subject.  So while the overall thrust of this presentation will be the same, I plan to keep it as fresh as possible.<\/p>\n\n<p>I will be updating this talk with more of a focus on Biometric data including Facial Recognition.<\/p>\n\n<p>I recently presented a version of this talk at UBUCON Europe in October 2019<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6496",
            "value": "Esther Payne"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=ZVXTojz4dZI",
            "value": "Ubucon October 2019"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10340.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9267",
        "start": "10:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_fixing_healthcare_data",
        "title": "Fixing healthcare data exchange with decentralized FOSS",
        "subtitle": "Building a decentralized Infrastructure to fix medical data exchange in The Netherlands.",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In The Netherlands we have a interesting problem: in 2011, weeks before going live, the national electronic health record system got shut down by our senate. They decided not to interveine and let the market fix the problem. Now, 9 years later, the market has made a mess out of it: there is no uniform way of exchanging medical data in The Netherlands.\nArchitects write countless of pages with solutions, the government pours  millions into subsidised programs, but the problem is only getting bigger.<\/p>\n\n<p>So, 2 years ago together with a group of other software vendors we started a foundation called Nuts. The goal is to end this impasse by building an open source decentralised infrastructure that nobody controls and can be used by everyone. It should be cheap to join, privacy by design, and use technology over lawyers.<\/p>\n\n<p>Our infrastructure allows parties to exchange data \"peer to peer\", only helping them solve four generic problems: user identity, patient consent, discovery of endpoints and logging.<\/p>\n\n<p>In this talk I would like to show our architecture, explain which choices we made, what we have learned while working with a distributed software and some anecdotes about what happens if you pitch such an idea to the establishment.<\/p>\n\n<hr />\n\n<p>A little more background: I'm one of the main devs. The system is written mostly in Go and some parts in Java. Every software vendor can spin up a node and join the network. Patient Consents are distributed by a DLT (Corda) and are only stored on the nodes of vendors who already process the patient`s data. No medical data flows through the system, Nuts is only used to connect them and provide a level of trust. Identities are managed by a self-sovereign Identity system called IRMA (irma.app) which is based on IBM idemix.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6581",
            "value": "Steven van der Vegt"
          }
        },
        "links":
        [
          {
            "_href": "https://nuts.nl",
            "value": "Main website (in Dutch)"
          },
          {
            "_href": "https://nuts-documentation.readthedocs.io/en/latest/",
            "value": "Docs"
          },
          {
            "_href": "https://github.com/nuts-foundation",
            "value": "Source"
          },
          {
            "_href": "https://irma.app/?lang=en",
            "value": "IRMA Identity app"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9267.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9324",
        "start": "11:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_p2p_kademlia",
        "title": "P2P how and Kademlia",
        "subtitle": "P2P how and Kademlia",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Recently there has been tremendous interest in P2P systems and their usefulness. However most people are confused about how they work, how nodes are techno-magically able to find each other or the right other node with expected data. This talk would start p2p from basics, it's differences with client-server systems and then different ways p2p systems can operate, dhts as one way. And then end with more specific things as kademlia being a good dht and how does it work. It would be interesting because it (kademlia) powers some of the most popular p2p systems such as bittorrent, IPFS, Ethereum, I2P, Tox etc.<\/p>",
        "description": "<p>Contents of the talk would be as follows\n- what is a p2p system\n- a bit about client-server\n- finding nodes in client-server vs p2p\n- p2p as overlay networks\n- some earlier p2p systems and their limits\n- distributed hash tables to rescue, dht basics\n- what makes a good dht<\/p>\n\n<p>since Kademlia is a good dht<\/p>\n\n<p>Kademlia\n- core ideas (Uniform ID Space, Closeness, Local view)\n- protocol messages\n- joining network\n- locating nodes and resources\n- storing\n- go-libp2p-kad-dht<\/p>\n\n<p>TADA!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6421",
            "value": "Kishan Sagathiya"
          }
        },
        "links":
        [
          {
            "_href": "https://kishansagathiya.github.io/talks/P2P_how_and_Kademlia.pdf",
            "value": "Slides for previous version of this talk"
          },
          {
            "_href": "https://www.youtube.com/watch?v=HGe_3EX0XZ8&feature=youtu.be&t=7849",
            "value": "Video for previous verision of this talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9324.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9321",
        "start": "11:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_gnunet",
        "title": "GNUnet: A network protocol stack for building secure, distributed, and privacy-preserving applications",
        "subtitle": "GNUnet basics, the GNU Name System and other applications.",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk we will give a brief introduction into the GNUnet peer-to-peer framework, its architecture and existing applications.\nThis includes details on the p2p overlay, double-ratchet messaging channels (CADET) the GNU Name System (GNS) and a selection of other applications and features.\nWe present the current status of the project, the roadmap as well as ways to participate and use GNUnet.<\/p>",
        "description": "<p>GNUnet is a new network protocol stack for building secure, distributed, and privacy-preserving applications. With strong roots in academic research, our goal is to replace the old insecure Internet protocol stack.<\/p>\n\n<p>GNUnet is typically run as an overlay network on top of the existing Internet infrastructure forming the basis of a hybrid peer-to-peer mesh and relay backbone for applications to run on. It could just as well be run independently of the Internet, over dedicated radio and cable.<\/p>\n\n<p>GNUnet is made for a free and open society: It's a self-organizing network and it is free software as in freedom. GNUnet puts you in control of your data. You determine which data to share with whom, and you're not pressured to accept compromises.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6630",
            "value": "Martin Schanzenbach"
          }
        },
        "links":
        [
          {
            "_href": "https://gnunet.org",
            "value": "The project website of GNUnet"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9321.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9296",
        "start": "12:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_secusharebox",
        "title": "Knocking Down the Nest",
        "subtitle": "secushareBOX - p2p & encrypted IoT and beyond...",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>More and more people are inviting corporate-controlled networked devices into their homes. Can we make truly \"smart devices\" which we control, and communicate directly with, instead of through the cloud? We're building a privacy-preserving and peer-to-peer IoT platform: secushareBOX<\/p>",
        "description": "<p>Lightbulbs, thermostats, video cameras, maybe even toasters; People are putting all kinds of networked devices in their homes these days. The majority of these devices can only be controlled through proprietary and centralized cloud based services, with the data and metadata being ingested by surveillance machine.<\/p>\n\n<p>Let's build a better \"Internet of Things\".<\/p>\n\n<p>secushareBOX is a peer-to-peer and privacy-preserving project for remote system management, including embedded devices. Conceived as an alternative to the centralized pattern so common to IoT platforms; With secushareBOX you communicate directly with your devices, and manage access control with your peers and other systems as modeled in a social graph. Using GNUnet as our underlying p2p framework, we inherit an active network of nodes with which we are able to route our traffic in a manner which preserves our metadata, and utilizes end-to-end encryption for all connections.<\/p>\n\n<p>This talk will introduce the ideals, and concepts of the project. Followed with a demo of the current state, and discussion of our future plans.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6608",
            "value": "Devan Carpenter"
          }
        },
        "links":
        [
          {
            "_href": "https://box.secushare.org",
            "value": "Homepage of secushareBOX project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9296.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10528",
        "start": "12:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_p2pcollab",
        "title": "Peer-to-peer collaboration, search & discovery",
        "subtitle": "Decentralized collaborative application development",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A data-centric, offline-first approach to decentralized collaborative application development focusing on data ownership and privacy.<\/p>",
        "description": "<p>Exploring replicated mergeable data structure stores as building blocks of decentralized applications that enable asynchronous collaboration and offline search in combination with peer-to-peer gossip-based protocols that provide pub/sub, dissemination, and recommendation services both over the internet as well as on local and mobile proximity networks, thereby forming interest-based networks that facilitate discovery of personally relevant content and people.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7267",
            "value": "TG x"
          }
        },
        "links":
        [
          {
            "_href": "https://p2pcollab.net",
            "value": "P2Pcollab"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10528.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10328",
        "start": "13:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_dat_browser",
        "title": "DAT protocol in the browser: Progress and Challenges",
        "subtitle": [],
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Dweb protocols, like DAT and IPFS, promise significant benefits over the standard client-server protocols for web content. Particularly for self-hosting and -publishing, these protocols could reduce barriers to entry by eliminating server costs as well as promoting data ownership. Despite this, there has been no adoption of these protocols in mainstream browsers yet. This talk gives an overview of work to add native-like support for the DAT protocol to Gecko-based browsers. We discuss the limitations of the current WebExtension APIs in Chrome and Firefox for this purpose, and how Firefox's libdweb project improves on this. We present the dat-webext browser extension which implements DAT support in Firefox on Desktop and for Geckoview on Android.<\/p>",
        "description": "<p>This talk will cover the content of the following two blog posts, as well as more recent developments:<\/p>\n\n<ul>\n<li>https://sammacbeth.eu/blog/2019/03/22/dat-for-firefox-1.html<\/li>\n<li>https://sammacbeth.eu/blog/2019/05/12/dat-for-firefox-2.html<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6004",
            "value": "Sam Macbeth"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10328.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10440",
        "start": "13:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_tor_dev_intro",
        "title": "An Introduction to the Tor Ecosystem for Developers",
        "subtitle": [],
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Tor is a free and open-source software anonymization system that allows people around the world to use the internet safely. The Tor network itself is operated by various volunteering individuals and organizations around the globe, and the network carries around 200 Gbit/s of traffic and helps somewhere between 2,000,000 and 8,000,000 users every day. The Tor ecosystem is much larger than the anonymity system that Tor provides itself: The Tor Project, the non-profit behind the anonymity system, also develops and maintains a web browser based on Mozilla Firefox. The organization also does monitoring of the network, work on emerging anti-censorship technology, work with translators, and downstream distributions that do packaging in free software operating system distributions.<\/p>\n\n<p>In this presentation, we will have a look at what it takes to develop and maintain an anonymity system like Tor and the various other components in the Tor ecosystem. We will look at what The Tor Project has been up to lately, primarily with a focus on core Tor itself. However, we will also have a look at some of our recent developments with anti-censorship technology. Finally, we will have a look at how the participant can contribute to the Tor project.<\/p>\n\n<p>No prior knowledge of Tor is necessary to participate.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7127",
            "value": "Alexander Færøy"
          }
        },
        "links":
        [
          {
            "_href": "https://www.torproject.org/",
            "value": "Tor Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10440.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10519",
        "start": "14:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_openpush",
        "title": "OpenPush",
        "subtitle": "Introducing a Free, Decentralized Push Messaging Framework for Android",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Push messages are an essential part of connected mobile devices. They are also one of the critical missing pieces in the open source Android ecosystem.\nUntil now, free Android apps would either need to implement their own push notification system, do without any push messaging or use the proprietary Google Cloud Messaging service.\nIn this talk I will introduce OpenPush, a free and open source, self-hosted and decentralized replacement for Google Cloud Messaging.<\/p>",
        "description": "<p>We expect both a long battery life and instant notifications from our mobile devices.\nWhen implementing your own mobile push functionality you can usually optimize for either of these goals.\nThis is especially true if the user is running multiple applications which each come with their own persistent on-going connection for push notifications.\nWanting to combat the battery drain associated with maintaining multiple connections Google introduced the Google Cloud Messaging (GCM) framework which recently has become Firebase Cloud Messaging (FCM). Firebase Cloud Messaging relies on the availability of the proprietary Google Play Services Framework on an Android device. Using FCM also requires the inclusion of the proprietary FCM client library into open source Android apps like Signal, Wire or even Firefox, which makes them effectively non-free software which cannot be distributed via the fully free F-Droid software repository.\nAdditionally all push notifications delivered via FCM need to pass through Google's servers leaving a metadata trace, even if it's an empty wakeup event or if the content of the message is encrypted.<\/p>\n\n<p>Decentralized, self-hosted systems like Matrix, Nextcloud or RocketChat currently still have a dependency on Google's infrastructure and Terms of Service for delivering push Notifications.<\/p>\n\n<p>In this talk I'll present a self-hosted, free alternative push messaging implementation which can either run alongside or as a replacement to FCM.\nThe talk will give a general architecture overview as well as walk through the design and implementation challenges of a push messaging service.<\/p>\n\n<p>Further I'll present how OpenPush can be used by different projects and discuss some additional ideas on how the wider ecosystem could look like in the future.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7120",
            "value": "Marcus Hoffmann"
          }
        },
        "links":
        [
          {
            "_href": "https://bubu1.eu/openpush",
            "value": "Project website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10519.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10368",
        "start": "14:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_p2p_matrix",
        "title": "The Path to Peer-to-Peer Matrix",
        "subtitle": "In which we throw away DNS and run Matrix clientside over libp2p and friends",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Matrix is an open source project run by the non-profit Matrix.org Foundation dedicated to building an open protocol and communication network for decentralised, encrypted communication - providing a viable open alternative to WhatsApp, Slack, Discord an other proprietary communication silos.  In this talk we will show of the work we've been doing over the last year to shift Matrix from being a decentralised-server architecture to a fully decentralised-client p2p architecture, through running clientside homeservers and experimenting with libp2p and friends as a p2p transport.  We'll also show the route we'll be following over the year to go from proof-of-concept to the live Matrix network.<\/p>",
        "description": "<p>Traditionally Matrix decentralises communication by replicating conversation history over a mesh of servers, so that no single server has ownership of a given conversation.  Meanwhile, users connect to their given homeserver from clients via plain HTTPS + DNS.  This has the significant disadvantage that for a user to have full control and ownership over their communication, they need to run their own server - which comes with a cost, and requires you to be a proficient sysadmin.  In order to fully democratise communication and eliminate a compulsory dependency on a homeserver, we've started seriously working on making Matrix run as a P2P protocol by compiling homeservers to run clientside and using P2P transports such as libp2p - while seamlessly supporting all existing Matrix clients (e.g. Riot.im), bots and bridges with negligible changes.  This work includes:<\/p>\n\n<ul>\n<li>Compiling Matrix homeservers (e.g. Dendrite) to efficiently run clientside<\/li>\n<li>Layering HTTPS over P2P transports such as libp2p (e.g. https://github.com/matrix-org/libp2p-proxy)<\/li>\n<li>Switching Matrix identifiers from @user:domain tuples to be Curve25519 public keys (<a href=\"https://github.com/matrix-org/matrix-doc/blob/rav/proposal/remove_mxids_from_events/proposals/1228-removing-mxids-from-events.md\">MSC1228<\/a>)<\/li>\n<li>Decentralising accounts so they can be hosted concurrently on multiple nodes (e.g. a mix of server-side and client-side homeservers)<\/li>\n<li>Experimenting with node discovery from DNS to DHTs and other mechanisms (e.g. gossip mechanisms)<\/li>\n<li>Experimenting with smarter bandwidth-efficient routing algorithms than full-mesh (e.g. combinations of spanning trees, overlapping spanning trees, gossip mechanisms)<\/li>\n<li>Making Matrix's low-bandwidth CoAP transport production grade<\/li>\n<li>Experimenting with metadata-protecting relay mechanisms rather than using full homeservers for server-side relaying.<\/li>\n<\/ul>\n\n\n<p>In this talk we'll show off our progress so far, and lay out the path forwards over the coming year as we go from proof-of-concept to the live Matrix network.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2951",
            "value": "Matthew Hodgson"
          }
        },
        "links":
        [
          {
            "_href": "https://matrix.org",
            "value": "Matrix.org"
          },
          {
            "_href": "https://matrix.org/foundation",
            "value": "The Matrix.org Foundation"
          },
          {
            "_href": "https://github.com/matrix-org/matrix-doc/blob/rav/proposal/remove_mxids_from_events/proposals/1228-removing-mxids-from-events.md",
            "value": "MSC1228 - Removing MXIDs from events"
          },
          {
            "_href": "https://github.com/matrix-org/libp2p-proxy",
            "value": "libp2p-proxy - libp2p as a Matrix transport"
          },
          {
            "_href": "https://matrix.org/docs/spec",
            "value": "The Matrix.org Specification"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10368.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10555",
        "start": "15:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_securing_protonmail",
        "title": "Building a Web App that Doesn’t Trust the Server",
        "subtitle": "Securing ProtonMail",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How do you know WhatsApp Web isn’t spying on your messages, despite the end-to-end encryption? Why did Signal decide to build a desktop application instead of a web app?<\/p>\n\n<p>Open Source clients are a necessary, but unfortunately not sufficient, requirement for guaranteeing privacy. This talk explores two other issues: how to securely deliver that source code, and how to securely deliver the encryption keys that users use to communicate. It also presents our proposed solutions to these problems.<\/p>",
        "description": "<p>At ProtonMail, we’re aiming to build a web application that gives users the guarantee that we are physically unable to read their email, even if we wanted to. This comes with a set of challenges: how can the user trust the source code that comes from the server (without reading it each time), and how can the user trust the public keys that they receive (without hosting key signing parties, however fun they may be :)).<\/p>\n\n<p>We currently support self-hosting, and manual key verification and pinning as solutions to these issues, respectively. However, these are highly manual solutions. This talk will present two projects we’ve been working on to provide privacy guarantees without requiring any action: Source Code Transparency and Key Transparency.<\/p>\n\n<p>Finally, we’ll also briefly discuss what kind of APIs we could add to browsers to make it easier to develop web apps that don’t trust the server.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7182",
            "value": "Daniel Huigens"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10555.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9691",
        "start": "15:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_maadix",
        "title": "MaadiX, your cloud in your hands",
        "subtitle": "Tool Kit and Graphical interface for VPS management",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Avoiding repressive surveillance, circumventing censorship and protecting privacy can become a complicated and costly challenge. Many of the available alternatives do not completely solve the problem of trust, centralization of information and dependency on whoever is offering the services to us. Initiatives that offer alternative tools often become targets of censorship and repressive surveillance. Others do not include all the services the community needs, or require a minimum of technical knowledge, forcing organizations to continue using applications offered by third parties or renounce them.<\/p>\n\n<p>MaadiX is a solution that reverses this imbalance in favor of users, giving them back control over their communications and data, as well as over all the applications they need in order to process them, facilitating the technical adoption and maintenance of server-side, privacy-oriented, secure, and censorship circumvention technologies.<\/p>",
        "description": "<p>MaadiX provides one click installation of advanced free and open source applications such as email server, mailman 3, openVPN, RocketChat. Owncloud, Nextcloud, OnlyOffice. Libre Office Online among many others, on remote or local private servers, without the need to have access to their system and data, and  providing updates and technical support.<\/p>\n\n<p>MaadiX  acts as a repository of 'recipes' that provides all the instructions and commands needed to automatically install and configure applications from a  graphical interface.<\/p>\n\n<p>The catalogs are served through Puppet modules but we've  changed the way these technologies works, improving them in order to avoid creating yet another centralized google-like model and avoiding having access to users' systems and data.<\/p>\n\n<p>MaadiX has been reviewed by external security auditors. We would like to dicuss with the audience how to better deal with the balance between security and usability and share how MaadiX works as well as which community is actually around the project or is using it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4169",
            "value": "Maddish Falzoni (MaadiX)"
          }
        },
        "links":
        [
          {
            "_href": "https://maadix.net",
            "value": "MaadiX Website"
          },
          {
            "_href": "https://gitlab.com/MaadiX",
            "value": "Repository"
          },
          {
            "_href": "https://twitter.com/MaadiXnet",
            "value": "twitter"
          },
          {
            "_href": "https://mastodon.social/@MaadiX",
            "value": "Mastodon"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9691.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9129",
        "start": "16:00",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_decentralizing_oauth",
        "title": "Decentralizing OAuth2.0 in a post-GDPR world for full privacy and portability",
        "subtitle": "Automating, API-fying and Tokenizing GDPR for privacy and portability with open source software",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Users want their data back and the ability to transfer them the way they want to the platform they want. This si user's freedom in a digital world. Today, because of current authorization protocols/framework design like OAuth2.0, power is concentrated to the identity providers who decide what applications they allow to access their API and the user cannot say anything about it.  New regulations like GDPR have appeared to enforce this freedom for users by law but there is not yet tooling for developers to make  GDPR data ownership and  GDPR data portability happen, useful for users to avoid this\nTo really decentralize data permissions from platforms control, make users in control of their privacy and make companies GDPR compliant, you need now to update OAuth2.0 dance into a stateless flow and tokenize the GDPR authorization and agreements to make it programmable for developers.\nIn this talk, Mehdi will explain how you can use open source technologies to automate GDPR requests for your users to, build APIs on top of GDPR takeouts, export GDPR user 3rd-party data in your system and tokenize your GDPR agreements to make them programmable for compliance using opens source technologies.<\/p>",
        "description": "<p>Making GDPR programmable and adding decentralization of data portability to OAuth2.0<\/p>\n\n<p>In the classic OAuth 2.0 flows, the authorization server and the resource server are behind the same firewall, giving full power and control about sharing capabilities to the Identity Provider (i.e. Facebook, Amazon, Google etc...). The Identity Provider decides what can be shared to whom via its API, and the user is limited into making data exportable to what the Identity provider allows.\nBecause of new regulations about data portability (GDPR in Europe and CCPA in California), now every user is able to ask a full export of its data to be stored anywhere, breaking Identity Provider monopoly and control. In that context, users can now own fully a copy of their data and share it to who they want. They can now become theoretically independent from previous Identity providers, by becoming their own Identity Provider if they are able to install a server to do so themselves, or theoretically choose the Identity provider that is the best delivering value for them about managing their personal data and permissions.\nAs we seen in Bitcoin, a large majority of users will still want to delegate authorizations to a trusted 3rd-party to manage permissions, as they do until today with banks for their money, or to wallet managers for their Bitcoins/Crytocurrencies. In the Alias protocol ecosystem,users decide where their data is stored (on the server of their choice) and decide the Alias authorization server that will manage its permissions.<\/p>\n\n<p>Introducing Alias protocol<\/p>\n\n<p>Alias is a protocol enabling decentralized data export authorizations. When implemented, Alias enables for users to decide to share the data they want, to whom they want, without limitations from any centralized Identity Provider, and in fine grained control.\nTechnically, Alias is a decentralized protocol based on OAuth 2.0, where each user, identified by an cryptographic alias, can let third-parties (\"clients\") access to their data stored in servers (\"resource servers\"). Access to the data is controlled by an Authorization server (\"authorization servers\") that manages permissions and scopes. The main innovation of Alias is that the resource server and the authorization server do not need to be behind the same firewall, enabling users to decide freely and in full control who store their data and who manage permissions in a decentralized way.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6518",
            "value": "Mehdi Medjaoui"
          }
        },
        "links":
        [
          {
            "_href": "http://gdpr.dev",
            "value": "Open source dev tools for GDPR"
          },
          {
            "_href": "https://github.com/progressive-identity",
            "value": "Repository of the project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9129.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10491",
        "start": "16:30",
        "duration": "00:30",
        "room": "UA2.220 (Guillissen)",
        "slug": "dip_decentralize_fediverse",
        "title": "Who will Decentralise the Fediverse?",
        "subtitle": "Self hosting on the Fediverse 3 years on.",
        "track": "Decentralized Internet and Privacy",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The promise of the internet has not been kind. In mainstream tech and open source alike, social media tech has failed a lot of people. People often face surveillance and abuse over valuable human interaction, or technology for technology's sake.<\/p>\n\n<p>Software like Mastodon has signaled a significant step forward towards a vision for how we can take existing social media and distribute power so that people can benefit.\nIn many respects, the experience is still not ideal, this talk highlight some of the key point that can make or break the fediverse<\/p>",
        "description": "<p>The talk will be split in 3 parts.\nMostly looking at the past and the Fediverse history.\nThe present and the set of challenges\nThe future and some proposal on how to overcome those challenges.\nQuesions<\/p>\n\n<h1>Past:<\/h1>\n\n<p>The success of Mastodon and other AP compatible software brought a lot of people from different sphere together, and with that diversity the network took off.<\/p>\n\n<p>Free and Open Source enthusiasts, activists, hacktivists, sex workers, G+ / Tumblr/Twitter refugee, communities of interest (tabletop, craft, parenthood, etc.) and people that simply wanted a more personal place to socialise, all mingled together and really pushed the envelop of what a social network can be.<\/p>\n\n<p>Within this mix of people and interest, the most marginalized people challenged the status quo and got us better tools than we ever had like post visibility, content warning, image description, etc.  as a standard way of communication.<\/p>\n\n<h1>Forward to today:<\/h1>\n\n<p>There are a few major obstacle for the fediverse to operate:\n* A naive vision of moderation and hostile actors constantly puts community moderators on the back foot. Gab and kiwifarm showed us that admins need to be constantly on the lookout if they want to protect their community<\/p>\n\n<ul>\n<li><p>Activity Pub software, by and large, are not made for efficiency. It's hard to host a Mastodon instance unless you have can afford expensive hosting and storage fees.<\/p><\/li>\n<li><p>Designs within AP compatible software is often confusing and not very friendly for newcomers. We have seen how waves of people come to the fediverse and how most of them leave again, unable to comprehend the experience possible.<\/p><\/li>\n<li><p>Marginalised communities are less and less heard, diminishing the trust in the current tooling. The fediverse pushing for a mainstream audience means that marginalised communities are now mostly operating in forks and the fringe rather than able to contribute to upstream.<\/p><\/li>\n<li><p>Tools and software have an increasing emphasis on emulating proprietary software like Twitter/Youtube/etc. The current direction is replicating mechanism to drive engagement rather than fostering meaningful interactions between people.<\/p><\/li>\n<li><p>ActivityPub - the protocol that Mastodon really help get traction, has significant privacy and security flaws. This is one of the fundamental challenge we currenltly have. It is being worked on.<\/p><\/li>\n<\/ul>\n\n\n<h1>Future<\/h1>\n\n<ul>\n<li>Proposal on some of the key feature and changes that would solve some of the problems mentionned above.<\/li>\n<\/ul>\n\n\n<h1>Question<\/h1>\n\n<p>Question from the audience.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7274",
            "value": "kyzh"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10491.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB2.147",
    "event":
    [
      {
        "_id": "10541",
        "start": "09:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_tesselle",
        "title": "Tesselle image viewer",
        "subtitle": "Ease viewing and sharing High Resolution images on the web",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Tesselle is an open source image viewer allowing anyone to open, annotate and share big images on the web. It is part of the \"Quinoa\" project family, a suite of digital storytelling tools tailored for the FORCCAST teaching program and the scientific activities of Sciences Po's médialab. (list tools with links ?)<\/p>",
        "description": "<p>Tesselle is a tool for annotating and publishing large, very large, huge images!\nTo scale with High Res image, it embeds a tiling feature to seamlessly display and navigate them on the web.\nIt allows to comment on specific portions of photographs, maps or visualizations. It gives you the possibility to explore and analyse visual items in detail and precisely.\nFurthermore, Tesselle allows to export your work as a simple folder to publish anywhere on the web.\nThose features have been built to allow scholars to create stories be crafting annotations on cartographic map, artwork analysis, network vizualisations... Using image opens many usecases.<\/p>\n\n<p>It is built using Typescript, React and Leaflet.\nAs a standalone serverless webapp, Tesselle has met some pitfalls:\n - What is the fastest way to tile an image on the front-end?\n - Are there enough tools in a browser or shall we bring WebAssembly in?\n - How to handle memory management when dealing with hundreds of tiles?\n - Can we beat a \"native\" image viewer?\n - How should we handle sharing and embedding?\n - Is IIIF an appropriate standard?\n - What are our limitations?\nThose are some of the questions we had / have to answer while building Tesselle.<\/p>\n\n<p>https://github.com/medialab/tesselle/<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7293",
            "value": "Arnaud Pichon"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10541.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9736",
        "start": "10:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_jpeg2000",
        "title": "The Rise and Fall and Rise of JPEG2000",
        "subtitle": "Currently a niche codec, recent enhancements to the JPEG 2000 standard speed it up by 10x and will propel it into the mainstream.",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>JPEG 2000 was developed to replace the very successful JPEG standard, but it has instead\nremained a niche code. With recent updates to the standard speeding up decode by 10X, is\nworld domination around the corner ? This talk will describe many of the sophisticated features\nthat JPEG 2000 offers, and discuss why a 20 year old standard may be the codec of the\nfuture.<\/p>",
        "description": "<p>Released in 2000 as a potential replacement for the wildly successful JPEG standard, JPEG 2000 is a versatile codec with many sophisticated features including:<\/p>\n\n<pre><code>Superior compression at low bit rates\nStorage of multiple resolutions in a single bitstream\nPrecise rate control without re-compression\nLossy and losssless compression\nProgression by resolution, component, spatial region or quality\n<\/code><\/pre>\n\n<p>It is an essential codec in medical imaging, digital cinema and remote sensing. However, due to its high complexity,\nit has remained a niche codec that never gained the popularity of its predecessor.<\/p>\n\n<p>All of this is about to change with the recently released High Throughput JPEG 2000 standard that speeds up the codec by up to 10x,\nwhile leaving almost all of its features intact. This will propel it into the mainstream, particularly in broadcast and digital cinema.<\/p>\n\n<p>I will talk about the history of JPEG 2000, give an overview of its features and discuss the upcoming changes.\nI will also talk about current and planned GStreamer support for JPEG 2000.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6924",
            "value": "Aaron Boxer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9736.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9100",
        "start": "10:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_qml",
        "title": "Rendering QML to make videos in Kdenlive",
        "subtitle": "How QML, a language prominently used for designing UI, is being used in editing videos.",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How QML, a language prominently used for designing UI, could be used to create title clips containing text and/or images and rendered using Qt OpenGL libraries, which can then be composited over videos during the video editing process. Kdenlive's Google Summer of Code 2019 project tried to achieve this and is still under active development.<\/p>",
        "description": "<p>QML is used primarily for UI development in Qt Applications, which means designing and creating is quite easy and comfortable in QML. Kdenlive is a popular non-linear open-source video editor and it currently makes use of XML to describe a title clip (which are clips which contain text or images used to composite over videos) and XML requires more processing on the backend as one needs to explicitly write code for, say an animation of the text. Using QML eases this restriction, making the backend more robust and maintainable. This year (2019), Kdenlive's Google Summer of Code Student tried to achieve this by creating a new rendering backend library and a new MLT QML producer and is still in active development. Also, rendering QML makes use of the Qt Scene Graph, which could possibly have a greater performance since the rendering backend makes use of the Qt Scene Graph.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6498",
            "value": "Akhil Gangadharan Kurungadathil"
          }
        },
        "links":
        [
          {
            "_href": "https://akhilam512.github.io/",
            "value": "Personal Blog"
          },
          {
            "_href": "https://community.kde.org/GSoC/2019/StatusReports/AkhilKGangadharan",
            "value": "GSoC 2019 Status Report"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9100.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10560",
        "start": "11:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_gstreamer_mlo",
        "title": "GStreamer on the Magic Leap One",
        "subtitle": [],
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Magic Leap One is an augmented reality glasses. Let's run an Open Source Browser (Mozilla Servo) using GStreamer multimedia framework on it.<\/p>",
        "description": "<p>The Magic Lean One device runs a custom OS called LuminOS, derived from Android with JAVA stripped off. Servo is Mozilla's browser written in Rust that uses GStreamer to render multimedia content.<\/p>\n\n<p>Presentation of the challenges and solutions found to make it happen:\n- GStreamer's Meson build system.\n- Stagefright-ish API in the SDK.\n- Completely new audio API, with 3D space localization.\n- OpenGL rendering, including stereoscopic SBS.\n- It's now all upstream!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7307",
            "value": "Xavier Claessens"
          }
        },
        "links":
        [
          {
            "_href": "https://servo.org/",
            "value": "Mozilla Servo"
          },
          {
            "_href": "https://creator.magicleap.com/home",
            "value": "Magic Leap One"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10560.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10406",
        "start": "11:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_gpac",
        "title": "GPAC 1.0 Overview",
        "subtitle": "GPAC's past, present and future",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, we present the next release of GPAC, the complete rearchitecture of its streaming core, the many new features and possibilities of the multimedia framework. Get ready for a lot of OTT/IP streaming and broadcast, encryption, packaging and media composition!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7235",
            "value": "Jean Le Feuvre"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10406.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10532",
        "start": "12:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_imsc",
        "title": "IMSC Open Source Projects",
        "subtitle": "How to combine different Open Souce Caption Tools",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>IMSC is the Internet Media Subtitle and Caption Profile of the W3C Timed Text Markup Languages. The presentation will show how to combine different open source tools to create, render and validate IMSC subtitles. The focus will be on an open-source editor for IMSC.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "2735",
            "value": "Andreas Tai"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/IRT-Open-Source/imsced",
            "value": "imedED - IMSC Subtitle Editor"
          },
          {
            "_href": "https://github.com/IRT-Open-Source/scf",
            "value": "SCF Subtitle Conversion Framework"
          },
          {
            "_href": "https://github.com/sandflow/imscJS",
            "value": "imscJS - Rendering Library for IMSC"
          },
          {
            "_href": "https://github.com/IRT-Open-Source/xcf",
            "value": "xcf - XML Checker Framework"
          },
          {
            "_href": "https://subcheck.io/#/",
            "value": "Awendungsbeispiel des XML Checker Frameworks"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10532.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10548",
        "start": "12:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_streaming",
        "title": "Which video network streaming protocol should I use?",
        "subtitle": [],
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open source stacks such as GStreamer, ffmpeg and UPipe now implement a large number of different ways to stream audio &amp; video over a network. Just to name a few, there are RTSP, SRT, RIST, WebRTC, HLS, DASH, AES67, SmoothStreaming, RTMP! Some are for local networks and some target the Internet, depending on the use-case, these protocols have different upsides and downsides. To create a successful project, one needs to select the best suited technology. I'll go over the various protocols and explain how they relate to each other and their individual advantages and inconveniences.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4797",
            "value": "Olivier Crête"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10548.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10561",
        "start": "13:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_animation",
        "title": "FOSS in Animation",
        "subtitle": "The state of Free and Open Source software in the Animation and VFX Industry",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Animation industry has always been ruled by proprietary software, mainly from Autodesk, Adobe and The Foundry. But recently we noticed a rise of interest in software like Blender or Krita. Alongside them, initiatives like the Academy Software Foundation are popping. Last but not least, more and more studios publish the sources of their in-house software. During this conference, we'll explain how a typical production pipeline works. Then, we'll discuss how open source impacts animation productions and what we can expect for the future. As a conclusion, I'll explain how studios collaborate more together through free and open-source software.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7309",
            "value": "Frank Rousseau"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/cgwire/awesome-cg-vfx-pipeline",
            "value": "List of all open source tools that can help in an animation pipeline"
          },
          {
            "_href": "https://landscape.aswf.io/",
            "value": "Open Source Landscape by the ASWF"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10561.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10716",
        "start": "13:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_dav1d",
        "title": "dav1d: 1 year later",
        "subtitle": "dav1d is a fast AV1 decoder",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>dav1d is an open source decoder for the AV1 format, focused on being fast and lean.<\/p>",
        "description": "<p>It was started a bit more than one year ago. This is a talk to see where this project is now, how fast we achieved for decoding AV1 samples and what is left to do on this project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2538",
            "value": "Jean-Baptiste Kempf"
          }
        },
        "links":
        [
          {
            "_href": "https://code.videolan.org/videolan/dav1d",
            "value": "Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10716.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10676",
        "start": "14:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_rav1e",
        "title": "rav1e - 0.3.0 and after",
        "subtitle": "What we did so far and what will do in the future",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>rav1e is an opensource Av1 encoder.<\/p>\n\n<p>We'll see what makes it fairly unique beside the choice of using Rust as main development language.<\/p>",
        "description": "<p>We'll see what we did in the past releases, what design choices we took and what we plan to do in the next two releases.<\/p>\n\n<p>By February we will have the release 0.2.0 and the release 0.3.0 out. I'll present what's coming in the release 0.4.0 and 0.5.0.<\/p>\n\n<p>This will include some performance evaluation and describing some of the features are currently unique in rav1e.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4860",
            "value": "Luca Barbato"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10676.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10217",
        "start": "14:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_spleeter",
        "title": "Spleeter by Deezer",
        "subtitle": "Open-Sourcing a Machine-Learning Music Source Separation Software",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Source separation, stem separation, de-mixing are all different ways of referring to the same problem of recovering the mono-instruments tracks that were mixed together to produce a music file. Recently, the research team at Deezer released a free and open source software as well as trained models to perform multi-source separation of music, with state-of-the-art accuracy.\nIn this presentation we come back on our journey to open sourcing the Spleeter library, from doing the ground research, training the models, to releasing them. We put emphasis on the technological challenges that had to be solved as well as the practical and legal considerations that came into play.<\/p>",
        "description": "<p>Released on october 29th 2019, the Spleeter (https://github.com/deezer/spleeter) github repository received more than 5000 stars on its first week online and numerous positive feedbacks as well as press coverage. This talk will explain how we went from research code to this fairly easy to use open Python library, that integrates pre-trained models for inference and re-training.<\/p>\n\n<p>While not a broadly known topic, the problem of source separation has interested a large community of music signal researchers for a couple of decades now. It starts from a simple observation: music recordings are usually a mix of several individual instrument tracks (lead vocal, drums, bass, piano etc..). The task of music source separation is: given a mix can we recover these separate tracks (sometimes called stems)? This has many potential applications: think remixes, upmixing, active listening, educational purposes, but also pre-processing for other tasks such as transcription.<\/p>\n\n<p>The current state-of-the-art systems start to give convincing results on very wide catalogs of tracks, but the possibility of training such models remains largely bound by training data availability. In the case of copyrighted material like music, getting access to enough data is a pain point, and a source of inequality between research teams. Beside, an essential feature of good scientific research is that it must be reproducible by others. For these reasons and to even the playing field, we decided to not only release the code, but also our models pretrained on a carefully crafter in-house dataset.<\/p>\n\n<p>Specific topics on which our presentation will dwell on are:\n- technical aspects of the models architecture and training\n- software design, and how to leverage tensorflow’s API in a user facing python library\n- how to package and version a code that leverages pre-trained models and that can be run on different architectures: CPU and GPU.\n- licensing and legal concerns\n- what we learned along the way\n- legacy<\/p>",
        "persons":
        [
          {
            "_id": "7144",
            "value": "Anis Khlif"
          },
          {
            "_id": "7145",
            "value": "Félix Voituret"
          }
        ],
        "links":
        [
          {
            "_href": "https://github.com/deezer/spleeter",
            "value": "github repository for the project"
          },
          {
            "_href": "https://deezer.io/releasing-spleeter-deezer-r-d-source-separation-engine-2b88985e797e",
            "value": "Medium article describing the project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10217.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10544",
        "start": "15:00",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_liquidsoap",
        "title": "Functional audio and video stream generation with Liquidsoap",
        "subtitle": [],
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The talk will give a general overview of the Liquidsoap language, and put focus on recent new features: support for HLS, efficient video, etc.<\/p>",
        "description": "<p>The task of generating multimedia streams such as for webradios or live youtube channels is a complicated task. One needs to face low-level issues (properly encoding and distributing the streams), mid-level issues (performing normalization, signal processing, color grading, etc.) and high-level issues such as generating the stream from a wide variety of sources (local files, other streams, live interventions, user requests, etc.) and properly combining them (performing transitions, adding commercials, vary the contents during the day, etc.). In this talk, we present Liquidsoap, a dedicated high-level functional language, which allows performing all these tasks in a modular way, with strong guarantees that the stream will not fail on the long run.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7289",
            "value": "Romain Beauxis"
          }
        },
        "links":
        [
          {
            "_href": "https://www.liquidsoap.info/",
            "value": "Liquidsoap website"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10544.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10550",
        "start": "15:30",
        "duration": "00:25",
        "room": "UB2.147",
        "slug": "om_audio_streaming",
        "title": "Building an Open-Source based audio streaming platform",
        "subtitle": [],
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn how Radiofrance leverage open-source software to transport, encode, deliver and monitor audio stream in the cloud. You will get a global infrastructure overview on a platform that serve audio stream at scale.<\/p>",
        "description": "<p>What we will talk about:\nHow we chose our audio streaming protocol (HLS and Icecast).\nHow to transport audio from corporate SI to the cloud with the protocol SRT.\nHow we use Liquidsoap as streaming server to implement high availability logic, encode and mux our stream.\nHow we monitor our system with Prometheus and Grafana.\nHow to scale an audio streaming platform for 80 radios and 200K+ concurrent listeners.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6741",
            "value": "Maxime Bugeia"
          }
        },
        "links":
        [
          {
            "_href": "https://www.franceinter.fr/",
            "value": "France Inter"
          },
          {
            "_href": "https://www.fip.fr/",
            "value": "Fip"
          },
          {
            "_href": "https://www.liquidsoap.info/",
            "value": "Liquidsoap"
          },
          {
            "_href": "https://github.com/Haivision/srt",
            "value": "SRT"
          },
          {
            "_href": "https://prometheus.io/",
            "value": "Prometheus"
          },
          {
            "_href": "https://grafana.com/",
            "value": "Grafana"
          },
          {
            "_href": "https://icecast.org/",
            "value": "Icecast"
          },
          {
            "_href": "https://tools.ietf.org/html/rfc8216",
            "value": "HLS RFC"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10550.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10422",
        "start": "16:00",
        "duration": "00:15",
        "room": "UB2.147",
        "slug": "om_mpv_museum",
        "title": "The moldability of mpv",
        "subtitle": "Deploying diverse media setups in our museum",
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Many museums around the world use commercial closed source solutions to present media and interact with their visitors. Biodiversity museum Naturalis has decided to present most of their interactive content using open source software. In this presentation we talk about our experiences with mpv as the go to tool for a diverse selection of media setups in our brand new museum and how we made it work with show controllers, Arduino devices and open source content and config management tools.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7205",
            "value": "David Heijkamp"
          }
        },
        "links":
        [
          {
            "_href": "http://naturalis.nl",
            "value": "Naturalis Biodiversity Center"
          },
          {
            "_href": "http://gitlab.com/naturalis",
            "value": "Naturalis at Gitlab"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10422.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10563",
        "start": "16:20",
        "duration": "00:40",
        "room": "UB2.147",
        "slug": "om_rist",
        "title": "Getting Your Virtual Hands On RIST",
        "subtitle": [],
        "track": "Open Media",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There are a number of error correction protocols that provide backwards error correction. These are commonly used to transport media streams from remotes to the content provider, or the content provider to distribution. They allow, for example, streams from a pro basketball game to be transported over public Internet from stadium to network NOC without error; or as another example, packages of ethnic TV channels, to be moved from continent to continent. Players include DVEO, which uses the proprietary Dozer protocol for which the speaker holds the patent; WOWZA uses a customized SRT which is based on open source, and a few more. They all work on the principle of shooting off a bunch of udp packets from one IP to another, setting up a buffer, and then using an automatic re-request mechanism to request re-sends of lost or corrupted udp packets. RIST was designed with the participation of several vendors to bring some of the features normally found in proprietary error correction protocols into the free and open source world. It may even become a \"lingua franca\" between vendors. VLC, upipe and gstreamer can already reassemble and play back RIST transported streams. We will talk about a new open source project that provides an easy to use lib for rist and we'll discuss two pre-packaged images we've made available for AWS, Azure, VMWare and KVM. With these images, you can send a RIST encoded stream from cloud to end user viewer, or from cloud to cloud.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7304",
            "value": "Sergio Ammirata"
          }
        },
        "links":
        [
          {
            "_href": "https://www.rist.tv/",
            "value": "https://www.rist.tv/"
          },
          {
            "_href": "http://www.videoservicesforum.org/RIST.shtml",
            "value": "http://www.videoservicesforum.org/RIST.shtml"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10563.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UB2.252A (Lameere)",
    "event":
    [
      {
        "_id": "10547",
        "start": "09:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "stateofgo",
        "title": "The State of Go",
        "subtitle": "What's new since Go 1.12",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Go 1.14 is planned to be released in February 2019 and this talk covers what's coming up with it.<\/p>\n\n<p>We'll talk about new features and fixes in Go, new proposals for Go 2. All of the new things you might have missed.<\/p>",
        "description": "<p>This has been a staple talk of the Go devroom, opening the stage every year, and has always been a successful one.<\/p>",
        "persons":
        [
          {
            "_id": "2072",
            "value": "Francesc Campoy"
          },
          {
            "_id": "4618",
            "value": "Maartje Eyskens"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10547.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9266",
        "start": "09:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "functionalgo",
        "title": "Functional Programming with Go",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Are you tired of seeing Object Oriented code everywhere, with mutations, side-effects and headaches? Luckily, writing Go does not have to be that way! Functional programming is perfectly possible within Go, hence we can leverage FP techniques to make our code more robust, testable and fun.<\/p>",
        "description": "<p>Functional Programming in Go\nGo is a multi-paradigm language, yet most code you encounter ‘in the wild’ is written in a mostly Object-Oriented way. Yet, Go allows us to write code in a functional way as well, which offers certain advantages over a more traditional “OO” approach. What follows in this description is also the general flow of how it will be presented.<\/p>\n\n<p>What is FP?\nFirst we’ll start by defining what we mean by functional programming. Superficially Go might not look like what you expect a functional language to look like. But we’re really just missing the syntactic sugar here, as a lot of the underlying concepts that are central to Functional Programming are reflected in Go. Hence it is important to take a look at what many programmers consider requirements for being “functional” such as: Higher-order functions, recursion (with tail-call optimization), purity, idempotence, .. and how these requirements are met (or aren’t met) by Go.<\/p>\n\n<p>How to leverage them in Go\nOnce we have convinced ourselves that Go gives us the building blocks for writing FP code, we’ll dive into some concrete examples of what we can do with Go. We’ll look at function currying, continuation-passing style programming, pure functions, recursion (without TCO), monads and more. It’s important to highlight here why we want to use these constructions and when. At best case, you’ll learn how to leverage them in your own codebase. At worst, you’ll have seen some cool things with Go. Don’t be put of if you don’t know these terms yet, we’ll start with the easy concepts you’ve probable already used such as recursion, and work our way up to the complexer ones.<\/p>\n\n<p>Using libraries\nGo actually has libraries that provide an API for programming in a more functional style. We’ll give them an honorable mention but they won’t be the focus of the talk, as you can get started easily without them. But, they do offer certain things we “miss” in Go by default (like Generics).<\/p>\n\n<p>Benefits\nWriting Go code in this style has numerous benefits over our traditional approach. My goal of this talk is not just to show you cool things you can do with Go, but also why you want to them. You’ll also see introducing them to an existing codebase is easy, and that FP is really not as scary as it might sound!<\/p>\n\n<p>Downsides\nUsing this style of programming is not entirely a walk in the park. There’s a price to be paid for writing functional code in Go, the main one will be that you’ll take a performance hit. But the performance hit might not be where you expect it! Functional programming is one tool in your toolbox, it’ll greatly empower you to solve certain problems, whilst it’ll help you shoot yourself in the foot for other problems.<\/p>\n\n<p>Bonus benefits!\nYes, you’ll even take away something from this talk you might not have expected! A lot of people think of Haskell when they hear functional programming. Which might have scared them away from functional programming. In this talk you’ll get a look at functional programming with a familiar syntax and a language you already love. This will help you understand the underlying concepts and see how they relate to Haskell and other functional languages, where the syntax might be a bit different but the idea remains the same.<\/p>\n\n<p>Do I need prior knowledge of FP?\nNo, absolutely not! You don’t need to have done functional programming before to benefit from this talk. There are concepts for all levels of understanding of functional programming. If you don’t know anything about functional programming yet, you’ll discover it in this talk. And if you’re already an FP-wizard who dreams in Haskell, you’ll learn how to transfer that understanding to Go.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6363",
            "value": "Dylan Meeus"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/presentation/d/1Kf9s7uyyE8mOSHEUidQzifMnVU5USBuY_1dSfEVuR48/edit?usp=sharing",
            "value": "Google Slides presentation"
          },
          {
            "_href": "https://medium.com/@meeusdylan/continuation-passing-style-in-go-fa06a0ca00a2",
            "value": "Continuation-Passing style blog"
          },
          {
            "_href": "https://blog.usejournal.com/function-currying-in-go-a88672d6ebcf",
            "value": "Function Currying in Go"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9266.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10086",
        "start": "10:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "gonetbsdarm64",
        "title": "Porting Go to NetBSD/arm64",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>An introduction to calling conventions, thread-local storage, signal handling and how they relate to Go, in the context of my new port of Go to NetBSD/arm64.<\/p>",
        "description": "<p>Running a weird operating system comes at the cost of having to adjust software to run on it.\nGo is probably one of the hardest projects to adjust.\nDoing so required learning the guts of:\n- ARM64 calling conventions\n- signal handling\n- thread-local storage\n- a lot of Go-specifics<\/p>\n\n<p>Which will be discussed in this lecture.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6452",
            "value": "Maya Rashish"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10086.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9406",
        "start": "10:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "tinygotoys",
        "title": "Build real-world gaming hardware with TinyGo",
        "subtitle": "Make toys and other contraptions that run on Go",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn the multiples and fun possibilities of using Go on microcontrollers like Arduino to make gaming related hardware.<\/p>",
        "description": "<p>After a brief overview of the new features of TinyGo (http://tinygo.org), we'll move onto some cool and easy to make smart-toys that run Go. From classic PONG and a \"Simon says\" device to a pocket gaming console, and some other surprises. We'll end with an Open LED Race competition and the possibility to win hardware and make your our TinyGo device.<\/p>\n\n<p>This talk will feature bright lights and sounds, maybe lasers too.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4416",
            "value": "Daniel Esteban"
          }
        },
        "links":
        [
          {
            "_href": "https://tinygo.org/",
            "value": "TinyGo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9406.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10488",
        "start": "11:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "godiversity",
        "title": "Diversity, Finally",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>What if we decided to solve, once and for all, the problem of underrepresentation in the Go community of women, gender minorities, people of color, or any other group the same way we handle our problems in production, by identifying \"bugs\" and then fixing them?  Can it even be done? What if we took the engineering approach? Ronna is planning to convince you it's not a matter of if, but a matter of how, and we are going to analyze some of the statistics, find where the problems actually lay, and build a Trello card full of achievable tasks to address them.<\/p>",
        "description": "<p>What if we decided to solve, once and for all, the problem of underrepresentation in the Go community of women, gender minorities, people of color, or any other group the same way we handle our problems in production, by identifying \"bugs\" and then fixing them?  Can it even be done? What if we took the engineering approach? Ronna is planning to convince you it's not a matter of if, but a matter of how, and we are going to analyze some of the statistics, find where the problems actually lay, and build a Trello card full of achievable tasks to address them.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7262",
            "value": "Ronna Steinberg"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10488.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10256",
        "start": "11:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "gokubernetes",
        "title": "From Go to Kubernetes CRDs and Back",
        "subtitle": "Workflow for building strongly typed APIs",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kubernetes is built using Golang. CustomResourceDefinitions are the primary extension points for bringing custom data into a Kubernetes cluster. This hands-on talk is about the workflow of API definitions in Golang, generation of OpenAPI schemas as part of the CRD, client and informer generation and how to use these to process data in real-time using logic implemented in Golang controllers.<\/p>",
        "description": "<p>This hands-on talk is an introduction to the creation of CustomResource based API extensions for Kubernetes clusters. Following an example project we will<\/p>\n\n<ul>\n<li>define API objects live on stage<\/li>\n<li>turn that into CRD definitions with OpenAPI schema<\/li>\n<li>install the CRD into a Kubernetes cluster<\/li>\n<li>generate typed Golang clients and informers<\/li>\n<li>build Golang based realtime logic reacting to changes to the CustomResource objects.<\/li>\n<\/ul>\n\n\n<p>The talk does not require any knowledge about Kubernetes, just some Golang experience for unterstanding API type definitions.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7163",
            "value": "Stefan Schimanski"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10256.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9344",
        "start": "12:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "debuggingwithdelve",
        "title": "Deterministic debugging with Delve",
        "subtitle": "And the state of Delve",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk I will begin by delivering the \"State of Delve\" update. In similar fashion to the popular \"State of Go\" talk I will begin by discussing all of the exciting new features and changes that have happened over the past year, since last FOSDEM. Following that I will go into a live demo showcasing how Delve can leverage Mozilla RR in order to perform deterministic debugging. This talk will begin by introducing users to the concept of deterministic debugging and the power that comes with it. Following that I will launch into a demo showcasing how to leverage this concept to debug an otherwise unpredictable highly concurrent program. Users will walk away with immediate practical knowledge they can begin applying in their day to day debugging.<\/p>",
        "description": "<p>It's been a year since last FOSDEM and a lot has changed with Delve! I will discuss all the new features and changes that have been implemented in the last year.<\/p>\n\n<p>Following the \"State of Delve\" introduction, I will dig into how Delve can be utilized to perform deterministic debugging. This style of debugging enables users to record the execution of their process and \"play it back\" in a deterministic fashion in order to more quickly and efficiently perform root cause analysis on a bug that may otherwise be difficult to reproduce or track down. This section of the talk will begin by introducing the concept of deterministic debugging and why it is so useful and powerful. Once everyone is familiar with the concept I will launch into a live demo showcasing how to leverage this debugging approach to track down and fix a bug which is hard to reproduce and happens only intermittently.<\/p>\n\n<p>Attendees will walk away with practical knowledge that they can begin applying to their debugging problems immediately.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3295",
            "value": "Derek Parker"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/go-delve/delve",
            "value": "Delve repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9344.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10430",
        "start": "12:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "classifyingo",
        "title": "Classify things in Go: the easy way.",
        "subtitle": "Building classifiers quickly with the community contributions.",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Go and public training models can provide great potential: A fast way to build \"eyes around the world\", also known as classifiers. And with great powers, come great opportunities, such as building fantastic applications to turn our world a better place to live through the technology with few steps.<\/p>",
        "description": "<p>Go and public training models can provide great potential: A fast way to build \"eyes around the world\", also known as classifiers. And with great powers, come great opportunities, such as building fantastic applications to turn our world a better place to live through the technology.\nThe GO language, have  GoCV package, and it provides the most modern and advanced Computational Vision libraries that exist like OpenCV.\nIn this talk, I'll demonstrate how to use public models from TensorFlow Hub and OpenCV library to easily build classifiers for APIs, taking a super leap from draft to a working classifier, in a few steps!\nThe idea is to demystify the concepts behind classifiers and show how to build one in a few steps and make rankers accessible to the business, showing how GO does this in a unique, scalable and self-performing way, and of course, encouraging the community to contribute and sharing more training models to they can turn more and more accurate!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7256",
            "value": "Sheimy Rahman"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10430.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9364",
        "start": "13:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "dragonscgo",
        "title": "Dragons of CGO",
        "subtitle": "Hard-learned Lessons from Writing Go Wrappers",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>YottaDB is a mature, hierarchical key-value, free / open source NoSQL database whose is used in enterprise-scale mission-critical applications in banking and healthcare, and also scales down to fit on IoT devices like the Raspberry Pi Zero, as well as applications in-between (like the University of Antwerp library catalog system). When a customer funded us to develop a Go API to YottaDB, we thought it would be a straightforward project. But it was a very painful exercise for us. The presentation discusses the problems we faced, and how we overcame them.<\/p>",
        "description": "<p>Go is a popular language for writing highly concurrent software, and works well when used in isolation. Using Go alongside software written in other languages (such as C) can be done, but there are some hidden dragons to keep an eye out for. In addition to obvious problems, such as calling C variadic functions, other more subtle problems are hidden deep in the depths of Go documentation.<\/p>\n\n<p>Consider callback functions; how does one pass a function pointer from Go to C to provide a callback? There are strict limitations enforced by Go on what pointers may be passed to C routines, intended to prevent faults resulting from Go structures being garbage collected without knowledge of the C code. Without being able to pass pointers, even function pointers, how do we “pass” a callback function to the C code to callback into? Furthermore, how do we pass data to the callback function, since we can’t pass Go structures?<\/p>\n\n<p>Given that we can’t pass Go structures to C code, at some point we will need to allocate C structures to store data for the C code to operate on. Go promises one thing about memory allocated in C land; it will not keep track of it for you. The garbage collector will gladly clean up any Go structures no longer needed, but will not clean up the associated C memory. How can one write code which isn’t likely to result in memory leaks, using this model?<\/p>\n\n<p>Perhaps the most difficult challenge to overcome is that Go makes no promises about what thread is running code. Go does its best to hide the identity of Go routines from the user, so they won’t rely on this metadata for handling code execution. This presents a problem for many C applications, which often use POSIX mutexes to control access, and the owner of a mutex needs to belong to a specific thread. How can one write Go applications that allow the concurrency Go users expect, without trashing the libraries they are calling?<\/p>\n\n<p>Of course, none of the solutions we talk about here are any good unless you can compile your program. The hidden dragons of Go also lurk behind the “go build“ command; fitting in the required C flags requires knowledge of, among other things, pkg-config, a systems tool used behind the scenes by programs like CMake and autotools.<\/p>\n\n<p>We had to tackle all these problems, and many more, during the development of the YottaDB Go wrapper (https://gitlab.com/YottaDB/Lang/YDBGo and https://yottadb.com). This presentation hopes to pass some of our hard-learned lessons to other programmers who will use Go to interface with non-Go libraries and utilities.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6382",
            "value": "K.S. Bhaskar"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.yottadb.com/MultiLangProgGuide/goprogram.html",
            "value": "Programmer documentation of API"
          },
          {
            "_href": "https://godoc.org/lang.yottadb.com/go/yottadb#CallMTable",
            "value": "YottadB wrapper package home page"
          },
          {
            "_href": "https://gitlab.com/YottaDB/Lang/YDBGo",
            "value": "Project page on GitLab"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9364.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9523",
        "start": "13:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "advanceddebugginggo",
        "title": "Advanced debugging techniques of Go code",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In an ideal world, you would write Go code, compile it, and then it would work perfectly the first time. But unfortunately it doesn't work in this manner. There are many different books and articles about how to write good code in go, but not so many how to debug code efficiently. In my talk I'll try to cover such important topic.\nGo is a new programming language with best tools for development. In my talk I'll cover how to efficiently using these tools to debug your code. I’ll start from history of debuggers, later I'll show you how to debug go itself, if you need to find bug in language. Than I can demonstrate  how to effectively debug microservices using docker and k8s, what’s remote debugging and how to apply it to application which already has been deployed. Debugging unit tests and not only code. Some tricks of debugging command line applications.<\/p>",
        "description": "<p>My talk is about:\n- compare go debuggers (delve, gdb) in real world applications;\n- how to effectively debug inside containers (using remote-debuggers)\n- how to use Mozilla rr to record and play you golang app (https://rr-project.org/)\n- how to use dig into slices using gdb\nI'm using the term docker and k8s to show how to debug applications in different environments without lot's of details of k8s, rather showing tips/tricks to speed up you microservices.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4447",
            "value": "Andrii Soldatenko"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9523.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9581",
        "start": "14:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "debugcodegenerationgo",
        "title": "Debug code generation in Go",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>If you are interested to learn about what and how Go generates machine code, this talk is for you. By learning more about the compilation, you can either avoid unnecessary hand-crafted optimizations or learn more about the compiler to become a contributor to the Go compiler.<\/p>",
        "description": "<p>Have you ever optimized some Go code to later realize Go compiler is already doing the same optimization automatically? Have you ever tried to understand what makes of of the Go compiler? Or, have you ever wondered how can you inspect machine code generated from Go source code? If you are interested to learn about what and how Go generates machine code, this talk is for you. By learning more about the compilation, you can either avoid unnecessary hand-crafted optimizations or learn more about the compiler to become a contributor to the Go compiler.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4881",
            "value": "Jaana Dogan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9581.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9092",
        "start": "14:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "golinux",
        "title": "Uplift your Linux systems programming skills with systemd and D-Bus",
        "subtitle": "Practical examples and best practices on how to leverage systemd and D-Bus in Go",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Systemd is a de-facto standard process manager in all mainstream Linux distributions for almost a decade.\nD-Bus is most widely used inter-process communication on a local host. It's used in many core apps on Linux Desktop.<\/p>\n\n<p>Yet both systemd and D-Bus are undervalued.\nVery often, programs that are only intended to run on Linux attempt to re-implement (with bugs) what systemd and D-Bus already provide\n(for example: watchdog function, reliable process termination, notifying another program about some event, coordination between multiple processes).<\/p>\n\n<p>The goal of this talk is to shift perspective on systemd and D-Bus (using concrete practical examples in Go),\nand show how basic building block these systems provide can be re-used in software you write for modern Linux system.<\/p>",
        "description": "<p>This is an exploratory talk. Then intent is to look at systemd and DBUS from a different angle.<\/p>\n\n<p>Most of current tutorials about systemd focused on operating a service like apache, nginx or redis.\nD-Bus tutorials are very abstract, basic and lack any concrete useful use-cases.<\/p>\n\n<p>I plan to present few recent additions to systemd, such as portable services and resource control.\nAs well as re-introduce few existing concepts, like sd-notify, watchdogs and transient units.<\/p>\n\n<p>On D-Bus I plan to show how to use bus abstraction and few neat features,\nlike passing file descriptors and receiving notifications.<\/p>\n\n<p>The focus is on how to not re-invent things that systemd and D-Bus do much better.<\/p>\n\n<p>Examples are given as a few simple Golang programs, with full source available on https://github.com/lvsl/tutorial-go-systemd-dbus.<\/p>\n\n<p>The indented audience is anyone who write and operate Go code on Linux.\nPreferred experience of the audience: basic knowledge of Linux and Golang, familiarity with systemd and D-Bus concepts would be useful as well.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6492",
            "value": "Leonid Vasilyev"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/lvsl/tutorial-go-systemd-dbus",
            "value": "Materials for the presentation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9092.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10486",
        "start": "15:00",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "deeplerningforgophers",
        "title": "Deep Learning For Gophers",
        "subtitle": [],
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The software has not eaten the world yet, but infact has changed the way it was before. That software has given us, the human a new superpower which is the power of artificial neural networks. The goal of those networks is to help us answer the question : “Given X, predict Y with Z% accuracy”. This is where Deep Learning comes into picture. Let’s build a basic building block of deep learning :  neural network.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7258",
            "value": "Rashmi Nagpal"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10486.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9496",
        "start": "15:30",
        "duration": "00:30",
        "room": "UB2.252A (Lameere)",
        "slug": "speedupmonolith",
        "title": "Speed up the monolith",
        "subtitle": "building a smart reverse proxy in Go",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>GitLab is a ruby on rails application, but this didn’t prevent us from having fun with Go.\nLearn how we decomposed our monolith by writing a smart reverse proxy in Go that handles I/O intensive operations.\nA technique that every web app can use, regardless of the company stack.<\/p>",
        "description": "<p>We set a deadline for releasing a cloud-native version of GitLab and put a team of engineers to work planning the helm charts, splitting several components into independently scalable PODs. The team faced a few challenges.<\/p>\n\n<p>GitLab’s main codebase is written in Ruby, which has a global interpreter lock. We relied on NFS to asynchronously upload files from our workers fleet. Removing shared file system by uploading directly from the controller was not an option. We wanted to move to an object storage based solution, but that was a paid feature and we had to port it to the open-source codebase. Oh, we also needed to make sure the rest of our engineers could keep shipping new features at our regular monthly cadence.<\/p>\n\n<p>At the same time, we were planning our infrastructure migration from Azure to Google Cloud. Removing this intermediate state, where a file is on GitLab server NFS but not yet uploaded to the object storage, would have made the migration a lot easier.<\/p>\n\n<p>We had to remove the NFS dependency to make GitLab easily deployable on Kubernetes and we needed a performant multi-cloud object storage uploader viable also for on-prem installations, a solution that would work for a single server setup up to Ggitlab.com scale.<\/p>\n\n<p>Luckily we already had written workhorse, a smart reverse proxy written in Go for handling git operations. It was time to extend workhorse capabilities leveraging the full power of goroutines.<\/p>\n\n<p>We had a plan, but the devil is in the detail. Allow me to guide you through this journey. During the talk I’ll tell you how a ruby-on-rails company began to write Go code, how we implemented an object storage uploader inside our proxy, the problems we faced, and tradeoffs we took to deliver this in time.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6762",
            "value": "Alessio Caiazza"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9496.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10652",
        "start": "16:00",
        "duration": "01:00",
        "room": "UB2.252A (Lameere)",
        "slug": "golightning",
        "title": "Go Lightning Talks",
        "subtitle": "Come speak!",
        "track": "Go",
        "type": "devroom",
        "language": [],
        "abstract": "<p>At the end of the day we will have lightning talks of 8 minutes in the Go Devroom!\nEach talk will be 8 minutes long, the CfP for these is open till a few hours before the talks start to give everyone the chance to submit a proposal.<\/p>",
        "description": [],
        "persons": [],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10652.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.132",
    "event":
    [
      {
        "_id": "9884",
        "start": "09:30",
        "duration": "02:00",
        "room": "UB4.132",
        "slug": "cert_lpi_3",
        "title": "LPI Exam Session 3",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<h3>LPI offers discounted certification exams at FOSDEM<\/h3>",
        "description": "<p>As in previous years, the Linux Professional Institute (LPI) will offer discounted certification exams to FOSDEM attendees.\nLPI offers level 1, level 2 and level 3 certification exams at FOSDEM with an almost <strong>50% discount<\/strong>.<\/p>\n\n<p>For further information and instructions see <a href=\"https://fosdem.org/certification\">https://fosdem.org/certification<\/a>.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1083",
            "value": "LPI Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9884.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10072",
        "start": "12:00",
        "duration": "01:00",
        "room": "UB4.132",
        "slug": "cert_libreoffice_1",
        "title": "LibreOffice Exam Session 1",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<p>LibreOffice Certifications are designed to recognize professionals in the areas of development, migrations and trainings who have the technical capabilities and the real-world experience to provide value added services to enterprises and organizations deploying LibreOffice on a large number of PCs.<\/p>",
        "description": "<p>In the future, LibreOffice Certifications will be extended to Level 1 and Level 2 Support professionals.<\/p>\n\n<p>The LibreOffice Certification is not targeted to end users, although Certified Training Professionals will be able to provide such a service upon request (although not as a LibreOffice Certification). In general, end user certification is managed by organizations with a wider reach such as the Linux Professional Institute.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2876",
            "value": "LibreOffice Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10072.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10073",
        "start": "13:30",
        "duration": "01:00",
        "room": "UB4.132",
        "slug": "cert_libreoffice_2",
        "title": "LibreOffice Exam Session 2",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<p>LibreOffice Certifications are designed to recognize professionals in the areas of development, migrations and trainings who have the technical capabilities and the real-world experience to provide value added services to enterprises and organizations deploying LibreOffice on a large number of PCs.<\/p>",
        "description": "<p>In the future, LibreOffice Certifications will be extended to Level 1 and Level 2 Support professionals.<\/p>\n\n<p>The LibreOffice Certification is not targeted to end users, although Certified Training Professionals will be able to provide such a service upon request (although not as a LibreOffice Certification). In general, end user certification is managed by organizations with a wider reach such as the Linux Professional Institute.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2876",
            "value": "LibreOffice Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10073.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10075",
        "start": "15:00",
        "duration": "01:00",
        "room": "UB4.132",
        "slug": "cert_libreoffice_3",
        "title": "LibreOffice Exam Session 3",
        "subtitle": [],
        "track": "Certification",
        "type": "certification",
        "language": [],
        "abstract": "<p>LibreOffice Certifications are designed to recognize professionals in the areas of development, migrations and trainings who have the technical capabilities and the real-world experience to provide value added services to enterprises and organizations deploying LibreOffice on a large number of PCs.<\/p>",
        "description": "<p>In the future, LibreOffice Certifications will be extended to Level 1 and Level 2 Support professionals.<\/p>\n\n<p>The LibreOffice Certification is not targeted to end users, although Certified Training Professionals will be able to provide such a service upon request (although not as a LibreOffice Certification). In general, end user certification is managed by organizations with a wider reach such as the Linux Professional Institute.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2876",
            "value": "LibreOffice Team"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10075.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.136",
    "event":
    [
      {
        "_id": "9246",
        "start": "09:00",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "continuous_delivery_starts_with_continuous_infrastructure",
        "title": "Continuous Delivery starts with Continuous Infrastructure",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Most organisations start their journey towards Continuous Delivery with their development teams, or often their web or mobile teams. I’ve seen many of these journeys fail because “ops” was not included in the picture.  The organisation assumed DevOps didn’t need ops. So the team didn’t adapt, didn’t provide the right stacks, couldn’t support the tools. I’ve started a number of successful journeys with the ops teams doing Continuous Delivery of their infrastructure as code. They changed their mindset, allowing them to understand, support and onboard the development teams.  This talk will document that approach with some supporting cases and examples.<\/p>\n\n<p>Taking one step further we'll showcase a on how to do Continuous Delivery of your Infrastructure as Code,    obviously with Open Source tools<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "3305",
            "value": "Kris Buytaert"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9246.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10369",
        "start": "09:45",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "an_event_based_approach_for_ci_cd_pipelines",
        "title": "An event based approach for CI/CD pipelines",
        "subtitle": "What challenges are there in the communication between different tools in CI/CD ecosystems and how can they be mitigated?",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>How can we listen to when new upstream software has been tested to the extent that we feel comfortable integrating it into our software? How can we communicate about new artifacts available for others to integrate? How can we see what has been integrated where? How can we achieve traceability across pipelines run on different tooling infrastructure? How can we visualize our pipelines to follow changes from source code to customer deployment?<\/p>\n\n<p>We will describe these challenges and show how we tackled them using self-documenting integration pipelines providing traceability and visualization to benefit multiple needs in the organization. We will present based on our experience from large-scale software development.<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "7223",
            "value": "Emelie Pettersson"
          },
          {
            "_id": "7225",
            "value": "Fredrik Fristedt"
          }
        ],
        "links":
        [
          {
            "_href": "https://eiffel-community.github.io/",
            "value": "Eiffel"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10369.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9133",
        "start": "10:30",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "marios_adventures_in_tekton_land",
        "title": "Mario’s adventures in Tekton land",
        "subtitle": "Testing, releasing and deploying Tekton with Tekton",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, the speakers will present their experiences about using Tekton - a cloud-native pipeline system - to test, release and continuously deploy itself.<\/p>",
        "description": "<p>Tekton is a Kubernetes-native, lightweight, easy to manage CI/CD pipelines engine. Pipeline building blocks can be reused, version controlled and curated in a catalogue that embeds best practices. Tekton, hosted by the CD Foundation, aspires to be the common denominator in CI/CD, modelling what Kubernetes has become in cloud-native application development. The Tekton team wanted to make sure that the project is going in the right direction by \"dogfooding\" i.e. by using Tekton to run its own automation \"plumbing\". The initial continuous integration setup embedded most of the testing pipelines in bash scripts. The speakers replaced this with Tekton, hence improving the readability of the pipelines and the reproducibility of CI runs. Eventually, they moved onto continuously delivering Tekton and its pipelines via Tekton. In this talk, the speakers will tell their experiences about using a cloud-native pipeline system to test, release and continuously deploy itself.<\/p>",
        "persons":
        [
          {
            "_id": "5852",
            "value": "Andrea Frittoli"
          },
          {
            "_id": "7362",
            "value": "Vincent Demeester"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9133.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10366",
        "start": "11:15",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "test_software_on_emulated_hardware_in_containers_in_the_cloud",
        "title": "Test Software On Emulated Hardware In Containers... In The Cloud",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Modernizing the traveler information systems of an international railway and transportation company, including the modernization and renewal of traveler facing devices at the train stations. For a variety of devices ranging from 20-year-old x86 PC104 based embedded systems up to modern 64bit multi-core systems, a Buildroot based Linux system, and a custom application stack is being developed.<\/p>",
        "description": "<p>In this talk, we will show how we use a fully automated CI pipeline to build our custom application components resulting in deployable Linux disk images. These images are then containerized and deployed on our Kubernetes cluster. Using Qemu in our containers allows us to simulate external hardware normally connected through serial interfaces and is the basis for automated tests.<\/p>\n\n<ul>\n<li>presentation of our technology stack.<\/li>\n<li>multi-stage Linux disk image creation in the CI.<\/li>\n<li>running embedded device images in a Kubernetes cluster.<\/li>\n<li>automated testing of simulated embedded systems.<\/li>\n<\/ul>",
        "persons":
        [
          {
            "_id": "5700",
            "value": "Sean A. Parker"
          },
          {
            "_id": "7221",
            "value": "Paul Schroeder"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10366.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10361",
        "start": "12:00",
        "duration": "00:15",
        "room": "UB4.136",
        "slug": "infrastructure_cicd_with_kubevirt_and_tekton",
        "title": "Infrastructure CICD with KubeVirt and Tekton",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Over the past few years, we’ve all realized the benefits of CICD. The more that we test our code and the faster that we can have these changes integrated, the more value we derive from these systems (and our code). However, in general this only ever seems to be applied to application code. We sometimes forget that no matter how fast deploy our applications -- if the underlying infrastructure components are not benefiting from this same process, we’ll only ever be as good as these weaker links. But why are things like this? Because testing these components can be hard and often access to these systems are highly restricted (for good reason!). But with tools like KubeVirt and Kubernetes, we don’t need this access  just to test out our changes. We can safely test infrastructure related  deployments and changes (DNS, networking, ansible roles) safely within our own environment before pushing things straight to production! What we’ll dig in on during this talk is how to safely deploy infrastructure related components on Kubernetes and orchestrate the testing and deployment of these changes with Tekton and KubeVirt. We’ll also discuss some of the advantages and disadvantages that may come with an approach like this and how we’re looking to use this on a handful of internal projects.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7220",
            "value": "Tyler Auerbeck"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10361.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9243",
        "start": "12:20",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "choosing_the_right_deployment_strategy",
        "title": "Choosing The Right Deployment Strategy",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Deployment strategies affect everyone, no matter whether we are focused only on a single aspect of the application lifecycle or we are in full control. The way we deploy affects the architecture, testing, monitoring, and many other aspects. And not only that, but we can say that architecture, testing, and monitoring affect the way we deploy. All those things are closely related and affect each other.<\/p>\n\n<p>We'll discuss different deployment strategies and answer a couple of questions. Is your application stateful or stateless? Does its architecture permit scaling? How do you roll back? How do you scale up and down? Do you need your application to run always? Should you use Kubernetes Deployments instead of, let's say, StatefulSets? Answers to those questions will not serve much unless we are familiar with some of the most commonly used deployment strategies. Not only that knowledge will help us choose which one to pick, but they might even influence the architecture of our applications.<\/p>",
        "description": "<p>For many people, deploying applications is transparent or even irrelevant. If you are a developer, you might be focused on writing code and allowing magic to happen. By magic, I mean letting other people and departments figure out how to deploy your code. Similarly, you might be oblivious to deployments. You might be a tester, or you might have some other role not directly related to system administration, operations, or infrastructure. Now, I doubt that you are one of the oblivious. The chances are that you would not be even reading this if that's the case. If, against all bets, you do belong to the deployment-is-not-my-thing group, the only thing I can say is that you are wrong.<\/p>\n\n<p>Deployment strategies affect everyone, no matter whether we are focused only on a single aspect of the application lifecycle or we are in full control. The way we deploy affects the architecture, testing, monitoring, and many other aspects. And not only that, but we can say that architecture, testing, and monitoring affect the way we deploy. All those things are closely related and affect each other in ways that might not be obvious on the first look.<\/p>\n\n<p>We'll discuss different deployment strategies and answer a couple of questions. Is your application stateful or stateless? Does its architecture permit scaling? How do you roll back? How do you scale up and down? Do you need your application to run always? Should you use Kubernetes Deployments instead of, let's say, StatefulSets? Those are only a few of the questions you need to answer to choose the right deployment mechanism. But, answers to those questions will not serve much unless we are familiar with some of the most commonly used deployment strategies. Not only that knowledge will help us choose which one to pick, but they might even influence the architecture of our applications.<\/p>\n\n<p>We'll explore <strong>serverless, recreate, rolling update, and canary deployment strategies<\/strong> and we'll automate them all using <strong>Jenkins X<\/strong>.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6552",
            "value": "Viktor Farcic"
          }
        },
        "links":
        [
          {
            "_href": "http://vfarcic.github.io/jx/deployment.html",
            "value": "Slides"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9243.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9341",
        "start": "13:05",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "progressive_delivery",
        "title": "Progressive Delivery",
        "subtitle": "Continuous Delivery the Right Way",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Progressive Delivery makes it easier to adopt Continuous Delivery, by deploying new versions to a subset of users and evaluating their correctness and performance before rolling them to the totality of the users, and rolled back if not matching some key metrics. Canary deployments is one of the techniques in Progressive Delivery, used in companies like Facebook to roll out new versions gradually. But good news! you don't need to be Facebook to take advantage of it.<\/p>\n\n<p>We will demo how to create a fully automated Progressive Delivery pipeline with Canary deployments and rollbacks in Kubernetes using Jenkins X, an open source platform for cloud native CI/CD in Kubernetes, and Flagger, a project that uses Istio and Prometheus to automate Canary rollouts and rollbacks.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "463",
            "value": "Carlos Sanchez"
          }
        },
        "links":
        [
          {
            "_href": "https://youtube.com/playlist?list=PLHsuXkXI4xdjGlGkCBdxIAmkzfWXqsUrO",
            "value": "videos"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9341.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9753",
        "start": "13:50",
        "duration": "00:15",
        "room": "UB4.136",
        "slug": "a_practical_ci_cd_framework_for_machine_learning_at_massive_scale",
        "title": "A Practical CI/CD Framework for Machine Learning at Massive Scale",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Managing production machine learning systems at scale has uncovered new challenges that have required fundamentally different approaches to that of traditional software engineering and data science. In this talk, we'll provide key insights on MLOps, which often encompasses the concepts around monitoring, deployment, orchestration and continuous delivery for machine learning. We will be covering a hands on an example where we will be training, deploying and monitoring ML at scale.  We'll be using Jenkins X (+ Prow &amp; Tekton) to deploy/promote these models across multiple environments. We will use KIND (Kubernetes in Docker) to run integration tests in our development environment. Finally, we'll be using Seldon to orchestrate &amp; monitor these models leveraging advanced ML techniques.<\/p>",
        "description": "<p>Managing production machine learning systems at scale has uncovered new challenges which have required fundamentally different approaches to that of traditional software engineering and data science. In this talk, we'll provide key insights on MLOps, which often encompasses the concepts around monitoring, deployment, orchestration and continuous delivery for machine learning. We will be covering a hands on an example where we will be training, deploying and monitoring ML at scale.  We'll be using Jenkins X (+ Prow &amp; Tekton) to deploy/promote these models across multiple environments. We will use KIND (Kubernetes in Docker) to run integration tests in our development environment. Finally, we'll be using Seldon to orchestrate &amp; monitor these models leveraging advanced ML techniques.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4188",
            "value": "Alejandro Saucedo"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9753.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10263",
        "start": "14:10",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "our_road_to_a_k8s_gke_based_closed_build_environment",
        "title": "Our road to a k8s/GKE based Closed Build Environment",
        "subtitle": "A small journey to an autoscaling build env based on Jenkins.",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>My team build a new Closed Build Environment for building Release Packages on Google Cloud Platform(gcp) with Google Kubernetes Engine (GKE).<\/p>\n\n<p>I like to take you on a small journey through a variety of topics we came across (open for change):<\/p>\n\n<ul>\n<li><p>How we bootstrap and how we use ArgoCD<\/p><\/li>\n<li><p>Autoscaling to 100 Build nodes for building<\/p><\/li>\n<li><p>Why we are using Prometheus-Operator<\/p><\/li>\n<li><p>SRE or how we maintain our stack<\/p><\/li>\n<li><p>Product aspect<\/p><\/li>\n<li><p>Base Image building &amp; scanning<\/p><\/li>\n<li><p>Network setup with Shared VPC<\/p><\/li>\n<li><p>Google Cloud Platform IAM Permissions vs. RBAC<\/p><\/li>\n<li><p>Specific GKE Features like Workload Identity<\/p><\/li>\n<\/ul>\n\n\n<p>And others<\/p>\n\n<p>Simple real live example how my team is doing it. Looking forward to inspire and to get feedback from others!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7166",
            "value": "Siegfried Kiermayer"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10263.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9493",
        "start": "14:55",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "from_a_pipeline_to_a_government_cloud",
        "title": "From a Pipeline to a Government Cloud",
        "subtitle": "How the UK government deploy a Platform-as-a-Service using Concourse, an open-source continuous thing-doer",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Since 2016, the UK Government has been running an open-source, cross-government Platform-as-a-Service (PaaS) to make it easier and cheaper to build government services. The GOV.UK PaaS is built on BOSH and Cloud Foundry, and is deployed using Concourse.<\/p>\n\n<p>Concourse is \"an open-source continuous thing-doer\", with abstractions that help build pipelines quickly, and for extending the behaviour of the system.<\/p>\n\n<p>This presentation will provide an introduction to Concourse, and then describe how the GOV.UK PaaS team use Concourse to continuously deploy a whole PaaS whilst ensuring high-availability and minimal impact to services and users.<\/p>",
        "description": "<p>Toby Lorne is a site reliability engineer working at the UK Government Digital Service on the GOV.UK Platform-as-a-Service.<\/p>\n\n<p>This presentation is split into four parts:<\/p>\n\n<ol>\n<li>An introduction to Concourse:<\/li>\n<li>How it works<\/li>\n<li>The abstractions<\/li>\n<li><p>The design decisions, patterns, and anti-patterns<\/p><\/li>\n<li><p>An overview of the architecture and implementation of GOV.UK PaaS:<\/p><\/li>\n<li>Terraform - a tool for managing infrastructure as code<\/li>\n<li>BOSH - a tool for release engineering and software lifecycle management<\/li>\n<li>Cloud Foundry - a set of components for Platform-as-a-Service<\/li>\n<li><p>Prometheus &amp; Grafana - monitoring and visualisation tools<\/p><\/li>\n<li><p>A walkthrough of the pipelines used in deployment and development<\/p><\/li>\n<li><p>An examination of patterns used in the GOV.UK PaaS deployment pipeline, and how you could use these patterns in your pipelines.<\/p><\/li>\n<\/ol>",
        "persons":
        {
          "person":
          {
            "_id": "6572",
            "value": "Toby Lorne (tlwr)"
          }
        },
        "links":
        [
          {
            "_href": "https://concourse-ci.org",
            "value": "Concourse project homepage"
          },
          {
            "_href": "https://www.cloud.service.gov.uk",
            "value": "GOV.UK PaaS product page"
          },
          {
            "_href": "https://github.com/search?q=org%3Aalphagov+topic%3Apaas",
            "value": "GOV.UK PaaS GitHub repositories"
          },
          {
            "_href": "https://www.cloudfoundry.org/",
            "value": "Cloud Foundry homepage"
          },
          {
            "_href": "https://bosh.io/",
            "value": "BOSH homepage"
          },
          {
            "_href": "https://grafana.com/",
            "value": "Grafana homepage"
          },
          {
            "_href": "https://prometheus.io/",
            "value": "Prometheus homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9493.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10412",
        "start": "15:40",
        "duration": "00:40",
        "room": "UB4.136",
        "slug": "deployment_to_hardware",
        "title": "Deployment to hardware",
        "subtitle": "A multi pipeline challenge",
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Our project takes a fun, road-following app which leverages a basic neural network and deploys it to real hardware with an OStree update system. This has meant managing a variety of different CI-runners; GPU, aarch64 and x86_64. These have variety of different dependencies, drivers and have interfaces with a number of services and caches.<\/p>\n\n<p>I will focus on how we constructed and developed our CI pipelines to build, test and integrate a number of disparate components to produce images and push updates into an OStree server to be deployed over the air onto our hardware.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7243",
            "value": "William Salmon"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10412.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10455",
        "start": "16:25",
        "duration": "00:35",
        "room": "UB4.136",
        "slug": "safe_gated_and_integrated_gitops_for_kubernetes",
        "title": "Safe, gated and integrated GitOps for Kubernetes",
        "subtitle": [],
        "track": "Continuous Integration and Continuous Deployment",
        "type": "devroom",
        "language": [],
        "abstract": [],
        "description": "<p>There is no single tool that can do everything in your CI/CD pipeline. You have the freedom to pick these tools and integrate them to complete the lifecycle of a release. In this talk, we’re discussing the integration of three different DevOps tool not only completes a CI/CD pipeline but also leads to effective automation by adding extra layers of intelligence.<\/p>\n\n<p>We begin with using Git as a version control system that houses the entire state for a Kubernetes deployment. Adding Zuul to the mix, as your open-source tool that assumes the role of project gating, ensuring no broken code is merged into the main branch of your clusters, and Argo CD as the continuous delivery platform in place that pulls that code and applies to all application code in question.<\/p>\n\n<p>It is the integration of all three tools that are essential for an efficient trail of your entire deployments. The talk will further elaborate on the role of each of these mechanisms when managing a Kubernetes cluster and their integration with one another.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7180",
            "value": "Mohammed Naser"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10455.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB4.228",
    "event":
    {
      "_id": "10754",
      "start": "10:00",
      "duration": "07:00",
      "room": "UB4.228",
      "slug": "soldering_workshop_sunday",
      "title": "Open Source Hardware and Soldering Workshop",
      "subtitle": [],
      "track": "Workshops",
      "type": "workshop",
      "language": [],
      "abstract": "<p>Open Source Hardware room with two day soldering workshops.<\/p>\n\n<p>Day 2 soldering workshop will be dedicated to Surface Mount Technology and is good for beginners which have no experience with SMT technology.<\/p>\n\n<p>Beside the soldering workshop we will show our latest OSHW boards we work on, you are welcome to join and show your own OSHW projects too.<\/p>",
      "description": "<p>We will solder Binary Watch PCB made exclusively with SMT components.<\/p>\n\n<p>During the soldering workshop we will introduce the electronic components used in the PCB and how to identify them and how components with polarity is to be recognized.<\/p>\n\n<p>We will teach you the basics of SMT soldering, how to print solder paste with stencil, how to reflow using hot air, how good and bad solder joints look like and what is cold solder joint.\nAt the end of the workshop you will build your own binary watch.<\/p>",
      "persons":
      {
        "person":
        {
          "_id": "1641",
          "value": "Tsvetan Usunov"
        }
      },
      "links":
      {
        "link":
        {
          "_href": "https://submission.fosdem.org/feedback/10754.php",
          "value": "Submit feedback"
        }
      }
    }
  },
  {
    "_name": "UB5.132",
    "event":
    [
      {
        "_id": "10409",
        "start": "09:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "rpi_cluster",
        "title": "Introducing HPC with a Raspberry Pi cluster",
        "subtitle": "A practical use of and good excuse to build Raspberry Pi Clusters",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will discuss the development of a RaspberryPi cluster for teaching an introduction to HPC.<\/p>\n\n<p>The motivation for this was to overcome four key problems faced by new HPC users:<\/p>\n\n<ol>\n<li>The availability of a real HPC system and the effect running training courses can have on the real system, conversely the availability of spare resources on the real system can cause problems for the training course.<\/li>\n<li>A fear of using a large and expensive HPC system for the first time and worries that doing something wrong might damage the system.<\/li>\n<li>That HPC systems are very abstract systems sitting in data centres that users never see, it is difficult for them to understand exactly what it is they are using.<\/li>\n<li>That new users fail to understand resource limitations, in part because of the vast resources in modern HPC systems a lot of mistakes can be made before running out of resources. A more resource constrained system makes it easier to understand this.<\/li>\n<\/ol>\n\n\n<p>The talk will also discuss some of the technical challenges in deploying an HPC environment to a Raspberry Pi and attempts to keep that environment as close to a \"real\" HPC as possible. The issue to trying to automate the installation process will also be covered.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7056",
            "value": "Colin Sauze"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/SCW-Aberystwyth/Introduction-to-HPC-with-RaspberryPi",
            "value": "Software Carpentry style lesson introducing HPC on the Raspberry Pi"
          },
          {
            "_href": "https://github.com/colinsauze/pi_cluster",
            "value": "Setup scripts, notes and slides from a previous talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10409.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9617",
        "start": "09:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "data_lake_cloud",
        "title": "Building an open source data lake at scale in the cloud",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This presentation will give an overview of the various tools, software, patterns and approaches that Expedia Group uses to operate a number of large scale data lakes in the cloud and on premise. The data journey undertaken by the\nExpedia Group is probably similar to many others who have been operating in this space over the past two decades - scaling out from relational databases to on premise Hadoop clusters to a much wider ecosystem in the cloud. This talk\nwill give an overview of that journey and then describe the various open source components that Expedia Group have used and built to create multi-petabyte data lakes. These include existing open source projects like Hive, Hadoop, Terraform,\nDocker, Kubernetes as well as open source tools that we built to overcome some of the unexpected challenges we faced. The first of these is Circus Train — a dataset replication tool that copies Hive tables between clusters and clouds. We will also discuss various other options for dataset replication and what unique features Circus Train has. The second tool is Waggle Dance — a federated Hive metadata service that enables querying of data stored across multiple Hive metastores. We will then look at Apiary - a means to simplify the deployment of the various components of an open source data lake at scale including the Hive metastore, Waggle Dance, S3 bucket access, metadata change notifications and much more. We focus on actual problems and solutions that have arisen in a huge, organically grown corporation, rather than idealised architectures.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6820",
            "value": "Adrian Woodhead"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/ExpediaGroup/apiary",
            "value": "Apiary umbrella project"
          },
          {
            "_href": "https://github.com/HotelsDotCom/circus-train/",
            "value": "Circus Train - Hive replication tool"
          },
          {
            "_href": "https://github.com/HotelsDotCom/waggle-dance/",
            "value": "Waggle Dance - Hive federation service"
          },
          {
            "_href": "https://github.com/ExpediaGroup/beekeeper/",
            "value": "Beekeeper - Orphaned Hive data cleanup service"
          },
          {
            "_href": "https://dataworkssummit.com/berlin-2018/session/tools-and-approaches-for-migrating-big-datasets-to-the-cloud/",
            "value": "Previous talk covering earlier versions of the software"
          },
          {
            "_href": "https://www.youtube.com/watch?v=gvtysDbDLeE",
            "value": "Previous talk covering earlier versions of the software"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9617.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10351",
        "start": "10:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "magic_castle",
        "title": "Magic Castle: Terraforming the Cloud for HPC",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Compute Canada provides HPC infrastructures and support to every academic research institution in Canada. In recent years, Compute Canada has started distributing research software to its HPC clusters using with CERN software distribution service, CVMFS. This opened the possibility for accessing the software from almost any location and therefore allow the replication of the Compute Canada experience outside of its physical infrastructure.<\/p>\n\n<p>From these new possibilities emerged an open-source software project named Magic Castle, which aims to recreate the Compute Canada user experience in public clouds. Magic Castle uses the open-source software Terraform and HashiCorp Language (HCL) to define the virtual machines, volumes, and networks that are required to replicate a virtual HPC infrastructure. The infrastructure definition is packaged as a Terraform module that users can customize as they require. Once their cluster is deployed, the user is provided with a complete HPC cluster software environment including a Slurm scheduler, a Globus Endpoint, JupyterHub, LDAP, DNS, and over 3000 research software compiled by experts with EasyBuild. Magic Castle is compatible with AWS, Microsoft Azure, Google Cloud, OpenStack, and OVH.<\/p>\n\n<p>Compute Canada staff has been using this software to deploy ephemeral clusters for training purposes every other week for the past two years. Magic Castle is also gaining in popularity with HPC cluster users for development, testing, and continuous integration.<\/p>\n\n<p>In this talk, we will give a live demonstration of the creation of a cluster. We will present the architecture of Magic Castle, explain infrastructure and provisioning design, and present use cases. We will conclude by describing some of the challenges experienced while developing this novel usage of Terraform.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7024",
            "value": "Félix-Antoine Fortin"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/computecanada/magic_castle",
            "value": "Magic Castle Repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10351.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10018",
        "start": "10:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "maggy",
        "title": "Maggy: Asynchronous distributed hyperparameter optimization based on Apache Spark",
        "subtitle": "Asynchronous algorithms on a bulk-synchronous system",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Maggy is an open-source framework built on Apache Spark, for asynchronous parallel execution of trials for machine learning experiments. In this talk, we will present our work to tackle search as a general purpose method efficiently with Maggy, focusing on hyperparameter optimization. We show that an asynchronous system enables state-of-the-art optimization algorithms and allows extensive early stopping in order to increase the number of trials that can be performed in a given period of time on a fixed amount of resources.<\/p>",
        "description": "<p>In \"The Bitter Lesson of AI\", Rich Sutton (father of reinforcement learning) claimed that general purpose methods (like search and learning) that scale with increased computation are the future of AI. Apache Spark is a general purpose framework for scaling out data processing with available compute, but there are challenges in making Sparks' bulk-synchronous execution mechanism work efficiently with search and (deep) learning.\nIn this talk, we will present our work on Maggy, an open-source framework to tackle search as a general purpose method efficiently on Spark. Spark can be used to deploy basic optimizers (grid search, random search, differential evolution) proposing combinations of hyperparameters (trials) that are run synchronously in parallel on executors. However, many such trials perform poorly, and a lot of CPU and hardware accelerator cycles are wasted on trials that could be stopped early, freeing up resources for other trials. What is needed is support for asynchronous mechanisms.\nMaggy is an asynchronous hyperparameter optimization framework built on Spark that is able to transparently schedule and manage hyperparameter trials, by allowing limited communication, thereby increasing resource utilization, and massively increasing the number of trials that can be performed in a given period of time on a fixed amount of resources. Maggy is also built to support parallel ablation studies and applies to black box optimization/search problems in general. We will report on the gains we have seen in reduced time to find good hyperparameters and improved utilization of GPU hardware. Finally, we will perform a live demo on a Jupyter notebook, showing how to integrate Maggy in existing PySpark applications.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7001",
            "value": "Moritz Meister"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/logicalclocks/maggy",
            "value": "Maggy on GitHub"
          },
          {
            "_href": "https://databricks.com/session_eu19/asynchronous-hyperparameter-optimization-with-apache-spark",
            "value": "Spark+AI EU Summit 2019 talk about Maggy"
          },
          {
            "_href": "https://www.slideshare.net/dowlingjim/asynchronous-hyperparameter-search-with-spark-on-hopsworks-and-maggy",
            "value": "Spark+AI EU Summit 2019 talk Maggy slides"
          },
          {
            "_href": "http://incompleteideas.net/IncIdeas/BitterLesson.html",
            "value": "The Bitter Lesson by Rich Sutton"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10018.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9975",
        "start": "11:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "snorkel_beambell",
        "title": "Snorkel Beambell - Real-time Weak Supervision on Apache Flink",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The advent of Deep Learning models has led to a massive growth of real-world machine learning. Deep Learning allows Machine Learning Practitioners to get the state-of-the-art score on benchmarks without any hand-engineered features. These Deep Learning models rely on massive hand-labeled training datasets which is a bottleneck in developing and modifying machine learning models.<\/p>\n\n<p>Most large scale Machine Learning systems today like Google’s DryBell use some form of Weak Supervision to construct lower quality, large scale training datasets that can be used to continuously retrain and deploy models in a real-world scenario.<\/p>\n\n<p>The challenge with continuous retraining is that one needs to maintain prior state (e.g., the learning functions in case of Weak Supervision or a pre-trained model like BERT or Word2Vec for Transfer Learning) that is shared across multiple streams, while continuously updating the model. Apache Beam’s Stateful Stream processing capabilities are a perfect match here including support for scalable Weak Supervision.<\/p>\n\n<p>Prior work on using Beam’s State coupled with Flink’s dynamic processing capabilities to store and update word embeddings for real-time Online Topic Modeling of text has been presented at Flink Forward Berlin 2018.  Similar streaming pipelines would also work for real-time model updates using Weak Supervision and Transfer Learning. In this talk, we’ll be looking at a framework - Snorkel BeamBell - a framework leveraging Stanford’s Snorkel library for Weak Supervision and Apache Beam for large scale Weak Supervision Learning for online labeling of large amounts of data that can continuously learn new classification models based on Stateful Learning Functions and user feedback.<\/p>",
        "description": "<p>The advent of Deep Learning models has led to a massive growth of real-world machine learning. Deep Learning allows Machine Learning Practitioners to get the state-of-the-art score on benchmarks without any hand-engineered features. These Deep Learning models rely on massive hand-labeled training datasets which is a bottleneck in developing and modifying machine learning models.<\/p>\n\n<p>Most large scale Machine Learning systems today like Google’s DryBell use some form of Weak Supervision to construct lower quality, large scale training datasets that can be used to continuously retrain and deploy models in a real-world scenario.<\/p>\n\n<p>The challenge with continuous retraining is that one needs to maintain prior state (e.g., the learning functions in case of Weak Supervision or a pre-trained model like BERT or Word2Vec for Transfer Learning) that is shared across multiple streams, while continuously updating the model. Apache Beam’s Stateful Stream processing capabilities are a perfect match here including support for scalable Weak Supervision.<\/p>\n\n<p>Prior work on using Beam’s State coupled with Flink’s dynamic processing capabilities to store and update word embeddings for real-time Online Topic Modeling of text has been presented at Flink Forward Berlin 2018.  Similar streaming pipelines would also work for real-time model updates using Weak Supervision and Transfer Learning. In this talk, we’ll be looking at a framework - Snorkel BeamBell - a framework leveraging Stanford’s Snorkel library for Weak Supervision and Apache Beam for large scale Weak Supervision Learning for online labeling of large amounts of data that can continuously learn new classification models based on Stateful Learning Functions and user feedback.<\/p>\n\n<p>The audience would come away with a better understanding of how Weak Supervision with Apache Beam’s stateful stream processing can be used to accelerate the labeling of training data, and real-time training and update of machine learning models.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3867",
            "value": "Suneel Marthi"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9975.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9976",
        "start": "11:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "mppdb",
        "title": "Efficient Model Selection for Deep Neural Networks on Massively Parallel Processing Databases",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this session we will present an efficient way to train many deep learning model configurations at the same time with Greenplum, a free and open source massively parallel database based on PostgreSQL.  The implementation involves distributing data to the workers that have GPUs available and hopping model state between those workers, without sacrificing reproducibility or accuracy.   Then we apply optimization algorithms to generate and prune the set of model configurations to try.<\/p>",
        "description": "<p>Deep neural networks are revolutionizing many machine learning applications, but hundreds of trials may be needed to generate a good model architecture and associated hyperparameters.  This is the challenge of model selection.  It is time consuming and expensive, especially if you are only training one model at a time.<\/p>\n\n<p>Massively parallel processing databases can have hundreds of workers, so can you use this parallel compute architecture to address the challenge of model selection for deep nets, in order to make it faster and cheaper?<\/p>\n\n<p>It’s possible!<\/p>\n\n<p>We will demonstrate results from this project using a version of Hyperband, which is a well known hyperparameter optimization algorithm, and the deep learning frameworks Keras and TensorFlow, all running on Greenplum database using Apache MADlib.  Other topics will include architecture, scalability results and bright opportunities for the future.<\/p>\n\n<p>We look forward to presenting this topic at FOSDEM’20!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3581",
            "value": "Frank McQuillan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9976.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10022",
        "start": "12:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "predictive_maintenance",
        "title": "Predictive Maintenance",
        "subtitle": "from milliseconds to months",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Predictive maintenance and condition monitoring for remote heavy machinery are compelling endeavors to reduce maintenance cost and increase availability. Beneficial factors for such endeavors include the degree of interconnectedness, availability of low cost sensors, and advances in predictive analytics. This work presents a condition monitoring platform built entirely from open-source software. A real world industry example for an escalator use case from Deutsche Bahn underlines the advantages of this approach.<\/p>",
        "description": "<p>Predictive maintenance and condition monitoring for remote heavy machinery are compelling endeavors to reduce maintenance cost and increase availability. Beneficial factors for such endeavors include the degree of interconnectedness, availability of low cost sensors, and advances in predictive analytics. This work presents a condition monitoring platform built entirely from open-source software. A real world industry example for an escalator use case from Deutsche Bahn underlines the advantages of this approach.<\/p>\n\n<p>Audio analysis is performed on miliseconds of audio data to get accurate predictions of an asset's condition. Even with this high resolution knowledge about our equipment under supervision, sensitive alarming of our customers requires a system of systems approach taking into account up to several months of data.<\/p>\n\n<p>This talk highlights the challenges and learnings involved in building the platform and high-level aggregation for our alarming system.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7011",
            "value": "Corvin Jaedicke"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10022.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9939",
        "start": "12:30",
        "duration": "00:10",
        "room": "UB5.132",
        "slug": "reprod_jupyter_guix",
        "title": "Towards reproducible Jupyter notebooks",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Jupyter has become a tool of choice for researchers willing to share a narrative and supporting code that their peers can re-run.  This talk is about Jupyter’s Achille’s heel: software deployment.  I will present Guix-Jupyter, which aims to make notebook self-contained and to support reproducible deployment.<\/p>",
        "description": "<p>Jupyter has become a tool of choice for researchers in data science and others fields.  Jupyter Notebooks allow them to share a narrative and supporting code that their peers can re-run, which is why it is often considered a good tool for reproducible science.<\/p>\n\n<p>However, Jupyter Notebooks do not describe their software dependencies, which significantly hinder reproducibility: What if your peer runs different Python version?  What if your notebook depends on a library that your peer hasn’t installed?  What will happen if you try to run your notebook in a few years?<\/p>\n\n<p>All these issues are being addressed by tools such as Binder and its friend repo2docker.  These solutions, though, do not address what we think is the core issue: that notebooks lack information about their software dependency.<\/p>\n\n<p>In this talk I will present our take on this problem, Guix-Jupyter. Guix-Jupyter allows users to annotate their notebook with information about their run-time environment.  Those annotations are interpreted and Guix takes care of deploying the dependencies described.  Furthermore, Guix-Jupyter ensures that code runs in an isolated environment (a container) as a way to maximize reproducibility.<\/p>\n\n<p>Guix-Jupyter is work-in-progress and we are eager to share our approach and get your feedback!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2003",
            "value": "Ludovic Courtès"
          }
        },
        "links":
        [
          {
            "_href": "https://hpc.guix.info/blog/2019/10/towards-reproducible-jupyter-notebooks/",
            "value": "Guix-Jupyter"
          },
          {
            "_href": "https://guix.gnu.org",
            "value": "GNU Guix"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9939.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9682",
        "start": "12:45",
        "duration": "00:10",
        "room": "UB5.132",
        "slug": "buildtest",
        "title": "Buildtest: HPC Software Stack Testing Framework",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HPC support teams are often tasked with installing\nscientific software for their user community and the complexity of\nmanaging a large software stack gets very challenging. Software\ninstallation brings forth many challenges that requires a team of\ndomain expertise and countless hours troubleshooting to build an\noptimal software state that is tuned to the architecture. In the past\ndecade, two software build tools (Easybuild, Spack) have emerged\nthat are widely accepted in HPC community to accelerate building\na complete software stack for HPC systems. The support team are\nconstantly involved in fulfilling software request for end-users\nwhich leads to an ever-growing software ecosystem. Once a\nsoftware is installed, the support team hands it off to the user\nwithout any testing because scientific software requires domain\nexpertise in order to test software. Some software packages are\nshipped with a test suite that can be run at post build while many\nsoftware have no mechanism for testing. This poses a knowledge\ngap between HPC support team and end-users on the type of\ntesting to do. Some HPC centers may have developed in-house test\nscripts that are suitable for testing their software, but these tests\nare not portable due to hardcoded paths and are often site\ndependent. In addition, there is no collaboration between HPC\nsites in building a test repository that will benefit the community.\nIn this talk I will presents buildtest, a framework to automate software\ntesting for a software stack along with several module operations\nthat would be of interest to the HPC support team.<\/p>",
        "description": "<p>HPC computing environment is a tightly coupled system that\nincludes a cluster of nodes and accelerators interconnected with\na high-speed interconnect, a parallel filesystem,multiple storage\ntiers, a batch scheduler for users to submit jobs to the cluster and\na software stack for users to run their workflows. A software\nstack is a collection of compilers, MPI, libraries, system utilities\nand scientific packages typically installed in a parallel filesystem.\nA module tool like environment-modules or Lmod is generally used for loading the software environment into\nthe users’ shell environment.<\/p>\n\n<p>Software are packaged in various forms that determine how\nthey are installed. A few package formats are: binary, Makefile,\nCMake, Autoconf, github, PyPi, Conda, RPM,tarball, rubygem,\nMakeCp, jar, and many more. With many packaging formats,\nthis creates a burden for HPC support team to learn how to build\nsoftware since each one has a unique build process. Software\nbuild tools like Easybuild and Spack can build up to\n1000+ software packages by supporting many packaging\nformats to address all sorts of software builds. Easybuild and\nSpack provide end-end software build automation that helps\nHPC site to build a very large software stack with many\ncombinatorial software configurations. During the installation,\nsome packages will provide a test harness that can be executed\nvia Easybuild or Spack which typically invokes a make test or\nctest for packages that follow ConfigureMake, Autoconf, or\nCMake install process.<\/p>\n\n<p>Many HPC sites rely on their users for testing the software\nstack, and some sites may develop in-house test scripts to run\nsanity check for popular scientific tools. Despite these efforts,\nthere is little or no collaboration between HPC sites on sharing\ntests because they are site-specific and often provide no\ndocumentation. For many sites, the HPC support team don’t\nhave the time for conducting software stack testing because: (1)\nlack of domain expertise and understaffed, (2) no standard testsuite and framework to automate test build and execution.\nFrankly, HPC support teams are so busy with important day-day\noperation and engineering projects that software testing is either\nneglected or left to end-users. This demands for a concerted\neffort by HPC community to build a strong open-source\ncommunity around software stack testing.<\/p>\n\n<p>There are two points that need to be addressed. First, we need\na framework to do automatic testing of installed software stack.\nSecond, is to build a test repository for scientific software that is\ncommunity driven and reusable amongst the HPC community.\nAn automated test framework is a harness for automating the\ntest creation process, but it requires a community contribution to\naccumulate this repository on per-package basis. Before we\ndive in, this talk will focus on conducting sanity check of the\nsoftware stack so tests will need to be generic with simple\nexamples that can be compiled easily. In future, buildtest will\nfocus on domain-specific tests once there is a strong community\nbehind this project.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5040",
            "value": "Shahzeb Siddiqui"
          }
        },
        "links":
        [
          {
            "_href": "https://buildtest.rtfd.io/",
            "value": "Documentation"
          },
          {
            "_href": "https://github.com/HPC-buildtest/buildtest-framework",
            "value": "Github"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9682.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10132",
        "start": "13:00",
        "duration": "00:10",
        "room": "UB5.132",
        "slug": "job_script_archival",
        "title": "Facilitating HPC job debugging through job scripts archival",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>SArchive is a lightweight tool to facilitate debugging HPC job issues by providing support teams with the exact version of the job script that is run in the HPC job in an archive either on the filesystem, in Elasticsearch, or by producing it to a Kafka topic.<\/p>",
        "description": "<p>HPC schedulers usually keep a version of the user’s job script in their spool directory for the lifetime of the job, i.e., from job submission until the job has run to completion — either succesfully or failed. However, once the job has completed, the job script and associated files are removed to avoid stacking up a large number of files. HPC systems typically run several millions of jobs, if not many more, over their lifetime -- it is not feasible to keep them all in the spool directory. In case the job failed, user support teams are often asked to help figure out the cause of the failure. For these occasions, it often is helpful if the exact job script is available. Since a typical scheduler setup will make changes to every submitted script through, e.g., a submission filter, simply obtaining what the user submitted requires an extra hoop to run the given script through the filter(s). Furthermore, users may have tweaked, changed, or removed the job script, which may add to the difficulty of debugging the issue at hand.<\/p>\n\n<p>SArchive aims to address this problem by providing user support teams with an exact copy of the script that was run, along with the exact additional files that are used by the scheduler, e.g., to set up the environment in which the jobs runs. It can be argued that making a backup copy is actually the job of the scheduler itself, but we decided to use a tool outside the scheduler. This has the advantages that (i) one need not have access to the scheduler’s source code (not all schedulers are open source) and (ii) sites running multiple schedulers need not make any changes to each of them, but only to SArchive — which should be a fairly limited effort, if any at all. SArchive is currenly tailored towards the Slurm scheduler (hence the name), but it also supports the Torque resource manager. Adding support for other schedulers should be fairly straightforward — pull requests are welcome :)<\/p>\n\n<p>Currently, SArchive provides three archival options: storing archived files inside a file hierarchy, ship them to Elasticsearch, or produce them to a Kafka topic. File archival is pretty feature complete, the code for shipping to Elasticsearch and Kafka is still under development and only has what is needed in our (HPCUGent) specific setup — which may evolve.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4600",
            "value": "Andy Georges"
          }
        },
        "links":
        [
          {
            "_href": "https://crates.io/crates/sarchive",
            "value": "The published crate"
          },
          {
            "_href": "https://github.com/itkovian/sarchive",
            "value": "Github repo, latest  version"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10132.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10332",
        "start": "13:15",
        "duration": "00:10",
        "room": "UB5.132",
        "slug": "reprod_container",
        "title": "Sharing Reproducible Results in a Container",
        "subtitle": "A container you can build anywhere",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Containers do a great job separating out different parts of a system, making sure that they don't interact unless we want them to. What happens when a colleague hands us a project they've written and we're supposed to host it for them? They're not programmers, they're scientists. Who knows what they have in their program? How can we keep it up to date and deployed with a minimum of fuss?\nCome and see how we've solved this problem with Guix, from rebuilding or replacing the dependencies with modern versions like a pro, having only the bare minimum required software in the container, deploying in an artisanally crafted container like a hero, and upgrading and rolling back when ready.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7096",
            "value": "Efraim Flashner"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10332.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9195",
        "start": "13:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "ai_in_peoples_hands",
        "title": "Putting Artificial Intelligence back into people's hands",
        "subtitle": "Toward an accessible, transparent and fair AI",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Artificial intelligence is now widespread for critical tasks such as crime recidivism risk assessment, credit risk scoring, job application review or disease detection. Because it has more and more impact on our lives, it becomes essential to make auditable AI software so that everyone can benefit from it and participate in its development.<\/p>\n\n<p>This talk will present the methods that can be used to build fairness into artificial intelligence and explain how to control its progress thanks to the four freedoms of Free Software.<\/p>",
        "description": "<p>The talk is divided in three parts:<\/p>\n\n<ul>\n<li>How to make accessible Artificial Intelligences?<\/li>\n<li>Can AI be transparent and accurate?<\/li>\n<li>How to build fairness into AI?<\/li>\n<\/ul>\n\n\n<p>For each part the context will be presented as well as possible solutions.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6559",
            "value": "Vincent Lequertier"
          }
        },
        "links":
        [
          {
            "_href": "https://https://vl8r.eu/posts/2019-07-30-algorithms-fairness/",
            "value": "Blog post about algorithm fairness"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9195.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9983",
        "start": "14:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "graphblas",
        "title": "GraphBLAS: A linear algebraic approach for high-performance graph algorithms",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There is increasing interest to apply graph analytical techniques to a wide array of problems, many operating on large-scale graphs with billions of edges. While graph algorithms and their complexity is textbook material, efficient implementation of such algorithms is still a major challenge due to a number of reasons. First, the irregular and unstructured nature of graphs leads to a massive amount of random data access, which makes it difficult to use typical caching and parallelization techniques. Second, to optimize their code, developers need to be aware of the nuances of the underlying hardware which, at the very least consists of multiple CPU cores but often also incorporates heterogeneous components such as GPUs or even FPGAs. During the last decade, a number of graph programming models (such as Google's Pregel) have been proposed but most of these focused defining high-level abstractions for distributed execution environments and introduced a significant runtime overhead.<\/p>\n\n<p>A potential approach for defining efficient graph processing algorithms is to exploit the well-known duality of graphs and sparse adjacency matrices, using matrix operations to capture algorithms. Surprisingly, only a few recent research prototypes have used this model with little consensus on the set of necessary building blocks. The GraphBLAS initiative (launched in 2013) aims to define a standard to capture graph algorithms in the language of linear algebra - following the footsteps of the BLAS standard which, starting four decades ago, revolutionized scientific computing by defining constructs on dense matrices.<\/p>\n\n<p>In this talk, I give an overview of the GraphBLAS standard and its key components. First, I illustrate how matrix operations on various semirings correspond to the steps in graph algorithms. I then use these operations to present fundamental graph algorithms such as breadth-first search, shortest paths, and the clustering coefficient. Finally, I demonstrate the scalability of the GraphBLAS-based algorithms with the LDBC Graphalytics benchmark. The presented implementations are available open-source as part of LAGraph, a library built on top of GraphBLAS to demonstrate how to design efficient algorithms in linear algebra.<\/p>",
        "description": "<p><strong>Intended audience:<\/strong> Developers interested in implementing high-performance graph algorithms.<\/p>\n\n<p><strong>Expected prior knowledge:<\/strong> Familiarity with linear algebra helps plus but we only use basic concepts such as matrix-matrix multiplication<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3954",
            "value": "Gabor Szarnyas"
          }
        },
        "links":
        [
          {
            "_href": "http://mit.bme.hu/~szarnyas/grb/graphblas-introduction.pdf",
            "value": "90-min tutorial which serves as a basis for this talk"
          },
          {
            "_href": "https://github.com/szarnyasg/graphblas-pointers",
            "value": "List of GraphBLAS pointers"
          },
          {
            "_href": "https://github.com/GraphBLAS/LAGraph/",
            "value": "LAGraph library"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9983.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10401",
        "start": "14:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "exascale_fusion_sim",
        "title": "Selecting a Finite Element Analysis Backend for Exascale Fusion Reactor Simulations",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Accelerating the development of fusion energy requires large scale simulations on cutting edge supercomputing resources.\nGreat hardware is only half the challenge and the software must be scalable to match.\nThis talk presents an objective approach to selecting a suitable back end to fusion simulations.<\/p>",
        "description": "<p>The UKAEA's mission is to develop commercially viable fusion energy.\nCurrent fusion technology is yet to break even\non power out compared to power in,\nthus designs for future reactors,\nwhich necessarily must exceed break even,\ncarry a great amount of uncertainty.\nWith cost estimates of a first of a kind fusion reactor\nin the order of billions of euros,\nany design flaw making it through to the construction stage\nwill be an expensive mistake.<\/p>\n\n<p>Thankfully, software can help.\nBy simulating a fusion reactor prior to construction,\nthe design can be tested and refined for a considerably lower cost.\nHowever, covering all the necessary scales and physics\nfor a digital twin of a fusion reactor\nrequires computational resources at the exascale.<\/p>\n\n<p>In this work, a number of potential finite element backends\nfor a multiphysics reactor simulation are evaluated.\nThe sheer scale makes open source a practical necessity\nand scalability is the primary performance metric.\nFrom the plethora of open source finite element libraries,\nthe most promising are selected\nand compared against a number of objective, unbiased criteria.<\/p>\n\n<p>None of the tested back ends scored perfectly in all criteria,\nso a method and rationale for weighting the results\nto select the best one for the purpose is presented.\nThe aspects of open source projects\nthat are important to high performance computing are highlighted.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7240",
            "value": "Aleksander J. Dubas"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10401.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10428",
        "start": "15:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "archspec",
        "title": "Build for your microarchitecture: experiences with Spack and archspec",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In HPC, software is typically distributed as source code, so that users can build optimized software that takes advantage of specific microarchitectures and other hardware.  While this approach provides a lot of flexibility, building software from source remains a huge barrier for users accustomed to simple, fast binary package mangers.  Most package managers and container registries label binaries with a high-level architecture family name, e.g., x86_64 or ppc64le, but there is no standard way to label binaries for specific microarchitectures (haswell, skylake, power9, zen2, etc.).<\/p>\n\n<p>We’ll present a new project called “archspec” that aims to bridge this gap.  Archspec provides a standard set of human-understandable labels for many popular microarchitectures.  It models compatibility relationships between microarchitectures, and it aggregates information on ISA extensions, compiler support, and compiler flags needed to optimize these machines.  Finally, it provides a standard set of names for both microarchitectures and ISA features.  These features allow container tools and package managers to detect, build, and use optimized binaries.<\/p>\n\n<p>Archspec grew out of the Spack package manager, but it is intended for widespread use by other build, packaging, and containerization tools.  We will describe how it has been used in practice so far, how it has simplified writing generic packages, and our plans to get contributions from vendors and the broader community.<\/p>",
        "description": "<p>Expected prior knowledge / intended audience:\nAudience should have basic knowledge of build systems, as well as some knowledge about processor architectures.  There will be some brief background on this in the talk.  This will be interesting to HPC users, developers, packagers, and admins, as well as to anyone writing tools that deal with microarchitecture metadata (like container systems).<\/p>\n\n<p>Speaker bio:\nTodd Gamblin is a Senior Principal Member of Technical Staff in the Advanced Technology Office in Livermore Computing at Lawrence Livermore National Laboratory. His research focuses on scalable tools for measuring, analyzing, and visualizing parallel performance data. In addition to his research, Todd leads LLNL's DevRAMP (Reproducibility, Analysis, Monitoring, and Performance) team and the Software Packaging Technologies project in the U.S. Exascale Computing Project.  He created Spack, a popular open source HPC package management tool with a community of over 450 contributors. Todd has been at LLNL since 2008.<\/p>\n\n<p>Links to code / slides / material for the talk (optional):\nTo be provided closer to FOSDEM.<\/p>\n\n<p>Links to previous talks by the speaker:\nhttps://www.youtube.com/watch?v=DRuyPDdNr0M\nhttps://www.youtube.com/watch?v=edpgwyOD79E&amp;t=2891s\nhttps://www.youtube.com/watch?v=BxNOxHu6FAI\nhttps://insidehpc.com/2019/03/spack-a-package-manager-for-hpc/\nhttps://www.youtube.com/watch?v=iTLBkpHskzA<\/p>\n\n<p>See https://tgamblin.github.io/cv/todd-cv.pdf for more (including tutorials and other presentations at major conferences)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4884",
            "value": "Todd Gamblin"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10428.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10019",
        "start": "15:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "hpc_openstack",
        "title": "HPC on OpenStack",
        "subtitle": "the good, the bad and the ugly",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HPC systems have been traditionally operated as monolithic installations on bare-metal hardware primarily used by users with computational background to submit classic batch jobs. However the commoditization of compute resources and the introduction of new scientific fields such as life sciences to high performance computing has caused a shift in this paradigm. Today, an increasing number of biological software is made accessible through web portals. This improved ease of use has led towards a democratization of access to computational resources\nUsers of those fields don’t have the same computational knowledge as traditional HPC users from physics or chemistry and additionally require different kinds of workloads and applications that don’t fit traditional non-interactive batch scheduling resource management systems. Additionally, cloud computing is becoming more and more relevant and various efforts to lift HPC into the Cloud were started.<\/p>\n\n<p>We manage the HPC infrastructure for 3 life science and 2 particle physics institutions at the Vienna Bio Center (VBC). For the new HPC system that was procured at the end of 2018, we decided to go with an on-prem cloud framework based on OpenStack to accommodate the various emerging workflows and programs. OpenStack is not a finished product and requires considerable amount of engineering. It took us around 2 years of testing and engineering to feel confident in deploying the new HPC infrastructure on top of OpenStack. Since summer 2019 we have our 200 node production SLURM cluster running on top of VMs in OpenStack.<\/p>\n\n<p>In this talk we want to share our experiences from our endeavor into HPC on OpenStack. We want to briefly discuss the reasoning behind HPC in the cloud and specifically OpenStack.\nOften times these kind of projects either completely fade away in case of failure or get published in a  high-level white paper that is only useful as marketing material.\nWe want to share our honest experience from both implementer and operator perspective. We discuss how we use 3 environments to test updates and configuration changes. We will also explain our approach to automation and infrastructure as code all the way from the underlying infrastructure to the SLURM payload and how we keep our sanity using development procedures around pull requests and code reviews. We will also share some stories from the trenches, such as why you still learn new things about OpenStack after 1000 deploys or discover that a simple config change can destroy performance.\nThis talk will contain information that you won’t find in success stories or white papers but is hopefully very helpful or anyone who considers deploying HPC on OpenStack.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7055",
            "value": "Ümit Seren"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10019.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9677",
        "start": "16:00",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "interactive_hpc",
        "title": "Interactive applications on HPC systems",
        "subtitle": "Jupyterhub, Galaxy, RStudio, XPRA",
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Exploratory data analysis has increased the demand for interactive tools. In the same way, workshops and other teaching events often benefit from immediate and on-demand access to preconfigured, interactive environments.<\/p>\n\n<p>For low resource requirements these interactive environments can be run on workstations. However, as user count and resource demand increase, these setups become more complex. While these frameworks typically provide good support for cloud based deployments in container orchestrations, it is often preferable to deploy them on existing compute infrastructure that provides access to both software packages and the data to be analysed. The deployment on HPC batch systems specifically brings challenges on how to handle authentication, user identities, and job submissions.<\/p>\n\n<p>The architecture of these applications can be considered as following the master -- minion paradigm in most cases. One central component manages user access and acts as a gateway. It launches one or multiple per-user instances of a compute component, that provides the actual user environment.<\/p>\n\n<p>We want to demonstrate how we provide applications like Galaxy, Jupyterhub, and RStudio to scientists of the Vienna Biocenter. The presentation will focus on the similarities and pitfalls of these deployments. We run the web application gateway based on our standardized container environment. The compute components run as SLURM jobs on the CLIP batch environment (CBE). Specific focus will be placed on the integration of web-based Single-Sign-On, and how we address the management of user identities for starting jobs on the batch system. Sources and configuration examples on the specific setup will be provided.<\/p>\n\n<p>After the operator’s perspective, we will pan to the end-users view. Beginners and workshop situations typically prefer a static, pre-configured setup of the user session. Contrary to that, advanced users will want to customize their execution environment as much as possible. We will explore how scientists can tailor the setup to their individual needs.<\/p>\n\n<p>Finally, we will summarize the setups of the applications in a high-level comparison from both the operators and the end-users perspective.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6438",
            "value": "Erich Birngruber"
          }
        },
        "links":
        [
          {
            "_href": "https://jupyter.org/",
            "value": "Jupyter (interactive Python environment)"
          },
          {
            "_href": "https://rstudio.com/",
            "value": "RStudio (interactive R environment)"
          },
          {
            "_href": "https://galaxyproject.org/",
            "value": "Galaxy (Workflow Engine)"
          },
          {
            "_href": "https://tower.nf/",
            "value": "Nextflow Tower (execution manager for Nextflow)"
          },
          {
            "_href": "https://www.eclipse.org/che/",
            "value": "Eclipse Che (collaborative editing)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9677.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10024",
        "start": "16:30",
        "duration": "00:25",
        "room": "UB5.132",
        "slug": "ecmwf",
        "title": "Building cloud-based data services to enable earth-science workflows across HPC centres",
        "subtitle": [],
        "track": "HPC, Big Data, and Data Science",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Weather forecasts produced by ECMWF and environment services by the Copernicus programme act as a vital input for many downstream simulations and applications. A variety of products, such as ECMWF reanalyses and archived forecasts, are additionally available to users via the MARS archive and the Copernicus data portal. Transferring, storing and locally modifying large volumes of such data prior to integration currently presents a significant challenge to users. The key aim for ECMWF within the H2020 HiDALGO project is to migrate some of these tasks to the cloud, thereby facilitating fast and seamless application integration by enabling precise and efficient data delivery to the end-user. The required cloud infrastructure development will also feed into ECMWF's contribution to the European Weather Cloud pilot which is a collaborative cloud development project between ECMWF and EUMETSAT.<\/p>\n\n<p>ECMWF and its HiDALGO partners aim to implement a set of services that enable the simulation of complex global challenges which require massive high performance computing resources alongside state-of-the-art data analytics and visualization.<\/p>\n\n<p>ECMWF's role in the project will be to enable seamless integration of two pilot applications with its meteorological data and services delivered via ECMWF's Cloud and orchestrated by bespoke HiDALGO workflows. The demonstrated workflows show the increased value of weather forecasts, but also derived forecasts for air quality as provided by the Copernicus Atmospheric Monitoring Service (CAMS).<\/p>\n\n<p>The HiDALGO use-case workflows are comprised of four main components: pre-processing, numerical simulation, post-processing and visualization. The core simulations are ideally suited to running in a dedicated HPC environment, due to their large computational demands, coupled with the heavy communication overhead between parallel processes. However, the pre-/post-processing and visualisation tasks generally do not demand more than a few cores to compute and do not require message passing between instances, hence they are good candidates to run in a cloud environment. Enabling, managing and orchestrating the integration of both HPC and cloud environments to improve overall performance is the key goal of HiDALGO.<\/p>\n\n<p>This talk will give a general overview of HiDALGO project and its main aims and objectives. It will present the two test pilot applications which will be used for integration, and an overview of the general workflows and services within HiDALGO. In particular, it will focus on how ECMWF's cloud data and services will couple with the test pilot applications to improve overall workflow performance and enable access to new data for the pilot users.<\/p>\n\n<p>This work is supported by the HiDALGO project and has been partly funded by the European Commission's ICT activity of the H2020 Programme under grant agreement number: 824115.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7053",
            "value": "John Hanley"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10024.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UB5.230",
    "event":
    [
      {
        "_id": "9469",
        "start": "09:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "distributedteams",
        "title": "Applying Open Culture Practices across Distributed Teams",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Distributed teams are where people you work with aren’t physically co-located, ie. they’re at another office building, home or an outsourced company abroad. They’re becoming increasingly popular, for DevOps and other teams, due to recruitment, diversity, flexibility and cost savings. Challenges arise due to timezones, language barriers, cultures and ways of working. People actively participating in Open Source communities tend to be effective in distributed teams. This session looks at how to apply core Open Source principles to distributed teams in Enterprise organisations, and the importance of shared purposes/goals, (mis)communication, leading vs managing teams, sharing and learning. We'll also look at practical aspects of what's worked well for others, such as alternatives to daily standups, promoting video conferencing, time management and virtual coffee breaks. This session is relevant for those leading or working in distributed teams, wanting to know how to cultivate an inclusive culture of increased trust and collaboration that leads to increased productivity and performance. All are welcome to attend.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5988",
            "value": "Katrina Novakovic"
          }
        },
        "links":
        [
          {
            "_href": "https://twitter.com/KatNovakovic",
            "value": "Twitter profile"
          },
          {
            "_href": "http://www.linkedin.com/in/katrina-novakovic",
            "value": "LinkedIn profile"
          },
          {
            "_href": "https://speakerhub.com/speaker/katrina-novakovic",
            "value": "Speakerhub profile"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9469.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10311",
        "start": "09:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "ospoforcities",
        "title": "Organizing Open Source for Cities",
        "subtitle": "Adapting the Open Source Program Office",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Source is vital in the expansion wave of smart cities. Yet, where is the sustainable municipal open innovation economic engine/s, and how do we start them spinning at scale? — Only through structured collaboration and community.  We present the community collaboration efforts, accomplishments, and vision of the partners behind the launch of the Johns Hopkins Open Source Program Office for Open Cities, the community creation efforts of the City of Paris's open source city services platform Lutece, and the interactions with and between Baltimore communities, Paris communities, and open source communities and institutions.<\/p>",
        "description": "<p>Open Source is vital in the expansion wave of smart cities. Yet, where is the sustainable municipal Open innovation economic engine/s, and how do we start them spinning at scale? — Only through structured collaboration and community. The open source communities and institutions are highly successful at this in other industries. In cities, open source is not enough, we also need open data, open standards, etc. As we scale, openness and transparency, interoperability, feedback mechanisms, security, non-bias, privacy, become dominating design requirements. Accelerating the scale of good solutions needs help and structure. There are 18,000 municipalities in the US alone, currently siloed, and meaningful technical and community cooperation is minimal. We need a new flexible institutional framework to advance cooperation and scaling within our interdisciplinary design requirements.<\/p>\n\n<p>The open source program office is a successful industry construct in the open source world, and we aim to investigate adapting this construct to accelerate and scale open cities; from open source software &amp; services, open data, and standards, to non-bias, security, privacy, access, diversity, and above all TRUST!<\/p>\n\n<p>Johns Hopkins University has launched what is the believed to be the first OSPO for higher education and launching it in part to support Open Cities including Baltimore.  Jacob Green from Mosslabs.io discussed the launch of the JHU OSPO, its initial initiatives, and collaborations with City of Paris.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7190",
            "value": "Jacob Green"
          }
        },
        "links":
        [
          {
            "_href": "https://www.youtube.com/watch?v=2zMpXsF9P1w&feature=youtu.be",
            "value": "JHU OSPO"
          },
          {
            "_href": "https://www.smartcitiesworld.net/special-reports/special-reports/paris-uses-open-source-to-get-closer-to-the-citizen",
            "value": "Paris Lutece news articles"
          },
          {
            "_href": "http://lutece.paris.fr/",
            "value": "Paris Lutece"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10311.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10250",
        "start": "10:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "nextgencontributors",
        "title": "The next generation of contributors is not on IRC",
        "subtitle": "Discussing communication channels for inclusive open source communities",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>There is some combination of a turf war and a diaspora happening in the open source communities I participate in. There are synchronous and async channels galore. Every one of them has fans and haters with firmly held opinions on how it's the best or worst thing in the world.<\/p>\n\n<p>Let's take a step back and take a look at the landscape together. What are our communities searching for when they hop into communication channels? How do we meet new members where they are comfortable in order to be more welcoming?<\/p>\n\n<p>As a self-defined GitHub generation of open source enthusiast, I'd like to start a conversation from my personal experience and then jump into research on the options available to us today. I hope we can leave with a view of the world spanning across channels with a focus on our contributors.<\/p>",
        "description": "<p>Topics to be discussed:\n-Defining new contributors - where are they coming from and why\n-Empathize with an inexperienced contributor trying to jump right in\n-Introduce the concept of \"a third place\"\n-The challenges of synchronous communication (IRC, Slack, Gitter, others)\n-Options to focus on asynchronous channels (Email, Discourse, others)\n-Understanding when you need which\n-A pitch for why IRC could be great with Matrix.org (Riot.im)\n-Bringing it back to the new contributor with specific examples\n-An optimistic conclusion of our collective efforts to improve<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7159",
            "value": "Matthew Broberg"
          }
        },
        "links":
        [
          {
            "_href": "https://mbbroberg.fun/talks",
            "value": "Previous talks"
          },
          {
            "_href": "https://mbbroberg.fun",
            "value": "About me"
          },
          {
            "_href": "https://github.com/mbbroberg",
            "value": "GitHub"
          },
          {
            "_href": "https://twitter.com/mbbroberg",
            "value": "Twitter"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10250.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9889",
        "start": "10:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "ethicsoss",
        "title": "The Ethics of Open Source",
        "subtitle": "A Critical Reflection",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Source was supposed to level the playing field for creating and consuming software by reducing the monopolistic power of companies building proprietary software. But we didn't get the kind of democratized gift economy we were expecting. Instead, we are seeing open source creating opportunities and incentives for the already privileged to create new, and exacerbate existing, injustices. To the extent that we want to use software to create a just world, we should reject the Open Source ideology, and start thinking seriously about what comes next.<\/p>",
        "description": "<p>The Open Source Movement has always been focused on code. The result is a system that sadly neglects people, and now many maintainers are in a bad place, as they struggle to figure out how to make ends meet even as their labor creates immense value for others, and how to avoid making the lives of others worse through weaponized code. We find ourselves in this position because the key Open Source values exacerbate an existing injustice; by valuing the consumers of code over the producers of code, Open Source helps concentrate power in the hands of already powerful economic actors at the expense of maintainers. I feel that not only could we do better, we have a moral imperative to find better development models.<\/p>\n\n<p>Building on Scanlon's contractualist theory of morality, we will apply it to the world of open source—and the results will shock you. Open Source as an ideology is focused first and foremost on code, rather than people. As I have argued in the past, and will continue to argue, morality is about people first and foremost. This by itself doesn’t damn the Open Source movement, but it doesn’t take a whole lot of digging into the heart of Open Source to see that it has created a context in which maintainers are dehumanized, atrocities are visited upon innocent third parties, and large wealthy corporations are lionized. If we think that people matter, then we must reject the Open Source ideology. I’ve not the foggiest idea what comes next, but it’s time to start having a serious conversation about what a collaborative development model that values people first and foremost looks like.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6984",
            "value": "Don Goodman-Wilson"
          }
        },
        "links":
        [
          {
            "_href": "https://dev.to/degoodmanwilson/open-source-is-broken-g60",
            "value": "Paper that this talk is based upon"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9889.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10441",
        "start": "11:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "corppolicyteamoutreach",
        "title": "Engineers, Call Your Policy People!",
        "subtitle": "Lessons from the Campaign against the Copyright Directive",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>To make a long story short, the game-changer in the SaveCodeshare campaign against the Copyright Directive was when the open letter reached the software team at one of Germany’s biggest industrial companies. Instead of just signing the open letter, they picked up the phone and called their Public Policy team in Brussels. Two weeks later, we saw new text in the Parliament’s version of the legal proposal.<\/p>\n\n<p>OFE therefore calls on everyone who cares about Free and Open Source Software, who works (or knows someone who works) at companies, across industrial verticals, to build relationships with your policy or government relations teams.<\/p>\n\n<p>This is more important than ever, as there are new challenges and opportunities for FOSS on the horizon. Apart from promoting FOSS, we have to make sure that it never becomes an unintended victim again, as was the case with the first version of the EU’s Copyright Directive. As we are entering the Age of Tech Regulation, we need to mature our advocacy to increase our effectiveness.<\/p>",
        "description": "<p>I hope to give you some ideas and tools for how to increase our your political impact as engineers and developers, and how to engage with your companies’ policy or government relations teams.<\/p>\n\n<p>To make a long story short, the game-changer in the SaveCodeshare campaign against the Copyright Directive was when the open letter reached the software team at one of Germany’s biggest industrial companies. Instead of just signing the open letter, they picked up the phone and called their Public Policy team in Brussels. Two weeks later, we saw new text in the Parliament’s version of the legal proposal.<\/p>\n\n<p>OFE therefore calls on everyone who cares about Free and Open Source Software, who works (or knows someone who works) at companies, across industrial verticals, to build relationships with your policy or government relations teams.<\/p>\n\n<p>This is more important than ever, as there are new challenges and opportunities for FOSS on the horizon. Apart from promoting FOSS, we have to make sure that it never becomes an unintended victim again, as was the case with the first version of the EU’s Copyright Directive. As we are entering the Age of Tech Regulation, we need to mature our advocacy to increase our effectiveness.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7263",
            "value": "Astor Nummelin Carlberg & Paula Grzegorzewska"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10441.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10178",
        "start": "11:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "capitalismethicaloss",
        "title": "Building Ethical Software Under Capitalism",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The software that is the easiest to build -- the software that is the easiest to fund the development of -- tends to serve those who are already extremely well-served. So, how do we bridge the gap between what society needs and what many people with money want to fund? Free and open source software platforms can get us part of the way there, but without some big changes, it won't be enough. Let's talk structure!<\/p>",
        "description": "<p>We want to provide useful, intuitive, non-invasive software that all people can use, whether they personally have money for fancy customizations or not. But the software that is the easiest to build -- the software that is the easiest to fund the development of -- tends to serve those who are already extremely well-served. A technology community that primarily serves privileged people, while leaving all other users behind is not one we should expect people to spend their unpaid or volunteer time on. And for certain reprehensible functions, no one should be building the software at all, under any license. So, how do we bridge the gap between what society needs and what many people with money want to fund?<\/p>\n\n<p>This talk will cover:<\/p>\n\n<pre><code>* Non-profits, fundraising and community-building\n* Small businesses, co-ops and other niches\n* Possible changes to the broader landscape\n<\/code><\/pre>\n\n<p>If we want to build a better world, we will have to move beyond quick fixes and silver bullets. Free and open source software platforms can get us part of the way there, but without some big changes, it won't be enough. We need to build ethical structures for the creation of ethical software.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "698",
            "value": "Deb Nicholson"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10178.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9235",
        "start": "12:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "cognitivebias",
        "title": "Cognitive biases, blindspots and inclusion",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open source thrives on diversity. The last couple of years has seen huge strides in that aspect with codes of conduct and initiatives like the Contributor Covenant. While these advancements are crucial, they are not enough. In order to truly be inclusive, it’s not enough for the community members to be welcoming and unbiased, the communities’ processes and procedures really support inclusiveness by not only making marginalized members welcome, but allowing them to fully participate.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1828",
            "value": "Allon Mureinik"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9235.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10247",
        "start": "12:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "ambassadornetworks",
        "title": "Growing Sustainable Contributions Through Ambassador Networks",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Open Source Program Offices are utilizing ambassador programs more and more. We'll talk about why we decided to implement ambassador programs, how we implemented them, got buy-in (from a time and budget standpoint), and more.<\/p>\n\n<p>We'll both talk about how we use this program in our respective companies to scale and reach thousands of developers internally. We'll also throw in a few case studies and lessons learned throughout our (ongoing) journeys.<\/p>",
        "description": "<p>Comcast and Indeed are committed to fostering open source contributions to the external projects that we depend on. One type of program that both companies use is an Open Source Ambassador Program to help new and experienced individuals contribute to open source projects that they use.<\/p>\n\n<p>During this talk we’ll go over what an ambassador program is, how we decided to use them in our organizations, the path to buy-in and budget approval, how they were implemented, results we saw, and lessons learned. We’ll present specific case studies of how our Ambassador Programs helped with specific campaigns and how that fosters open source sustainability.<\/p>\n\n<p>At Indeed we’ll compare results from Hacktoberfest in 2018 and 2019, and the results that we saw before and after implementing the Open Source Ambassador Program.<\/p>\n\n<p>At Comcast, the Open Source Ambassador working group was formed in 2018 where ambassadors focus on Open Source practices, raising awareness, compliance and strategy. The aim of the OSAP is to foster discussion across the various Comcast tech offices and understand Open Source needs and issues across the organization.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7158",
            "value": "Alison Yu and Shilla Saebi"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10247.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10310",
        "start": "13:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "ethicsbackinoss",
        "title": "Bringing back ethics to open source",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Most discussions around ethical licenses today consider the Open Source Definition (OSD) with the same reverence as Moses did the tablets delivered to him on Mount Sinai.<\/p>\n\n<p>The OSD is in fact much more mundane than that. And it tells us more about its authors than about the open source movement in general; had open source been born in less privileged circles, ethical considerations would have been baked in from the start.<\/p>\n\n<p>With that in mind, let's revisit what we're actually trying to collectively achieve through the open source movement and reconsider the notion that its mission requires we allow the software we build be used in violation of Human Rights.<\/p>\n\n<p>There are minimally-disruptive changes that can be made to the OSD and to existing licenses which would puth ethical concerns centerstage, where they belong, and help us foster responsibility and accountability within our community and within software vendors.<\/p>\n\n<p>We'll look at the past attempts at creating ethical licenses and why they have failed. We'll ask all of the hard questions, even those we don't have good answers to yet. And we'll propose a new, multi-pronged approach to this issue. One that we believe, while more demanding to implement, has a much better chance of success than previous attempts have had.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5632",
            "value": "Tobie Langel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10310.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9758",
        "start": "13:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "leadeross",
        "title": "Be The Leader You Need in Open Source",
        "subtitle": "Learn key skills to guide yourself and your project towards a healthy future",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Stronger open source leadership can address a myriad of sustainability challenges and there is a call for more leaders in every project. Good news! Every contributor is a leader either through self leadership, leading others, or leading the community, yet most people have never been trained on how to lead.<\/p>\n\n<p>This talk provides the leadership the training you need and covers:\n- Why strengthen community leadership\n- Key leadership and emotional intelligence principles\n- Practical ways to lead as a contributor<\/p>",
        "description": "<p>Open source crossed the chasm into mainstream with users in all industries. Maintaining the users’ trust and sustaining innovation is key to open source’s success.<\/p>\n\n<p>However, in a world where communities are passionate, multicultural, and primarily use online communication, it is challenging to move communities towards a shared vision in a frictionless, sustainable way. Community challenges can impact innovation, putting user adoption at risk and even more importantly, hurting community members.<\/p>\n\n<p>Stronger open source leadership can address these challenges and there is a call for more leaders in every project. Good news! Every contributor is a leader either through self leadership, leading others, or leading the community, yet most people have never been trained on how to lead.<\/p>\n\n<p>This talk provides the leadership the training you need and covers:\n- Why strengthen community leadership\n- Key leadership and emotional intelligence principles\n- Practical ways to lead as a contributor<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6929",
            "value": "Megan Sanicki"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9758.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9277",
        "start": "14:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "corposscommunity",
        "title": "Building Community for your Company’s OSS Projects",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Your company has just started an open source project, but where is the community? This talk provides practical tips and suggestions along with what not to do when building a community around your company’s open source project.<\/p>",
        "description": "<p>Building a community around your company’s open source project is no easy task, and there is no magic bullet or one size fits all solution. However, there are some things that you can do (or not do) to increase the chances of successfully building a community for your project.<\/p>\n\n<p>A few of the dos and don’ts covered in this talk include:<\/p>\n\n<ul>\n<li>Planning and product management: Do use a transparent process in the open with tools that allow anyone to participate. Don’t use your internal tools and private meetings to make all of the decisions.<\/li>\n<li>Encourage participation: Do be proactive about helping community members contribute in meaningful ways. Don’t inadvertently set the expectation that employees will be the ones always answering questions and making decisions.<\/li>\n<li>Be honest: Do be honest with yourselves about where and how you prefer to have community members contribute. Don’t encourage people to contribute in areas where you are less likely to accept outside contributions.<\/li>\n<li>Managing contributions: Do have enough people trained in how to provide constructive feedback to manage the flow of incoming community contributions. Don’t assume that your existing developers have the time and skills to magically perform this difficult function.<\/li>\n<\/ul>\n\n\n<p>The audience will walk away with practical advice about building communities for corporate open source projects.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "640",
            "value": "Dawn Foster"
          }
        },
        "links":
        [
          {
            "_href": "https://fastwonderblog.com/",
            "value": "Blog"
          },
          {
            "_href": "https://twitter.com/geekygirldawn",
            "value": "Twitter"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9277.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9260",
        "start": "14:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "osslessons",
        "title": "Lessons Learned from Cultivating Open Source Projects and Communities",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Over the last decade, I’ve had the privilege professionally of building and cultivating some Open Source projects and communities. I’ve grown other projects along the way some successful, and some not. I’ve learned a ton on this journey; honestly still am, and I want to tell this story.<\/p>",
        "description": "<p>Over the last decade, I’ve had the privilege professionally of building and cultivating some Open Source projects and communities. To start off this isn’t a tools talk, this is a talk about the soft skills you have to have to be able to succeed as a leader in an Open Source project. My journey started tending the frequently asked questions for a small Linux Distribution called CRUX, and then years later professionally moved to the OpenStack-Chef project to build OpenStack clouds. I’ve grown other projects along the way helped build tooling and communities some successful and still running today, others were just flashes in the pan.  I’ve learned a ton on this journey; honestly still am, but I have some lessons that are hard learned and hopefully I warn pitfalls that can cause wasted cycles and pain.\nI’ll be going over:<\/p>\n\n<pre><code>This isn’t a tools talk\nScoping your project\n    Personally-backed\n    Corporate-backed\nEmpathy and audience is important\n    Celebrations\n    Defeats\nSuccessful traits of Open Source projects\n    Trust\n    Clear Vision\n    Have a plan to move on if needed\nHonestly, is it even worth this hassle?\n<\/code><\/pre>",
        "persons":
        {
          "person":
          {
            "_id": "5847",
            "value": "JJ Asghar"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9260.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9644",
        "start": "15:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "edufoss",
        "title": "Free software in education",
        "subtitle": "News on tools and developments for free software and data liberation in schools",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Schools is where IT and software users of tomorrow are made, and next to teaching digital skills, educating on privacy and consequences of the use of different types of software and servcies plays an important role. We would like to report on various projects from the field.<\/p>",
        "description": "<p>Helping schools and teachers with using free software is far more involved than just selling a product. Where big companies have huge budgets for advertising and marketing, free software projects have to attract educators with the power of the community.<\/p>\n\n<p>The most exciting upside of this is that our community does not only sell a product, but wants to get people involved. One of the benefits of free software for educators is that all our community goals play into their hands - free software is the basis of extending independence, democracy and all values modern schools are supposed to convey into the digital lives of students.<\/p>\n\n<p>As a person or project getting involved with free software in education, there are many challenges and opportunities. Teckids and the projects around it have collected experience from the work with schools, teachers, political decision makers and free software developers that we would like to share with the community.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2214",
            "value": "Dominik George"
          }
        },
        "links":
        [
          {
            "_href": "https://www.teckids.org",
            "value": "Teckids e.V."
          },
          {
            "_href": "https://www.schul-frei.org",
            "value": "schul-frei"
          },
          {
            "_href": "https://www.skolelinux.org",
            "value": "Skolelinux / Debian Edu"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9644.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10301",
        "start": "15:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "enterpriseoss",
        "title": "Engaging Enterprise consumers of OSS",
        "subtitle": "Enterprise contribution, participation, and support of OSS",
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>It is no secret that open source software is a foundational element to many enterprise IT and software development strategies and it's also not a secret that the rate of participation, contribution, or support amongst many enterprise companies lags significantly behind the adoption rate. Higher rates of participation are seen in software-based or forwarded companies founded in the past decade, but older companies have been slow to adapt. The solution to participation is often seen as a cultural shift, but this only accounts for a portion of the lack of participation. Motiviation and incentive structures, legal structures, and project governance and management structual alignments can have a bigger impact on enterprise participation in open source projects. In this talk I'd like to discuss a mixture of academic research and my personal real-world experience in bridging the gap between enterprise development and open source projects.<\/p>",
        "description": "<p>Over the past decade Open Source has grown to become the de facto standard and preferred software for Enterprise businesses and government agencies and continues to be the choice amongst small businesses and non-profits. We are now entering a new era where not only are these organizations adopting the use of Open Source, but they are actively participating in and contributing back to the projects. This is a large shift that requires change both within the Enterprise organizations and in the open source projects to welcome these new contributors and methods of working. However, not all organizations are ready for this shift and not all open source projects are ready to handle enterprise collaboration.<\/p>\n\n<p>As an example the motivation and incentive structure are often misaligned with an open source project incentivizing long-term participation and enterprise software development encouraging short and fast development and deployment. The problem is compounded when discussing the role of system integrators, outsourced development agencies, and consulting agencies, which are frequently used to accelerate the development of enterprise software. This mismatched timelines, management practices, and incentive structured can lead to reduced participation in open source software. However, there are changes that can be made on both sides to counteract this tension, which can lead to greater participation of enterprise software developers in open source software.<\/p>\n\n<p>In this talk I’d like to call upon academic research and lessons learned in other industries. In particular I pull lessons from the following areas:<\/p>\n\n<p>“Community Development as a Process: 1970 - Lee J. Cary - A collection of academic researching in community development organizations with reviews of the psychological (Warren C. Haggstrom) and sociological (Willis A. Sutton, Jr) implications of development organization (including discussions of Burnout and the impact thereof to the individual and community), and the role of the agent in the community development process (Robert Morris)<\/p>\n\n<p>“Governing The Commons” - 1990 - Elinor Ostrom - An academic review of institutions for collective actions including longitudinal studies of fisheries and forest management.<\/p>\n\n<p>“Roles of Boundary Organizations” - 2008 - Siobhan O’Mahony and Beth A. Bechky (University of California, Davis) - Research drawing on social movement and organizational theory that reviews the roles of a boundard organization (Association, Foundations, etc.) in managing four critical domains - governance, membership, ownership, and control over production - to provide\nanalytic levers for determining when boundary organizations work.<\/p>\n\n<p>“How Firms Leverage Crowds and Communities for Open Innovation” - 2016 - Joel West (Keck Graduate Institute) and Jonathan Sims (Babson College) - Research on crowds and communities, identifying a third form — a crowd-community hybrid — that combines attributes of both<\/p>\n\n<p>\"100 Years of Sustainability\" - 2019 - Me :) Jacob Redding - A review of the American Society of Composers, Artists, and Publishers (ASCAP) and the lessons the open source world could learn and adapt to build the next century of sustainability in open source development and innovation.<\/p>\n\n<p>In addition I want to bring in my own personal experience spending 12+ years growing the Drupal Open Source project spending time as a developer, founding board member, and founding Executive Director watching the project grow from a handful of developers to over 30,000 active contributors. I also pull from the other side of the table in my current role as an Open Source Strategy/Governance lead within Accenture - a systems integrator with nearly 500,000 employees worldwide. In my role at Accenture I craft our internal open source strategies including the use of Inner source and legal and cultural shifts to encourage more open source participation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7183",
            "value": "Jacob Redding"
          }
        },
        "links":
        [
          {
            "_href": "https://jredding.info/oss-sustainability",
            "value": "100 years of Sustainability"
          },
          {
            "_href": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2823279",
            "value": "How Firms Leverage Crowds and Communities for Open Innovation"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10301.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9150",
        "start": "16:05",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "burnout",
        "title": "Recognising Burnout",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Mental health is becoming an increasingly important topic. For this talk Andrew will focus on one particular aspect of mental health, burnout. Including his own personal experiences of when it can get really bad and steps that could be taken to help catch it early.<\/p>",
        "description": "<p>Working in technology can be extremely demanding and stressful. People put a lot of passion and themselves into what they do, removing the separation of their work from themselves. This can lead to burnout in many cases which is similar to depression in many ways.<\/p>\n\n<p>In this talk Andrew will talk through his personal experience of his worst case of burnout including the mental and physical toll it took, as well as giving advice on how to spot it early and ways to help mitigate against it.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5142",
            "value": "Andrew Hutchings"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9150.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10318",
        "start": "16:35",
        "duration": "00:25",
        "room": "UB5.230",
        "slug": "innersourceupstream",
        "title": "How Does Innersource Impact on the Future of Upstream Contributions?",
        "subtitle": [],
        "track": "Community devroom",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Innersource is a growing phenomenon that is widely viewed as improvement over existing regimes of proprietary silos within for-profit corporate walls. The bargain it strikes is compelling but curious: developers yield benefits that please them regarding software sharing &amp; improvement, while companies succeed in keeping their software crown jewels locked up &amp; locked down.\n How will that impact software freedom? Will it increase or decrease upstream contribution?  Will developers use Innersource as a jumping ground to FLOSS contribution, or will silos stay siloed?   What can Open Source Program Offices do to mitigate downsides to Innersource in an effort to increase FOSS-curious employee retention and interest? This talk explores these issues.<\/p>",
        "description": "<p>Innersource is a growing phenomenon that is widely viewed as improvement over existing regimes of proprietary silos within for-profit corporate walls. The bargain it strikes is compelling but curious: developers yield benefits that please them regarding software sharing &amp; improvement, while companies succeed in keeping their software crown jewels locked up &amp; locked down.\n How will that impact software freedom? Will it increase or decrease upstream contribution?  Will developers use Innersource as a jumping ground to FLOSS contribution, or will silos stay siloed?   What can Open Source Program Offices do to mitigate downsides to Innersource in an effort to increase FOSS-curious employee retention and interest? This talk explores these issues.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "441",
            "value": "Bradley M. Kuhn"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10318.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.119",
    "event":
    [
      {
        "_id": "10709",
        "start": "09:00",
        "duration": "00:05",
        "room": "UD2.119",
        "slug": "welcomefreetoolseditors",
        "title": "Welcome to the Free Tools & Editors Room!",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A quick introduction to the room, the sessions, and the team that put everything together. :-)<\/p>",
        "description": [],
        "persons":
        [
          {
            "_id": "1025",
            "value": "Geertjan Wielenga"
          },
          {
            "_id": "2230",
            "value": "Lars Vogel"
          },
          {
            "_id": "6913",
            "value": "Trisha Gee"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10709.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9668",
        "start": "09:05",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "insightseclipse",
        "title": "Insights into the Eclipse Open Source Project - News from the Eclipse Platform and IDE Project",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Join this talk to learn about the current status of the Eclipse IDE Open Source projects. We'll talk about new developments, our improvements in the development process, performance improvements, and new features in the Eclipse IDE.<\/p>",
        "description": "<p>In this talk, we'll demo the new features of the Eclipse IDE and show the improvements of the latest, best, and fastest Eclipse IDE ever.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2230",
            "value": "Lars Vogel"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9668.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9784",
        "start": "09:30",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "surfingintellij",
        "title": "Surfing the Tsunami - News from the IntelliJ IDEA Community",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With releases of Java coming thick and fast every 6 months, it's a full time job staying on top of the features. If your IDE can help you here, it's one less thing to worry about.  IntelliJ IDEA Community had three releases this year, each on improved the support for modern versions of Java, but that's not the only thing on offer.<\/p>\n\n<p>Join this session to see what's new in IntelliJ IDEA Community (the free one!). This is not limited to just supporting new language features, which some of us might not get to use for ages, but better support for things developers do every day, and improved performance and stability, because an all-singing, all-dancing IDE is all well and good, but if it's not usable those features mean nothing.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6913",
            "value": "Trisha Gee"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9784.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10088",
        "start": "09:55",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "fromoracleapache",
        "title": "From Oracle to Apache - News from the NetBeans Community",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>NetBeans is now a top level Apache project! How did it get to Apache and what's the state of the donation process? What are the new features and how can you get involved? Join this session to find out!<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "1025",
            "value": "Geertjan Wielenga"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10088.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9962",
        "start": "10:20",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "newjavanetbeans",
        "title": "New Java Features & Apache NetBeans",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Java platform experiences an outburst of cool new features – recently, local variable type inference, switch enhancements and multi-line string literals have been added to the Java language. Many other features are being in the pipeline and are actively worked on, like simple data carriers and pattern matching for the Java language, or  value classes for the Java virtual machine. These features are delivered quickly, thanks to the recently adopted, predictable, six-months schedule of major Java SE releases. This new release cadence means new Java platform features are delivered twice every year!<\/p>\n\n<p>In this talk, we will show a live demo of many of the recently added and newly developed features and improvements for the Java platform, including those mentioned above. The Apache NetBeans IDE will be used to demonstrate the features.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6197",
            "value": "Jan Lahoda"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9962.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9722",
        "start": "10:45",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "openbeans",
        "title": "OpenBeans IDE - Creating an Apache NetBeans Distribution",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A talk about how OpenBeans, an Apache NetBeans IDE distribution was possible due to pkgsrc, the NetBSD package management framework.<\/p>",
        "description": "<p>OpenBeans IDE started in Nov 2018 under the name CoolBeans. This was an Apache NetBeans IDE 'distribution' which repackaged the Apache NetBeans modules, plus some other modules that were still not available yet (such as the C/C++ support modules, JavaEE modules, native notifications on macOS/Windows, etc).<\/p>\n\n<p>CoolBeans was open sourced under the plain ISC license under the OpenBeans name.<\/p>\n\n<p>OpenBeans produces Windows installers as well as macOS disk images for end users. It does this using pkgsrc from NetBSD, which seems to be a very good match for distribution-like projects.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6915",
            "value": "Emilian Bold"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9722.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9961",
        "start": "11:10",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "lspgraalvm",
        "title": "LSP for Java and GraalVM Development",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this session, we will explore how the Language Server Protocol, LSP, is used to aid developers. We will cover not only the Java language, but also other languages, especially those supported by the GraalVM, like JavaScript, R, Python, Ruby. This includes development in various IDEs and editors, for example the NetBeans IDE and VisualStudio Code.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6233",
            "value": "Martin Entlicher"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9961.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9450",
        "start": "11:35",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "eclipselsp1",
        "title": "Eclipse Loves LSP - Achieving More with Less",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Eclipse and Language Server Protocol - what, why, how and most important visible results for users thanks to it.<\/p>",
        "description": "<p>Brief description of how it all started. Followed by examples of the success stories benefiting almost every Eclipse user by getting better tools while minimizing the burden on Eclipse developers.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6677",
            "value": "Alexander Kurtakov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9450.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9847",
        "start": "12:00",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "lspdebug",
        "title": "Language Server Protocol & Debug Adapter Protocol to the Rescue of Web Development in Eclipse IDE",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The state of Web (HTML, CSS, JS...) development in Eclipse IDE used to be bad. Indeed, some internal parsers had to be maintained to follow the frequent and major changes in those standards; the developer community behind them couldn't catch up, leading tools to a pretty bad and outdated state. Fortunately, the rise of technologies like TextMate grammars, Language Servers and Debug Adapters as reusable components have allowed Eclipse ecosystem to catch up with the best tools for web development. By integrating pieces of VSCode and others and with a relatively small investment, Eclipse Wild Web Developer provides a quite comfortable and efficient tool set for a wide variety of web-based projects. In this presentation, we'll demo Wild Web Developer in practicie, explaining as we demo how the LSP/DAP world is leveraged to enable those productive workflows.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6584",
            "value": "Mickael Istria"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9847.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9435",
        "start": "12:25",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "fluttereclipse",
        "title": "Flutter Development in Eclipse",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The Eclipse IDE was once heavily used for mobile app development on Android. The Android Development Tools (ADT) for Eclipse have since been deprecated and replaced by a dedicated Android Studio. To make mobile app development possible again, we leveraged the language server protocol to provide stable support for the Dart language and the Flutter SDK in the Eclipse IDE.<\/p>\n\n<p>This talk will provide an overview of the Dartboard project including its Dart language support as well as the Flutter development experience.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6182",
            "value": "Jonas Hungershausen"
          }
        },
        "links":
        [
          {
            "_href": "https://projects.eclipse.org/projects/tools.dartboard",
            "value": "Dartboard Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9435.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10531",
        "start": "12:50",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "emacsthoughts",
        "title": "Emacs Should Be Emacs Lisp - Thoughts on the Future of Emacs",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Emacs Lisp is good, actually, and Emacs should primarily be written in Emacs Lisp.  This talk will describe a way forward.<\/p>",
        "description": "<p>The future of the Emacs core is a frequent topic in the Emacs community.  Should the core be in C?  Or Rust?  Should Elisp continue to be the scripting language?  Or Guile?  Or Python, Perl (the \"Perfect Emacs Rewriting Language\") or JS?<\/p>\n\n<p>This talk advocates the rarely discussed view that Emacs Lisp is good, actually, and that Emacs should be written in Emacs Lisp.  Threading, compilation, and addressing Emacs' other low-level deficiencies will be covered, with an eye toward a practical way to roll out the changes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1585",
            "value": "Tom Tromey"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10531.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10121",
        "start": "13:15",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "teroshdl",
        "title": "TerosHDL - Open Source IDE for FPGA Developers.",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>TerosHDL is an open source project focused in the development and integration of EDA tools (ghdl, VUnit...) in an IDE. It is currently based on Atom, but in the future it will be extended to other code editors such as Visual Studio Code.<\/p>",
        "description": "<p>The goal of TerosHDL is bringing all facilities of software code tools to the HDL (VHDL and Verilog)development: linter, code completion, simulators management, automate documentation, snippets...<\/p>\n\n<p>https://youtu.be/tgr1KGIitIQ.<\/p>\n\n<p>We will introduce TerosHDL 2.0 with multiple features. In the new release the architecture has been completely rebuild in order to support more tools, reduce some dependencies and clarify the code. Some of the new features include Verilog support, additional simulators, a linter and more beautiful documentation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5500",
            "value": "Carlos Alberto"
          }
        },
        "links":
        [
          {
            "_href": "https://www.terostech.com/",
            "value": "Project page."
          },
          {
            "_href": "https://github.com/TerosTechnology",
            "value": "Github page."
          },
          {
            "_href": "https://www.youtube.com/watch?v=_wxTjOSO5oY",
            "value": "ORConf presentation."
          },
          {
            "_href": "https://drive.google.com/file/d/1be1opsHnjCPNVNqrrj3B_p0oZRV13GgU/view?usp=sharing",
            "value": "Slides."
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10121.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9291",
        "start": "13:40",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "projectional_editing_and_its_implications",
        "title": "Projectional Editing and Its Implications",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Let’s shake some of the dogmas that constrain our programming worldview. In this session, I would like to take you to an alternative world - a world where programming languages are not parsed, a world where languages can be downloaded from the Internet and plugged easily into your IDE. A world where you have the power to customize the languages that you use. You’ll see that projectional editing in JetBrains MPS gives you incredible freedom in how you express your thoughts. It allows you to choose notations that best fit the task at hand. Your code can be edited as text, tables, diagrams, a form, or a combination of those. This is especially useful for Domain-specific languages and we’ll see real-life examples from domains such as the insurance industry, embedded software development, bioinformatics, enterprise systems and legislation. We’ll also discuss the downsides and integration challenges that projectional editors face. My goal is that you’ll leave this session inspired, enriched and motivated to try something new.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6603",
            "value": "Václav Pech"
          }
        },
        "links":
        [
          {
            "_href": "http://jetbrains.com/mps",
            "value": "The project home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9291.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9276",
        "start": "14:05",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "intellijelixxir",
        "title": "IntelliJ Elixir - Elixir Plugin for JetBrains IDEs",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Using Java, Kotlin, and GrammarKit to reimplement to Erlang, Yecc grammars, and Elixir for static analysis for Elixir source and BEAM bytecode.  How decompiling and disassembly tools can quickly answer optimization arguments.<\/p>",
        "description": "<p>IntelliJ Elixir is the Elixir plugin for JetBrains IDEs like IntelliJ and Rubymine.  It uses JetBrains OpenAP, JFlexI and GrammarKit to reimplement the Elixir grammar, which is natively implemented as bespoke Erlang lexer and YECC LALR parser.  This meant translating a recursive Erlang lexer into a strict regular expression state machine used by JFlex with some interesting needed extension.  Porting the grammar from LALR Yecc to the LL Pratt Parser generated by Grammar Kit involved understanding the non-universality of BNF.  Reimplementing and extensive testing of the plugin led to finding bugs in native Elixir, showing that alternative implementations of languages in editors and tools can find bugs in the original implementations.  The BEAM bytecode decompiler and disassembler has led to better understanding of how the VM optimizes different Elixir code.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6591",
            "value": "Luke Imhoff"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/KronicDeth/intellij-elixir",
            "value": "IntelliJ Elixir GitHub repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9276.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9226",
        "start": "14:30",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "vscodeopenshift",
        "title": "VSCode Extension for OpenShift Developers",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>IDE based extension to run the instance of OpenShift on the local machine.<\/p>\n\n<p>Easy to use all OpenShift related command in VSCode to create, building, and deploying an application on OpenShift.<\/p>\n\n<p>Key points:<\/p>\n\n<ol>\n<li>OpenShift VSCode IDE base extension and it's Dependency.<\/li>\n<li>Ease installation of extension from VSCode Market Place.<\/li>\n<li>How to create Project, application, component, Services, Storage and more in OpenShift VSCode extension (Demo)<\/li>\n<\/ol>\n\n\n<p>Link: https://github.com/redhat-developer/vscode-openshift-tools<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6476",
            "value": "Sudhir Verma"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9226.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9655",
        "start": "14:55",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "developer_workspace_as_code_is_developer_heaven_in_the_cloud",
        "title": "Developer Workspace As Code - Is Developer Heaven in the Cloud?",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Developer workspaces are assembled using outdated wiki pages and usually require weeks to \"get right\". What if the IDE and workspace setup (in the broadest sense) lived directly with the code?<\/p>",
        "description": "<p>In the age of devops many things live with the source code. We compose our applications from Kubernetes/OpenShift objects, CI/CD pipelines and IDEs have their configuration in dot files, all defined along with the source code of our precious applications. But how do you define the common development environment/workspace for your developers? Let's take a look at the devfile - a declarative format for specifying the developer workspace with all the tools the developers need to code, build, test and debug the applications and how it enables Eclipse Che to be the next-gen Kubernetes-native IDE for developer teams.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6825",
            "value": "Lukas Krejci"
          }
        },
        "links":
        [
          {
            "_href": "http://eclipse.org/che",
            "value": "Eclipse Che homepage"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9655.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9724",
        "start": "15:20",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "faas",
        "title": "FaaS You Like It: Create Serverless Functions & Run Anywhere",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>\"Serverless\" is a hot topic right now, and something that a lot of developers are keen to try.<\/p>\n\n<p>A lot of focus has been on implementations that are proprietary to and only run on a single provider's cloud.<\/p>\n\n<p>In this talk, I'll show how you can develop \"serverless\" functions on your laptop, with an open source platform and run them where you like.<\/p>",
        "description": "<p>However, if you attend a Serverless event, you may come away with the impression that it's a world of proprietary walled gardens from the major cloud providers.<\/p>\n\n<p>In this talk I will cover:<\/p>\n\n<ul>\n<li> The case for open source serverless frameworks in general<\/li>\n<li> The fnproject (fnproject.io) in particular<\/li>\n<li> Implementing serverless Shakespeare on a laptop<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6213",
            "value": "Ewan Slater"
          }
        },
        "links":
        [
          {
            "_href": "http://fnproject.io",
            "value": "The Fn Project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9724.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9350",
        "start": "15:45",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "bach",
        "title": "Bach.java",
        "subtitle": "Lightweight Java Build Tool for modular projects",
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>I present \"Bach.java\" - a lightweight build tool for Java. Bach.java uses jshell/java to build\nmodular Java projects. It supports a \"zero installation\" run mode, convention over configuration\npragmatism, simple properties file to tweak defaults, and an API to build custom projects.<\/p>\n\n<p>In the spirit of Rémix Forax, who wrote: \"No need to be a maven to be able to use a build tool\",\nBach.java is targeted to coders of small to mid-size Java projects, who want to focus on their\nideas and modules instead of learning and taming a build tool.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6657",
            "value": "Christian Stein"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9350.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9279",
        "start": "16:15",
        "duration": "00:20",
        "room": "UD2.119",
        "slug": "junitjupiter",
        "title": "Unit Testing with JUnit Jupiter - How to Use the new JUnit Jupiter Platform",
        "subtitle": [],
        "track": "Free Tools and Editors",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Starting with the new <a href=\"https://junit.org/\">JUnit Jupiter Platform<\/a> which is available for longer time there are much more options than with JUnit 4 or TestNG. This lecture will show the differences of JUnit Jupiter platform and how it can be used to write better unit- and or integration tests.<\/p>",
        "description": "<p>It will be shown how to migrate to JUnit Jupiter platform and which things should be considered/changed based on the differences between JUnit Jupiter and JUnit 4/TestNG and which things have been changed in comparison to TestNG/JUnit 4. Furthermore things like dynamic tests will be taken a short overview and things like extensions will also taken into account.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3026",
            "value": "Karl Heinz Marbaise"
          }
        },
        "links":
        [
          {
            "_href": "https://junit.org/junit5/",
            "value": "JUnit Jupiter"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9279.php",
            "value": "Submit feedback"
          }
        ]
      }
    ]
  },
  {
    "_name": "UD2.120 (Chavanne)",
    "event":
    [
      {
        "_id": "10735",
        "start": "09:00",
        "duration": "00:05",
        "room": "UD2.120 (Chavanne)",
        "slug": "monitoring_and_observability_devroom_intro",
        "title": "Intro",
        "subtitle": "Monitoring and Observability Devroom",
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Introduction and welcome to the monitoring and observability devroom<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "497",
            "value": "Richard Hartmann"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10735.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9442",
        "start": "09:10",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "tracing_beginners",
        "title": "Distributed Tracing for beginners",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Distributed tracing is a tool that belongs to every developer's tool belt, but what it actually can do remains a mystery to most developers.<\/p>\n\n<p>In this slideless talk, we will introduce you to the world of distributed tracing by developing a cloud native application from scratch and applying all important distributed tracing concepts in practice, at first by hand and then by using existing libraries to automate our work.<\/p>\n\n<p>We will deploy this application in a Kubernetes cluster and see how we can take advantage of infrastructure components like service meshes to understand the routing decisions taken for specific requests.<\/p>\n\n<p>You will learn not only what distributed tracing is, but how it works, what it can do and what it can’t. By the end of this talk, you will have working knowledge to start using distributed tracing tools with your new projects, as well as with your legacy ones.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6702",
            "value": "Juraci Paixão Kröhling"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9442.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10168",
        "start": "09:50",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "tracing_grafana",
        "title": "Grafana: Successfully correlate metrics, logs, and traces",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk presents current capabilities of Grafana to integrate metrics, logs and traces and shows how to setup both Grafana and application code to be able to correlate all 3 in Grafana. It assumes some familiarity with Grafana to follow the How To steps but should be suitable for beginner users. Afterwards it shows future direction of Grafana in context of \"Experiences\", for even more seamless experience when correlating data from multiple data sources.<\/p>",
        "description": "<ul>\n<li>Quick intro to observability, alerting > metrics > logs > traces.<\/li>\n<li>How to instrument sample 3 tiered app (metrics, logging, traces).<\/li>\n<li>How to setup Grafana to observe the sample app.\n\n<ul>\n<li>Setup metrics, logging and tracing data source<\/li>\n<li>Setup integrations between data sources.<\/li>\n<\/ul>\n<\/li>\n<li>Live demo of Grafana UI, going from metric to logs to trace when debugging.<\/li>\n<li>Future of Grafana and look at \"Experiences\".<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7123",
            "value": "Andrej Ocenas"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10168.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10130",
        "start": "10:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "tracing_ceph",
        "title": "Jaegertracing in Ceph",
        "subtitle": "An interesting case of distributed tracing",
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Jaeger and Opentracing provide ready to use tracing services for distributed systems and are becoming widely used de-facto standard because of their ease of use. Making use of these libraries, Ceph, can reach to a much-improved monitoring state, supporting visibility to its background distributed processes. This would, in turn, add up to the way Ceph is being debugged, “making Ceph more transparent” in identifying abnormalities.\nIn this session, the audience will get to learn about using distributed tracing in large scale distributed systems like Ceph, an overview of Jaegertracing in Ceph and how someone can use it for debugging Ceph.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7103",
            "value": "Deepika Upadhyay"
          }
        },
        "links":
        [
          {
            "_href": "https://docs.google.com/presentation/d/1yKa6VlA3FfAHeck257KtUt5JNK_f9pw1oQ_l8fX9ri8/edit?usp=sharing",
            "value": "A draft of the presentation"
          },
          {
            "_href": "https://deepikascribbles.wordpress.com",
            "value": "Blogpost related to my work can be found here"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10130.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10171",
        "start": "11:10",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "modbus_2020",
        "title": "Stories around ModBus",
        "subtitle": "Why ModBus is worse than SNMP",
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Society would end if all ModBus stopped working overnight. Good thing it has zero security built in. Still, it's useful to get data out of industrial systems, be they a datacenter or a power plant.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "497",
            "value": "Richard Hartmann"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10171.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10156",
        "start": "11:50",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "strawberries",
        "title": "Monitoring strawberries",
        "subtitle": "Building observability for indoor farming",
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>According to the United Nations, 2.5 billion more people will be living in cities by 2050. This trend has caused indoor farming to draw a lot of attention and effort in recent years, in an attempt to scale the production of highly nutritious, healthy food inside cities.<\/p>\n\n<p>Over the past 3 years, Agricool has recycled 20 industrial containers into farms that grow strawberries, herbs and salads, in the very heart of cities, and without any pesticide. These urban farms are currently operated in Paris and Dubaï.<\/p>\n\n<p>Operating a fleet of indoor farms presents a diverse set of observability challenges. At the most traditional end of the observability spectrum, engineers rely on devops tools to operate computers, microservices, and an IoT infrastructure embedded inside the farms. On the other hand, living organisms like strawberry plants draw their own observability requirements, such as disease detection, physiological measurements, nutrient absorption, water analysis, or exposition rate to pollinating bumblebees.<\/p>\n\n<p>The purpose of this talk is to highlight observability challenges and best practices that are specific to indoor farming, and to illustrate them through the learnings that were made at Agricool when building observability pipelines.<\/p>",
        "description": "<ul>\n<li><p>Deployment of microservices to automate indoor farming environments.<\/p><\/li>\n<li><p>How to build an operational model for indoor farming based on telemetry, alerting and event stores, by using widely adopted devops/observability tools like Docker, Prometheus, InfluxDB, Grafana and Redash.<\/p><\/li>\n<li><p>Discover agronomic SLAs to drive design decisions for observability. eg. outages in irrigation systems that last too long can cause irreparable damage to strawberry plants, or a too great exposure to pollinating bumblebees can damage flowers and reduce yield.<\/p><\/li>\n<li><p>Understand that indoor farming requires to apply observability to a wide-ranging set of technical aspects such as microservices, hardware, sensors, actuators, hydraulic circuits, lighting systems, electrical cabinets, climate regulations, plant health or water quality.<\/p><\/li>\n<li><p>Build observability within an R&amp;D context in which scientists are continuously figuring out how to use time series to make breakthroughs about plant physiology.<\/p><\/li>\n<li><p>Align employees with different technical backgrounds (agronomists, engineers, technical operators) around a shared set of observability best practices.<\/p><\/li>\n<li><p>Enable domain experts to craft their own visualizations and alert rules.<\/p><\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "7113",
            "value": "Jean-Marc Davril"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10156.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10244",
        "start": "12:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "m3db",
        "title": "Querying millions to billions of metrics with M3DB's inverted index",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The cardinality of monitoring data we are collecting today continues to rise, in no small part due to the ephemeral nature of containers and compute platforms like Kubernetes. Querying a flat dataset comprised of an increasing number of metrics requires searching through millions and in some cases billions of metrics to select a subset to display or alert on. The ability to use wildcards or regex within the tag name and values of these metrics and traces are becoming less of a nice-to-have feature and more useful for the growing popularity of ad-hoc exploratory queries.<\/p>\n\n<p>In this talk we will look at how Prometheus introduced the concept of a reverse index existing side-by-side with a traditional column based TSDB in a single process.  We will then walk through the evolution of M3’s metric index, starting with ElasticSearch and evolving over the years to the current M3DB reverse index. We will give an in depth overview of the alternate designs and dive deep into the architecture of the current distributed index and the optimizations we’ve made in order to fulfill wildcards and regex queries across billions of metrics.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6073",
            "value": "Rob Skillington"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10244.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10209",
        "start": "13:10",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "histograms",
        "title": "Secret History of Prometheus Histograms",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Representing distributions in a metrics-based monitoring system is both important and hard. Doing it right unlocks many powerful use cases that would otherwise require expensive event processing. Prometheus offers the somewhat weirdly named Histogram and Summary metric types for distributions. How have they become what they are today with all their weal and woe? To help understand the present, let's shed light on the past. Studying this piece of Prometheus's history will also allow a glimpse of the bigger picture, why certain things are the way they are in Prometheus, and which parts of the original vision are still awaiting fulfillment.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7140",
            "value": "Björn Rabenstein (Beorn)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10209.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10216",
        "start": "13:50",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "testing_observability",
        "title": "Are You Testing Your Observability? Patterns for Instrumenting Your Services",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Observability is the key to understand how your application runs and behaves in action. This is especially true for distributed environments like Kubernetes, where users run Cloud-Native microservices.<\/p>\n\n<p>Among many other observability signals like logs and traces, the metrics signal has a substantial role. Sampled measurements observed throughout the system are crucial for monitoring the health of the applications and, they enable real-time, actionable alerting. While there are many open-source robust libraries, in various languages, that allow us to easily instrument services for backends like Prometheus, there are still numerous possibilities to make a mistake or misuse those tools.<\/p>\n\n<p>During this talk, two engineers from Red Hat: Kemal and Bartek (Prometheus and Thanos project maintainer) will discuss valuable patterns and best practices for instrumenting your application. The speakers will go through common pitfalls and failure cases while sharing valuable insights and methods to avoid those mistakes. In addition, this talk will demonstrate, how to leverage unit testing to verify the correctness of your observability signals. How it helps and why it is important. Last but not least, the talk will cover a demo of the example instrumented application based on the experience and projects we maintain.<\/p>\n\n<p>The audience will leave knowing how to answer the following important questions:<\/p>\n\n<p>What are the essential metrics that services should have?\nShould you test your observability? What are the ways to test it on a unit-test level?\nWhat are the common mistakes while instrumenting services and how to avoid them?<\/p>\n\n<p>And more!<\/p>",
        "description": "<p>The end goal of this talk is to demonstrate to the audience, how to harvest the powers of metric-based instrumentation in their applications. We would like to share some pragmatic, best practices and common patterns that we learned while maintaining several open-source projects.<\/p>\n\n<p>During this talk:<\/p>\n\n<p>We will discuss valuable patterns and best practices for instrumenting libraries and applications.\nWe will go through a set of common pitfalls failure cases, and methods to avoid those mistakes. Some of the topics we plan to mention: common cardinality issues, summaries vs histograms, choosing histogram bucket, testing, instrumenting libraries vs applications, common middlewares etc\nWe will demonstrate, why, when and how to leverage unit testing to verify your observability signals.\nWe plan to present a demo of the example instrumented application. We plan to use Go as an example language of such application but the talk should be mostly language agnostic.<\/p>",
        "persons":
        [
          {
            "_id": "5750",
            "value": "Bartek Plotka"
          },
          {
            "_id": "7147",
            "value": "Kemal Akkoyun"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10216.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9923",
        "start": "14:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "measure_linux_performance",
        "title": "How to measure Linux Performance Wrong",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this presentation, we will look at typical mistakes measuring or interpreting Linux Performance. Do you use LoadAvg to assess if your CPU is overloaded or Disk Utilization to see if your disks are overloaded?  We will look into these and a number of other metrics that are often misunderstood and/or misused as well as provide suggestions for better ways to measure Linux  Performance.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "4015",
            "value": "Peter Zaitsev"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9923.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9657",
        "start": "15:10",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "useless",
        "title": "From Zero to Useless to Hero: Make Runtime Data Useful in Teams",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Description:<\/p>\n\n<p>We introduced distributed tracing, central logging with trace correlation and monitoring with Prometheus and Grafana in a large internationally distributed software development project from the beginning. The result: Nobody used it.<\/p>\n\n<p>In this talk we show the good and not so good sides we have learned while introducing and operating the observability tools. We show which extensions and conventions were necessary in order to carry out a cultural change and to awaken enthusiasm for these tools. Today the tools are a first-class citizen and people are shouting when they are not available.<\/p>\n\n<p>Intended Audience:\n- Beginner (Should know the basic terms of monitoring, tracing etc..)\n- Anyone who wants to establish monitoring, distributed tracing and central logging in a team as profitably as possible<\/p>",
        "description": "<p>Rough Outline:\n- Brief description of the used toolchain to understand the runtime behavior of a cloud-native software system and our motivation to set it up very early (development phase)\n- Describe the initial standard toolchain setup that does not work\n- Show the reasons why other team members does not use the toolchain and its drawbacks\n- Describe the implemented solution and the necessary improvements to the toolchain that lowers the hurdle to use the toolchain\n- Show the outcomes in terms of cultural change: Willing to understand the software system at runtime, write tickets with important details and shorter times to fix bugs<\/p>\n\n<p>Goals:\n- Understand that a widely used tool chain in a team can improve the quality of the software system and the work culture (no finger pointing)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2890",
            "value": "Florian Lautenschlager"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9657.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9945",
        "start": "15:50",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "grafana_as_code",
        "title": "Grafana-As-Code: Fully reproducible Grafana dashboards with Grafonnet",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Grafana configuration can nowadays be fully done as code, which enables code review, code reuse, and in general better workflows when working with dashboards.<\/p>\n\n<p>This talk will present Grafonnet, a Jsonnet library to generate Grafana dashboards and some tips and tricks about how to use it efficiently and how to manage fully your grafana instances from code. We will also explore how Jsonnet and Grafonnet enable collaboration on dashboards, using Mixins and explain how to push dashboards to Grafana, either using Kubernetes, or direct to the Grafana API.<\/p>",
        "description": "<ul>\n<li>Presentation of Grafana provisioning as code features<\/li>\n<li>Presentation of Grafonnet<\/li>\n<li>How to make reusable components with jsonnet<\/li>\n<li>How to include raw json<\/li>\n<li>How to link both (jsonnet -m to generate a folder)<\/li>\n<li>How to make PR efficient (generate grafana snapshots on merge requests)<\/li>\n<li>Jsonnet Mixins<\/li>\n<\/ul>",
        "persons":
        [
          {
            "_id": "4010",
            "value": "Julien Pivotto"
          },
          {
            "_id": "7244",
            "value": "Malcolm Holmes"
          }
        ],
        "links":
        [
          {
            "_href": "http://github.com/grafana/grafonnet-lib",
            "value": "http://github.com/grafana/grafonnet-lib"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9945.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10211",
        "start": "16:30",
        "duration": "00:25",
        "room": "UD2.120 (Chavanne)",
        "slug": "monitoring_large_scale_uni_network",
        "title": "Monitoring of a Large-Scale University Network: Lessons Learned and Future Directions",
        "subtitle": [],
        "track": "Monitoring and Observability",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The complexity of network monitoring strongly depends on the size of the network under observation. Challenges in monitoring large-scale networks arise not only from dealing with a large volume of traffic, but also from keeping track of all traffic sources, destinations, and who-talks-to-whom communications. Analyzing this information allows to uncover new behaviors that would have not been visible by merely observing common metrics such as bytes and packets. The drawback is that extra pressure is put on the monitoring system as well and on the downstream data- and timeseries-stores.<\/p>\n\n<p>This talk presents a case study based on the monitoring of a large-scale university network. Challenges faced, findings, and lessons learned will be examined. It will be shown how to make sense of the input data to properly manage and reduce its scale as early as possible in the monitoring system. The discussion will also highlight the advantages and limitations of the opensource software components of the monitoring system. In particular, the opensource network monitoring tool ntopng and the timeseries-store InfluxDB will be considered. It will be shown what happens when ntopng and InfluxDB are pushed to their limits and beyond, and what it can be done to ensure their smooth operation. Relevant findings, behaviors uncovered in the network traffic, and future directions will conclude the talk. Intended audience is technical and managerial individuals who are familiar with network monitoring.<\/p>",
        "description": "<ul>\n<li>Main challenges of monitoring large-scale networks<\/li>\n<li>Case study based on the monitoring of a university network<\/li>\n<li>Availability, scalability and suitability of opensource software for network monitoring<\/li>\n<\/ul>",
        "persons":
        [
          {
            "_id": "5103",
            "value": "Simone Mainardi"
          },
          {
            "_id": "7414",
            "value": "Tobias Appel"
          }
        ],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10211.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.208 (Decroly)",
    "event":
    [
      {
        "_id": "10648",
        "start": "09:00",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "jitsi",
        "title": "Jitsi: video conferencing for the privacy minded",
        "subtitle": "Journalists, tinkerers, privacy concerned netizens, Jitsi may help you!",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Jitsi is a set of Open Source projects which provide state-of-the-art videocconferencing capabilities. In this presentation we will explore the Jitsi ecosystem from a privacy minded point of view.<\/p>",
        "description": "<p>Communicating privately via a public network (specially if we are using video) can be challenging. Jitsi provides the necessary tools to do so and we'll explore the seccurity model employed by our tools and how to setup a Jitsi instance with ease, while respecting your privacy.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "186",
            "value": "Saúl Ibarra Corretgé"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10648.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10285",
        "start": "09:20",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "janus",
        "title": "Janus as a WebRTC \"enabler\"",
        "subtitle": "Having fun with RTP and external applications",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will cover several aspects related to Janus as a WebRTC \"enabler\" for non-WebRTC applications. In particular, it will focus on the RTP management in Janus, namely how to use it as input/output to interact with external applications for different use cases.<\/p>",
        "description": "<p>Janus is an open source and general purpose WebRTC server. Its modular nature makes it easy to implement heterogeneous multimedia applications based on WebRTC, whether it's for conferencing, talking to a SIP infrastructure, broadcast a stream or interacting with an IoT device. One of its strongest points is the ability to seamlessly involve plain RTP within the context of a WebRTC communication, whether it's for feeding media to a WebRTC endpoint, or use a WebRTC stream somewhere else: this makes Janus a good WebRTC \"enabler\" for platforms that may not be aware of, or be compliant with, the WebRTC specification.<\/p>\n\n<p>This talk will cover the different features Janus provides implementers with, when it comes to RTP. In particular, it will introduce the Streaming plugin (RTP- and RTSP-to-WebRTC broadcaster), the SIP/NoSIP plugins (for legacy VoIP integration) and the so-called RTP forwarders (to relay media coming from WebRTC sources as plain RTP to external endpoints), and explain how these different components can be used together in different scenarios, whether it's just to increase scalability or to implement a complex and rich multimedia application. Besides, it will spend a few words on how simulcast, SRTP and recordings can be part of the picture.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3242",
            "value": "Lorenzo Miniero"
          }
        },
        "links":
        [
          {
            "_href": "https://janus.conf.meetecho.com",
            "value": "Janus demo and docs"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10285.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10653",
        "start": "09:40",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "cgrates",
        "title": "Build your own ENUM server using CGRateS",
        "subtitle": [],
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In this talk, Teo will explain how you can use CGRateS as an ENUM server together with other subsystems to achieve advanced ENUM functionality as number portability or least cost routing.\nCGRateS is a battle-tested Enterprise Billing Suite with support for various prepaid and postpaid billing modes.<\/p>",
        "description": "<p>In this talk, Teo will explain how you can use CGRateS as an ENUM server together with other subsystems to achieve advanced ENUM functionality as number portability or least cost routing.\nAs part of the recipe for such implementation, there will be few major CGRateS components exemplified: AttributeService ( combined with FilterService) which will be used to replace data from events arrives in CGRateS based on filters and SupplierService which can be used to select your desired provider based on different strategies such as least cost, highest cost, weight, load distribution or a mixed ( in case a two providers have the same cost if supplier was configured it can fall through on weight strategy automatically)\nCGRateS is a battle-tested Enterprise Billing Suite with support for various prepaid and postpaid billing modes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5976",
            "value": "Teofil Voivozeanu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10653.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9428",
        "start": "10:00",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "linphone",
        "title": "Linphone Instant Messaging Encryption",
        "subtitle": "Protocols' extension to existing SIP standards, implementation challenges and future extensions",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>For many years, Linphone has been one of the most active free communication software. Originally focused on voice, aditionnal functionalities were rapidly added like video, group chat and presence. All of these communication modes imply privacy.<\/p>\n\n<p>To achieve a good level of privacy, users must be able to ensure that their communications can only be displayed to the receiver of those communications, especially no-one from server infrastructure crossed by the messages shall be in the position of compromising secrecy of the communication. Basically, this is what end-to-end encryption is aiming to achieve.<\/p>\n\n<p>Linphone does implement end-to-end encryption for voice and video communications thanks to ZRTP (rfc 6189). However, for messaging, security was only performed using point-to-point cyphering, based on SIP TLS. To bring users of instant messaging features the same level of security, we decided to implement end-to-end encryption mechanisms for messaging too, including group chat.  Linphone Instant Messaging Encryption follows state-of-the-art methods for forward secrecy and MitM detection.<\/p>\n\n<p>This discussion will focus on protocols' extension to existing SIP standards, implementation challenges and future extensions.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5169",
            "value": "Elisa Nectoux"
          }
        },
        "links":
        [
          {
            "_href": "https://www.linphone.org/secure-communications",
            "value": "Linphone's secure communications web page"
          },
          {
            "_href": "https://gitlab.linphone.org/BC/public/lime",
            "value": "LIME's GitLab repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9428.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10671",
        "start": "10:25",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "freertc_collab",
        "title": "Collaboration between Free RTC projects",
        "subtitle": "Sharing resources for mutual benefit",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This session will discuss how we can share infrastructure and resources between projects, with the goals of reducing administrative burdens, reducing duplication of effort and increasing interoperability between our solutions.  To satisfy user expectations, interoperability is more critical in the field of real-time communications than any other free software eco-system.  In particular, we will look at how to share management of an event calendar, Planet sites, repositories, CI for interop testing and various other tools.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "925",
            "value": "Daniel Pocock"
          }
        },
        "links":
        [
          {
            "_href": "https://planet.freertc.org",
            "value": "FreeRTC Planet"
          },
          {
            "_href": "https://danielpocock.com",
            "value": "Daniel Pocock's blog"
          },
          {
            "_href": "https://rtcquickstart.org",
            "value": "RTC Quick Start Guide"
          },
          {
            "_href": "https://freertc.org",
            "value": "FreeRTC community portal"
          },
          {
            "_href": "https://lists.freertc.org/mailman/listinfo/announce",
            "value": "FreeRTC-Announce mailing list"
          },
          {
            "_href": "https://freertc.org/events.ics",
            "value": "FreeRTC calendar"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10671.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10534",
        "start": "10:50",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "xmpp",
        "title": "XMPP: get your shoping cart ready!",
        "subtitle": "Your guide through the candy store of XMPP extensions",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The eXtensibility of XMPP makes it extremely powerful. But it is easy to get lost in the supermarket of extensions. In this talk I will guide you though the extensions: how to read the labels? How to cook some common recipes? I will also show some exotic but nice ingredients. And last but not least: we will be having some protocol-fun!<\/p>",
        "description": "<p>The eXtensible Messaging and Presence Protocol, XMPP, has extensibility at its core. It is because of the extensibility that there is a vivid XMPP ecosystem: it is easy to adapt XMPP to new developments and to new use cases. The XMPP Standards Foundation maintains a list of extensions to XMPP. In this talk I will dive into this list of extensions: what kind of extensions are there? What statuses can an extension have? What extensions to use in some common use cases? And I will touch some exotic extensions for use cases you may never have thought about. Oh, and what is the story about these ‘humorous’ extensions, can a protocol be humorous?<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3348",
            "value": "Winfried Tilanus"
          }
        },
        "links":
        [
          {
            "_href": "https://xmpp.org/extensions/",
            "value": "The XMPP candystore"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10534.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10373",
        "start": "11:15",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "matrix_bridge",
        "title": "Crossing the Bifröst - Bridging All The Things with Matrix",
        "subtitle": "In which we bridge together as many comms systems as possible via Matrix",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Matrix is an open source project developing an open protocol and network for decentralised end-to-end-encrypted communication, providing a viable open alternative to the proprietary communication silos of WhatsApp, Slack, Discord and friends.  One of Matrix's main goals is to provide a highest-common-denominator open network which can bridge together existing communication silos.  In this talk, we'll show off Bifröst, our new application framework for building bridges, and demonstrate high quality bridging with XMPP, Slack, Discord, WhatsApp, and more!<\/p>",
        "description": "<p>Matrix owes its name to the idea of binding together existing communication platforms into an open 'matrix' in which they can interoperate.  Over the last year the wider Matrix ecosystem has been focusing increasingly on bridging, with lots of exciting development happening around:<\/p>\n\n<ul>\n<li>Bifröst - a TypeScript application framework for building bridges, including high quality XMPP support via xmpp.js and freeform protocol support via libpurple<\/li>\n<li>Slack - matrix-appservice-bridge, including bridging edits, reactions, threads, and full DM support via \"puppetting\"<\/li>\n<li>WhatsApp - mautrix-whatsapp, a fully functional WhatsApp bridge (using the API from WhatsApp Web)<\/li>\n<li>Discord - matrix-appservice-discord, with experimental puppetting support for full<\/li>\n<li>IRC - matrix-appservice-irc<\/li>\n<\/ul>\n\n\n<p>We'll explain all the flavours of bridging available these days (from bot-based, virtual users, puppetted, gatewaying etc) and show off Bifröst providing full gatewayed bridging between Matrix &amp; XMPP (so that anyone in Matrix can reach anywhere in XMPP and vice versa), as well as double-bridging (e.g. IRC&lt;->Slack via Matrix) - and generally illustrate how Matrix can be used to heal fragmented communities which have ended up shattered between Slack, Discord, IRC and other platforms.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2951",
            "value": "Matthew Hodgson"
          }
        },
        "links":
        [
          {
            "_href": "https://matrix.org",
            "value": "Matrix.org"
          },
          {
            "_href": "https://matrix.org/foundation",
            "value": "The Matrix.org Foundation"
          },
          {
            "_href": "https://matrix.org/docs/spec/application_service/latest",
            "value": "The Matrix Application Service API"
          },
          {
            "_href": "https://matrix.org/blog/2017/03/11/how-do-i-bridge-thee-let-me-count-the-ways/",
            "value": "How do I bridge thee? Let me count the ways"
          },
          {
            "_href": "https://github.com/matrix-org/matrix-bifrost",
            "value": "Bifröst - general purpose bridging framework for Matrix"
          },
          {
            "_href": "https://github.com/tulir/mautrix-whatsapp",
            "value": "Mautrix-Whatsapp - a Matrix/WhatsApp bridge"
          },
          {
            "_href": "https://github.com/matrix-org/matrix-appservice-slack",
            "value": "matrix-appservice-slack - a Matrix/Slack bridge"
          },
          {
            "_href": "https://github.com/Half-Shot/matrix-appservice-discord",
            "value": "matrix-appservice-discord - a Matrix/Discord bridge"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10373.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10624",
        "start": "11:40",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "kamailio",
        "title": "High quality VoIP platforms with Kamailio",
        "subtitle": "test driven development and debugging",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kamailio as widely-used Open Source SIP Server is used to implement large and complex real-time communication platforms. Ensuring a good user experience, performance and quality can be a challenge in these enviroments. The talk will present different ways how to use the power of Kamailio to support you with a modern testing and debugging workflow.<\/p>",
        "description": "<p>Kamailio as widely-used Open Source SIP Server is used to implement large VoIP and real-time communication platforms. Ensuring a good user experience, perfomance and quality can be a challenge in these complex enviroments. The talk will present different ways how to use the power of Kamailio to support you with a modern testing and debugging workflow.<\/p>\n\n<p>Kamailio contains different modules that support you to test and debug your configuration. Different usage examples based on real world problems are used to explain them in detail. A usual process to find problems in code is to use a debugger to step through your code. Due to the architecture of Kamailio this setup needs a bit more preparation. Additional the talk will show how to step through your configuration language execution process to debug complicated logic.<\/p>\n\n<p>Testing config logic that involves different modules together can be challenging due to the many involved moving parts. Kamailio can support you here with a dedicated and easy to use component testing infrastructure. This test infrastructure is based on docker container, is freely available and can help also in your setup.<\/p>\n\n<p>Ensuring a good code quality is especially important for a stable and secure VoIP server. Kamailio is using different static code analyzer and other testing methods to improve the quality of the server. The talk will give you an overview about this tools and highlight how to use them by yourself.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6084",
            "value": "Henning Westerholt"
          }
        },
        "links":
        [
          {
            "_href": "http://kamailio.org",
            "value": "Kamailio project website"
          },
          {
            "_href": "https://github.com/kamailio/kamailio",
            "value": "Kamailio github project"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10624.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10608",
        "start": "12:00",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "webrtc_android",
        "title": "WebRTC for Android",
        "subtitle": "Creating a serverless communication app",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Develop a serverless communication app Android by leveraging the WebRTC protocol<\/p>",
        "description": "<p>I will share my experience of developing a serverless communication app for android using the WebRTC protocol using the official WebRTC library.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5435",
            "value": "Mohammad Murad"
          }
        },
        "links":
        [
          {
            "_href": "https://webrtc.org/native-code/android/",
            "value": "Native WebRTC library for android"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10608.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9410",
        "start": "12:25",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "sip3",
        "title": "Explore your VoIP Network with SIP3",
        "subtitle": "Explore your VoIP Network with SIP3",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>It's most likely that you have already heard about the SIP3 platform which allows you to monitor and troubleshoot your VoIP infrastructure.<\/p>\n\n<p>For the last year SIP3 team has grown and added tons of nice features into platform.<\/p>\n\n<p>This talk will tell about past, present and upcoming future of SIP3 and will be useful for both newcomer users and people who've played with SIP3 in the past.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "5717",
            "value": "Oleg Agafonov"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9410.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10106",
        "start": "12:45",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "webrtc_misc",
        "title": "WebRTC isn't just for (video) conference calls",
        "subtitle": [],
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>WebRTC is showing up in many places: security cameras, babymonitors, games streaming, autonomous cars etc\nI'll describe the advantages of WebRTC in these devices but also the challenges of non-mainstream usage.\nI'll bring a demo or two and some sample code.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7090",
            "value": "Tim Panton"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10106.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9697",
        "start": "13:10",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "wazo",
        "title": "Wazo Platform",
        "subtitle": "An Open Source Project to build your own IP Telecom Platform",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Learn what is Wazo Platform. How it evolved from Wazo and Xivo. What it is the vision for this Open Source project. How we leverage Asterisk, Kamailio and RTPEngine in this vision. How to get involved.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6905",
            "value": "Mathias Wolff"
          }
        },
        "links":
        [
          {
            "_href": "https://wazo-platform.org/",
            "value": "Wazo Platform"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9697.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9951",
        "start": "13:35",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "homer",
        "title": "HOMER 2020",
        "subtitle": "Meet the latest HOMER and its ground breaking features, and learn about our project vision for the future of HEP and RTC monitoring",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>HOMER 2020: The future of the HEP Stack<\/p>",
        "description": "<p>Meet the latest HOMER and its ground breaking features, and learn about our project vision for the future of HEP and OSS RTC monitoring tool and technologies<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "3287",
            "value": "Lorenzo Mangani"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9951.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9849",
        "start": "13:55",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "nextcloud_talk",
        "title": "Nextcloud Talk",
        "subtitle": "A real-time communication platform for teams",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Real-Time communication happens often in teams these days: at work, in your sports club, your Free Software project and in many other places. For a long time this was, and in many areas often still is, dominated by centralized and proprietary tools. While there are many great Free Software projects out there which fill the gap, Nextcloud Talk is unique as it ingrates in a complete collaboration platform. You can have your files, calendar, contacts, project plan and any other data in the same place where the communication takes place, all nicely integrated. You can edit collaboratively office documents (text, spreadsheets, presentations,...) or markdown files while having a chat, video- or audio call for example. This talk will introduce you to some of the unique features Nextcloud Talk can offer to your teams.<\/p>",
        "description": "<p>Nextcloud Talk is part of the Nextcloud collaboration platform. A complete Free Software and on-premise cloud solution which allows you to manage all kind of data and work collaboratively on it, both in one Nextcloud instance and even across different Nextcloud instances. Nextcloud Talk is based on WebRTC and offers a nicely integrated tool for text-, video- and audio-chats. As Nextcloud Talk is a first-class citizen in the Nextcloud platform it is well integrated with all the other components. You can share documents from Nextcloud Files into a room and every user will directly be able to see, sync and edit the files. You can work on a document with your team while have a call or chat, and many more things are possible. While you can find for every single task great Free Software tools these days. The uniqueness of Nextcloud Talk is the integration in one collaboration platform so that all the different areas can work nicely together, integrated in a way which often even outperform proprietary competitors. This talk will introduce the audience to all the possibilities of Nextcloud Talk and will show them how they can reach a new level of productivity for their group with the collaboration platform Nextcloud.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2448",
            "value": "Björn Schießle"
          }
        },
        "links":
        [
          {
            "_href": "https://nextcloud.com",
            "value": "Nextcloud"
          },
          {
            "_href": "https://nextcloud.com/talk",
            "value": "Nextcloud Talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9849.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9440",
        "start": "14:20",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "modern_voip_infra",
        "title": "Modern VoIP in Modern Infrastructures",
        "subtitle": "Designing and implementing VoIP architectures in the cloud and container era",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>In the last years we have seen huge changes in IT infrastructures and concepts. VoIP architectures too are evolving towards Software Defined Telecoms. In this talk we'll see how VoIP solutions are being shaped by the Cloud, the open points and share some thoughts about its future.<\/p>\n\n<p>This is co-authored by Giacomo Vacca and Federico Cabiddu.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "6733",
            "value": "Giacomo Vacca"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9440.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10680",
        "start": "14:40",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "resiprocate",
        "title": "Migrating reSIProcate to C99 stdint types",
        "subtitle": [],
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>reSIProcate was developed over many years using a custom set of fixed-width data types defined in one of the headers, compat.hxx. The C99 stdint header provides a more standard solution. I talk about how we experimented with replacing the types throughout the entire stack and the consequences for users.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7351",
            "value": "Izabela Bakollari"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10680.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10687",
        "start": "15:05",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "falconieri",
        "title": "Introducing Falconieri: Remote Provisioning Service as a Service",
        "subtitle": "A new, modern, open source and cloud native remote provisioning service gateway.",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Remote Provisioning Service is a service offered by phones vendors for easily and quickly provide a configuration for a phone.\nDespite the advantages of have a phone ready to use without any specific network configuration  (except for a internet connection), there are some drawbacks like different APIs for any vendors.\nFalconieri try to unify all the vendors specific APIs under a set of HTTP rest APIs.<\/p>",
        "description": "<p>In this talk will be shown the motivations beoynd the creation of Falconieri and the technical choises.\nWill be illustrated also the APIs of the four currently supported vendors:<\/p>\n\n<ul>\n<li>SNOM<\/li>\n<li>Gigaset<\/li>\n<li>Yealink<\/li>\n<li>Fanvil<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "5705",
            "value": "Matteo Valentini"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/nethesis/falconieri",
            "value": "https://github.com/nethesis/falconieri"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10687.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10667",
        "start": "15:30",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "asterisk",
        "title": "Asterisk: A Project Update",
        "subtitle": [],
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will be about what's happened this last year in the world of Asterisk, including what's happened in the latest major release of Asterisk (Asterisk 17) as well as a discussion of some of the more recent developments that have happened since 17's release.<\/p>",
        "description": "<p>This talk will be about what's happened this last year in the world of Asterisk, including what's happened in the latest major release of Asterisk (Asterisk 17) as well as a discussion of some of the more recent developments that have happened since 17's release.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4733",
            "value": "Matthew Fredrickson"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10667.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9554",
        "start": "15:50",
        "duration": "00:15",
        "room": "UD2.208 (Decroly)",
        "slug": "coi",
        "title": "Chat Over IMAP (COI): State of the Union",
        "subtitle": "When will messaging via e-mail crash the monopolies?",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>With the free &amp; open COI standard we enable every mail user to chat via email. We presented this idea last year, have in the meantime launched the COI plugin of the Dovecot IMAP server and the OX COI Messenger app. In this talk you will learn how the basic idea evolved over time, what we have learned during the journey, where we are heading to and: Why and how you should join us on that trip.<\/p>",
        "description": "<p>We presented the idea on last year's FOSDEM: Instead of trusting companies like Facebook, Tencent and rely on their infrastructure for personal communication, we wanted to create a new chat ecosystem based on open standards and federated infrastructure. As much as we like privacy-entered messengers like Signal, it's just another silo and you have to trust the provider.\nIn the end all popular messaging services today are proprietary, closed and operated by single providers.\nThis has unwilling consequences we are not willing to accept anymore:\nYour provider knows all about your social network: when you communicate with whom, the frequency of your communication and the number, type and length of your messages – even with end to end encryption in place.\nYou are locked in as a user: You cannot simply change to another provider, because your friends and peers are also using your current provider. If you want to switch you would need to convince everyone to follow. And of course you would lose all your conversation history if you dare to move away.\nThe network is only controlled by a single party, you cannot start hosting your own WhatsApp, WeChat or FB Messenger service. They set the rules and usually do not give you access to the API for creating your own software.\nSo why not taking an existing network based on open protocols which is already used by almost everyone? Why not using.... email? It already provides a federated infrastructure and is based on open standards like SMTP and IMAP. Why not building build a chat ecosystem on top of it? We called it COI - Chat Over Imap.\nThis was the initial idea and some key players joined the initiative around this idea right from the beginning: Dovecot (the most popular IMAP server), DeltaChat (an open source email based messenger) and Open-Xchange (an open source email technology and service provider) joined forces and kicked of COI - Chat Over IMAP.\nThe Dovecot team started working on extending the existing IMAP protocol and build some services on top to allow encrypted push notifications, to reduce latency etc. The DeltaChat developers worked on improving the client's core and adjust it to the needs of the Open-Xchange team who worked on compatible Flutter-based clients for Android and iOS. Of course everything was a little more complicated than most of us thought, but in the end we made it: In October 2019 we presented beta versions of iOS and Android COI Messenger clients and we introduced the COI plugin for Dovecot.\nIn this talk we will share the main challenges we have been facing while adding real-time messaging features to IMAP and how we solved them. And we will give insights into the problems we ran into in client development where we had to combine a Rust-based DeltaChat-Core code base with Flutter based mobile UIs and platform-specific native features.<br/>\nWe would also like to share with you what the main outstanding challenges are that might still stop us from being the WhatsApp killer we'd love to be.\nAnd of course we would love to encourage you to join the party.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5618",
            "value": "Robert Virkus"
          }
        },
        "links":
        [
          {
            "_href": "https://www.coi-dev.org",
            "value": "Project presentation for developers and other partners"
          },
          {
            "_href": "https://github.com/coi-dev",
            "value": "Documentation + Specification"
          },
          {
            "_href": "https://doc.dovecot.org/configuration_manual/coi/",
            "value": "Dovecot's COI Plugin"
          },
          {
            "_href": "https://github.com/open-xchange/ox-coi",
            "value": "The COI Messenger app"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9554.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10273",
        "start": "16:10",
        "duration": "00:20",
        "room": "UD2.208 (Decroly)",
        "slug": "opensips",
        "title": "Reach for the Clouds With OpenSIPS 3.0",
        "subtitle": "A major release focused on the DevOps mindset",
        "track": "Real Time Communications",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Tune in and get up-to-date with the philosophy and features behind the major\nversion shift in the latest OpenSIPS 3.0 release.<\/p>",
        "description": "<p>OpenSIPS 3.0 embraces the cloud movement with open arms and aims to be easier to deploy and\na lot more enjoyable to maintain.  You can now automate routing logic updates to hundreds of\ninstances with a single click, thanks to the long-awaited ability to reload the routing script which\nis finally here!<\/p>\n\n<p>Individual running instances of OpenSIPS 3.0 are now capable of automatically upscaling or downscaling\nthemselves according to the volume of traffic that is running through them.  By auto-forking more SIP\nworker processes during peak day hours and un-forking them at night, OpenSIPS 3.0 maintains steady\nperformance while minimizing the costs of the cloud instances which host it.<\/p>\n\n<p>Say goodbye to \"opensipsctl\" and meet the new Python3-based tool for managing 3.x instances:\n\"opensips-cli\".  While retaining the majority of features of its predecessor, opensips-cli builds\nupon them, adding an intuitive way of interacting with multiple instances, the ability to filter, trace\nand troubleshoot specific calls which take place on any of them or to ask for an instance\ndiagnosis, which will instantly pinpoint issues such as insufficient memory, slow SQL/NoSQL service,\nslow DNS service, overflowing UDP queues and many more!<\/p>\n\n<p>Presented by Liviu Chircu and <a href=\"https://archive.fosdem.org/2019/schedule/speaker/razvan_crainea/\">Răzvan Crainea<\/a><\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4132",
            "value": "Liviu Chircu"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10273.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.218A",
    "event":
    [
      {
        "_id": "10678",
        "start": "09:00",
        "duration": "00:10",
        "room": "UD2.218A",
        "slug": "iotwelcome",
        "title": "How many engineers does it take to change an IOT light bulb?",
        "subtitle": "Welcome to the IOT devroom 2020",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Welcome to the IOT devroom<\/p>",
        "description": "<p>How many engineers does it take to change an IOT light bulb?<\/p>\n\n<p>Let's discuss the Philips Hue architecture.<\/p>\n\n<p>\"Our new cloud \"maintains a permanent, open socket connection into every Hue home, 24x7, everywhere in the world to obtain real-time performance\"\n\"- Holy fcking what?\"<\/p>",
        "persons": [],
        "links":
        [
          {
            "_href": "https://twitter.com/internetofshit/status/986006653605687296",
            "value": "Internet of Shit: How many servers could it take to turn on a light bulb LOL - Philips: hold my beer"
          },
          {
            "_href": "https://twitter.com/internetofshit/status/986006653605687296/photo/1",
            "value": "Internet of Shit: High resolution version of the architecture bis"
          },
          {
            "_href": "https://www.youtube.com/watch?v=mqp8_ROAIJY",
            "value": "Big Bang Theory: Internet success"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10678.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10675",
        "start": "09:10",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotcheckpointpower",
        "title": "Checkpointing in a real time OS for transiently-powered embedded systems",
        "subtitle": "Checkpointing in a real time OS for transiently-powered embedded systems (MSP430)",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Some constrained embedded systems cannot use batteries, those are called transiently-powered embedded systems.\nThey can be equipped with a non volatile RAM (NVRAM) and a super capacitor for gathering energy when available.\nDeveloping in such an environment is not straight.\nDuring this talk, we will expose our work on a constrained real time OS tolerant with power loss on a MSP430 based platform.\nThis platform is a MSP430FR5994 Launchpad equipped with FRAM and a super capacitor.<\/p>",
        "description": "<p>This talk deals with constrained transiently-powered embedded systems equipped with non volatile RAM (NVRAM).\nTransiently-powered systems may be autonomous sensors, sensor networks, mobile devices without batteries, systems where the use of batteries is infeasible.\nIn our case, such systems are equipped with a super capacitor that gathers energy and restitutes that energy to the system for a short time (from a few tens of milliseconds to a few minutes).\nProgramming on such a device is difficult because it operates only intermittently, as energy is available.\nSuch devices must not reboot but continue their computations all along successive powered periods, meaning that they must keep their states and values even when loosing power.\nUsing NVRAM may seem to be an easy solution, but that is not the case. Indeed, using NVRAM as a kind of RAM is likely to lead the system to an altered behaviour, an inconsistent state.<\/p>\n\n<p>Our motivation is to provide a transiently-powered computing platform to accommodate both usual sensing and transmission functions as well as as heavy as possible computations aka edge computing.\nThis platform shall abstract the use of NVRAM or at least assist the user in the design of its application.<\/p>\n\n<p>Our based test platform is an Autosar compliant open source real time OS, Trampoline (https://github.com/TrampolineRTOS/trampoline), already used inside high-end vehicles.\nTrampoline is very light, configurable, suitable for constrained devices.\nWe have made some experimentations on a MSP430FR5994 platform, it is equipped with a MSP430 and a 0.22F super capacitor.\nOur device shall start just once, and then restart from the last checkpoint on each power recovery.<\/p>\n\n<p>During this talk we will present the current state of our experimentations.\nThat is to say :\n- Real-time and estimation of remaining energy;\n- Task scheduling model for such devices;\n- Platform energy consumption models: start and restart;\n- Peripherals states and initializations.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7321",
            "value": "David Garriou"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10675.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10649",
        "start": "09:30",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotdockernoderedopenocd",
        "title": "Building composable IOT toolsets with Docker, Node-Red and OpenOCD",
        "subtitle": "Building composable IOT toolsets with Docker, Node-Red and OpenOCD",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We will demonstrate how to quickly develop simple tools to: check for a GPIO state, communicate with an I2C OLED screen or gdb into a running firmware.<\/p>",
        "description": "<p>Thanks to <a href=\"https://hub.docker.com/r/multiarch/qemu-user-static/\">multiarch/qemu-user-static<\/a>, it is now trivially easy to build arm32 docker images from any workstation or server. These images can be shared on public repositories like any other x86 image.<\/p>\n\n<p>Single board computers such as the Raspberrry Pis have built in Linux primitives for basic manipulations of GPIOs and ports (I2C, UART, SPI) such as <code>/sys/class/gpio<\/code> or <code>/dev/i2c*<\/code>.<\/p>\n\n<p>Node-RED allows to visually develop simple workflows that can leverage the kernel primitives but also other packages like OpenOCD.<\/p>\n\n<p>Most of the presentation will be live with just a few stops on GitHub or the Docker Hub. No slides should be necessary.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7348",
            "value": "Dimitri del Marmol (ddm)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10649.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10696",
        "start": "09:50",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotnuttx",
        "title": "Making a robot controller from scratch",
        "subtitle": "With NuttX, IoT.js, WebThing and more",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Technical barrier to target low cost micro controllers can be too high for many developers already used to high level API. But did you know that those devices can support many operating systems like NuttX inspired by POSIX (same for Linux), but it goes even behind than C APIs, even JavaScript runtimes like IoT.js can be supported too. IoT.js can also support JS community modules such as Generic-sensor-lite to support sensors and actuators or webthing-iotjs to enable REST API for embedded applications.<\/p>",
        "description": "<p>A Robot demonstration running on IoT.js will be explained from porting task to support new STM32F7 board, generate PWM signal to handle servo motors and also providing REST API for \"Web Of Things (WoT)\" applications. To illustrate \"Digital Twins\" concept the robot can interact with a WebVR application using A-Frame framework bridged to Mozilla webthing protocol.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "1773",
            "value": "Philippe Coval"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/rzr/twins",
            "value": "Web Of Twin robot"
          },
          {
            "_href": "https://nuttx.org/",
            "value": "NuttX"
          },
          {
            "_href": "https://iotjs.net/",
            "value": "IoT.js"
          },
          {
            "_href": "https://github.com/jerryscript-project/iotjs-modules",
            "value": "Generic-sensors-lite IoT.js modules"
          },
          {
            "_href": "https://github.com/rzr/generic-sensors-lite",
            "value": "IoT.js generic sensors module"
          },
          {
            "_href": "https://github.com/rzr/aframe-webthing",
            "value": "Aframe webthing bridge"
          },
          {
            "_href": "https://github.com/rzr/webthing-iotjs/wiki/DigitalTwins",
            "value": "Notes about Digital Twins wiki page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10696.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9384",
        "start": "10:10",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iottensorflow",
        "title": "AI at the edge with Tensorflow Lite to Design the Future of Vertical Farming",
        "subtitle": [],
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>While Machine Learning is usually deployed in the cloud, lightweight versions of these algorithms that fit for constrained IoT systems such as microcontrollers are appearing.\nUsing Machine Learning « at-the-edge » has indeed several advantages such as the reduction of network latency, it provides better privacy, and are working offline.\nIn this presentation, we will demonstrate how to deploy Deep Learning algorithms on IoT devices thanks to TensorFlow Lite. We will see how to use it to design a smart vertical farming system able to predict and optimize the plant growth, at home or in developing countries where a reliable Internet connection still is missing.<\/p>",
        "description": "<p>In this talk I will show how trending technologies like IoT, Machine Learning and Tensorflow can make the world better :)\nI will discuss how we can use Tensorflow Lite on IoT and evaluate its performances and limits.\nI will explain our use case in vertical farming, show code snippets and make some short demo.<\/p>\n\n<p>Summary:<\/p>\n\n<ul>\n<li>Vertical farming use case, how to use technologies to try stopping hunger in poor countries<\/li>\n<li>Our IoT system for data collection: data collection, electronics and embedded system<\/li>\n<li>Tensorflow Lite<\/li>\n<li>How we use Tensorflow Lite on RPI<\/li>\n<li>Short Demo<\/li>\n<li>Performance evaluation, limits, further work<\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "6682",
            "value": "Alexis DUQUE"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9384.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "9814",
        "start": "10:30",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotsphactor",
        "title": "Sphactor: actor model concurrency for creatives",
        "subtitle": "Sphactor: actor model concurrency for creatives",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We propose a combined visual and text-based programming environment based on the actor model suitable for novice to expert programmers. This model encompasses simple communicating entities which easily scale from utilizing threads inside the computer to massive distributed computer systems. Our proposal is very suitable for IOT scenarios, creative coding practices and rapid prototyping. The prototype utilizes zeromq transports and embeds python for easy creation of actors.<\/p>",
        "description": "<p>Sphactor is currently a research project for a framework for concurrent programming suitable for novice users while maintaining features needed by expert programmers. The library features an actor model at its core and features a GUI application to manage actor dependencies visually and also program individual actors using a classical text based approach.<\/p>\n\n<p>One of the initial questions for Sphactor was the fact that when students want to access new technologies they often need to be experienced programmers. However this is hardly ever the case. As an example; students need to access motion capture sensors however only an SDK is provided. We can overcome this hurdle by adding some software to make this more accessible. We found that most tools used by students in our academy can utilize the OSC (Open Sound Control) out of the box. Therefore we started transmitting sensor data through OSC. This has proven to be very comfortable for students. We then ran into the situation that for every technology we needed to develop a piece of software to translate its features to OSC. To prevent creating a jungle of tools we started researching how we could create a general intermediate layer between technologies and use OSC as a transport. This is a common question in the IOT world.<\/p>\n\n<p>Continued research showed us that students, using existing tools and frameworks were hardly ever utilizing all processors in their machines. This is due to the fact that tools they operate are only designed for single threaded situations. Tools utilizing all processors are very rare, especially for novice users. Message passing is one of the fundamental models for concurrent programming and is actually very similar to what we were already doing in our intermediate software layer and in common IOT scenarios when we are processing all our sensor data.<\/p>\n\n<p>These situation are driving the development of Sphactor. We currently have a prototype ready for testing which we will demonstrate and talk about. Sphactor is being researched by the HKU University of the Arts Utrecht in the Netherlands for use in creative processes and as a educational environment for programming and interacting with new technologies. Libsphactor is developed in C using Zeromq's czmq framework. The gui is done is C++ using an Immediate Mode UI with minimal dependencies.<\/p>\n\n<p>This research project is a continuation of research which was presented in the FOSDEM IOT devroom in 2015 and 2016.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2256",
            "value": "Arnaud Loonstra"
          }
        },
        "links":
        [
          {
            "_href": "http://github.com/hku-ect/libsphactor",
            "value": "Sphactor C library"
          },
          {
            "_href": "http://github.com/hku-ect/gazebosc",
            "value": "Sphactor GUI application"
          },
          {
            "_href": "https://archive.fosdem.org/2015/schedule/event/deviot02/",
            "value": "Orchestrating computer systems, a new protocol (FOSDEM'15)"
          },
          {
            "_href": "https://archive.fosdem.org/2016/schedule/event/deviot02/",
            "value": "Code Orchestration (FOSDEM'16)"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9814.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9302",
        "start": "10:50",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotzyre",
        "title": "Zyre: p2p messaging to fuck the cloud",
        "subtitle": "Pieter Hintjens last IOT project",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Pieter Hintjens last IOT project, running OpenWRT and the Zyre p2p library.<\/p>",
        "description": "<p>Zyre has the potential to change the cloud paradigm, with auto-discovery inside the LAN, and without any requirement of an internet connectivity.<\/p>\n\n<p>Your TV can then discover your fridge.<\/p>\n\n<p>3 years ago, I was working with Pieter Hintjens, main author of ZeroMQ and organiser of the IOT devroom, on a demo setup for his last conference at IOT Munich.<\/p>\n\n<p>When he came back from Munich, he was diagnosed with terminal lung cancer.<\/p>\n\n<p>We demonstrated a pile of OpenWRT routers blinking LED lamps in an orchestrated way.<\/p>\n\n<p>Most of my work included assembling the hardware, writing OpenWRT packages, making a CI/CD for the devices.<\/p>\n\n<p>I will show how to build OpenWRT packages with new cluster technologies, like Kubernetes.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "697",
            "value": "Benjamin Henrion (zoobab)"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/9302.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10681",
        "start": "11:10",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotmozilla",
        "title": "How to build Webthings?",
        "subtitle": "Interact with Mozilla IoT gateway",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Mozilla Webthing is a smart home platform built with Privacy by Design. It is an implementation of Web of Things concepts specified by W3C. The presentation explains how to create new things and interact with gateway using addon adapters.<\/p>",
        "description": "<p>Mozilla's WebThing schemas specify many IoT devices. They are also flexible enough to describe any devices using generic types. Standalone devices can be interacted with using WebThings REST API or using the Mozilla gateway. The gateway is designed to be extensible using addon adapters. A couple of my contributions involving sensors and virtual things will be demonstrated. Recipes will be shared to build your own adapters using your favorite language (Js, Python, etc). The addons can easily be deployed on your RaspberryPi for self-hosted home automation.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6668",
            "value": "Christian Paul"
          }
        },
        "links":
        [
          {
            "_href": "https://iot.mozilla.org/",
            "value": "Mozilla WebThing project page"
          },
          {
            "_href": "https://github.com/rzr/mozilla-iot-generic-sensors-adapter",
            "value": "Sensors AddOn"
          },
          {
            "_href": "https://github.com/rzr/mastodon-lite/",
            "value": "ActivityPub AddOn"
          },
          {
            "_href": "https://github.com/rzr/webthing-iotjs/wiki/Addons",
            "value": "Wiki page about addons"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10681.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9782",
        "start": "11:30",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotastarte",
        "title": "Astarte: A Data-First approach to IoT",
        "subtitle": "Astarte: A Data-First approach to IoT",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Even though the IoT buzz has been around for years, ecosystems are still scattered and developers must usually patch together a number of solutions to achieve their goals. Astarte is a free software, opinionated \"blackbox\" solution which aims at empowering developers with a platform which puts Data as the first-class citizen rather than focusing on Device-to-Cloud communication, and can scale to production-tier deployments easily.<\/p>",
        "description": "<p>Astarte enables developers to skip the details of all the plumbing in IoT data collection, and skip straight to easy-to-use mechanisms for harnessing data produced by IoT devices through analytics, AI, or simply visualisation.\nThe talk will go over Astarte's design and architecture, both from a plumbing perspective and from the daily developer usage. The live demo will show how to install Astarte in a Kubernetes Cluster, set up a Device (real or a simulator) to interact with Astarte, and build a minimal web application to interact with it - all in the timespan of the talk.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6938",
            "value": "Dario Freddi"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/astarte-platform/astarte",
            "value": "Project Umbrella Repository"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9782.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9609",
        "start": "11:50",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "ioteclipse",
        "title": "Building IoT solutions with Eclipse IoT technology",
        "subtitle": "Building IoT solutions with Eclipse IoT technology",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>The  IoT working group within the Eclipse Foundation is a joint effort to develop generic building blocks for creating IoT solutions. As of now, they host over 30 projects, which address different aspects of the realization of IoT use cases. The vast number of projects allow the design of tailored IoT solutions but bear the risk that people get lost in the wide range of projects. The recently introduced project Eclipse IoT packages will help here. It aims to provide pre-bundled software packages for the IoT.<\/p>\n\n<p>In this talk, we are going to introduce the work of the Eclipse IoT working group and showcase selected projects with the focus on how one can use those technologies to build custom domain specific IoT solutions. Specifically, we will focus on the message hub Eclipse Hono,, the digital twin solution Eclipse Ditto, the update manager Eclipse hawkBit and Eclipse Vorto a description language for IoT devices. We further plan to show how one can combine and use the projects in a sensible way within the Eclipse IoT packages project.<\/p>",
        "description": "<p>Building your own backend for an IoT based solution can be difficult, as one needs to solve a number of challenges like among others connecting large number of devices in a scalable way, abstracting the access to the device and managing the software on the device. Within the Eclipse Foundation, developers contributes to over 30 projects to tackle the aforementioned and further issues. Various partners drive this working group from academia and industry like the strategic partners RedHat, Eurotech and Bosch. In this talk we intend to give an overview of the ongoing work in the working group and want to showcase some of the projects that are developed in that context. Namely, we plan to focus on the following projects:<\/p>\n\n<p>Eclipse Hono – A scalable message hub for connecting a larger number of IoT devices to the cloud supporting various protocols<\/p>\n\n<p>Eclipse Ditto – Abstracting the access to the state and actions of the physical IoT device in the digital world. This is done, by the provision of HTTP and WebSocket endpoints that can be used by other applications in order to access the data of the device or send commands to the device.<\/p>\n\n<p>Eclipse hawkBit – Manage the software version of an IoT device and manage campaigns for rolling out new software updates.<\/p>\n\n<p>Eclipse Vorto – Description language for stating the capabilities and features of an IoT device. The Eclipse Vorto models can then be used by other tools e.g. to provide an API for the features or generate implementations that are already integrated with the backend.<\/p>\n\n<p>Based on those projects it is possible to build your own IoT solution for which we will give examples during this talk. Moreover, we will introduce the new Eclipse IoT packages project, which aims to provide pre-bundled packages of Eclipse IoT projects. The aim of creating those packages is to support developers who want to leverage Eclipse IoT technology in their specific context or domain.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6764",
            "value": "Sven Erik Jeroschewski"
          }
        },
        "links":
        [
          {
            "_href": "https://www.eclipse.org/hono/",
            "value": "Eclipse Hono"
          },
          {
            "_href": "https://www.eclipse.org/ditto/",
            "value": "Eclipse Ditto"
          },
          {
            "_href": "https://www.eclipse.org/hawkbit/",
            "value": "Eclipse hawkBit"
          },
          {
            "_href": "https://www.eclipse.org/vorto/",
            "value": "Eclipse Vorto"
          },
          {
            "_href": "https://iot.eclipse.org/",
            "value": "Eclipse IoT Working Group"
          },
          {
            "_href": "https://www.eclipse.org/packages/",
            "value": "Eclipse IoT Packages"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9609.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10097",
        "start": "12:10",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotmulticast",
        "title": "IoT Updates with IPv6 Multicast",
        "subtitle": "Updating a Billion Nodes from One Tiny Server",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Could we update a billion IoT nodes from just one tiny virtual server?<\/p>\n\n<p>Could a server that is behind a completely closed inbound firewall, using no caching, no CDNs and which never accepts any inbound traffic communicate at massive scale?<\/p>\n\n<p>How can we handle flow control, with no feedback mechanism?<\/p>",
        "description": "<p>Lets find out!<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4805",
            "value": "Brett Sheffield"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/librestack/iotupd",
            "value": "IoT Updater POC"
          },
          {
            "_href": "https://librecast.net/",
            "value": "Librecast Project"
          },
          {
            "_href": "https://blog.brettsheffield.com/multicast",
            "value": "Brett Sheffield"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10097.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10672",
        "start": "12:30",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotcircuitpython",
        "title": "IoT with CircuitPython",
        "subtitle": "Look mam, no development environment.",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Introduction to CircuitPython and how to make basic IoT without a development environment.<\/p>",
        "description": "<p>A brief history of CircuitPython\nCircuitPython vs MicroPython<\/p>\n\n<p>Hello World demo:\n1. Hello World in REPL\n2. Hello World in a Python script\n3. Blink (the electronic Hello World)\n4. Cheerlights (the internet connectivity Hello World)\n5. Hide and Seek (a BLE Hello World?)<\/p>\n\n<p>Circuit Python supported hardware used for the IoT demo:\n* nRF52840 (Nordic Semiconductor) with build-in BLE\n* ATSAMD51 (Microchip) M4 with Airlift (ESP32 used as a Wifi Co-Processor)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6751",
            "value": "David Glaude"
          }
        },
        "links":
        [
          {
            "_href": "https://twitter.com/DavidGlaude/status/1203450247688654848?s=20",
            "value": "BLE hide and seek"
          },
          {
            "_href": "https://twitter.com/DavidGlaude/status/1200775886980681729?s=20",
            "value": "Cheerlight for PyGamer + AirLift FeatherWing"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10672.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10618",
        "start": "12:50",
        "duration": "00:10",
        "room": "UD2.218A",
        "slug": "iotpslab",
        "title": "PSLab.io",
        "subtitle": "Pocket Science Lab",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>PSLab is a small USB powered iOT board to do measurements. It comes with slots for ESP WiFi chips and Bluetooth and can be used as hardware extension for Android phones or PCs. PSLab has a built-in Oscilloscope, Multimeter, Wave Generator, Logic Analyzer, Power Source, and we are constantly adding more digital instruments. To start measuring, connect two wires to the relevant pins and use the Android or desktop apps to view and collect the data. You can also plug in hundreds of compatible I²C standard sensors to the PSLab pin slots or even control robots with the robotic arm tool.<\/p>",
        "description": "<p>PSLab is a small USB powered iOT board to do measurements. It comes with slots for ESP WiFi chips and Bluetooth and can be used as hardware extension for Android phones or PCs. PSLab has a built-in Oscilloscope, Multimeter, Wave Generator, Logic Analyzer, Power Source, and we are constantly adding more digital instruments. To start measuring, connect two wires to the relevant pins and use the Android or desktop apps to view and collect the data. You can also plug in hundreds of compatible I²C standard sensors to the PSLab pin slots or even control robots with the robotic arm tool.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "2541",
            "value": "Mario Behling"
          }
        },
        "links":
        [
          {
            "_href": "https://pslab.io",
            "value": "Pocket Science Lab"
          },
          {
            "_href": "https://github.com/fossasia?utf8=%E2%9C%93&q=pslab",
            "value": "PSLab Repositories"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10618.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10669",
        "start": "13:00",
        "duration": "00:10",
        "room": "UD2.218A",
        "slug": "ioterlang",
        "title": "Erlang and Elixir on IoT devices using AtomVM",
        "subtitle": "Boost your IoT project with functional languages",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will present AtomVM, a tiny portable virtual machine that allows Elixir and Erlang code to run on microcontrollers with less than 500KB of RAM such as the ESP32 or several STM32.<\/p>",
        "description": "<p>Erlang and Elixir are really good at handling network packets, running concurrent processes, dealing with faults, writing testable software and enabling rapid development.\nAll this features are relevant for any language or framework that aims to IoT devices, therefore Erlang and Elixir might be good choice for IoT devices. However the BEAM, which is the standard Erlang and Elixir VM, cannot fit on those devices. AtomVM aims to overcome this limitation, by implementing a tiny virtual machine from scratch.<\/p>\n\n<p>This talk aims to present AtomVM and to show how a functional language such as Elixir might boost development of IoT projects.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "6485",
            "value": "Davide Bettio"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/bettio/AtomVM",
            "value": "AtomVM repo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10669.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10679",
        "start": "13:10",
        "duration": "00:20",
        "room": "UD2.218A",
        "slug": "iotpet",
        "title": "IOT Lightning Talks",
        "subtitle": "Show us your IOT pet project, 5mins each, don't be shy",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Show us your IOT pet project, 5mins each, don't be shy<\/p>",
        "description": "<p>Show us your IOT pet project, 5mins each, no need to register, if you have a proposal, send a quick email to zoobabATgmail.com.<\/p>",
        "persons": [],
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10679.php",
            "value": "Submit feedback"
          }
        }
      },
      {
        "_id": "10630",
        "start": "13:30",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iotfoundation",
        "title": "IoT Projects in FLOSS Foundations",
        "subtitle": "A report based on communities data",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>A data based analysis of IoT Projects in FLOSS Foundations<\/p>",
        "description": "<p>In the last decade, Industry 4.0 has emerged as a revolution for the traditional technology, and the Internet of Things (IoT) is at the core of it. Apache, Eclipse and Linux foundations, three of the main actors in Open Source, have put in place their own IoT architectures powered by different Open Source projects. In this talk, these architectures are compared and a common architecture is identified based on emerging standards, with a special focus in the Edge. Then, the common architecture is used to classify the different Open Source projects.<\/p>\n\n<p>For each project, activity and community analysis based on the data extracted from Git and Github issue trackers is achieved using the GrimoireLab platform, a powerful Open Source tool for software analytics. Finally, the data obtained is used to understand the Open Source IoT landscape in terms of companies involved, leading projects, technologies adopted and communities.<\/p>\n\n<p>A total of 55 projects have been analyzed and all of them are classified in the categories: Edge, Cloud, Enterprise, Tools. And inside the Edge category, five subcategories are defined: OS and virtualization in devices, communication protocols, data processing, platforms for interoperability and applications. For all the projects the data for the activity (commits) and community size (people doing commits) are extracted and analyzed in time series.<\/p>\n\n<p>The data will be presented as dashboards that all attendees can consult online and all the data could be shared with interested people for further analysis.<\/p>\n\n<ul>\n<li><a href=\"https://www.linkedin.com/in/acslinkedin/\">Alvaro del Castillo<\/a><\/li>\n<li><a href=\"https://www.linkedin.com/in/valerio-cosentino-29980121\">Valerio Cosentino<\/a><\/li>\n<\/ul>",
        "persons":
        {
          "person":
          {
            "_id": "1774",
            "value": "Alvaro del Castillo"
          }
        },
        "links":
        [
          {
            "_href": "https://chaoss.github.io/grimoirelab/",
            "value": "GrimoireLab Analysis platform"
          },
          {
            "_href": "https://iot.eclipse.org/",
            "value": "Eclipse IoT"
          },
          {
            "_href": "https://www.lfedge.org/",
            "value": "Linux Foundation Edge"
          },
          {
            "_href": "https://projects.apache.org/projects.html?category#iot",
            "value": "Apache Foundation IoT"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10630.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10254",
        "start": "14:00",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iotk8s",
        "title": "Kubernetes of Things",
        "subtitle": "Case-study building sensors and actors as CRDs",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Kubernetes allows to extend its API surface with custom objects called CustomResources (CR) whose JSON contents is described via OpenAPI schemas. The REST API allows realtime notification of changes sent out to multiple listeners. This sounds like the ingredients necessary to build an open IoT platform. This talk is about using CustomResources for Kubernetes as Things, i.e. namespaced objects representing sensors and actors. It is based on a case-study implementing this idea following an example of a deep sea station with valves and pumps, a controller controlling the air pressure in the station.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "7163",
            "value": "Stefan Schimanski"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/jpbetz/KoT/",
            "value": "prototype project"
          },
          {
            "_href": "https://www.youtube.com/watch?v=AAxuEPIzHUQ",
            "value": "KubeCon talk"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10254.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10307",
        "start": "14:30",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iotfieldtracks",
        "title": "Insight Fieldtracks",
        "subtitle": "Tracking firefighters, medics & actors during field exercises",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Understanding the course of a drill is important for both steering and evaluation. Fieldtracks implements localization and tracking based on BLE, ESP32 and mesh networking for indoor and outdoor environments. This talk will introduce you into fieldtracks and its challenges.<\/p>",
        "description": "<p>Back in 2018, we started implementing a small prototype for indoor tracking using inexpensive and compact Espressif ESP32 devices. Beaconing and scanning at the same time, results are transmitted using MQTT for real time analysis and recording.<\/p>\n\n<p>The first results looked promising and shifted the focus towards user-experience (UX) and visualization. An Angular client allows accessing data in real-time, utilizing a distributed on-site network integrated into the cloud. On-site, UX also concerns the rapid tactical deployment of mesh networks utilizing various links (IEEE 802.3 / 802.11, ITU G.992.5 aka DSL).<\/p>\n\n<p>The initial deployment happened in September 2019. It has demonstrated the general feasibility and outlined the room for a lot of UI an UX improvements, from which the need for expertise and new contributors has arisen.<\/p>\n\n<p>Let's have a look at the challenges we encountered building the network and see, why it's exciting to build an IoT-network to be used in the field. We would like to invite you to work with us and welcome some networking later on.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7134",
            "value": "yanosz"
          }
        },
        "links":
        [
          {
            "_href": "https://fieldtracks.org",
            "value": "https://fieldtracks.org"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10307.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10069",
        "start": "15:00",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iotwolfboot",
        "title": "WolfBoot",
        "subtitle": "Secure boot and remote updates",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>Firmware updates in IoT pose a new set of security risks. Secure bootloaders can be handy to deploy new versions of the firmware on those devices that are only reachable through a remote connection.<\/p>\n\n<p>wolfBoot is a portable, GPL, OS-agnostic, secure bootloader solution for 32-bit microcontrollers, relying on wolfCrypt for firmware authentication, providing secure firmware update mechanisms.<\/p>\n\n<p>Due to the minimalist design of the bootloader and the tiny HAL API, wolfBoot is completely independent from any OS or bare-metal application, and can be easily ported and integrated in existing embedded software projects to provide a secure firmware update mechanism.<\/p>\n\n<p>This presentation will focus on the implementation details and the design choices of the project, and the porting done to ARM Cortex-M and RISCV32 microcontrollers.<\/p>",
        "description": [],
        "persons":
        {
          "person":
          {
            "_id": "384",
            "value": "Daniele Lacamera"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/wolfSSL/wolfBoot",
            "value": "repository"
          },
          {
            "_href": "https://www.wolfssl.com/products/wolfBoot/",
            "value": "Home page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10069.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "9561",
        "start": "15:30",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iotmicropython",
        "title": "Using Micropython to develop an IoT sensor platform with an Augmented Reality UI",
        "subtitle": "How to marry the physical world and IoT with the virtual",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<h1>IoT with Augmented Reality<\/h1>\n\n<p>Anyone with a curious mind and interested in how to marry the physical world and IoT with the virtual. This talk is pitched at intermediate, but for beginners extensive documentation and a github repo is available to read and learn from. It shows the tiny <a href=\"https://pybd.io/\">Micorpython Pyboard 'D'<\/a> being used as a tiny web server serving up an Augmented Reality display. The display shows sensor data overlay on a marker used to identify the IoT device. The work is open sourced from a project being run at the Samsung Research Institute in the UK.<\/p>",
        "description": "<h1>Using Micropython to develop an IoT multimode sensor platform with an Augmented Reality UI<\/h1>\n\n<h2>Who is this for<\/h2>\n\n<p>Anyone with a curious mind and interested in how to marry the physical world and IoT with the virtual. This talk is pitched at intermediate, but for beginners extensive documentation and a <a href=\"https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform/wiki\">github repo<\/a> is available to read and learn from.<\/p>\n\n<h2>What is it about<\/h2>\n\n<p>The story of a project at Samsung to capture data for the purpose of using in AI projects, which then became an OS platform with innovative ideas more important that the original concept. A multimode sensor platform using Augmented Reality for visualization.<\/p>\n\n<h2>Will I See The Real Prototype<\/h2>\n\n<p>Yes there will be a demonstration of the prototype and this will be used as part of the talk to explain the concepts.<\/p>\n\n<h2>What Technologies Will It Cover<\/h2>\n\n<p>This talk will cover a microcontroller with plug-able sensors using <a href=\"http://www.micropython.org/\">micropython<\/a> for the main software development platform. For the serve side components the talk will be using a micro web server used to serve sensor data and a simple AR display. For Augmented Reality the talk will switch to using HTML and JavaScript needed to render objects in the browser for the demo.<\/p>\n\n<h2>What Will I Learn<\/h2>\n\n<p>Hopefully you will learn an introduction to IoT concepts to developers who are interested in this tech, but we will use <a href=\"http://micropython.org/\">micropython<\/a> for embedded systems and show how to used. You will see in this talk:\n1. How to use a tiny microcontroller with real sensors using <a href=\"http://www.micropython.org/\">micropython<\/a>.\n2. How to connect 'things' to the platform.\n3. A micro web server to serve content.\n4. The web side, using web technologies like A-Frame, AR.js for the purpose of having AR capabilities.<\/p>\n\n<h2>In Summary<\/h2>\n\n<p>This talk will cover going from the small embedded world of IoT and sensors using micropython. Some time will be given to go over the general micro server. Then the last part of the talk will go over the concepts of Augmented Reality and using a mobile browser to view data from the sensors.<\/p>\n\n<h2>Resources<\/h2>\n\n<p>The main github repo for the <a href=\"https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform\">project is here<\/a>. It's open source and still changing. Be sure to keep track on it! :-)<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "5309",
            "value": "Nicholas Herriot"
          }
        },
        "links":
        [
          {
            "_href": "https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform",
            "value": "Main GITHUB repo"
          },
          {
            "_href": "https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform/wiki",
            "value": "WiKi page"
          },
          {
            "_href": "https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform/wiki/Sensor-Page",
            "value": "Sensors beng used"
          },
          {
            "_href": "https://github.com/SamsungResearchUK-IoT-Meetup/multimode_sensor_platform/wiki/Augmented-Reality",
            "value": "Augmented Reality page"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/9561.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10465",
        "start": "16:00",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iottinygo",
        "title": "TinyGo: Fast, Small, Concurrent: Choose Three",
        "subtitle": "TinyGo on microcontrollers",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>This talk will show using live demos why TinyGo (http://tinygo.org) the Go compiler for \"small places\" is a excellent choice for next generation IoT and embedded devices.<\/p>",
        "description": "<p>This talk will show using live demos why TinyGo (http://tinygo.org) the Go compiler for \"small places\" is a excellent choice for next generation IoT and embedded devices.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "4480",
            "value": "Ron Evans"
          }
        },
        "links":
        [
          {
            "_href": "https://tinygo.org",
            "value": "TinyGo"
          },
          {
            "_href": "https://submission.fosdem.org/feedback/10465.php",
            "value": "Submit feedback"
          }
        ]
      },
      {
        "_id": "10573",
        "start": "16:30",
        "duration": "00:30",
        "room": "UD2.218A",
        "slug": "iottarantool",
        "title": "Tarantool Cartridge: Framework for Distributed Apps",
        "subtitle": "Tarantool Cartridge: Framework for Distributed Apps",
        "track": "Internet of Things",
        "type": "devroom",
        "language": [],
        "abstract": "<p>We will have to talk about Tarantool Cartridge: it's framework for creating distributed applications. The application will be based on Tarantool – blazing fast in-memory database and Lua application server in one.\nInstances interconnect with each other by SWIM protocol – UDP Gossip protocol. We believe that our platform can bring brand new opportunities for the IoT world: we have the aggregated solution for many potential cases in IoT.<\/p>",
        "description": "<p>We will have to talk about Tarantool Cartridge: it's framework for creating distributed applications. The application will be based on Tarantool – blazing fast in-memory database and Lua application server in one.\nInstances interconnect with each other by SWIM protocol – UDP Gossip protocol. We believe that our platform can bring brand new opportunities for the IoT world: we have the aggregated solution for many potential cases in IoT.<\/p>",
        "persons":
        {
          "person":
          {
            "_id": "7313",
            "value": "Artur Barsegyan"
          }
        },
        "links":
        {
          "link":
          {
            "_href": "https://submission.fosdem.org/feedback/10573.php",
            "value": "Submit feedback"
          }
        }
      }
    ]
  },
  {
    "_name": "UD2.Corridor",
    "event":
    {
      "_id": "10764",
      "start": "14:00",
      "duration": "02:00",
      "room": "UD2.Corridor",
      "slug": "keysigning",
      "title": "PGP Keysigning",
      "subtitle": [],
      "track": "Keysigning",
      "type": "keysigning",
      "language": [],
      "abstract": "<p>The FOSDEM 2020 PGP Keysigning<\/p>",
      "description": "<p>The keysigning event takes place in the corridor on the second level of the U building. There is no fixed end time. Previous editions last for approximately one hour per 100 keys on the list. You must register before the conference to take part. Please bring the printed list, a pen and appropriate form of identification with you the event.<\/p>\n\n<p>Please note that you must register your key at least a week in advance of the conference.<\/p>",
      "persons":
      {
        "person":
        {
          "_id": "6",
          "value": "FOSDEM Staff"
        }
      },
      "links":
      [
        {
          "_href": "https://fosdem.org/2020/keysigning/",
          "value": "Instructions"
        },
        {
          "_href": "https://submission.fosdem.org/feedback/10764.php",
          "value": "Submit feedback"
        }
      ]
    }
  }
]