{
  "start": 1577900700000,
  "duration": 40,
  "room": "K.4.201",
  "title": "HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems",
  "subtitle": "",
  "track": "LLVM",
  "abstract": "TITLE: HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems\n\nSPEAKER: Vikram Adve, University of Illinois at Urbana-Champaign\n\nAbstract:\n\nWe will present a detailed description of HPVM, an extension to LLVM for\ncompiling to heterogeneous parallel systems.  HPVM aims to make it much\neasier to develop compilers for diverse parallel hardware, and to implement\nparallel languages (including domain-specific languages) for such hardware.\nWe will briefly describe at a high-level the key parallel abstraction of\nhierarchical dataflow graphs used in HPVM, and then focus on on how HPVM is\nintegrated on top of LLVM.  A second part of the talk will briefly describe\nhow we are extending HPVM to enable greater energy efficiency and\nperformance by taking advantage of approximation opportunities in\napplication domains such as machine learning and image processing.  To\nconclude, I will briefly discuss how HPVM might be added as a dialect in\nMLIR so that other MLIR dialects and MLIR-based compilers can use HPVM for\ncode generation to diverse heterogeneous hardware targets, including GPUs,\nFPGAs, and custom accelerators.",
  "description": "TITLE: HPVM: Extending LLVM For Compiling to Heterogeneous Parallel Systems\n\nSPEAKER: Vikram Adve, University of Illinois at Urbana-Champaign\n\nBackground\n\nLLVM has been extraordinarily successful as a compiler infrastructure for\nenabling a wide range of compilers and compiler-based tools for scalar and\nvector processors, and for supporting GPU compilers for OpenCL and CUDA.\nLLVM has seen only limited use, however, for other classes of target\narchitectures, such as reconfigurable hardware (FPGAs) and domain-specific\naccelerators such as for machine learning, image processing, signal\nprocessing, graph processing, and other emerging domains.  More generally,\nheterogeneous system-on-chip (SoC) architectures are becoming increasingly\nimportant, especially in \"edge computing,\" but LLVM has largely been\nlimited to the host CPU and GPU on such SoCs, even though the number of\nother programmable components on these systems has been steadily increasing.\n\nOverview\n\nIn this talk, I will describe an extension of LLVM for developing a compiler\ninfrastructure -- Heterogeneous Parallel Virtual Machine, or HPVM -- for\nheterogeneous parallel systems [1].  I will briefly describe at a high-level\nthe key parallel abstraction of hierarchical dataflow graphs used in HPVM to\ndescribe heterogeneous parallelism, where ordinary LLVM code is used to\nrepresent the computatational tasks.  The main focus of this part of the\ntalk is how HPVM is integrated on top of LLVM.  First, HPVM has been\nimplemented as a set of intrinsic functions that extend the LLVM\ninfrastructure.  Second, the HPVM code generation framework reuses existing\nLLVM (and other) back-ends, in order to leverage existing (often well-tuned)\ncode generators for individual programmable hardware elements, such as NVPTX\nfor NVIDIA GPUs, Intel's SPIR-V code generator for Intel SSE and AVX vector\nhardware, and Altera's AOCL compiler for targeting Altera's FPGAs.\n\nA second part of the talk will briefly describe how we are extending\nHPVM to enable greater energy efficiency and performance by taking\nadvantage of approximation opportunities in application domains such\nas machine learning and image processing.  In particular, we are\ncurrently developing ApproxHPVM, an extension of HPVM that supports a\nrange of algorithmic and hardware-level approximation mechanisms [2].\nMoreover, ApproxHPVM only requires application programmers to specify\nhigh-level, \"end-to-end\" design goals such as the maximum allowable\naccuracy loss in a neural network or loss of image quality (e.g.,\nPSNR) and the system automatically selects, optimizes and maps\napproximation choices for individual coarse-grain tensor operations in\nthe application.  The goal is to make sophisticated and well-tested\napproximation techniques widely accessible to application developers.\n\nTo conclude, I will briefly discuss how HPVM and ApproxHPVM might be added\nas a dialect in MLIR so that other MLIR dialects and MLIR-based compilers\ncan use HPVM for diverse heterogeneous hardware targets, including GPUs,\nFPGAs, and custom accelerators.\n\nTarget Audience\n\nThe intended target audience for this talk falls into broadly two classes.\nThe first includes compiler practitioners and researchers interested in\ncompiling to heterogeneous systems, such as SoCs, FPGAs, and other\n\"edge-compute\" hardware.  The second includes language implementers\ninterested in implementing or porting domain-specific languages such as\nTensorFlow, Halide, SPIRAL, and others to heterogeneous parallel systems.\n\nTakeaways\n\nWe envision several takeaways for the audience: (1) Understand how to\ndevelop an extension of LLVM that makes it easier to target emerging\nhardware platforms not sufficiently well-supported by the existing LLVM IR\nand code generation framework. (2) Expose attendees to the opportunities and\nchallenges in supporting and reasoning about approximate computations in a\ncompiler framework. (3) Discuss the opportunities and limitations of using\nHPVM for supporting heterogeneous parallel systems in the context of MLIR.\n\nWeb Site and Software Availability\n\nMore information about HPVM is available at http://hpvm.cs.illinois.edu/.\nThe HPVM infrastructure is implemented as an extension to LLVM.  To date,\nthe software is being developed using an internal Git repository at Illinois\nand has been shared with collaborators at IBM and at Harvard University.\nWe will make it available publicly in open-source form on Github before the\nFOSDEM conference.\n\nREFERENCES\n\n[1] Maria Kotsifakou, Prakalp Srivastava, Matthew D. Sinclair,\nRakesh Komuravelli, Vikram S. Adve and Sarita V. Adve, \u201cHPVM:\nHeterogeneous Parallel Virtual Machine.\u201d Proceedings of Principles and\nPractice of Parallel Programming (PPoPP), Feb 2018, V\u00f6sendorf / Wien,\nAustria.\n\n[2] Hashim Sharif, Prakalp Srivastava, Mohammed Huzaifa, Maria\nKotsifakou, Yasmin Sarita, Nathan Zhou, Keyur Joshi, Vikram S. Adve,\nSasa Misailovic and Sarita V. Adve, \u201cApproxHPVM: A Portable Compiler\nIR for Accuracy-aware Optimizations,\u201d OOPSLA 2019, October 2019,\nAthens, Greece.",
  "persons": [
    "Vikram Adve"
  ]
}